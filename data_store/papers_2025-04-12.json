{
  "Brain": {
    "2504.07913v1": {
      "title": "Optimal Control For Anti-Abeta Treatment in Alzheimer's Disease using a Reaction-Diffusion Model",
      "url": "http://arxiv.org/abs/2504.07913v1",
      "authors": "Wenrui Hao, Chiu-Yen Kao, Sun Lee, Zhiyuan Li",
      "update_time": "2025-04-10",
      "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that significantly impairs patient survival and quality of life. While current pharmacological treatments aim to slow disease progression, they remain insufficient in halting cognitive decline. Mathematical modeling has emerged as a powerful tool for understanding the dynamics of AD and optimizing treatment strategies. However, most existing models focus on temporal dynamics using ordinary differential equation-based approaches, often neglecting the critical role of spatial heterogeneity in disease progression.   In this study, we employ a spatially explicit reaction-diffusion model to describe amyloid-beta (A beta) dynamics in the brain, incorporating treatment optimization while accounting for potential side effects. Our objective is to minimize amyloid-beta plaque concentration while balancing therapeutic efficacy against adverse effects, such as amyloid-related imaging abnormalities (ARIA). Under specific assumptions, we establish the well-posedness and uniqueness of the optimal solution. We employ numerical methods based on the Finite Element Method to compute personalized treatment strategies, leveraging real patient amyloid-beta positron emission tomography (PET) scan data.   Our results demonstrate that optimal treatment strategies outperform constant dosing regimens, achieving significant reductions in amyloid burden while minimizing side effects. By integrating spatial dynamics and personalized treatment planning, our framework offers a novel approach to refining therapeutic interventions for Alzheimer's disease."
    },
    "2504.07721v1": {
      "title": "From empirical brain networks towards modeling music perception -- a perspective",
      "url": "http://arxiv.org/abs/2504.07721v1",
      "authors": "Jakub Sawicki",
      "update_time": "2025-04-10",
      "abstract": "This perspective article investigates how auditory stimuli influence neural network dynamics using the FitzHugh-Nagumo (FHN) model and empirical brain connectivity data. Results show that synchronization is sensitive to both the frequency and amplitude of auditory input, with synchronization enhanced when input frequencies align with the system's intrinsic frequencies. Increased stimulus amplitude broadens the synchronization range governed by a delicate interplay involving the network's topology, the spatial location of the input, and the frequency characteristics of the cortical input signals. This perspective article also reveals that brain activity alternates between synchronized and desynchronized states, reflecting critical dynamics and phase transitions in neural networks. Notably, gamma-band synchronization is crucial for processing music, with coherence peaking in this frequency range. The findings emphasize the role of structural connectivity and network topology in modulating synchronization, providing insights into how music perception engages brain networks. This perspective article offers a computational framework for understanding neural mechanisms in music perception, with potential implications for cognitive neuroscience and music psychology."
    },
    "2504.07695v1": {
      "title": "Learning Higher-Order Interactions in Brain Networks via Topological Signal Processing",
      "url": "http://arxiv.org/abs/2504.07695v1",
      "authors": "Breno C. Bispo, Stefania Sardellitti, Fernando A. N. Santos, Juliano B. Lima",
      "update_time": "2025-04-10",
      "abstract": "Our goal in this paper is to leverage the potential of the topological signal processing (TSP) framework for analyzing brain networks. Representing brain data as signals over simplicial complexes allows us to capture higher-order relationships within brain regions of interest (ROIs). Here, we focus on learning the underlying brain topology from observed neural signals using two distinct inference strategies. The first method relies on higher-order statistical metrics to infer multiway relationships among ROIs. The second method jointly learns the brain topology and sparse signal representations, of both the solenoidal and harmonic components of the signals, by minimizing the total variation along triangles and the data-fitting errors. Leveraging the properties of solenoidal and irrotational signals, and their physical interpretations, we extract functional connectivity features from brain topologies and uncover new insights into functional organization patterns. This allows us to associate brain functional connectivity (FC) patterns of conservative signals with well-known functional segregation and integration properties. Our findings align with recent neuroscience research, suggesting that our approach may offer a promising pathway for characterizing the higher-order brain functional connectivities."
    },
    "2504.07308v1": {
      "title": "MoEDiff-SR: Mixture of Experts-Guided Diffusion Model for Region-Adaptive MRI Super-Resolution",
      "url": "http://arxiv.org/abs/2504.07308v1",
      "authors": "Zhe Wang, Yuhua Ru, Aladine Chetouani, Fang Chen, Fabian Bauer, Liping Zhang, Didier Hans, Rachid Jennane, Mohamed Jarraya, Yung Hsin Chen",
      "update_time": "2025-04-09",
      "abstract": "Magnetic Resonance Imaging (MRI) at lower field strengths (e.g., 3T) suffers from limited spatial resolution, making it challenging to capture fine anatomical details essential for clinical diagnosis and neuroimaging research. To overcome this limitation, we propose MoEDiff-SR, a Mixture of Experts (MoE)-guided diffusion model for region-adaptive MRI Super-Resolution (SR). Unlike conventional diffusion-based SR models that apply a uniform denoising process across the entire image, MoEDiff-SR dynamically selects specialized denoising experts at a fine-grained token level, ensuring region-specific adaptation and enhanced SR performance. Specifically, our approach first employs a Transformer-based feature extractor to compute multi-scale patch embeddings, capturing both global structural information and local texture details. The extracted feature embeddings are then fed into an MoE gating network, which assigns adaptive weights to multiple diffusion-based denoisers, each specializing in different brain MRI characteristics, such as centrum semiovale, sulcal and gyral cortex, and grey-white matter junction. The final output is produced by aggregating the denoised results from these specialized experts according to dynamically assigned gating probabilities. Experimental results demonstrate that MoEDiff-SR outperforms existing state-of-the-art methods in terms of quantitative image quality metrics, perceptual fidelity, and computational efficiency. Difference maps from each expert further highlight their distinct specializations, confirming the effective region-specific denoising capability and the interpretability of expert contributions. Additionally, clinical evaluation validates its superior diagnostic capability in identifying subtle pathological features, emphasizing its practical relevance in clinical neuroimaging. Our code is available at https://github.com/ZWang78/MoEDiff-SR."
    },
    "2504.07279v1": {
      "title": "Search for Axion Dark Matter from 1.1 to 1.3 GHz with ADMX",
      "url": "http://arxiv.org/abs/2504.07279v1",
      "authors": "ADMX Collaboration, G. Carosi, C. Cisneros, N. Du, S. Durham, N. Robertson, C. Goodman, M. Guzzetti, C. Hanretty, K. Enzian, L. J Rosenberg, G. Rybka, J. Sinnis, D. Zhang, John Clarke, I. Siddiqi, A. S. Chou, M. Hollister, A. Sonnenschein, S. Knirck, T. J. Caligiure, J. R. Gleason, A. T. Hipp, P. Sikivie, M. E. Solano, N. S. Sullivan, D. B. Tanner, R. Khatiwada, L. D. Duffy, C. Boutan, T. Braine, E. Lentz, N. S. Oblath, M. S. Taubman, E. J. Daw, C. Mostyn, M. G. Perry, C. Bartram, J. Laurel, A. Yi, T. A. Dyson, S. Ruppert, M. O. Withers, C. L. Kuo, B. T. McAllister, J. H. Buckley, C. Gaikwad, J. Hoffman, K. Murch, M. Goryachev, E. Hartman, A. Quiskamp, M. E. Tobar",
      "update_time": "2025-04-09",
      "abstract": "Axion dark matter can satisfy the conditions needed to account for all of the dark matter and solve the strong CP problem. The Axion Dark Matter eXperiment (ADMX) is a direct dark matter search using a haloscope to convert axions to photons in an external magnetic field. Key to this conversion is the use of a microwave resonator that enhances the sensitivity at the frequency of interest. The ADMX experiment boosts its sensitivity using a dilution refrigerator and near quantum-limited amplifier to reduce the noise level in the experimental apparatus. In the most recent run, ADMX searched for axions between 1.10-1.31 GHz to extended Kim-Shifman-Vainshtein-Zakharov (KSVZ) sensitivity. This Letter reports on the results of that run, as well as unique aspects of this experimental setup."
    },
    "2504.07058v1": {
      "title": "Physics informed neural network for forward and inverse modeling of low grade brain tumors",
      "url": "http://arxiv.org/abs/2504.07058v1",
      "authors": "K. Murari, P. Roul, S. Sundar",
      "update_time": "2025-04-09",
      "abstract": "A low grade tumor is a slow growing tumor with a lower likelihood of spreading compared to high grade tumors. Mathematical modeling using partial differential equations (PDEs) plays a crucial role in describing tumor behavior, growth and progression. This study employs the Burgess and extended Fisher Kolmogorov equations to model low-grade brain tumors. We utilize Physics Informed Neural Networks (PINNs) based algorithm to develop an automated numerical solver for these models and explore their application in solving forward and inverse problems in brain tumor modeling. The study aims to demonstrate that the PINN based algorithms serve as advanced methodologies for modeling brain tumor dynamics by integrating deep learning with physics-informed principles. Additionally, we establish generalized error bounds in terms of training and quadrature errors. The convergence and stability of the neural network are derived for both models. Numerical tests confirm the accuracy and efficiency of the algorithms in both linear and nonlinear cases. Additionally, a statistical analysis of the numerical results is presented."
    },
    "2504.06997v1": {
      "title": "Cerebral blood flow monitoring using a deep learning implementation of the two-layer DCS analytical model with a 512 512 SPAD array",
      "url": "http://arxiv.org/abs/2504.06997v1",
      "authors": "Mingliang Pan, Chenxu Li, Yuanzhe Zhang, Alan Mollins, Quan Wang, Ahmet T. Erdogan, Yuanyuan Hua, Zhenya Zang, Neil Finlayson, Robert K. Henderson, David Day-Uei Li",
      "update_time": "2025-04-09",
      "abstract": "Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function of photons scattered by red blood cells, enabling non-invasive, continuous measurement of deep tissue blood flow at the bedside. Multi-layer DCS models (two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and mitigate interference from extracerebral tissues. However, these models require multiple predefined parameters and are computationally intensive, making them impractical for real-time bedside monitoring. To address this challenge, we integrate a single-photon avalanche diode (SPAD) array with a deep learning (DL)-based approach trained on data generated by the two-layer analytical model. This method bypasses traditional model fitting, enabling real-time CBFi monitoring while minimizing superficial tissue contamination. We first validate our approach using Monte Carlo-simulated test datasets, demonstrating superior accuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional fitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our method effectively isolates shallow blood flow changes and 750-fold faster than single-exponential fitting in a realistic scenario. We further evaluate the system in a healthy adult, achieving real-time CBFi monitoring and pulsatile waveform recovery during a brain activity test using a 512 512 SPAD array sensor. These results highlight the potential of our approach for real-time brain activity monitoring."
    },
    "2504.06996v1": {
      "title": "Neural Signal Compression using RAMAN tinyML Accelerator for BCI Applications",
      "url": "http://arxiv.org/abs/2504.06996v1",
      "authors": "Adithya Krishna, Sohan Debnath, Andr\u00e9 van Schaik, Mahesh Mehendale, Chetan Singh Thakur",
      "update_time": "2025-04-09",
      "abstract": "High-quality, multi-channel neural recording is indispensable for neuroscience research and clinical applications. Large-scale brain recordings often produce vast amounts of data that must be wirelessly transmitted for subsequent offline analysis and decoding, especially in brain-computer interfaces (BCIs) utilizing high-density intracortical recordings with hundreds or thousands of electrodes. However, transmitting raw neural data presents significant challenges due to limited communication bandwidth and resultant excessive heating. To address this challenge, we propose a neural signal compression scheme utilizing Convolutional Autoencoders (CAEs), which achieves a compression ratio of up to 150 for compressing local field potentials (LFPs). The CAE encoder section is implemented on RAMAN, an energy-efficient tinyML accelerator designed for edge computing, and subsequently deployed on an Efinix Ti60 FPGA with 37.3k LUTs and 8.6k register utilization. RAMAN leverages sparsity in activation and weights through zero skipping, gating, and weight compression techniques. Additionally, we employ hardware-software co-optimization by pruning CAE encoder model parameters using a hardware-aware balanced stochastic pruning strategy, resolving workload imbalance issues and eliminating indexing overhead to reduce parameter storage requirements by up to 32.4%. Using the proposed compact depthwise separable convolutional autoencoder (DS-CAE) model, the compressed neural data from RAMAN is reconstructed offline with superior signal-to-noise and distortion ratios (SNDR) of 22.6 dB and 27.4 dB, along with R2 scores of 0.81 and 0.94, respectively, evaluated on two monkey neural recordings."
    },
    "2504.06908v1": {
      "title": "UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation",
      "url": "http://arxiv.org/abs/2504.06908v1",
      "authors": "Emmanuelle Bourigault, Amir Jamaludin, Abdullah Hamdi",
      "update_time": "2025-04-09",
      "abstract": "In medical imaging, the primary challenge is collecting large-scale labeled data due to privacy concerns, logistics, and high labeling costs. In this work, we present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset of body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D images) and more than 1.37 billion 2D segmentation masks of 72 organs, all based on the UK Biobank MRI dataset. We utilize automatic labeling, introduce an automated label cleaning pipeline with organ-specific filters, and manually annotate a subset of 300 MRIs with 11 abdominal classes to validate the quality (referred to as UKBOB-manual). This approach allows for scaling up the dataset collection while maintaining confidence in the labels. We further confirm the validity of the labels by demonstrating zero-shot generalization of trained models on the filtered UKBOB to other small labeled datasets from similar domains (e.g., abdominal MRI). To further mitigate the effect of noisy labels, we propose a novel method called Entropy Test-time Adaptation (ETTA) to refine the segmentation output. We use UKBOB to train a foundation model, Swin-BOB, for 3D medical image segmentation based on the Swin-UNetr architecture, achieving state-of-the-art results in several benchmarks in 3D medical imaging, including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the BTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained models and the code are available at https://emmanuelleb985.github.io/ukbob , and the filtered labels will be made available with the UK Biobank."
    },
    "2504.06836v1": {
      "title": "Determining Fetal Orientations From Blind Sweep Ultrasound Video",
      "url": "http://arxiv.org/abs/2504.06836v1",
      "authors": "Jakub Maciej Wi\u015bniewski, Anders Nymark Christensen, Mary Le Ngo, Martin Gr\u00f8nneb\u00e6k Tolsgaard, Chun Kit Wong",
      "update_time": "2025-04-09",
      "abstract": "Cognitive demands of fetal ultrasound examinations pose unique challenges among clinicians. With the goal of providing an assistive tool, we developed an automated pipeline for predicting fetal orientation from ultrasound videos acquired following a simple blind sweep protocol. Leveraging on a pre-trained head detection and segmentation model, this is achieved by first determining the fetal presentation (cephalic or breech) with a template matching approach, followed by the fetal lie (facing left or right) by analyzing the spatial distribution of segmented brain anatomies. Evaluation on a dataset of third-trimester ultrasound scans demonstrated the promising accuracy of our pipeline. This work distinguishes itself by introducing automated fetal lie prediction and by proposing an assistive paradigm that augments sonographer expertise rather than replacing it. Future research will focus on enhancing acquisition efficiency, and exploring real-time clinical integration to improve workflow and support for obstetric clinicians."
    }
  },
  "EEG": {
    "2504.07720v1": {
      "title": "Filtering through a topological lens: homology for point processes on the time-frequency plane",
      "url": "http://arxiv.org/abs/2504.07720v1",
      "authors": "Juan Manuel Miramont, Kin Aun Tan, Soumendu Sundar Mukherjee, R\u00e9mi Bardenet, Subhroshekhar Ghosh",
      "update_time": "2025-04-10",
      "abstract": "We introduce a very general approach to the analysis of signals from their noisy measurements from the perspective of Topological Data Analysis (TDA). While TDA has emerged as a powerful analytical tool for data with pronounced topological structures, here we demonstrate its applicability for general problems of signal processing, without any a-priori geometric feature. Our methods are well-suited to a wide array of time-dependent signals in different scientific domains, with acoustic signals being a particularly important application. We invoke time-frequency representations of such signals, focusing on their zeros which are gaining salience as a signal processing tool in view of their stability properties. Leveraging state-of-the-art topological concepts, such as stable and minimal volumes, we develop a complete suite of TDA-based methods to explore the delicate stochastic geometry of these zeros, capturing signals based on the disruption they cause to this rigid, hyperuniform spatial structure. Unlike classical spatial data tools, TDA is able to capture the full spectrum of the stochastic geometry of the zeros, thereby leading to powerful inferential outcomes that are underpinned by a principled statistical foundation. This is reflected in the power and versatility of our applications, which include competitive performance in processing. a wide variety of audio signals (esp. in low SNR regimes), effective detection and reconstruction of gravitational wave signals (a reputed signal processing challenge with non-Gaussian noise), and medical time series data from EEGs, indicating a wide horizon for the approach and methods introduced in this paper."
    },
    "2504.04664v1": {
      "title": "Classification of ADHD and Healthy Children Using EEG Based Multi-Band Spatial Features Enhancement",
      "url": "http://arxiv.org/abs/2504.04664v1",
      "authors": "Md Bayazid Hossain, Md Anwarul Islam Himel, Md Abdur Rahim, Shabbir Mahmood, Abu Saleh Musa Miah, Jungpil Shin",
      "update_time": "2025-04-07",
      "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) is a common neurodevelopmental disorder in children, characterized by difficulties in attention, hyperactivity, and impulsivity. Early and accurate diagnosis of ADHD is critical for effective intervention and management. Electroencephalogram (EEG) signals have emerged as a non-invasive and efficient tool for ADHD detection due to their high temporal resolution and ability to capture neural dynamics. In this study, we propose a method for classifying ADHD and healthy children using EEG data from the benchmark dataset. There were 61 children with ADHD and 60 healthy children, both boys and girls, aged 7 to 12. The EEG signals, recorded from 19 channels, were processed to extract Power Spectral Density (PSD) and Spectral Entropy (SE) features across five frequency bands, resulting in a comprehensive 190-dimensional feature set. To evaluate the classification performance, a Support Vector Machine (SVM) with the RBF kernel demonstrated the best performance with a mean cross-validation accuracy of 99.2\\% and a standard deviation of 0.0079, indicating high robustness and precision. These results highlight the potential of spatial features in conjunction with machine learning for accurately classifying ADHD using EEG data. This work contributes to developing non-invasive, data-driven tools for early diagnosis and assessment of ADHD in children."
    },
    "2504.04329v1": {
      "title": "Modeling the Dynamics of Attentional Gamma Oscillations During the Encoding Process of Noise-Mixed Speech Signals",
      "url": "http://arxiv.org/abs/2504.04329v1",
      "authors": "Duoyu Feng, Jiajia Li, Ying Wu",
      "update_time": "2025-04-06",
      "abstract": "The brain's bottom-up loop for processing speech influx involves both the selective attention and the encoding of specific speech information. Previous human studies have found that such attention can be represented by the cortical gamma-rhythm oscillations. However, the underlying mechanisms remain unclear. To address this issue, this paper proposes a neural network model that incorporates speech signal input, the cochlea, the thalamus, and a balanced excitatory-inhibitory cortical neural network, with the aim of connecting real speech signals to brain cortical responses. Using this model, we explored neural oscillation patterns in response to mixed speech stimuli and background noise. The findings revealed that the peak of gamma oscillation decreased as the frequency of the pure-tone stimuli diminished. This suggests a strong correlation and coding role of gamma oscillation peaks in auditory attention. Similar results were confirmed by analyzing the rhythmic oscillations of EEG data in response to pure-tone signals. Further results indicated that dynamic gamma oscillations are involved in the encoding capacity of continuous speech input. The coding entropy of the dynamic series was found to be proportional to the complexity of the content. This suggests that gamma oscillations play multiple roles, not only in sustaining the bottom-up attentional state but also in potentially conveying specific information from external speech inputs. Finally, we found that enhancing the excitatory-inhibitory balance level properly could improve auditory attention. This finding provides a potential endogenous explanation for the dynamic switching process of brain attention in processing auditory signals."
    },
    "2504.03984v1": {
      "title": "Optimized Feature Selection and Neural Network-Based Classification of Motor Imagery Using EEG Signals",
      "url": "http://arxiv.org/abs/2504.03984v1",
      "authors": "Muhammad Sudipto Siam Dip, Mohammod Abdul Motin, Md. Anik Hasan, Sumaiya Kabir",
      "update_time": "2025-04-04",
      "abstract": "Objective: Machine learning- and deep learning-based models have recently been employed in motor imagery intention classification from electroencephalogram (EEG) signals. Nevertheless, there is a limited understanding of feature selection to assist in identifying the most significant features in different spatial locations. Methods: This study proposes a feature selection technique using sequential forward feature selection with support vector machines and feeding the selected features to deep neural networks to classify motor imagery intention using multi-channel EEG. Results: The proposed model was evaluated with a publicly available dataset and achieved an average accuracy of 79.70 percent with a standard deviation of 7.98 percent for classifying two motor imagery scenarios. Conclusions: These results demonstrate that our method effectively identifies the most informative and discriminative characteristics of neural activity at different spatial locations, offering potential for future prosthetics and brain-computer interface applications. Significance: This approach enhances model performance while identifying key spatial EEG features, advancing brain-computer interfaces and prosthetic systems."
    },
    "2504.02976v1": {
      "title": "Localized Definitions and Distributed Reasoning: A Proof-of-Concept Mechanistic Interpretability Study via Activation Patching",
      "url": "http://arxiv.org/abs/2504.02976v1",
      "authors": "Nooshin Bahador",
      "update_time": "2025-04-03",
      "abstract": "This study investigates the localization of knowledge representation in fine-tuned GPT-2 models using Causal Layer Attribution via Activation Patching (CLAP), a method that identifies critical neural layers responsible for correct answer generation. The model was fine-tuned on 9,958 PubMed abstracts (epilepsy: 20,595 mentions, EEG: 11,674 mentions, seizure: 13,921 mentions) using two configurations with validation loss monitoring for early stopping. CLAP involved (1) caching clean (correct answer) and corrupted (incorrect answer) activations, (2) computing logit difference to quantify model preference, and (3) patching corrupted activations with clean ones to assess recovery. Results revealed three findings: First, patching the first feedforward layer recovered 56% of correct preference, demonstrating that associative knowledge is distributed across multiple layers. Second, patching the final output layer completely restored accuracy (100% recovery), indicating that definitional knowledge is localised. The stronger clean logit difference for definitional questions further supports this localized representation. Third, minimal recovery from convolutional layer patching (13.6%) suggests low-level features contribute marginally to high-level reasoning. Statistical analysis confirmed significant layer-specific effects (p<0.01). These findings demonstrate that factual knowledge is more localized and associative knowledge depends on distributed representations. We also showed that editing efficacy depends on task type. Our findings not only reconcile conflicting observations about localization in model editing but also emphasize on using task-adaptive techniques for reliable, interpretable updates.",
      "code_url": "https://github.com/nbahador/-fine_tuned_gpt2_model_on_epilepsy_related_pubmed_abstracts"
    },
    "2504.01887v2": {
      "title": "Dual mechanism of Anti-Seizure Medications in controlling seizure activity",
      "url": "http://arxiv.org/abs/2504.01887v2",
      "authors": "Guillermo M. Besne, Emmanuel Molefi, Sarah J. Gascoigne, Nathan Evans, Billy Smith, Chris Thornton, Fahmida A. Chowdhury, Beate Diehl, John S. Duncan, Andrew W. McEvoy, Anna Miserocchi, Jane de Tisi, Matthew Walker, Peter N. Taylor, Yujiang Wang",
      "update_time": "2025-04-05",
      "abstract": "Background: Anti-seizure medications (ASMs) can reduce seizure duration, but their precise modes of action are unclear. Specifically, it is unknown whether ASMs shorten seizures by simply compressing existing seizure activity into a shorter time frame or by selectively suppressing certain seizure activity patterns.   Methods: We analysed intracranial EEG (iEEG) recordings of 457 seizures from 28 people with epilepsy undergoing ASM tapering. Beyond measuring seizure occurrence and duration, we categorized distinct seizure activity patterns (states) based on spatial and frequency power characteristics and related these to different ASM levels.   Results: We found that reducing ASM levels led to increased seizure frequency (r = 0.87, p < 0.001) and longer seizure duration ($\\beta$ = -0.033, p < 0.001), consistent with prior research. Further analysis revealed two distinct mechanisms in which seizures became prolonged:   Emergence of new seizure patterns - In approx. 40% of patients, ASM tapering unmasked additional seizure activity states, and seizures containing these 'taper-emergent states' were substantially longer (r = 0.49, p < 0.001).   Prolongation of existing seizure patterns - Even in seizures without taper-emergent states, lower ASM levels still resulted in approx. 12-224% longer durations depending on the ASM dosage and tapering ($\\beta$ = -0.049, p < 0.001).   Conclusion: ASMs influence seizures through two mechanisms: they (i) suppress specific seizure activity patterns (states) in an all-or-nothing fashion and (ii) curtail the duration of other seizure patterns. These findings highlight the complex role of ASMs in seizure modulation and could inform personalized dosing strategies for epilepsy management. These findings may also have implications in understanding the effects of ASMs on cognition and mood.",
      "code_url": "https://github.com/cnnp-lab/2025_asm-szstate_gmb"
    },
    "2504.03762v1": {
      "title": "Decoding Covert Speech from EEG Using a Functional Areas Spatio-Temporal Transformer",
      "url": "http://arxiv.org/abs/2504.03762v1",
      "authors": "Muyun Jiang, Yi Ding, Wei Zhang, Kok Ann Colin Teo, LaiGuan Fong, Shuailei Zhang, Zhiwei Guo, Chenyu Liu, Raghavan Bhuvanakantham, Wei Khang Jeremy Sim, Chuan Huat Vince Foo, Rong Hui Jonathan Chua, Parasuraman Padmanabhan, Victoria Leong, Jia Lu, Balazs Gulyas, Cuntai Guan",
      "update_time": "2025-04-02",
      "abstract": "Covert speech involves imagining speaking without audible sound or any movements. Decoding covert speech from electroencephalogram (EEG) is challenging due to a limited understanding of neural pronunciation mapping and the low signal-to-noise ratio of the signal. In this study, we developed a large-scale multi-utterance speech EEG dataset from 57 right-handed native English-speaking subjects, each performing covert and overt speech tasks by repeating the same word in five utterances within a ten-second duration. Given the spatio-temporal nature of the neural activation process during speech pronunciation, we developed a Functional Areas Spatio-temporal Transformer (FAST), an effective framework for converting EEG signals into tokens and utilizing transformer architecture for sequence encoding. Our results reveal distinct and interpretable speech neural features by the visualization of FAST-generated activation maps across frontal and temporal brain regions with each word being covertly spoken, providing new insights into the discriminative features of the neural representation of covert speech. This is the first report of such a study, which provides interpretable evidence for speech decoding from EEG. The code for this work has been made public at https://github.com/Jiang-Muyun/FAST"
    },
    "2504.03761v1": {
      "title": "Augmentation of EEG and ECG Time Series for Deep Learning Applications: Integrating Changepoint Detection into the iAAFT Surrogates",
      "url": "http://arxiv.org/abs/2504.03761v1",
      "authors": "Nina Moutonnet, Gregory Scott, Danilo P. Mandic",
      "update_time": "2025-04-02",
      "abstract": "The performance of deep learning methods critically depends on the quality and quantity of the available training data. This is especially the case for physiological time series, which are both noisy and scarce, which calls for data augmentation to artificially increase the size of datasets. Another issue is that the time-evolving statistical properties of nonstationary signals prevent the use of standard data augmentation techniques. To this end, we introduce a novel method for augmenting nonstationary time series. This is achieved by combining offline changepoint detection with the iterative amplitude-adjusted Fourier transform (iAAFT), which ensures that the time-frequency properties of the original signal are preserved during augmentation. The proposed method is validated through comparisons of the performance of i) a deep learning seizure detection algorithm on both the original and augmented versions of the CHB-MIT and Siena scalp electroencephalography (EEG) databases, and ii) a deep learning atrial fibrillation (AF) detection algorithm on the original and augmented versions of the Computing in Cardiology Challenge 2017 dataset. By virtue of the proposed method, for the CHB-MIT and Siena datasets respectively, accuracy rose by 4.4% and 1.9%, precision by 10% and 5.5%, recall by 3.6% and 0.9%, and F1 by 4.2% and 1.4%. For the AF classification task, accuracy rose by 0.3%, precision by 2.1%, recall by 0.8%, and F1 by 2.1%."
    },
    "2504.03760v1": {
      "title": "EEG-EyeTrack: A Benchmark for Time Series and Functional Data Analysis with Open Challenges and Baselines",
      "url": "http://arxiv.org/abs/2504.03760v1",
      "authors": "Tiago Vasconcelos Afonso, Florian Heinrichs",
      "update_time": "2025-04-02",
      "abstract": "A new benchmark dataset for functional data analysis (FDA) is presented, focusing on the reconstruction of eye movements from EEG data. The contribution is twofold: first, open challenges and evaluation metrics tailored to FDA applications are proposed. Second, functional neural networks are used to establish baseline results for the primary regression task of reconstructing eye movements from EEG signals. Baseline results are reported for the new dataset, based on consumer-grade hardware, and the EEGEyeNet dataset, based on research-grade hardware."
    },
    "2504.03757v1": {
      "title": "EEG2GAIT: A Hierarchical Graph Convolutional Network for EEG-based Gait Decoding",
      "url": "http://arxiv.org/abs/2504.03757v1",
      "authors": "Xi Fu, Rui Liu, Aung Aung Phyo Wai, Hannah Pulferer, Neethu Robinson, Gernot R M\u00fcller-Putz, Cuntai Guan",
      "update_time": "2025-04-02",
      "abstract": "Decoding gait dynamics from EEG signals presents significant challenges due to the complex spatial dependencies of motor processes, the need for accurate temporal and spectral feature extraction, and the scarcity of high-quality gait EEG datasets. To address these issues, we propose EEG2GAIT, a novel hierarchical graph-based model that captures multi-level spatial embeddings of EEG channels using a Hierarchical Graph Convolutional Network (GCN) Pyramid. To further improve decoding accuracy, we introduce a Hybrid Temporal-Spectral Reward (HTSR) loss function, which combines time-domain, frequency-domain, and reward-based loss components. Moreover, we contribute a new Gait-EEG Dataset (GED), consisting of synchronized EEG and lower-limb joint angle data collected from 50 participants over two lab visits. Validation experiments on both the GED and the publicly available Mobile Brain-body imaging (MoBI) dataset demonstrate that EEG2GAIT outperforms state-of-the-art methods and achieves the best joint angle prediction. Ablation studies validate the contributions of the hierarchical GCN modules and HTSR Loss, while saliency maps reveal the significance of motor-related brain regions in decoding tasks. These findings underscore EEG2GAIT's potential for advancing brain-computer interface applications, particularly in lower-limb rehabilitation and assistive technologies."
    }
  },
  "BCI": {
    "2504.06996v1": {
      "title": "Neural Signal Compression using RAMAN tinyML Accelerator for BCI Applications",
      "url": "http://arxiv.org/abs/2504.06996v1",
      "authors": "Adithya Krishna, Sohan Debnath, Andr\u00e9 van Schaik, Mahesh Mehendale, Chetan Singh Thakur",
      "update_time": "2025-04-09",
      "abstract": "High-quality, multi-channel neural recording is indispensable for neuroscience research and clinical applications. Large-scale brain recordings often produce vast amounts of data that must be wirelessly transmitted for subsequent offline analysis and decoding, especially in brain-computer interfaces (BCIs) utilizing high-density intracortical recordings with hundreds or thousands of electrodes. However, transmitting raw neural data presents significant challenges due to limited communication bandwidth and resultant excessive heating. To address this challenge, we propose a neural signal compression scheme utilizing Convolutional Autoencoders (CAEs), which achieves a compression ratio of up to 150 for compressing local field potentials (LFPs). The CAE encoder section is implemented on RAMAN, an energy-efficient tinyML accelerator designed for edge computing, and subsequently deployed on an Efinix Ti60 FPGA with 37.3k LUTs and 8.6k register utilization. RAMAN leverages sparsity in activation and weights through zero skipping, gating, and weight compression techniques. Additionally, we employ hardware-software co-optimization by pruning CAE encoder model parameters using a hardware-aware balanced stochastic pruning strategy, resolving workload imbalance issues and eliminating indexing overhead to reduce parameter storage requirements by up to 32.4%. Using the proposed compact depthwise separable convolutional autoencoder (DS-CAE) model, the compressed neural data from RAMAN is reconstructed offline with superior signal-to-noise and distortion ratios (SNDR) of 22.6 dB and 27.4 dB, along with R2 scores of 0.81 and 0.94, respectively, evaluated on two monkey neural recordings."
    },
    "2504.00490v1": {
      "title": "SCFANet: Style Distribution Constraint Feature Alignment Network For Pathological Staining Translation",
      "url": "http://arxiv.org/abs/2504.00490v1",
      "authors": "Zetong Chen, Yuzhuo Chen, Hai Zhong, Xu Qiao",
      "update_time": "2025-04-01",
      "abstract": "Immunohistochemical (IHC) staining serves as a valuable technique for detecting specific antigens or proteins through antibody-mediated visualization. However, the IHC staining process is both time-consuming and costly. To address these limitations, the application of deep learning models for direct translation of cost-effective Hematoxylin and Eosin (H&E) stained images into IHC stained images has emerged as an efficient solution. Nevertheless, the conversion from H&E to IHC images presents significant challenges, primarily due to alignment discrepancies between image pairs and the inherent diversity in IHC staining style patterns. To overcome these challenges, we propose the Style Distribution Constraint Feature Alignment Network (SCFANet), which incorporates two innovative modules: the Style Distribution Constrainer (SDC) and Feature Alignment Learning (FAL). The SDC ensures consistency between the generated and target images' style distributions while integrating cycle consistency loss to maintain structural consistency. To mitigate the complexity of direct image-to-image translation, the FAL module decomposes the end-to-end translation task into two subtasks: image reconstruction and feature alignment. Furthermore, we ensure pathological consistency between generated and target images by maintaining pathological pattern consistency and Optical Density (OD) uniformity. Extensive experiments conducted on the Breast Cancer Immunohistochemical (BCI) dataset demonstrate that our SCFANet model outperforms existing methods, achieving precise transformation of H&E-stained images into their IHC-stained counterparts. The proposed approach not only addresses the technical challenges in H&E to IHC image translation but also provides a robust framework for accurate and efficient stain conversion in pathological analysis."
    },
    "2504.03707v1": {
      "title": "Towards Practical Emotion Recognition: An Unsupervised Source-Free Approach for EEG Domain Adaptation",
      "url": "http://arxiv.org/abs/2504.03707v1",
      "authors": "Md Niaz Imtiaz, Naimul Khan",
      "update_time": "2025-03-26",
      "abstract": "Emotion recognition is crucial for advancing mental health, healthcare, and technologies like brain-computer interfaces (BCIs). However, EEG-based emotion recognition models face challenges in cross-domain applications due to the high cost of labeled data and variations in EEG signals from individual differences and recording conditions. Unsupervised domain adaptation methods typically require access to source domain data, which may not always be feasible in real-world scenarios due to privacy and computational constraints. Source-free unsupervised domain adaptation (SF-UDA) has recently emerged as a solution, enabling target domain adaptation without source data, but its application in emotion recognition remains unexplored. We propose a novel SF-UDA approach for EEG-based emotion classification across domains, introducing a multi-stage framework that enhances model adaptability without requiring source data. Our approach incorporates Dual-Loss Adaptive Regularization (DLAR) to minimize prediction discrepancies on confident samples and align predictions with expected pseudo-labels. Additionally, we introduce Localized Consistency Learning (LCL), which enforces local consistency by promoting similar predictions from reliable neighbors. These techniques together address domain shift and reduce the impact of noisy pseudo-labels, a key challenge in traditional SF-UDA models. Experiments on two widely used datasets, DEAP and SEED, demonstrate the effectiveness of our method. Our approach significantly outperforms state-of-the-art methods, achieving 65.84% accuracy when trained on DEAP and tested on SEED, and 58.99% accuracy in the reverse scenario. It excels at detecting both positive and negative emotions, making it well-suited for practical emotion recognition applications."
    },
    "2503.12705v1": {
      "title": "A Brain-Computer Interface Data Persistence System for Multi-Scenario and Multi-Modal Data: NeuroStore",
      "url": "http://arxiv.org/abs/2503.12705v1",
      "authors": "Yang Chen, Hongxin Zhang, Guanyu Xiong, Chenxu Li, Chengcheng Hong, Chen Yang",
      "update_time": "2025-03-17",
      "abstract": "With the rapid advancement of brain-computer interface (BCI) technology, the volume of physiological data generated in related research and applications has grown significantly. Data is a critical resource in BCI research and a key factor in the development of BCI technology, making efficient storage and management of this data increasingly vital. In the realm of research, ample data can facilitate the development of novel algorithms, which can be more accurately validated. In terms of applications, well-organized data can foster the emergence of new business opportunities, thereby maximizing the commercial value of the data. Currently, there are two major challenges in the storage and management of BCI data: providing different classification storage modes for multi-modal data, and adapting to varying application scenarios while improving storage strategies. To address these challenges, this study has developed the NeuroStore BCI data persistence system, which provides a general and easily scalable data model and can effectively handle multiple types of data storage. The system has a flexible distributed framework and can be widely applied to various scenarios. It has been utilized as the core support platform for efficient data storage and management services in the \"BCI Controlled Robot Contest in World Robot Contest.\""
    },
    "2503.11202v1": {
      "title": "Decoding Imagined Handwriting from EEG",
      "url": "http://arxiv.org/abs/2503.11202v1",
      "authors": "Srinivas Ravishankar, Nora Zajzon, Virginia de Sa",
      "update_time": "2025-03-14",
      "abstract": "Patients with extreme forms of paralysis face challenges in communication, adversely impacting their quality of life. Recent studies have reported higher-than-chance performance in decoding handwritten letters from EEG signals, potentially allowing these subjects to communicate. However, all prior works have attempted to decode handwriting from EEG during actual motion. Furthermore, they assume that precise movement-onset is known. In this work, we focus on settings closer to real-world use where either movement onset is not known or movement does not occur at all, fully utilizing motor imagery. We show that several existing studies are affected by confounds that make them inapplicable to the imagined handwriting setting. We also investigate how sample complexity affects handwriting decoding performance, guiding future data collection efforts. Our work shows that (a) Sample complexity analysis in single-trial EEG reveals a noise ceiling, which can be alleviated by averaging over trials. (b) Knowledge of movement-onset is crucial to reported performance in prior works. (c) Fully imagined handwriting can be decoded from EEG with higher-than-chance performance. Taken together, these results highlight both the unique challenges and avenues to pursue to build a practical EEG-based handwriting BCI."
    },
    "2503.09961v1": {
      "title": "Edge-Fog Computing-Enabled EEG Data Compression via Asymmetrical Variational Discrete Cosine Transform Network",
      "url": "http://arxiv.org/abs/2503.09961v1",
      "authors": "Xin Zhu, Hongyi Pan, Ahmet Enis Cetin",
      "update_time": "2025-03-13",
      "abstract": "The large volume of electroencephalograph (EEG) data produced by brain-computer interface (BCI) systems presents challenges for rapid transmission over bandwidth-limited channels in Internet of Things (IoT) networks. To address the issue, we propose a novel multi-channel asymmetrical variational discrete cosine transform (DCT) network for EEG data compression within an edge-fog computing framework. At the edge level, low-complexity DCT compression units are designed using parallel trainable hard-thresholding and scaling operators to remove redundant data and extract the effective latent space representation. At the fog level, an adaptive filter bank is applied to merge important features from adjacent channels into each individual channel by leveraging inter-channel correlations. Then, the inverse DCT reconstructed multi-head attention is developed to capture both local and global dependencies and reconstruct the original signals. Furthermore, by applying the principles of variational inference, a new evidence lower bound is formulated as the loss function, driving the model to balance compression efficiency and reconstruction accuracy. Experimental results on two public datasets demonstrate that the proposed method achieves superior compression performance without sacrificing any useful information for BCI detection compared with state-of-the-art techniques, indicating a feasible solution for EEG data compression."
    },
    "2503.08284v1": {
      "title": "Neural cyberattacks applied to the vision under realistic visual stimuli",
      "url": "http://arxiv.org/abs/2503.08284v1",
      "authors": "Victoria Magdalena L\u00f3pez Madejska, Sergio L\u00f3pez Bernal, Gregorio Mart\u00ednez P\u00e9rez, Alberto Huertas Celdr\u00e1n",
      "update_time": "2025-03-11",
      "abstract": "Brain-Computer Interfaces (BCIs) are systems traditionally used in medicine and designed to interact with the brain to record or stimulate neurons. Despite their benefits, the literature has demonstrated that invasive BCIs focused on neurostimulation present vulnerabilities allowing attackers to gain control. In this context, neural cyberattacks emerged as threats able to disrupt spontaneous neural activity by performing neural overstimulation or inhibition. Previous work validated these attacks in small-scale simulations with a reduced number of neurons, lacking real-world complexity. Thus, this work tackles this limitation by analyzing the impact of two existing neural attacks, Neuronal Flooding (FLO) and Neuronal Jamming (JAM), on a complex neuronal topology of the primary visual cortex of mice consisting of approximately 230,000 neurons, tested on three realistic visual stimuli: flash effect, movie, and drifting gratings. Each attack was evaluated over three relevant events per stimulus, also testing the impact of attacking 25% and 50% of the neurons. The results, based on the number of spikes and shift percentages metrics, showed that the attacks caused the greatest impact on the movie, while dark and fixed events are the most robust. Although both attacks can significantly affect neural activity, JAM was generally more damaging, producing longer temporal delays, and had a larger prevalence. Finally, JAM did not require to alter many neurons to significantly affect neural activity, while the impact in FLO increased with the number of neurons attacked.",
      "code_url": "https://github.com/victorialm/neural-cyberattacks-complete-topology-v1"
    },
    "2503.05349v1": {
      "title": "Spatial Distillation based Distribution Alignment (SDDA) for Cross-Headset EEG Classification",
      "url": "http://arxiv.org/abs/2503.05349v1",
      "authors": "Dingkun Liu, Siyang Li, Ziwei Wang, Wei Li, Dongrui Wu",
      "update_time": "2025-03-07",
      "abstract": "A non-invasive brain-computer interface (BCI) enables direct interaction between the user and external devices, typically via electroencephalogram (EEG) signals. However, decoding EEG signals across different headsets remains a significant challenge due to differences in the number and locations of the electrodes. To address this challenge, we propose a spatial distillation based distribution alignment (SDDA) approach for heterogeneous cross-headset transfer in non-invasive BCIs. SDDA uses first spatial distillation to make use of the full set of electrodes, and then input/feature/output space distribution alignments to cope with the significant differences between the source and target domains. To our knowledge, this is the first work to use knowledge distillation in cross-headset transfers. Extensive experiments on six EEG datasets from two BCI paradigms demonstrated that SDDA achieved superior performance in both offline unsupervised domain adaptation and online supervised domain adaptation scenarios, consistently outperforming 10 classical and state-of-the-art transfer learning algorithms.",
      "code_url": "https://github.com/Dingkun0817/SDDA"
    },
    "2503.04163v1": {
      "title": "VLA Model-Expert Collaboration for Bi-directional Manipulation Learning",
      "url": "http://arxiv.org/abs/2503.04163v1",
      "authors": "Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duang, Si-Cheng Wang, Zheng Lei, Zeng-Guang Hou",
      "update_time": "2025-03-06",
      "abstract": "The emergence of vision-language-action (VLA) models has given rise to foundation models for robot manipulation. Although these models have achieved significant improvements, their generalization in multi-task manipulation remains limited. This study proposes a VLA model-expert collaboration framework that leverages a limited number of expert actions to enhance VLA model performance. This approach reduces expert workload relative to manual operation while simultaneously improving the reliability and generalization of VLA models. Furthermore, manipulation data collected during collaboration can further refine the VLA model, while human participants concurrently enhance their skills. This bi-directional learning loop boosts the overall performance of the collaboration system. Experimental results across various VLA models demonstrate the effectiveness of the proposed system in collaborative manipulation and learning, as evidenced by improved success rates across tasks. Additionally, validation using a brain-computer interface (BCI) indicates that the collaboration system enhances the efficiency of low-speed action systems by involving VLA model during manipulation. These promising results pave the way for advancing human-robot interaction in the era of foundation models for robotics. (Project website: https://aoqunjin.github.io/Expert-VLA/)"
    },
    "2503.16471v1": {
      "title": "A Review of Brain-Computer Interface Technologies: Signal Acquisition Methods and Interaction Paradigms",
      "url": "http://arxiv.org/abs/2503.16471v1",
      "authors": "Yifan Wang, Cheng Jiang, Chenzhong Li",
      "update_time": "2025-03-01",
      "abstract": "Brain-Computer Interface (BCI) technology facilitates direct communication between the human brain and external devices, representing a substantial advancement in human-machine interaction. This review provides an in-depth analysis of various BCI paradigms, including classic paradigms, current classifications, and hybrid paradigms, each with distinct characteristics and applications. Additionally, we explore a range of signal acquisition methods, classified into non-implantation, intervention, and implantation techniques, elaborating on their principles and recent advancements. By examining the interdependence between paradigms and signal acquisition technologies, this review offers a comprehensive perspective on how innovations in one domain propel progress in the other. The goal is to present insights into the future development of more efficient, user-friendly, and versatile BCI systems, emphasizing the synergy between paradigm design and signal acquisition techniques and their potential to transform the field."
    }
  },
  "fMRI": {
    "2504.01274v1": {
      "title": "BOLDSimNet: Examining Brain Network Similarity between Task and Resting-State fMRI",
      "url": "http://arxiv.org/abs/2504.01274v1",
      "authors": "Boseong Kim, Debashis Das Chakladar, Haejun Chung, Ikbeom Jang",
      "update_time": "2025-04-02",
      "abstract": "Traditional causal connectivity methods in task-based and resting-state functional magnetic resonance imaging (fMRI) face challenges in accurately capturing directed information flow due to their sensitivity to noise and inability to model multivariate dependencies. These limitations hinder the effective comparison of brain networks between cognitive states, making it difficult to analyze network reconfiguration during task and resting states. To address these issues, we propose BOLDSimNet, a novel framework utilizing Multivariate Transfer Entropy (MTE) to measure causal connectivity and network similarity across different cognitive states. Our method groups functionally similar regions of interest (ROIs) rather than spatially adjacent nodes, improving accuracy in network alignment. We applied BOLDSimNet to fMRI data from 40 healthy controls and found that children exhibited higher similarity scores between task and resting states compared to adolescents, indicating reduced variability in attention shifts. In contrast, adolescents showed more differences between task and resting states in the Dorsal Attention Network (DAN) and the Default Mode Network (DMN), reflecting enhanced network adaptability. These findings emphasize developmental variations in the reconfiguration of the causal brain network, showcasing BOLDSimNet's ability to quantify network similarity and identify attentional fluctuations between different cognitive states."
    },
    "2504.01004v1": {
      "title": "Enhancing 3T BOLD fMRI SNR using Unpaired 7T Data with Schr\u00f6dinger Bridge Diffusion",
      "url": "http://arxiv.org/abs/2504.01004v1",
      "authors": "Yujian Xiong, Xuanzhao Dong, Sebastian Waz, Wenhui Zhu, Negar Mallak, Zhong-lin Lu, Yalin Wang",
      "update_time": "2025-04-01",
      "abstract": "High spatial and temporal resolution, coupled with a strong signal-to-noise ratio (SNR), has made BOLD 7 Tesla fMRI an invaluable tool for understanding how the brain processes visual stimuli. However, the limited availability of 7T MRI systems means that most research relies on 3T MRI systems, which offer lower spatial and temporal resolution and SNR. This naturally raises the question: Can we enhance the spatiotemporal resolution and SNR of 3T BOLD fMRI data to approximate 7T quality? In this study, we propose a novel framework that aligns 7T and 3T fMRI data from different subjects and datasets in a shared parametric domain. We then apply an unpaired Brain Disk Schr\\\"odinger Bridge diffusion model to enhance the spatiotemporal resolution and SNR of the 3T data. Our approach addresses the challenge of limited 7T data by improving the 3T scan quality. We demonstrate its effectiveness by testing it on two distinct fMRI retinotopy datasets (one 7T and one 3T), as well as synthetic data. The results show that our method significantly improves the SNR and goodness-of-fit of the population receptive field (pRF) model in the enhanced 3T data, making it comparable to 7T quality. The codes will be available at Github."
    },
    "2504.00942v1": {
      "title": "Experiential Semantic Information and Brain Alignment: Are Multimodal Models Better than Language Models?",
      "url": "http://arxiv.org/abs/2504.00942v1",
      "authors": "Anna Bavaresco, Raquel Fern\u00e1ndez",
      "update_time": "2025-04-01",
      "abstract": "A common assumption in Computational Linguistics is that text representations learnt by multimodal models are richer and more human-like than those by language-only models, as they are grounded in images or audio -- similar to how human language is grounded in real-world experiences. However, empirical studies checking whether this is true are largely lacking. We address this gap by comparing word representations from contrastive multimodal models vs. language-only ones in the extent to which they capture experiential information -- as defined by an existing norm-based 'experiential model' -- and align with human fMRI responses. Our results indicate that, surprisingly, language-only models are superior to multimodal ones in both respects. Additionally, they learn more unique brain-relevant semantic information beyond that shared with the experiential model. Overall, our study highlights the need to develop computational models that better integrate the complementary semantic information provided by multimodal data sources."
    },
    "2504.00432v1": {
      "title": "DecoFuse: Decomposing and Fusing the \"What\", \"Where\", and \"How\" for Brain-Inspired fMRI-to-Video Decoding",
      "url": "http://arxiv.org/abs/2504.00432v1",
      "authors": "Chong Li, Jingyang Huo, Weikang Gong, Yanwei Fu, Xiangyang Xue, Jianfeng Feng",
      "update_time": "2025-04-01",
      "abstract": "Decoding visual experiences from brain activity is a significant challenge. Existing fMRI-to-video methods often focus on semantic content while overlooking spatial and motion information. However, these aspects are all essential and are processed through distinct pathways in the brain. Motivated by this, we propose DecoFuse, a novel brain-inspired framework for decoding videos from fMRI signals. It first decomposes the video into three components - semantic, spatial, and motion - then decodes each component separately before fusing them to reconstruct the video. This approach not only simplifies the complex task of video decoding by decomposing it into manageable sub-tasks, but also establishes a clearer connection between learned representations and their biological counterpart, as supported by ablation studies. Further, our experiments show significant improvements over previous state-of-the-art methods, achieving 82.4% accuracy for semantic classification, 70.6% accuracy in spatial consistency, a 0.212 cosine similarity for motion prediction, and 21.9% 50-way accuracy for video generation. Additionally, neural encoding analyses for semantic and spatial information align with the two-streams hypothesis, further validating the distinct roles of the ventral and dorsal pathways. Overall, DecoFuse provides a strong and biologically plausible framework for fMRI-to-video decoding. Project page: https://chongjg.github.io/DecoFuse/."
    },
    "2503.23653v2": {
      "title": "Scalable Geometric Learning with Correlation-Based Functional Brain Networks",
      "url": "http://arxiv.org/abs/2503.23653v2",
      "authors": "Kisung You, Yelim Lee, Hae-Jeong Park",
      "update_time": "2025-04-09",
      "abstract": "The correlation matrix is a central representation of functional brain networks in neuroimaging. Traditional analyses often treat pairwise interactions independently in a Euclidean setting, overlooking the intrinsic geometry of correlation matrices. While earlier attempts have embraced the quotient geometry of the correlation manifold, they remain limited by computational inefficiency and numerical instability, particularly in high-dimensional contexts. This paper presents a novel geometric framework that employs diffeomorphic transformations to embed correlation matrices into a Euclidean space, preserving salient manifold properties and enabling large-scale analyses. The proposed method integrates with established learning algorithms - regression, dimensionality reduction, and clustering - and extends naturally to population-level inference of brain networks. Simulation studies demonstrate both improved computational speed and enhanced accuracy compared to conventional manifold-based approaches. Moreover, applications in real neuroimaging scenarios illustrate the framework's utility, enhancing behavior score prediction, subject fingerprinting in resting-state fMRI, and hypothesis testing in electroencephalogram data. An open-source MATLAB toolbox is provided to facilitate broader adoption and advance the application of correlation geometry in functional brain network research.",
      "code_url": "https://github.com/kisungyou/CORRbox"
    },
    "2503.23394v1": {
      "title": "Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications",
      "url": "http://arxiv.org/abs/2503.23394v1",
      "authors": "Sangyoon Bae, Junbeom Kwon, Shinjae Yoo, Jiook Cha",
      "update_time": "2025-03-30",
      "abstract": "Understanding how the brain's complex nonlinear dynamics give rise to adaptive cognition and behavior is a central challenge in neuroscience. These dynamics exhibit scale-free and multifractal properties, influencing the reconfiguration of neural networks. However, conventional neuroimaging models are constrained by linear and stationary assumptions, limiting their ability to capture these processes. Transformer-based architectures, known for capturing long-range dependencies, align well with the brain's hierarchical and temporal organization. We introduce Multi-Band Brain Net (MBBN), a transformer-based framework that models frequency-specific spatiotemporal brain dynamics from fMRI by integrating scale-free network principles with frequency-resolved multi-band self-attention. Trained on three large-scale neuroimaging cohorts (UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previously undetectable frequency-dependent network interactions, shedding light on connectivity disruptions in psychiatric conditions (ADHD, ASD, depression). This validation shows robust generalizability and highlights core neural principles conserved across populations. MBBN achieves up to 30.59% higher predictive accuracy than state-of-the-art methods, demonstrating the advantage of frequency-informed spatiotemporal modeling in capturing latent neural computations. MBBN's interpretability uncovers novel frequency-specific biomarkers for neurodevelopmental disorders, providing insights into the hierarchical organization of brain function. By offering an interpretable framework for spatiotemporal learning, MBBN provides insights into how neural computations underpin cognitive function and psychiatric vulnerability, with implications for brain decoding, cognitive neuroscience, and precision psychiatry.",
      "code_url": "https://github.com/transconnectome/mbbn"
    },
    "2503.21964v1": {
      "title": "NeuroLIP: Interpretable and Fair Cross-Modal Alignment of fMRI and Phenotypic Text",
      "url": "http://arxiv.org/abs/2503.21964v1",
      "authors": "Yanting Yang, Xiaoxiao Li",
      "update_time": "2025-03-27",
      "abstract": "Integrating functional magnetic resonance imaging (fMRI) connectivity data with phenotypic textual descriptors (e.g., disease label, demographic data) holds significant potential to advance our understanding of neurological conditions. However, existing cross-modal alignment methods often lack interpretability and risk introducing biases by encoding sensitive attributes together with diagnostic-related features. In this work, we propose NeuroLIP, a novel cross-modal contrastive learning framework. We introduce text token-conditioned attention (TTCA) and cross-modal alignment via localized tokens (CALT) to the brain region-level embeddings with each disease-related phenotypic token. It improves interpretability via token-level attention maps, revealing brain region-disease associations. To mitigate bias, we propose a loss for sensitive attribute disentanglement that maximizes the attention distance between disease tokens and sensitive attribute tokens, reducing unintended correlations in downstream predictions. Additionally, we incorporate a negative gradient technique that reverses the sign of CALT loss on sensitive attributes, further discouraging the alignment of these features. Experiments on neuroimaging datasets (ABIDE and ADHD-200) demonstrate NeuroLIP's superiority in terms of fairness metrics while maintaining the overall best standard metric performance. Qualitative visualization of attention maps highlights neuroanatomical patterns aligned with diagnostic characteristics, validated by the neuroscientific literature. Our work advances the development of transparent and equitable neuroimaging AI."
    },
    "2503.21414v1": {
      "title": "Brain Age Group Classification Based on Resting State Functional Connectivity Metrics",
      "url": "http://arxiv.org/abs/2503.21414v1",
      "authors": "Prerna Singh, Kuldeep Singh Yadav, Lalan Kumar, Tapan Kumar Gandhi",
      "update_time": "2025-03-27",
      "abstract": "This study investigated age-related changes in functional connectivity using resting-state fMRI and explored the efficacy of traditional deep learning for classifying brain developmental stages (BDS). Functional connectivity was assessed using Seed-Based Phase Synchronization (SBPS) and Pearson correlation across 160 ROIs. Clustering was performed using t-SNE, and network topology was analyzed through graph-theoretic metrics. Adaptive learning was implemented to classify the age group by extracting bottleneck features through mobileNetV2. These deep features were embedded and classified using Random Forest and PCA. Results showed a shift in phase synchronization patterns from sensory-driven networks in youth to more distributed networks with aging. t-SNE revealed that SBPS provided the most distinct clustering of BDS. Global efficiency and participation coefficient followed an inverted U-shaped trajectory, while clustering coefficient and modularity exhibited a U-shaped pattern. MobileNet outperformed other models, achieving the highest classification accuracy for BDS. Aging was associated with reduced global integration and increased local connectivity, indicating functional network reorganization. While this study focused solely on functional connectivity from resting-state fMRI and a limited set of connectivity features, deep learning demonstrated superior classification performance, highlighting its potential for characterizing age-related brain changes."
    },
    "2503.18981v1": {
      "title": "FedSKD: Aggregation-free Model-heterogeneous Federated Learning using Multi-dimensional Similarity Knowledge Distillation",
      "url": "http://arxiv.org/abs/2503.18981v1",
      "authors": "Ziqiao Weng, Weidong Cai, Bo Zhou",
      "update_time": "2025-03-23",
      "abstract": "Federated learning (FL) enables privacy-preserving collaborative model training without direct data sharing. Model-heterogeneous FL (MHFL) extends this paradigm by allowing clients to train personalized models with heterogeneous architectures tailored to their computational resources and application-specific needs. However, existing MHFL methods predominantly rely on centralized aggregation, which introduces scalability and efficiency bottlenecks, or impose restrictions requiring partially identical model architectures across clients. While peer-to-peer (P2P) FL removes server dependence, it suffers from model drift and knowledge dilution, limiting its effectiveness in heterogeneous settings. To address these challenges, we propose FedSKD, a novel MHFL framework that facilitates direct knowledge exchange through round-robin model circulation, eliminating the need for centralized aggregation while allowing fully heterogeneous model architectures across clients. FedSKD's key innovation lies in multi-dimensional similarity knowledge distillation, which enables bidirectional cross-client knowledge transfer at batch, pixel/voxel, and region levels for heterogeneous models in FL. This approach mitigates catastrophic forgetting and model drift through progressive reinforcement and distribution alignment while preserving model heterogeneity. Extensive evaluations on fMRI-based autism spectrum disorder diagnosis and skin lesion classification demonstrate that FedSKD outperforms state-of-the-art heterogeneous and homogeneous FL baselines, achieving superior personalization (client-specific accuracy) and generalization (cross-institutional adaptability). These findings underscore FedSKD's potential as a scalable and robust solution for real-world medical federated learning applications."
    },
    "2503.15978v1": {
      "title": "A Survey on fMRI-based Brain Decoding for Reconstructing Multimodal Stimuli",
      "url": "http://arxiv.org/abs/2503.15978v1",
      "authors": "Pengyu Liu, Guohua Dong, Dan Guo, Kun Li, Fengling Li, Xun Yang, Meng Wang, Xiaomin Ying",
      "update_time": "2025-03-20",
      "abstract": "In daily life, we encounter diverse external stimuli, such as images, sounds, and videos. As research in multimodal stimuli and neuroscience advances, fMRI-based brain decoding has become a key tool for understanding brain perception and its complex cognitive processes. Decoding brain signals to reconstruct stimuli not only reveals intricate neural mechanisms but also drives progress in AI, disease treatment, and brain-computer interfaces. Recent advancements in neuroimaging and image generation models have significantly improved fMRI-based decoding. While fMRI offers high spatial resolution for precise brain activity mapping, its low temporal resolution and signal noise pose challenges. Meanwhile, techniques like GANs, VAEs, and Diffusion Models have enhanced reconstructed image quality, and multimodal pre-trained models have boosted cross-modal decoding tasks. This survey systematically reviews recent progress in fMRI-based brain decoding, focusing on stimulus reconstruction from passive brain signals. It summarizes datasets, relevant brain regions, and categorizes existing methods by model structure. Additionally, it evaluates model performance and discusses their effectiveness. Finally, it identifies key challenges and proposes future research directions, offering valuable insights for the field. For more information and resources related to this survey, visit https://github.com/LpyNow/BrainDecodingImage."
    }
  },
  "MEG": {
    "2503.16892v1": {
      "title": "Multifractal analysis based on the weak scaling exponent and applications to MEG recordings in neuroscience",
      "url": "http://arxiv.org/abs/2503.16892v1",
      "authors": "Patrice Abry, Phipippe Ciuciu, Merlin Dumeur, St\u00e9phane Jaffard, Guillaume Sa\u00ebs",
      "update_time": "2025-03-21",
      "abstract": "We develop the mathematical properties of a multifractal analysis of data based on the weak scaling exponent. The advantage of this analysis is that it does not require any a priori global regularity assumption on the analyzed signal, in contrast with the previously used H{\\\"o}lder or p-exponents. As an illustration, we show that this technique allows one to perform a multifractal analysis of MEG signals, which records electromagnetic brain activity, that was not theoretically valid using the formerly introduced methods based on H{\\\"o}lder or p-exponents."
    },
    "2503.10965v2": {
      "title": "Auditing language models for hidden objectives",
      "url": "http://arxiv.org/abs/2503.10965v2",
      "authors": "Samuel Marks, Johannes Treutlein, Trenton Bricken, Jack Lindsey, Jonathan Marcus, Siddharth Mishra-Sharma, Daniel Ziegler, Emmanuel Ameisen, Joshua Batson, Tim Belonax, Samuel R. Bowman, Shan Carter, Brian Chen, Hoagy Cunningham, Carson Denison, Florian Dietz, Satvik Golechha, Akbir Khan, Jan Kirchner, Jan Leike, Austin Meek, Kei Nishimura-Gasparian, Euan Ong, Christopher Olah, Adam Pearce, Fabien Roger, Jeanne Salle, Andy Shih, Meg Tong, Drake Thomas, Kelley Rivoire, Adam Jermyn, Monte MacDiarmid, Tom Henighan, Evan Hubinger",
      "update_time": "2025-03-28",
      "abstract": "We study the feasibility of conducting alignment audits: investigations into whether models have undesired objectives. As a testbed, we train a language model with a hidden objective. Our training pipeline first teaches the model about exploitable errors in RLHF reward models (RMs), then trains the model to exploit some of these errors. We verify via out-of-distribution evaluations that the model generalizes to exhibit whatever behaviors it believes RMs rate highly, including ones not reinforced during training. We leverage this model to study alignment audits in two ways. First, we conduct a blind auditing game where four teams, unaware of the model's hidden objective or training, investigate it for concerning behaviors and their causes. Three teams successfully uncovered the model's hidden objective using techniques including interpretability with sparse autoencoders (SAEs), behavioral attacks, and training data analysis. Second, we conduct an unblinded follow-up study of eight techniques for auditing the model, analyzing their strengths and limitations. Overall, our work provides a concrete example of using alignment audits to discover a model's hidden objective and proposes a methodology for practicing and validating progress in alignment auditing."
    },
    "2503.06086v1": {
      "title": "Characterizing optimal monitoring edge-geodetic sets for some structured graph classes",
      "url": "http://arxiv.org/abs/2503.06086v1",
      "authors": "Florent Foucaud, Arti Pandey, Kaustav Paul",
      "update_time": "2025-03-08",
      "abstract": "Given a graph $G=(V,E)$, a set $S\\subseteq V$ is said to be a monitoring edge-geodetic set if the deletion of any edge in the graph results in a change in the distance between at least one pair of vertices in $S$. The minimum size of such a set in $G$ is called the monitoring edge-geodetic number of $G$ and is denoted by $meg(G)$.   In this work, we compute the monitoring edge-geodetic number efficiently for the following graph classes: distance-hereditary graphs, $P_4$-sparse graphs, bipartite permutation graphs, and strongly chordal graphs. The algorithms follow from structural characterizations of the optimal monitoring edge-geodetic sets for these graph classes in terms of \\emph{mandatory vertices} (those that need to be in every solution). This extends previous results from the literature for cographs, interval graphs and block graphs."
    },
    "2503.05211v1": {
      "title": "Language-specific Tonal Features Drive Speaker-Listener Neural Synchronization",
      "url": "http://arxiv.org/abs/2503.05211v1",
      "authors": "Chen Hong, Xiangbin Teng, Yu Li, Shen-Mou Hsu, Feng-Ming Tsao, Patrick C. M. Wong, Gangyi Feng",
      "update_time": "2025-03-07",
      "abstract": "Verbal communication transmits information across diverse linguistic levels, with neural synchronization (NS) between speakers and listeners emerging as a putative mechanism underlying successful exchange. However, the specific speech features driving this synchronization and how language-specific versus universal characteristics facilitate information transfer remain poorly understood. We developed a novel content-based interbrain encoding model to disentangle the contributions of acoustic and linguistic features to speaker-listener NS during Mandarin storytelling and listening, as measured via magnetoencephalography (MEG). Results revealed robust NS throughout frontotemporal-parietal networks with systematic time lags between speech production and perception. Crucially, suprasegmental lexical tone features (tone categories, pitch height, and pitch contour), essential for lexical meaning in Mandarin, contributed more significantly to NS than either acoustic elements or universal segmental units (consonants and vowels). These tonal features generated distinctive spatiotemporal NS patterns, creating language-specific neural \"communication channels\" that facilitated efficient representation sharing between interlocutors. Furthermore, the strength and patterns of NS driven by these language-specific features predicted communication success. These findings demonstrate the neural mechanisms underlying shared representations during verbal exchange and highlight how language-specific features can shape neural coupling to optimize information transfer during human communication."
    },
    "2502.16797v1": {
      "title": "Forecasting Rare Language Model Behaviors",
      "url": "http://arxiv.org/abs/2502.16797v1",
      "authors": "Erik Jones, Meg Tong, Jesse Mu, Mohammed Mahfoud, Jan Leike, Roger Grosse, Jared Kaplan, William Fithian, Ethan Perez, Mrinank Sharma",
      "update_time": "2025-02-24",
      "abstract": "Standard language model evaluations can fail to capture risks that emerge only at deployment scale. For example, a model may produce safe responses during a small-scale beta test, yet reveal dangerous information when processing billions of requests at deployment. To remedy this, we introduce a method to forecast potential risks across orders of magnitude more queries than we test during evaluation. We make forecasts by studying each query's elicitation probability -- the probability the query produces a target behavior -- and demonstrate that the largest observed elicitation probabilities predictably scale with the number of queries. We find that our forecasts can predict the emergence of diverse undesirable behaviors -- such as assisting users with dangerous chemical synthesis or taking power-seeking actions -- across up to three orders of magnitude of query volume. Our work enables model developers to proactively anticipate and patch rare failures before they manifest during large-scale deployments."
    },
    "2502.17480v1": {
      "title": "Brain-to-Text Decoding: A Non-invasive Approach via Typing",
      "url": "http://arxiv.org/abs/2502.17480v1",
      "authors": "Jarod L\u00e9vy, Mingfang Zhang, Svetlana Pinet, J\u00e9r\u00e9my Rapin, Hubert Banville, St\u00e9phane d'Ascoli, Jean-R\u00e9mi King",
      "update_time": "2025-02-18",
      "abstract": "Modern neuroprostheses can now restore communication in patients who have lost the ability to speak or move. However, these invasive devices entail risks inherent to neurosurgery. Here, we introduce a non-invasive method to decode the production of sentences from brain activity and demonstrate its efficacy in a cohort of 35 healthy volunteers. For this, we present Brain2Qwerty, a new deep learning architecture trained to decode sentences from either electro- (EEG) or magneto-encephalography (MEG), while participants typed briefly memorized sentences on a QWERTY keyboard. With MEG, Brain2Qwerty reaches, on average, a character-error-rate (CER) of 32% and substantially outperforms EEG (CER: 67%). For the best participants, the model achieves a CER of 19%, and can perfectly decode a variety of sentences outside of the training set. While error analyses suggest that decoding depends on motor processes, the analysis of typographical errors suggests that it also involves higher-level cognitive factors. Overall, these results narrow the gap between invasive and non-invasive methods and thus open the path for developing safe brain-computer interfaces for non-communicating patients."
    },
    "2502.07429v2": {
      "title": "From Thought to Action: How a Hierarchy of Neural Dynamics Supports Language Production",
      "url": "http://arxiv.org/abs/2502.07429v2",
      "authors": "Mingfang Zhang, Jarod L\u00e9vy, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, F. -Xavier Alario, Pierre Bourdillon, Svetlana Pinet, Jean-R\u00e9mi King",
      "update_time": "2025-02-18",
      "abstract": "Humans effortlessly communicate their thoughts through intricate sequences of motor actions. Yet, the neural processes that coordinate language production remain largely unknown, in part because speech artifacts limit the use of neuroimaging. To elucidate the unfolding of language production in the brain, we investigate with magnetoencephalography (MEG) and electroencephalography (EEG) the neurophysiological activity of 35 skilled typists, while they typed sentences on a keyboard. This approach confirms the hierarchical predictions of linguistic theories: the neural activity preceding the production of each word is marked by the sequential rise and fall of context-, word-, syllable-, and letter-level representations. Remarkably, each of these neural representations is maintained over long time periods within each level of the language hierarchy. This phenomenon results in a superposition of successive representations that is supported by a hierarchy of dynamic neural codes. Overall, these findings provide a precise computational breakdown of the neural dynamics that coordinate the production of language in the human brain."
    },
    "2502.05161v2": {
      "title": "Estimated Roadway Segment Traffic Data by Vehicle Class for the United States: A Machine Learning Approach",
      "url": "http://arxiv.org/abs/2502.05161v2",
      "authors": "Brittany Antonczak, Meg Fay, Aviral Chawla, Gregory Rowangould",
      "update_time": "2025-03-31",
      "abstract": "The Highway Performance Monitoring System, managed by the Federal Highway Administration, provides essential data on average annual daily traffic across U.S. roadways, but it has limited representation of medium- and heavy-duty vehicles on non-interstate roads. This gap limits research and policy analysis on the impacts of truck traffic, especially concerning air quality and public health. To address this, we use random forest regression to estimate medium- and heavy-duty vehicle traffic volumes in areas with sparse data. This results in a more comprehensive dataset, which enables the estimation of traffic density at the census block level as a proxy for traffic-related air pollution exposure. Our high-resolution spatial data products, rigorously validated, provide a more accurate representation of truck traffic and its environmental and health impacts. These datasets are valuable for transportation planning, public health research, and policy decisions aimed at mitigating the effects of truck traffic on vulnerable communities exposed to air pollution."
    },
    "2502.04658v1": {
      "title": "Shifting Attention to You: Personalized Brain-Inspired AI Models",
      "url": "http://arxiv.org/abs/2502.04658v1",
      "authors": "Stephen Chong Zhao, Yang Hu, Jason Lee, Andrew Bender, Trisha Mazumdar, Mark Wallace, David A. Tovar",
      "update_time": "2025-02-07",
      "abstract": "The integration of human and artificial intelligence represents a scientific opportunity to advance our understanding of information processing, as each system offers unique computational insights that can enhance and inform the other. The synthesis of human cognitive principles with artificial intelligence has the potential to produce more interpretable and functionally aligned computational models, while simultaneously providing a formal framework for investigating the neural mechanisms underlying perception, learning, and decision-making through systematic model comparisons and representational analyses. In this study, we introduce personalized brain-inspired modeling that integrates human behavioral embeddings and neural data to align with cognitive processes. We took a stepwise approach, fine-tuning the Contrastive Language-Image Pre-training (CLIP) model with large-scale behavioral decisions, group-level neural data, and finally, participant-level neural data within a broader framework that we have named CLIP-Human-Based Analysis (CLIP-HBA). We found that fine-tuning on behavioral data enhances its ability to predict human similarity judgments while indirectly aligning it with dynamic representations captured via MEG. To further gain mechanistic insights into the temporal evolution of cognitive processes, we introduced a model specifically fine-tuned on millisecond-level MEG neural dynamics (CLIP-HBA-MEG). This model resulted in enhanced temporal alignment with human neural processing while still showing improvement on behavioral alignment. Finally, we trained individualized models on participant-specific neural data, effectively capturing individualized neural dynamics and highlighting the potential for personalized AI systems. These personalized systems have far-reaching implications for the fields of medicine, cognitive research, human-computer interfaces, and AI development."
    },
    "2502.04258v1": {
      "title": "Detecting Mild Traumatic Brain Injury with MEG Scan Data: One-vs-K-Sample Tests",
      "url": "http://arxiv.org/abs/2502.04258v1",
      "authors": "Jian Zhang, Gary Green",
      "update_time": "2025-02-06",
      "abstract": "Magnetoencephalography (MEG) scanner has been shown to be more accurate than other medical devices in detecting mild traumatic brain injury (mTBI). However, MEG scan data in certain spectrum ranges can be skewed, multimodal and heterogeneous which can mislead the conventional case-control analysis that requires the data to be homogeneous and normally distributed within the control group. To meet this challenge, we propose a flexible one-vs-K-sample testing procedure for detecting brain injury for a single-case versus heterogeneous controls. The new procedure begins with source magnitude imaging using MEG scan data in frequency domain, followed by region-wise contrast tests for abnormality between the case and controls. The critical values for these tests are automatically determined by cross-validation. We adjust the testing results for heterogeneity effects by similarity analysis. An asymptotic theory is established for the proposed test statistic. By simulated and real data analyses in the context of neurotrauma, we show that the proposed test outperforms commonly used nonparametric methods in terms of overall accuracy and ability in accommodating data non-normality and subject-heterogeneity."
    }
  },
  "neuroAI": {
    "2503.06286v1": {
      "title": "A 7T fMRI dataset of synthetic images for out-of-distribution modeling of vision",
      "url": "http://arxiv.org/abs/2503.06286v1",
      "authors": "Alessandro T. Gifford, Radoslaw M. Cichy, Thomas Naselaris, Kendrick Kay",
      "update_time": "2025-03-08",
      "abstract": "Large-scale visual neural datasets such as the Natural Scenes Dataset (NSD) are boosting NeuroAI research by enabling computational models of the brain with performances beyond what was possible just a decade ago. However, these datasets lack out-of-distribution (OOD) components, which are crucial for the development of more robust models. Here, we address this limitation by releasing NSD-synthetic, a dataset consisting of 7T fMRI responses from the eight NSD subjects for 284 carefully controlled synthetic images. We show that NSD-synthetic's fMRI responses reliably encode stimulus-related information and are OOD with respect to NSD. Furthermore, OOD generalization tests on NSD-synthetic reveal differences between models of the brain that are not detected with NSD - specifically, self-supervised deep neural networks better explain neural responses than their task-supervised counterparts. These results showcase how NSD-synthetic enables OOD generalization tests that facilitate the development of more robust models of visual processing, and the formulation of more accurate theories of human vision."
    },
    "2502.16238v1": {
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "url": "http://arxiv.org/abs/2502.16238v1",
      "authors": "Jenelle Feather, Meenakshi Khosla, N. Apurva Ratan Murty, Aran Nayebi",
      "update_time": "2025-02-22",
      "abstract": "What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \\emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development."
    },
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": "https://github.com/henri-edinb/async_learning"
    },
    "2411.18526v2": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v2",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias, Anthony Zador",
      "update_time": "2025-04-03",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety."
    },
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research."
    },
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    }
  },
  "medical": {
    "2504.07933v1": {
      "title": "Geometric and Dosimetric Validation of Deformable Image Registration for Prostate MR-guided Adaptive Radiotherapy",
      "url": "http://arxiv.org/abs/2504.07933v1",
      "authors": "Victor N. Malkov, Iymad R. Mansour, Vickie Kong, Winnie Li, Jennifer Dang, Parisa Sadeghi, Inmaculada Navarro, Jerusha Padayachee, Peter Chung, Jeff D. Winter, Tony Tadic",
      "update_time": "2025-04-10",
      "abstract": "Objective: Quantify geometric and dosimetric accuracy of a novel prostate MR-to-MR deformable image registration (DIR) approach to support MR-guided adaptive radiation therapy dose accumulation.   Approach: We evaluated DIR accuracy in 25 patients treated with 30 Gy in 5 fractions on a 1.5 T MR-linac using an adaptive workflow. A reference MR was used for planning, with three images collected at each fraction: adapt MR for adaptive planning, verify MR for pretreatment position verification and beam-on for capturing anatomy during radiation delivery. We assessed three DIR approaches: intensity-based, intensity-based with controlling structures (CS) and novel intensity based with controlling structures and points of interest (CS+P). DIRs were performed between the reference and fraction images and within fractions. We propagated CTV, bladder, and rectum contours using the DIRs and compared to manual contours using Dice similarity coefficient, mean distance to agreement (DTAmean), and dose-volume metrics.   Results: CS and CS+P improved geometric agreement between contours over intensity-only DIR. DTAmean for reference-to-beam-on intensity-only DIR was 0.131+/-0.009cm (CTV), 0.46+/-0.08cm (bladder), and 0.154+/-0.013cm (rectum). For the CS, the values were 0.018+/-0.002cm, 0.388+/-0.14cm, and 0.036+/-0.013cm. For CS+P these values were 0.015+/-0.001cm, 0.025+/-0.004cm, and 0.021+/-0.002cm. Dosimetrically, comparing CS and CS+P for reference to beam-on DIRs resulted in a change of CTV D98% from [-29cGy, 19cGy] to [-18cGy, 26cGy], rectum D1cc from [-106cGy, 72cGy] to [-52cGy, 74cGy], and bladder D5cc from [-51cGy, 544cGy] to [-79cGy, 36cGy].   Significance: CS improved geometric and dosimetric accuracy over intensity-only DIR, with CS+P providing the most consistent performance. However, session image segmentation remains a challenge, which may be addressed with automated contouring."
    },
    "2504.07904v1": {
      "title": "The Efficacy of Semantics-Preserving Transformations in Self-Supervised Learning for Medical Ultrasound",
      "url": "http://arxiv.org/abs/2504.07904v1",
      "authors": "Blake VanBerlo, Alexander Wong, Jesse Hoey, Robert Arntfield",
      "update_time": "2025-04-10",
      "abstract": "Data augmentation is a central component of joint embedding self-supervised learning (SSL). Approaches that work for natural images may not always be effective in medical imaging tasks. This study systematically investigated the impact of data augmentation and preprocessing strategies in SSL for lung ultrasound. Three data augmentation pipelines were assessed: (1) a baseline pipeline commonly used across imaging domains, (2) a novel semantic-preserving pipeline designed for ultrasound, and (3) a distilled set of the most effective transformations from both pipelines. Pretrained models were evaluated on multiple classification tasks: B-line detection, pleural effusion detection, and COVID-19 classification. Experiments revealed that semantics-preserving data augmentation resulted in the greatest performance for COVID-19 classification - a diagnostic task requiring global image context. Cropping-based methods yielded the greatest performance on the B-line and pleural effusion object classification tasks, which require strong local pattern recognition. Lastly, semantics-preserving ultrasound image preprocessing resulted in increased downstream performance for multiple tasks. Guidance regarding data augmentation and preprocessing strategies was synthesized for practitioners working with SSL in ultrasound."
    },
    "2504.07844v1": {
      "title": "A quantum computing approach to beam angle optimization",
      "url": "http://arxiv.org/abs/2504.07844v1",
      "authors": "Nimita Shinde, Ya-Nan Zhu, Haozheng Shen, Hao Gao",
      "update_time": "2025-04-10",
      "abstract": "Background: Beam angle optimization (BAO) is a critical component of radiation therapy (RT) treatment planning, where small changes in beam configuration can significantly impact treatment quality, especially for proton RT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is NP-hard due to its exponential growing search space. Traditional optimization techniques often struggle with computational efficiency, necessitating the development of novel approaches. Purpose: This study introduces QC-BAO, a hybrid quantum-classical approach that leverages quantum computing to solve the MIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as an MIP problem, incorporating binary variables for beam angle selection and continuous variables for optimizing spot intensities for proton therapy. The proposed approach employs a hybrid quantum-classical framework, utilizing quantum computing to solve the binary decision component while integrating classical optimization techniques, including iterative convex relaxation and alternating direction method of multipliers. Results: Computational experiments were conducted on clinical test cases to evaluate QC-BAO's performance against clinically verified angles and a heuristic approach, GS-BAO. QC-BAO demonstrated improved treatment plan quality over both clinical and GS-BAO. The method consistently increased the conformity index (CI) for target coverage while reducing mean and maximum doses to organs-at-risk (OAR). Additionally, QC-BAO produced the lowest objective function value, confirming its superior optimization capability. Conclusions: The findings highlight the potential of quantum computing to enhance the solution to BAO problem by demonstrated improvement in plan quality using the proposed method, QC-BAO. This study paves the way for future clinical implementation of quantum-accelerated optimization in RT."
    },
    "2504.07827v1": {
      "title": "HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature Fusion and Growth-Suppression Balanced Loss",
      "url": "http://arxiv.org/abs/2504.07827v1",
      "authors": "Yi Huang, Ke Zhang, Wei Liu, Yuanyuan Wang, Vishal M. Patel, Le Lu, Xu Han, Dakai Jin, Ke Yan",
      "update_time": "2025-04-10",
      "abstract": "Accurate segmentation of tubular structures in medical images, such as vessels and airway trees, is crucial for computer-aided diagnosis, radiotherapy, and surgical planning. However, significant challenges exist in algorithm design when faced with diverse sizes, complex topologies, and (often) incomplete data annotation of these structures. We address these difficulties by proposing a new tubular structure segmentation framework named HarmonySeg. First, we design a deep-to-shallow decoder network featuring flexible convolution blocks with varying receptive fields, which enables the model to effectively adapt to tubular structures of different scales. Second, to highlight potential anatomical regions and improve the recall of small tubular structures, we incorporate vesselness maps as auxiliary information. These maps are aligned with image features through a shallow-and-deep fusion module, which simultaneously eliminates unreasonable candidates to maintain high precision. Finally, we introduce a topology-preserving loss function that leverages contextual and shape priors to balance the growth and suppression of tubular structures, which also allows the model to handle low-quality and incomplete annotations. Extensive quantitative experiments are conducted on four public datasets. The results show that our model can accurately segment 2D and 3D tubular structures and outperform existing state-of-the-art methods. External validation on a private dataset also demonstrates good generalizability."
    },
    "2504.07775v1": {
      "title": "Focal Cortical Dysplasia Type II Detection Using Cross Modality Transfer Learning and Grad-CAM in 3D-CNNs for MRI Analysis",
      "url": "http://arxiv.org/abs/2504.07775v1",
      "authors": "Lorenzo Lasagni, Antonio Ciccarone, Renzo Guerrini, Matteo Lenge, Ludovico D'incerti",
      "update_time": "2025-04-10",
      "abstract": "Focal cortical dysplasia (FCD) type II is a major cause of drug-resistant epilepsy, often curable only by surgery. Despite its clinical importance, the diagnosis of FCD is very difficult in MRI because of subtle abnormalities, leading to misdiagnosis. This study investigates the use of 3D convolutional neural networks (3D-CNNs) for FCD detection, using a dataset of 170 subjects (85 FCD patients and 85 controls) composed of T1-weighted and FLAIR MRI scans. In particular, it investigates the benefits obtained from cross-modality transfer learning and explainable artificial intelligence (XAI) techniques, in particular Gradient-weighted Class Activation Mapping (Grad-CAM). ResNet architectures (ResNet-18, -34, and -50) were implemented, employing transfer learning strategies that used pre-trained weights from segmentation tasks. Results indicate that transfer learning significantly enhances classification accuracy (up to 80.3%) and interpretability, as measured by a novel Heat-Score metric, which evaluates the model's focus on clinically relevant regions. Improvements in the Heat-Score metric underscore the model's seizure zone localization capabilities, bringing AI predictions and clinical insights closer together. These results highlight the importance of transfer learning, including cross-modality, and XAI in advancing AI-based medical diagnostics, especially for difficult-to-diagnose pathologies such as FCD."
    },
    "2504.07763v1": {
      "title": "Data over dialogue: Why artificial intelligence is unlikely to humanise medicine",
      "url": "http://arxiv.org/abs/2504.07763v1",
      "authors": "Joshua Hatherley",
      "update_time": "2025-04-10",
      "abstract": "Recently, a growing number of experts in artificial intelligence (AI) and medicine have be-gun to suggest that the use of AI systems, particularly machine learning (ML) systems, is likely to humanise the practice of medicine by substantially improving the quality of clinician-patient relationships. In this thesis, however, I argue that medical ML systems are more likely to negatively impact these relationships than to improve them. In particular, I argue that the use of medical ML systems is likely to comprise the quality of trust, care, empathy, understanding, and communication between clinicians and patients."
    },
    "2504.07760v1": {
      "title": "PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model Development",
      "url": "http://arxiv.org/abs/2504.07760v1",
      "authors": "Zhenhuan Zhou, Yuchen Zhang, Ruihong Xu, Xuansen Zhao, Tao Li",
      "update_time": "2025-04-10",
      "abstract": "Deep learning (DL), a pivotal technology in artificial intelligence, has recently gained substantial traction in the domain of dental auxiliary diagnosis. However, its application has predominantly been confined to imaging modalities such as panoramic radiographs and Cone Beam Computed Tomography, with limited focus on auxiliary analysis specifically targeting Periapical Radiographs (PR). PR are the most extensively utilized imaging modality in endodontics and periodontics due to their capability to capture detailed local lesions at a low cost. Nevertheless, challenges such as resolution limitations and artifacts complicate the annotation and recognition of PR, leading to a scarcity of publicly available, large-scale, high-quality PR analysis datasets. This scarcity has somewhat impeded the advancement of DL applications in PR analysis. In this paper, we present PRAD-10K, a dataset for PR analysis. PRAD-10K comprises 10,000 clinical periapical radiograph images, with pixel-level annotations provided by professional dentists for nine distinct anatomical structures, lesions, and artificial restorations or medical devices, We also include classification labels for images with typical conditions or lesions. Furthermore, we introduce a DL network named PRNet to establish benchmarks for PR segmentation tasks. Experimental results demonstrate that PRNet surpasses previous state-of-the-art medical image segmentation models on the PRAD-10K dataset. The codes and dataset will be made publicly available."
    },
    "2504.07729v1": {
      "title": "Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric T1-weighted Abdominal MRI",
      "url": "http://arxiv.org/abs/2504.07729v1",
      "authors": "Nicole Tran, Anisa Prasad, Yan Zhuang, Tejas Sudharshan Mathai, Boah Kim, Sydney Lewis, Pritam Mukherjee, Jianfei Liu, Ronald M. Summers",
      "update_time": "2025-04-10",
      "abstract": "The segmentation of multiple organs in multi-parametric MRI studies is critical for many applications in radiology, such as correlating imaging biomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three publicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI (TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ segmentation in MRI. However, the performance of these tools on specific MRI sequence types has not yet been quantified. In this work, a subset of 40 volumes from the public Duke Liver Dataset was curated. The curated dataset contained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w, venous T1w, and delayed T1w phases, respectively. Ten abdominal structures were manually annotated in these volumes. Next, the performance of the three public tools was benchmarked on this curated dataset. The results indicated that MRSeg obtained a Dice score of 80.7 $\\pm$ 18.6 and Hausdorff Distance (HD) error of 8.9 $\\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence types in contrast to TS and VIBE."
    },
    "2504.07724v1": {
      "title": "MRD-RAG: Enhancing Medical Diagnosis with Multi-Round Retrieval-Augmented Generation",
      "url": "http://arxiv.org/abs/2504.07724v1",
      "authors": "Yixiang Chen, Penglei Sun, Xiang Li, Xiaowen Chu",
      "update_time": "2025-04-10",
      "abstract": "In recent years, accurately and quickly deploying medical large language models (LLMs) has become a significant trend. Among these, retrieval-augmented generation (RAG) has garnered significant attention due to its features of rapid deployment and privacy protection. However, existing medical RAG frameworks still have shortcomings. Most existing medical RAG frameworks are designed for single-round question answering tasks and are not suitable for multi-round diagnostic dialogue. On the other hand, existing medical multi-round RAG frameworks do not consider the interconnections between potential diseases to inquire precisely like a doctor. To address these issues, we propose a Multi-Round Diagnostic RAG (MRD-RAG) framework that mimics the doctor's diagnostic process. This RAG framework can analyze diagnosis information of potential diseases and accurately conduct multi-round diagnosis like a doctor. To evaluate the effectiveness of our proposed frameworks, we conduct experiments on two modern medical datasets and two traditional Chinese medicine datasets, with evaluations by GPT and human doctors on different methods. The results indicate that our RAG framework can significantly enhance the diagnostic performance of LLMs, highlighting the potential of our approach in medical diagnosis. The code and data can be found in our project website https://github.com/YixiangCh/MRD-RAG/tree/master."
    },
    "2504.07720v1": {
      "title": "Filtering through a topological lens: homology for point processes on the time-frequency plane",
      "url": "http://arxiv.org/abs/2504.07720v1",
      "authors": "Juan Manuel Miramont, Kin Aun Tan, Soumendu Sundar Mukherjee, R\u00e9mi Bardenet, Subhroshekhar Ghosh",
      "update_time": "2025-04-10",
      "abstract": "We introduce a very general approach to the analysis of signals from their noisy measurements from the perspective of Topological Data Analysis (TDA). While TDA has emerged as a powerful analytical tool for data with pronounced topological structures, here we demonstrate its applicability for general problems of signal processing, without any a-priori geometric feature. Our methods are well-suited to a wide array of time-dependent signals in different scientific domains, with acoustic signals being a particularly important application. We invoke time-frequency representations of such signals, focusing on their zeros which are gaining salience as a signal processing tool in view of their stability properties. Leveraging state-of-the-art topological concepts, such as stable and minimal volumes, we develop a complete suite of TDA-based methods to explore the delicate stochastic geometry of these zeros, capturing signals based on the disruption they cause to this rigid, hyperuniform spatial structure. Unlike classical spatial data tools, TDA is able to capture the full spectrum of the stochastic geometry of the zeros, thereby leading to powerful inferential outcomes that are underpinned by a principled statistical foundation. This is reflected in the power and versatility of our applications, which include competitive performance in processing. a wide variety of audio signals (esp. in low SNR regimes), effective detection and reconstruction of gravitational wave signals (a reputed signal processing challenge with non-Gaussian noise), and medical time series data from EEGs, indicating a wide horizon for the approach and methods introduced in this paper."
    }
  }
}