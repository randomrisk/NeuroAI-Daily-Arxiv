{
  "Brain": {
    "2501.17158v1": {
      "title": "Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain Research",
      "url": "http://arxiv.org/abs/2501.17158v1",
      "authors": "Fahad Salman, Abhisri Ramesh, Thomas Jochmann, Mirjam Prayer, Ademola Adegbemigun, Jack A. Reeves, Gregory E. Wilding, Junghun Cho, Dejan Jakimovski, Niels Bergsland, Michael G. Dwyer, Robert Zivadinov, Ferdinand Schweser",
      "update_time": "2025-01-28",
      "abstract": "Background: Quantitative susceptibility mapping (QSM) of the brain is an advanced MRI technique for assessing tissue characteristics based on magnetic susceptibility, which varies with the composition of the tissue, such as iron, calcium, and myelin levels. QSM consists of multiple processing steps, with various choices for each step. Despite its increasing application in detecting and monitoring neurodegenerative diseases, the impact of algorithmic choices in QSM's workflow on clinical outcomes has not been thoroughly quantified.   Objective: This study aimed to evaluate how choices in background field removal (BFR), dipole inversion algorithms, and anatomical referencing impact the sensitivity and reproducibility error of QSM in detecting group-level and longitudinal changes in deep gray matter susceptibility in a clinical setting.   Methods: We compared 378 different QSM pipelines using a 10-year follow-up dataset of healthy adults. We analyzed the sensitivity of pipelines to detect known aging-related susceptibility changes in the DGM over time.   Results: We found high variability in the sensitivity of QSM pipelines to detect susceptibility changes. The study highlighted that while most pipelines could detect changes reliably, the choice of BFR algorithm and the referencing strategy substantially influenced the outcome reproducibility error and sensitivity. Notably, pipelines using RESHARP with AMP-PE, HEIDI or LSQR inversion showed the highest overall sensitivity.   Conclusions: The findings underscore the critical influence of algorithmic choices in QSM processing on the accuracy and reliability of detecting physiological changes in the brain. This has profound implications for clinical research and trials where QSM is used as a biomarker for disease progression, highlighting that careful consideration should be given to pipeline configuration to optimize clinical outcomes."
    },
    "2501.16886v1": {
      "title": "Unconventional resistive switching in dense Ag-based nanowire networks with brain-inspired perspectives",
      "url": "http://arxiv.org/abs/2501.16886v1",
      "authors": "Juan I. Diaz Schneider, Cynthia P. Quinteros, Eduardo D. Mart\u00ednez, Pablo E. Levy",
      "update_time": "2025-01-28",
      "abstract": "We report an unconventional resistive switching effect on high-density self-assembled Ag-nanowire networks tailored by a fuse-like operation. We propose a mechanism to rationalize the observed phenomenology by analyzing the electrical signatures before and after such a fusing. The explanation allows reconciling the results obtained in similar systems early adopted as transparent electrodes and the more recent attempts to use this type of substrate for in-materia computational operations. In addition to the usual analog nature of the available resistance states and the ability to tune internal weights, we show that these networks' sparsity and non-linear behavior are also attributes. Thus, the formerly exhibited nanowires' abilities to code synaptic behavior are complemented by neuronal features upon properly tuning the network density and the applied electrical protocol."
    },
    "2501.16879v1": {
      "title": "Ultra-high resolution multimodal MRI dense labelled holistic brain atlas",
      "url": "http://arxiv.org/abs/2501.16879v1",
      "authors": "Jos\u00e9 V. Manj\u00f3n, Sergio Morell-Ortega, Marina Ruiz-Perez, Boris Mansencal, Edern Le Bot, Marien Gadea, Enrique Lanuza, Gwenaelle Catheline, Thomas Tourdias, Vincent Planche, R\u00e9mi Giraud, Denis Rivi\u00e8re, Jean-Fran\u00e7ois Mangin, Nicole Labra-Avila, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Maria de la Iglesia-Vaya, Pierrick Coup\u00e9",
      "update_time": "2025-01-28",
      "abstract": "In this paper, we introduce holiAtlas, a holistic, multimodal and high-resolution human brain atlas. This atlas covers different levels of details of the human brain anatomy, from the organ to the substructure level, using a new dense labelled protocol generated from the fusion of multiple local protocols at different scales. This atlas has been constructed averaging images and segmentations of 75 healthy subjects from the Human Connectome Project database. Specifically, MR images of T1, T2 and WMn (White Matter nulled) contrasts at 0.125 $mm^{3}$ resolution that were nonlinearly registered and averaged using symmetric group-wise normalisation to construct the atlas. At the finest level, the holiAtlas protocol has 350 different labels derived from 10 different delineation protocols. These labels were grouped at different scales to provide a holistic view of the brain at different levels in a coherent and consistent manner. This multiscale and multimodal atlas can be used for the development of new ultra-high resolution segmentation methods that can potentially leverage the early detection of neurological disorders.",
      "code_url": "https://github.com/BBillot/hypothalamus_seg"
    },
    "2501.16762v1": {
      "title": "Rate-Distortion under Neural Tracking of Speech: A Directed Redundancy Approach",
      "url": "http://arxiv.org/abs/2501.16762v1",
      "authors": "Jan \u00d8stergaard, Sangeeth Geetha Jayaprakash, Rodrigo Ordo\u00f1ez",
      "update_time": "2025-01-28",
      "abstract": "The data acquired at different scalp EEG electrodes when human subjects are exposed to speech stimuli are highly redundant. The redundancy is partly due to volume conduction effects and partly due to localized regions of the brain synchronizing their activity in response to the stimuli. In a competing talker scenario, we use a recent measure of directed redundancy to assess the amount of redundant information that is causally conveyed from the attended stimuli to the left temporal region of the brain. We observe that for the attended stimuli, the transfer entropy as well as the directed redundancy is proportional to the correlation between the speech stimuli and the reconstructed signal from the EEG signals.   This demonstrates that both the rate as well as the rate-redundancy are inversely proportional to the distortion in neural speech tracking. Thus, a greater rate indicates a greater redundancy between the electrode signals, and a greater correlation between the reconstructed signal and the attended stimuli. A similar relationship is not observed for the distracting stimuli."
    },
    "2501.16745v1": {
      "title": "Toward Relative Positional Encoding in Spiking Transformers",
      "url": "http://arxiv.org/abs/2501.16745v1",
      "authors": "Changze Lv, Yansen Wang, Dongqi Han, Yifei Shen, Xiaoqing Zheng, Xuanjing Huang, Dongsheng Li",
      "update_time": "2025-01-28",
      "abstract": "Spiking neural networks (SNNs) are bio-inspired networks that model how neurons in the brain communicate through discrete spikes, which have great potential in various tasks due to their energy efficiency and temporal processing capabilities. SNNs with self-attention mechanisms (Spiking Transformers) have recently shown great advancements in various tasks such as sequential modeling and image classifications. However, integrating positional information, which is essential for capturing sequential relationships in data, remains a challenge in Spiking Transformers. In this paper, we introduce an approximate method for relative positional encoding (RPE) in Spiking Transformers, leveraging Gray Code as the foundation for our approach. We provide comprehensive proof of the method's effectiveness in partially capturing relative positional information for sequential tasks. Additionally, we extend our RPE approach by adapting it to a two-dimensional form suitable for image patch processing. We evaluate the proposed RPE methods on several tasks, including time series forecasting, text classification, and patch-based image classification. Our experimental results demonstrate that the incorporation of RPE significantly enhances performance by effectively capturing relative positional information."
    },
    "2501.16471v1": {
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "url": "http://arxiv.org/abs/2501.16471v1",
      "authors": "Simon Dahan, Gabriel B\u00e9n\u00e9dict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson",
      "update_time": "2025-01-27",
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at https://github.com/metrics-lab/sim, processed data for training will be available upon request at https://gin.g-node.org/Sdahan30/sim.",
      "code_url": "https://github.com/metrics-lab/sim"
    },
    "2501.16282v1": {
      "title": "Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models",
      "url": "http://arxiv.org/abs/2501.16282v1",
      "authors": "Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang, Tong Chen, Chao Cao, Yan Zhuang, Minheng Chen, Tianming Liu, Dajiang Zhu",
      "update_time": "2025-01-27",
      "abstract": "Understanding brain disorders is crucial for accurate clinical diagnosis and treatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a promising approach to interpreting medical images with the support of text descriptions. However, previous research has primarily focused on 2D medical images, leaving richer spatial information of 3D images under-explored, and single-modality-based methods are limited by overlooking the critical clinical information contained in other modalities. To address this issue, this paper proposes Brain-Adapter, a novel approach that incorporates an extra bottleneck layer to learn new knowledge and instill it into the original pre-trained knowledge. The major idea is to incorporate a lightweight bottleneck layer to train fewer parameters while capturing essential information and utilize a Contrastive Language-Image Pre-training (CLIP) strategy to align multimodal data within a unified representation space. Extensive experiments demonstrated the effectiveness of our approach in integrating multimodal data to significantly improve the diagnosis accuracy without high computational costs, highlighting the potential to enhance real-world diagnostic workflows."
    },
    "2501.16409v1": {
      "title": "Classification of Mild Cognitive Impairment Based on Dynamic Functional Connectivity Using Spatio-Temporal Transformer",
      "url": "http://arxiv.org/abs/2501.16409v1",
      "authors": "Jing Zhang, Yanjun Lyu, Xiaowei Yu, Lu Zhang, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Tianming Liu, Dajiang Zhu",
      "update_time": "2025-01-27",
      "abstract": "Dynamic functional connectivity (dFC) using resting-state functional magnetic resonance imaging (rs-fMRI) is an advanced technique for capturing the dynamic changes of neural activities, and can be very useful in the studies of brain diseases such as Alzheimer's disease (AD). Yet, existing studies have not fully leveraged the sequential information embedded within dFC that can potentially provide valuable information when identifying brain conditions. In this paper, we propose a novel framework that jointly learns the embedding of both spatial and temporal information within dFC based on the transformer architecture. Specifically, we first construct dFC networks from rs-fMRI data through a sliding window strategy. Then, we simultaneously employ a temporal block and a spatial block to capture higher-order representations of dynamic spatio-temporal dependencies, via mapping them into an efficient fused feature representation. To further enhance the robustness of these feature representations by reducing the dependency on labeled data, we also introduce a contrastive learning strategy to manipulate different brain states. Experimental results on 345 subjects with 570 scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) demonstrate the superiority of our proposed method for MCI (Mild Cognitive Impairment, the prodromal stage of AD) prediction, highlighting its potential for early identification of AD."
    },
    "2501.16246v1": {
      "title": "CLISC: Bridging clip and sam by enhanced cam for unsupervised brain tumor segmentation",
      "url": "http://arxiv.org/abs/2501.16246v1",
      "authors": "Xiaochuan Ma, Jia Fu, Wenjun Liao, Shichuan Zhang, Guotai Wang",
      "update_time": "2025-01-27",
      "abstract": "Brain tumor segmentation is important for diagnosis of the tumor, and current deep-learning methods rely on a large set of annotated images for training, with high annotation costs. Unsupervised segmentation is promising to avoid human annotations while the performance is often limited. In this study, we present a novel unsupervised segmentation approach that leverages the capabilities of foundation models, and it consists of three main steps: (1) A vision-language model (i.e., CLIP) is employed to obtain image-level pseudo-labels for training a classification network. Class Activation Mapping (CAM) is then employed to extract Regions of Interest (ROIs), where an adaptive masking-based data augmentation is used to enhance ROI identification.(2) The ROIs are used to generate bounding box and point prompts for the Segment Anything Model (SAM) to obtain segmentation pseudo-labels. (3) A 3D segmentation network is trained with the SAM-derived pseudo-labels, where low-quality pseudo-labels are filtered out in a self-learning process based on the similarity between the SAM's output and the network's prediction. Evaluation on the BraTS2020 dataset demonstrates that our approach obtained an average Dice Similarity Score (DSC) of 85.60%, outperforming five state-of-the-art unsupervised segmentation methods by more than 10 percentage points. Besides, our approach outperforms directly using SAM for zero-shot inference, and its performance is close to fully supervised learning."
    },
    "2501.16230v1": {
      "title": "MIND-EEG: Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition",
      "url": "http://arxiv.org/abs/2501.16230v1",
      "authors": "Yuzhe Zhang, Chengxi Xie, Huan Liu, Yuhan Shi, Dalin Zhang",
      "update_time": "2025-01-27",
      "abstract": "Emotion recognition using electroencephalogram (EEG) signals has broad potential across various domains. EEG signals have ability to capture rich spatial information related to brain activity, yet effectively modeling and utilizing these spatial relationships remains a challenge. Existing methods struggle with simplistic spatial structure modeling, failing to capture complex node interactions, and lack generalizable spatial connection representations, failing to balance the dynamic nature of brain networks with the need for discriminative and generalizable features. To address these challenges, we propose the Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition (MIND-EEG). The framework employs a multi-granularity approach, integrating global and regional spatial information through a Global State Encoder, an Intra-Regional Functionality Encoder, and an Inter-Regional Interaction Encoder to comprehensively model brain activity. Additionally, we introduce a discrete codebook mechanism for constructing network structures via vector quantization, ensuring compact and meaningful brain network representations while mitigating over-smoothing and enhancing model generalization. The proposed framework effectively captures the dynamic and diverse nature of EEG signals, enabling robust emotion recognition. Extensive comparisons and analyses demonstrate the effectiveness of MIND-EEG, and the source code is publicly available at https://anonymous.4open.science/r/MIND_EEG."
    }
  },
  "EEG": {
    "2501.16762v1": {
      "title": "Rate-Distortion under Neural Tracking of Speech: A Directed Redundancy Approach",
      "url": "http://arxiv.org/abs/2501.16762v1",
      "authors": "Jan \u00d8stergaard, Sangeeth Geetha Jayaprakash, Rodrigo Ordo\u00f1ez",
      "update_time": "2025-01-28",
      "abstract": "The data acquired at different scalp EEG electrodes when human subjects are exposed to speech stimuli are highly redundant. The redundancy is partly due to volume conduction effects and partly due to localized regions of the brain synchronizing their activity in response to the stimuli. In a competing talker scenario, we use a recent measure of directed redundancy to assess the amount of redundant information that is causally conveyed from the attended stimuli to the left temporal region of the brain. We observe that for the attended stimuli, the transfer entropy as well as the directed redundancy is proportional to the correlation between the speech stimuli and the reconstructed signal from the EEG signals.   This demonstrates that both the rate as well as the rate-redundancy are inversely proportional to the distortion in neural speech tracking. Thus, a greater rate indicates a greater redundancy between the electrode signals, and a greater correlation between the reconstructed signal and the attended stimuli. A similar relationship is not observed for the distracting stimuli."
    },
    "2501.16329v1": {
      "title": "sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic Sleep Staging",
      "url": "http://arxiv.org/abs/2501.16329v1",
      "authors": "Jingyuan Chen, Yuan Yao, Mie Anderson, Natalie Hauglund, Celia Kjaerby, Verena Untiet, Maiken Nedergaard, Jiebo Luo",
      "update_time": "2025-01-27",
      "abstract": "Automatic sleep staging based on electroencephalography (EEG) and electromyography (EMG) signals is an important aspect of sleep-related research. Current sleep staging methods suffer from two major drawbacks. First, there are limited information interactions between modalities in the existing methods. Second, current methods do not develop unified models that can handle different sources of input. To address these issues, we propose a novel sleep stage scoring model sDREAMER, which emphasizes cross-modality interaction and per-channel performance. Specifically, we develop a mixture-of-modality-expert (MoME) model with three pathways for EEG, EMG, and mixed signals with partially shared weights. We further propose a self-distillation training scheme for further information interaction across modalities. Our model is trained with multi-channel inputs and can make classifications on either single-channel or multi-channel inputs. Experiments demonstrate that our model outperforms the existing transformer-based sleep scoring methods for multi-channel inference. For single-channel inference, our model also outperforms the transformer-based models trained with single-channel signals."
    },
    "2501.16230v1": {
      "title": "MIND-EEG: Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition",
      "url": "http://arxiv.org/abs/2501.16230v1",
      "authors": "Yuzhe Zhang, Chengxi Xie, Huan Liu, Yuhan Shi, Dalin Zhang",
      "update_time": "2025-01-27",
      "abstract": "Emotion recognition using electroencephalogram (EEG) signals has broad potential across various domains. EEG signals have ability to capture rich spatial information related to brain activity, yet effectively modeling and utilizing these spatial relationships remains a challenge. Existing methods struggle with simplistic spatial structure modeling, failing to capture complex node interactions, and lack generalizable spatial connection representations, failing to balance the dynamic nature of brain networks with the need for discriminative and generalizable features. To address these challenges, we propose the Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition (MIND-EEG). The framework employs a multi-granularity approach, integrating global and regional spatial information through a Global State Encoder, an Intra-Regional Functionality Encoder, and an Inter-Regional Interaction Encoder to comprehensively model brain activity. Additionally, we introduce a discrete codebook mechanism for constructing network structures via vector quantization, ensuring compact and meaningful brain network representations while mitigating over-smoothing and enhancing model generalization. The proposed framework effectively captures the dynamic and diverse nature of EEG signals, enabling robust emotion recognition. Extensive comparisons and analyses demonstrate the effectiveness of MIND-EEG, and the source code is publicly available at https://anonymous.4open.science/r/MIND_EEG."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.15062v1": {
      "title": "Exact Fit Attention in Node-Holistic Graph Convolutional Network for Improved EEG-Based Driver Fatigue Detection",
      "url": "http://arxiv.org/abs/2501.15062v1",
      "authors": "Meiyan Xu, Qingqing Chen, Duo Chen, Yi Ding, Jingyuan Wang, Peipei Gu, Yijie Pan, Deshuang Huang, Xun Zhang, Jiayang Guo",
      "update_time": "2025-01-25",
      "abstract": "EEG-based fatigue monitoring can effectively reduce the incidence of related traffic accidents. In the past decade, with the advancement of deep learning, convolutional neural networks (CNN) have been increasingly used for EEG signal processing. However, due to the data's non-Euclidean characteristics, existing CNNs may lose important spatial information from EEG, specifically channel correlation. Thus, we propose the node-holistic graph convolutional network (NHGNet), a model that uses graphic convolution to dynamically learn each channel's features. With exact fit attention optimization, the network captures inter-channel correlations through a trainable adjacency matrix. The interpretability is enhanced by revealing critical areas of brain activity and their interrelations in various mental states. In validations on two public datasets, NHGNet outperforms the SOTAs. Specifically, in the intra-subject, NHGNet improved detection accuracy by at least 2.34% and 3.42%, and in the inter-subjects, it improved by at least 2.09% and 15.06%. Visualization research on the model revealed that the central parietal area plays an important role in detecting fatigue levels, whereas the frontal and temporal lobes are essential for maintaining vigilance."
    },
    "2501.14246v1": {
      "title": "Adaptive Progressive Attention Graph Neural Network for EEG Emotion Recognition",
      "url": "http://arxiv.org/abs/2501.14246v1",
      "authors": "Tianzhi Feng, Chennan Wu, Yi Niu, Fu Li, Boxun Fu, Zhifu Zhao, Xiaotian Wang, Guangming Shi",
      "update_time": "2025-01-24",
      "abstract": "In recent years, numerous neuroscientific studies have shown that human emotions are closely linked to specific brain regions, with these regions exhibiting variability across individuals and emotional states. To fully leverage these neural patterns, we propose an Adaptive Progressive Attention Graph Neural Network (APAGNN), which dynamically captures the spatial relationships among brain regions during emotional processing. The APAGNN employs three specialized experts that progressively analyze brain topology. The first expert captures global brain patterns, the second focuses on region-specific features, and the third examines emotion-related channels. This hierarchical approach enables increasingly refined analysis of neural activity. Additionally, a weight generator integrates the outputs of all three experts, balancing their contributions to produce the final predictive label. Extensive experiments on three publicly available datasets (SEED, SEED-IV and MPED) demonstrate that the proposed method enhances EEG emotion recognition performance, achieving superior results compared to baseline methods."
    },
    "2501.11081v1": {
      "title": "Robust Functional Ward's Linkages with Applications in EEG data Clustering",
      "url": "http://arxiv.org/abs/2501.11081v1",
      "authors": "Tianbo Chen",
      "update_time": "2025-01-19",
      "abstract": "This paper proposes two new distance measures, called functional Ward's linkages, for functional data clustering that are robust against outliers. Conventional Ward's linkage defines the distance between two clusters as the increase in sum of squared errors (SSE) upon merging, which can be interpreted graphically as an increase in the diameter. Analogously, functional Ward's linkage defines the distance of two clusters as the increased width of the band delimited by the merged clusters. To address the limitations of conventional Ward's linkage in handling outliers and contamination, the proposed linkages focus exclusively on the most central curves by leveraging magnitude-shape outlyingness measures and modified band depth, respectively. Simulations and real-world electroencephalogram (EEG) data analysis demonstrate that the proposed methods outperform other competitive approaches, particularly in the presence of various types of outliers and contamination."
    },
    "2501.16353v1": {
      "title": "Synthetic Data Generation by Supervised Neural Gas Network for Physiological Emotion Recognition Data",
      "url": "http://arxiv.org/abs/2501.16353v1",
      "authors": "S. Muhammad Hossein Mousavi",
      "update_time": "2025-01-19",
      "abstract": "Data scarcity remains a significant challenge in the field of emotion recognition using physiological signals, as acquiring comprehensive and diverse datasets is often prevented by privacy concerns and logistical constraints. This limitation restricts the development and generalization of robust emotion recognition models, making the need for effective synthetic data generation methods more critical. Emotion recognition from physiological signals such as EEG, ECG, and GSR plays a pivotal role in enhancing human-computer interaction and understanding human affective states. Utilizing these signals, this study introduces an innovative approach to synthetic data generation using a Supervised Neural Gas (SNG) network, which has demonstrated noteworthy speed advantages over established models like Conditional VAE, Conditional GAN, diffusion model, and Variational LSTM. The Neural Gas network, known for its adaptability in organizing data based on topological and feature-space proximity, provides a robust framework for generating real-world-like synthetic datasets that preserve the intrinsic patterns of physiological emotion data. Our implementation of the SNG efficiently processes the input data, creating synthetic instances that closely mimic the original data distributions, as demonstrated through comparative accuracy assessments. In experiments, while our approach did not universally outperform all models, it achieved superior performance against most of the evaluated models and offered significant improvements in processing time. These outcomes underscore the potential of using SNG networks for fast, efficient, and effective synthetic data generation in emotion recognition applications."
    },
    "2501.10885v2": {
      "title": "CEReBrO: Compact Encoder for Representations of Brain Oscillations Using Efficient Alternating Attention",
      "url": "http://arxiv.org/abs/2501.10885v2",
      "authors": "Alexandru Dimofte, Glenn Anta Bucagu, Thorir Mar Ingolfsson, Xiaying Wang, Andrea Cossettini, Luca Benini, Yawei Li",
      "update_time": "2025-01-27",
      "abstract": "Electroencephalograph (EEG) is a crucial tool for studying brain activity. Recently, self-supervised learning methods leveraging large unlabeled datasets have emerged as a potential solution to the scarcity of widely available annotated EEG data. However, current methods suffer from at least one of the following limitations: i) sub-optimal EEG signal modeling, ii) model sizes in the hundreds of millions of trainable parameters, and iii) reliance on private datasets and/or inconsistent public benchmarks, hindering reproducibility. To address these challenges, we introduce a Compact Encoder for Representations of Brain Oscillations using alternating attention (CEReBrO), a new small EEG foundation model. Our tokenization scheme represents EEG signals at a per-channel patch granularity. We propose an alternating attention mechanism that jointly models intra-channel temporal dynamics and inter-channel spatial correlations, achieving 2x speed improvement with 6x less memory required compared to standard self-attention. We present several model sizes ranging from 3.6 million to 85 million parameters. Pre-trained on over 20,000 hours of publicly available scalp EEG recordings with diverse channel configurations, our models set new benchmarks in emotion detection and seizure detection tasks, with competitive performance in anomaly classification and gait prediction. This validates our models' effectiveness and efficiency."
    },
    "2501.10342v1": {
      "title": "Hybrid Deep Learning Model for epileptic seizure classification by using 1D-CNN with multi-head attention mechanism",
      "url": "http://arxiv.org/abs/2501.10342v1",
      "authors": "Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed",
      "update_time": "2025-01-17",
      "abstract": "Epilepsy is a prevalent neurological disorder globally, impacting around 50 million people \\cite{WHO_epilepsy_50million}. Epileptic seizures result from sudden abnormal electrical activity in the brain, which can be read as sudden and significant changes in the EEG signal of the brain. The signal can vary in severity and frequency, which results in loss of consciousness and muscle contractions for a short period of time \\cite{epilepsyfoundation_myoclonic}. Individuals with epilepsy often face significant employment challenges due to safety concerns in certain work environments. Many jobs that involve working at heights, operating heavy machinery, or in other potentially hazardous settings may be restricted for people with seizure disorders. This certainly limits job options and economic opportunities for those living with epilepsy."
    }
  },
  "BCI": {
    "2501.16471v1": {
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "url": "http://arxiv.org/abs/2501.16471v1",
      "authors": "Simon Dahan, Gabriel B\u00e9n\u00e9dict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson",
      "update_time": "2025-01-27",
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at https://github.com/metrics-lab/sim, processed data for training will be available upon request at https://gin.g-node.org/Sdahan30/sim.",
      "code_url": "https://github.com/metrics-lab/sim"
    },
    "2501.09700v1": {
      "title": "Cueless EEG imagined speech for subject identification: dataset and benchmarks",
      "url": "http://arxiv.org/abs/2501.09700v1",
      "authors": "Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee",
      "update_time": "2025-01-16",
      "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for biometric identification. While previous studies have explored the use of imagined speech with semantically meaningful words for subject identification, most have relied on additional visual or auditory cues. In this study, we introduce a cueless EEG-based imagined speech paradigm, where subjects imagine the pronunciation of semantically meaningful words without any external cues. This innovative approach addresses the limitations of prior methods by requiring subjects to select and imagine words from a predefined list naturally. The dataset comprises over 4,350 trials from 11 subjects across five sessions. We assess a variety of classification methods, including traditional machine learning techniques such as Support Vector Machines (SVM) and XGBoost, as well as time-series foundation models and deep learning architectures specifically designed for EEG classification, such as EEG Conformer and Shallow ConvNet. A session-based hold-out validation strategy was employed to ensure reliable evaluation and prevent data leakage. Our results demonstrate outstanding classification accuracy, reaching 97.93%. These findings highlight the potential of cueless EEG paradigms for secure and reliable subject identification in real-world applications, such as brain-computer interfaces (BCIs).",
      "code_url": "https://github.com/alidr79/cueless_eeg_subject_identification"
    },
    "2501.09459v1": {
      "title": "Teaching Wav2Vec2 the Language of the Brain",
      "url": "http://arxiv.org/abs/2501.09459v1",
      "authors": "Tobias Fiedler, Leon Hermann, Florian M\u00fcller, Sarel Cohen, Peter Chin, Tobias Friedrich, Eilon Vaadia",
      "update_time": "2025-01-16",
      "abstract": "The decoding of continuously spoken speech from neuronal activity has the potential to become an important clinical solution for paralyzed patients. Deep Learning Brain Computer Interfaces (BCIs) have recently successfully mapped neuronal activity to text contents in subjects who attempted to formulate speech. However, only small BCI datasets are available. In contrast, labeled data and pre-trained models for the closely related task of speech recognition from audio are widely available. One such model is Wav2Vec2 which has been trained in a self-supervised fashion to create meaningful representations of speech audio data. In this study, we show that patterns learned by Wav2Vec2 are transferable to brain data. Specifically, we replace its audio feature extractor with an untrained Brain Feature Extractor (BFE) model. We then execute full fine-tuning with pre-trained weights for Wav2Vec2, training ''from scratch'' without pre-trained weights as well as freezing a pre-trained Wav2Vec2 and training only the BFE each for 45 different BFE architectures. Across these experiments, the best run is from full fine-tuning with pre-trained weights, achieving a Character Error Rate (CER) of 18.54\\%, outperforming the best training from scratch run by 20.46\\% and that of frozen Wav2Vec2 training by 15.92\\% percentage points. These results indicate that knowledge transfer from audio speech recognition to brain decoding is possible and significantly improves brain decoding performance for the same architectures. Related source code is available at https://github.com/tfiedlerdev/Wav2Vec2ForBrain.",
      "code_url": "https://github.com/tfiedlerdev/wav2vec2forbrain"
    },
    "2501.08518v1": {
      "title": "Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface",
      "url": "http://arxiv.org/abs/2501.08518v1",
      "authors": "Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li",
      "update_time": "2025-01-15",
      "abstract": "Seasickness is a prevalent issue that adversely impacts both passenger experiences and the operational efficiency of maritime crews. While techniques that redirect attention have proven effective in alleviating motion sickness symptoms in terrestrial environments, applying similar strategies to manage seasickness poses unique challenges due to the prolonged and intense motion environment associated with maritime travel. In this study, we propose a mindfulness brain-computer interface (BCI), specifically designed to redirect attention with the aim of mitigating seasickness symptoms in real-world settings. Our system utilizes a single-channel headband to capture prefrontal EEG signals, which are then wirelessly transmitted to computing devices for the assessment of mindfulness states. The results are transferred into real-time feedback as mindfulness scores and audiovisual stimuli, facilitating a shift in attentional focus from physiological discomfort to mindfulness practices. A total of 43 individuals participated in a real-world maritime experiment consisted of three sessions: a real-feedback mindfulness session, a resting session, and a pseudofeedback mindfulness session. Notably, 81.39% of participants reported that the mindfulness BCI intervention was effective, and there was a significant reduction in the severity of seasickness, as measured by the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in the theta/beta ratio, corresponding with the alleviation of seasickness symptoms. A decrease in overall EEG band power during the real-feedback mindfulness session suggests that the mindfulness BCI fosters a more tranquil and downregulated state of brain activity. Together, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, with the potential to enhance the cruising experience for both passengers and crews."
    },
    "2501.06326v1": {
      "title": "On Creating A Brain-To-Text Decoder",
      "url": "http://arxiv.org/abs/2501.06326v1",
      "authors": "Zenon Lamprou, Yashar Moshfeghi",
      "update_time": "2025-01-10",
      "abstract": "Brain decoding has emerged as a rapidly advancing and extensively utilized technique within neuroscience. This paper centers on the application of raw electroencephalogram (EEG) signals for decoding human brain activity, offering a more expedited and efficient methodology for enhancing our understanding of the human brain. The investigation specifically scrutinizes the efficacy of brain-computer interfaces (BCI) in deciphering neural signals associated with speech production, with particular emphasis on the impact of vocabulary size, electrode density, and training data on the framework's performance. The study reveals the competitive word error rates (WERs) achievable on the Librispeech benchmark through pre-training on unlabelled data for speech processing. Furthermore, the study evaluates the efficacy of voice recognition under configurations with limited labeled data, surpassing previous state-of-the-art techniques while utilizing significantly fewer labels. Additionally, the research provides a comprehensive analysis of error patterns in voice recognition and the influence of model size and unlabelled training data. It underscores the significance of factors such as vocabulary size and electrode density in enhancing BCI performance, advocating for an increase in microelectrodes and refinement of language models."
    },
    "2501.05610v1": {
      "title": "Towards Probabilistic Inference of Human Motor Intentions by Assistive Mobile Robots Controlled via a Brain-Computer Interface",
      "url": "http://arxiv.org/abs/2501.05610v1",
      "authors": "Xiaoshan Zhou, Carol M. Menassa, Vineet R. Kamat",
      "update_time": "2025-01-09",
      "abstract": "Assistive mobile robots are a transformative technology that helps persons with disabilities regain the ability to move freely. Although autonomous wheelchairs significantly reduce user effort, they still require human input to allow users to maintain control and adapt to changing environments. Brain Computer Interface (BCI) stands out as a highly user-friendly option that does not require physical movement. Current BCI systems can understand whether users want to accelerate or decelerate, but they implement these changes in discrete speed steps rather than allowing for smooth, continuous velocity adjustments. This limitation prevents the systems from mimicking the natural, fluid speed changes seen in human self-paced motion. The authors aim to address this limitation by redesigning the perception-action cycle in a BCI controlled robotic system: improving how the robotic agent interprets the user's motion intentions (world state) and implementing these actions in a way that better reflects natural physical properties of motion, such as inertia and damping. The scope of this paper focuses on the perception aspect. We asked and answered a normative question \"what computation should the robotic agent carry out to optimally perceive incomplete or noisy sensory observations?\" Empirical EEG data were collected, and probabilistic representation that served as world state distributions were learned and evaluated in a Generative Adversarial Network framework. The ROS framework was established that connected with a Gazebo environment containing a digital twin of an indoor space and a virtual model of a robotic wheelchair. Signal processing and statistical analyses were implemented to identity the most discriminative features in the spatial-spectral-temporal dimensions, which are then used to construct the world model for the robotic agent to interpret user motion intentions as a Bayesian observer."
    },
    "2501.05589v1": {
      "title": "LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric Learning",
      "url": "http://arxiv.org/abs/2501.05589v1",
      "authors": "Jianchao Lu, Yuzhe Tian, Yang Zhang, Quan Z. Sheng, Xi Zheng",
      "update_time": "2025-01-09",
      "abstract": "Brain--computer interfaces are groundbreaking technology whereby brain signals are used to control external devices. Despite some advances in recent years, electroencephalogram (EEG)-based motor-imagery tasks face challenges, such as amplitude and phase variability and complex spatial correlations, with a need for smaller models and faster inference. In this study, we develop a prototype, called the Lightweight Geometric Learning Brain--Computer Interface (LGL-BCI), which uses our customized geometric deep learning architecture for swift model inference without sacrificing accuracy. LGL-BCI contains an EEG channel selection module via a feature decomposition algorithm to reduce the dimensionality of a symmetric positive definite matrix, providing adaptiveness among the continuously changing EEG signal. Meanwhile, a built-in lossless transformation helps boost the inference speed. The performance of our solution was evaluated using two real-world EEG devices and two public EEG datasets. LGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54% compared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses fewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency. These findings underscore both the superior accuracy and computational efficiency of LGL-BCI, demonstrating the feasibility and robustness of geometric deep learning in motor-imagery brain--computer interface applications."
    },
    "2501.05525v1": {
      "title": "MECASA: Motor Execution Classification using Additive Self-Attention for Hybrid EEG-fNIRS Data",
      "url": "http://arxiv.org/abs/2501.05525v1",
      "authors": "Gourav Siddhad, Juhi Singh, Partha Pratim Roy",
      "update_time": "2025-01-09",
      "abstract": "Motor execution, a fundamental aspect of human behavior, has been extensively studied using BCI technologies. EEG and fNIRS have been utilized to provide valuable insights, but their individual limitations have hindered performance. This study investigates the effectiveness of fusing electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) data for classifying rest versus task states in a motor execution paradigm. Using the SMR Hybrid BCI dataset, this work compares unimodal (EEG and fNIRS) classifiers with a multimodal fusion approach. It proposes Motor Execution using Convolutional Additive Self-Attention Mechanisms (MECASA), a novel architecture leveraging convolutional operations and self-attention to capture complex patterns in multimodal data. MECASA, built upon the CAS-ViT architecture, employs a computationally efficient, convolutional-based self-attention module (CASA), a hybrid block design, and a dedicated fusion network to combine features from separate EEG and fNIRS processing streams. Experimental results demonstrate that MECASA consistently outperforms established methods across all modalities (EEG, fNIRS, and fused), with fusion consistently improving accuracy compared to single-modality approaches. fNIRS generally achieved higher accuracy than EEG alone. Ablation studies revealed optimal configurations for MECASA, with embedding dimensions of 64-128 providing the best performance for EEG data and OD128 (upsampled optical density) yielding superior results for fNIRS data. This work highlights the potential of deep learning, specifically MECASA, to enhance EEG-fNIRS fusion for BCI applications."
    },
    "2501.04844v1": {
      "title": "Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction",
      "url": "http://arxiv.org/abs/2501.04844v1",
      "authors": "Jihwan Lee, Tiantian Feng, Aditya Kommineni, Sudarsana Reddy Kadiri, Shrikanth Narayanan",
      "update_time": "2025-01-08",
      "abstract": "Brain-computer interfaces (BCI) offer numerous human-centered application possibilities, particularly affecting people with neurological disorders. Text or speech decoding from brain activities is a relevant domain that could augment the quality of life for people with impaired speech perception. We propose a novel approach to enhance listened speech decoding from electroencephalography (EEG) signals by utilizing an auxiliary phoneme predictor that simultaneously decodes textual phoneme sequences. The proposed model architecture consists of three main parts: EEG module, speech module, and phoneme predictor. The EEG module learns to properly represent EEG signals into EEG embeddings. The speech module generates speech waveforms from the EEG embeddings. The phoneme predictor outputs the decoded phoneme sequences in text modality. Our proposed approach allows users to obtain decoded listened speech from EEG signals in both modalities (speech waveforms and textual phoneme sequences) simultaneously, eliminating the need for a concatenated sequential pipeline for each modality. The proposed approach also outperforms previous methods in both modalities. The source code and speech samples are publicly available.",
      "code_url": "https://github.com/lee-jhwn/icassp25-fesde-phoneme"
    },
    "2501.04359v1": {
      "title": "Decoding EEG Speech Perception with Transformers and VAE-based Data Augmentation",
      "url": "http://arxiv.org/abs/2501.04359v1",
      "authors": "Terrance Yu-Hao Chen, Yulin Chen, Pontus Soederhaell, Sadrishya Agrawal, Kateryna Shapovalenko",
      "update_time": "2025-01-08",
      "abstract": "Decoding speech from non-invasive brain signals, such as electroencephalography (EEG), has the potential to advance brain-computer interfaces (BCIs), with applications in silent communication and assistive technologies for individuals with speech impairments. However, EEG-based speech decoding faces major challenges, such as noisy data, limited datasets, and poor performance on complex tasks like speech perception. This study attempts to address these challenges by employing variational autoencoders (VAEs) for EEG data augmentation to improve data quality and applying a state-of-the-art (SOTA) sequence-to-sequence deep learning architecture, originally successful in electromyography (EMG) tasks, to EEG-based speech decoding. Additionally, we adapt this architecture for word classification tasks. Using the Brennan dataset, which contains EEG recordings of subjects listening to narrated speech, we preprocess the data and evaluate both classification and sequence-to-sequence models for EEG-to-words/sentences tasks. Our experiments show that VAEs have the potential to reconstruct artificial EEG data for augmentation. Meanwhile, our sequence-to-sequence model achieves more promising performance in generating sentences compared to our classification model, though both remain challenging tasks. These findings lay the groundwork for future research on EEG speech perception decoding, with possible extensions to speech production tasks such as silent or imagined speech."
    }
  },
  "fMRI": {
    "2501.16471v1": {
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "url": "http://arxiv.org/abs/2501.16471v1",
      "authors": "Simon Dahan, Gabriel B\u00e9n\u00e9dict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson",
      "update_time": "2025-01-27",
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at https://github.com/metrics-lab/sim, processed data for training will be available upon request at https://gin.g-node.org/Sdahan30/sim.",
      "code_url": "https://github.com/metrics-lab/sim"
    },
    "2501.16409v1": {
      "title": "Classification of Mild Cognitive Impairment Based on Dynamic Functional Connectivity Using Spatio-Temporal Transformer",
      "url": "http://arxiv.org/abs/2501.16409v1",
      "authors": "Jing Zhang, Yanjun Lyu, Xiaowei Yu, Lu Zhang, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Tianming Liu, Dajiang Zhu",
      "update_time": "2025-01-27",
      "abstract": "Dynamic functional connectivity (dFC) using resting-state functional magnetic resonance imaging (rs-fMRI) is an advanced technique for capturing the dynamic changes of neural activities, and can be very useful in the studies of brain diseases such as Alzheimer's disease (AD). Yet, existing studies have not fully leveraged the sequential information embedded within dFC that can potentially provide valuable information when identifying brain conditions. In this paper, we propose a novel framework that jointly learns the embedding of both spatial and temporal information within dFC based on the transformer architecture. Specifically, we first construct dFC networks from rs-fMRI data through a sliding window strategy. Then, we simultaneously employ a temporal block and a spatial block to capture higher-order representations of dynamic spatio-temporal dependencies, via mapping them into an efficient fused feature representation. To further enhance the robustness of these feature representations by reducing the dependency on labeled data, we also introduce a contrastive learning strategy to manipulate different brain states. Experimental results on 345 subjects with 570 scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) demonstrate the superiority of our proposed method for MCI (Mild Cognitive Impairment, the prodromal stage of AD) prediction, highlighting its potential for early identification of AD."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.14854v1": {
      "title": "BOLDreams: Dreaming with pruned in-silico fMRI Encoding Models of the Visual Cortex",
      "url": "http://arxiv.org/abs/2501.14854v1",
      "authors": "Uzair Hussain, Kamil Uludag",
      "update_time": "2025-01-24",
      "abstract": "In this article we use the Natural Scenes Dataset (NSD) to train a family of feature-weighted receptive field neural encoding models. These models use a pre-trained vision or text backbone and map extracted features to the voxel space via receptive field readouts. We comprehensively assess such models, quantifying performance changes based on using different modalities like text or images, toggling finetuning, using different pre-trained backbones, and changing the width of the readout. We also dissect each model using explainable AI (XAI) techniques, such as feature visualization via input optimization, also referred to as ``dreaming'' in the AI literature, and the integrated gradients approach to calculate implicit attention maps to illustrate which features drive the predicted signal in different brain areas. These XAI tools illustrate biologically plausible features that drive the predicted signal. Traversing the model hyperparameter space reveals the existence of a maximally minimal model, balancing simplicity while maintaining performance."
    },
    "2501.14309v1": {
      "title": "BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from Brain Activities",
      "url": "http://arxiv.org/abs/2501.14309v1",
      "authors": "Zhibo Tian, Ruijie Quan, Fan Ma, Kun Zhan, Yi Yang",
      "update_time": "2025-01-24",
      "abstract": "Reconstructing perceived images from human brain activity forms a crucial link between human and machine learning through Brain-Computer Interfaces. Early methods primarily focused on training separate models for each individual to account for individual variability in brain activity, overlooking valuable cross-subject commonalities. Recent advancements have explored multisubject methods, but these approaches face significant challenges, particularly in data privacy and effectively managing individual variability. To overcome these challenges, we introduce BrainGuard, a privacy-preserving collaborative training framework designed to enhance image reconstruction from multisubject fMRI data while safeguarding individual privacy. BrainGuard employs a collaborative global-local architecture where individual models are trained on each subject's local data and operate in conjunction with a shared global model that captures and leverages cross-subject patterns. This architecture eliminates the need to aggregate fMRI data across subjects, thereby ensuring privacy preservation. To tackle the complexity of fMRI data, BrainGuard integrates a hybrid synchronization strategy, enabling individual models to dynamically incorporate parameters from the global model. By establishing a secure and collaborative training environment, BrainGuard not only protects sensitive brain data but also improves the image reconstructions accuracy. Extensive experiments demonstrate that BrainGuard sets a new benchmark in both high-level and low-level metrics, advancing the state-of-the-art in brain decoding through its innovative design.",
      "code_url": "https://github.com/kunzhan/brainguard"
    },
    "2501.13239v1": {
      "title": "Peak Inference for Gaussian Random Fields on a Lattice",
      "url": "http://arxiv.org/abs/2501.13239v1",
      "authors": "Tuo Lin, Armin Schwartzman, Samuel Davenport",
      "update_time": "2025-01-22",
      "abstract": "In this work we develop a Monte Carlo method to compute the height distribution of local maxima of a stationary Gaussian or Gaussian-related random field that is observed on a regular lattice. We show that our method can be used to provide valid peak based inference in datasets with low levels of smoothness, where existing formulae derived for continuous domains are not accurate. We also extend the methods in Worsley (2005) and Taylor et al. (2007) to compute the peak height distribution and compare them with our approach. Lastly, we apply our method to a task fMRI dataset to show how it can be used in practice.",
      "code_url": "https://github.com/tuolin123/dlm-code"
    },
    "2501.12111v1": {
      "title": "Using Space-Filling Curves and Fractals to Reveal Spatial and Temporal Patterns in Neuroimaging Data",
      "url": "http://arxiv.org/abs/2501.12111v1",
      "authors": "Jacek Grela, Zbigniew Drogosz, Jakub Janarek, Jeremi K. Ochab, Ignacio Cifre, Ewa Gudowska-Nowak, Maciej A. Nowak, Pawe\u0142 O\u015bwi\u0119cimka, Dante R. Chialvo",
      "update_time": "2025-01-21",
      "abstract": "We present a novel method, Fractal Space-Curve Analysis (FSCA), which combines Space-Filling Curve (SFC) mapping for dimensionality reduction with fractal Detrended Fluctuation Analysis (DFA). The method is suitable for multidimensional geometrically embedded data, especially for neuroimaging data which is highly correlated temporally and spatially. We conduct extensive feasibility studies on diverse, artificially generated data with known fractal characteristics: the fractional Brownian motion, Cantor sets, and Gaussian processes. We compare the suitability of dimensionality reduction via Hilbert SFC and a data-driven alternative. FSCA is then successfully applied to real-world magnetic resonance imaging (MRI) and functional MRI (fMRI) scans.   The method utilizing Hilbert curves is optimized for computational efficiency, proven robust against boundary effects typical in experimental data analysis, and resistant to data sub-sampling. It is able to correctly quantify and discern correlations in both stationary and dynamic two-dimensional images. In MRI Alzheimer's dataset, patients reveal a progression of the disease associated with a systematic decrease of the Hurst exponent. In fMRI recording of breath-holding task, the change in the exponent allows distinguishing different experimental phases.   This study introduces a robust method for fractal characterization of spatial and temporal correlations in many types of multidimensional neuroimaging data. Very few assumptions allow it to be generalized to more dimensions than typical for neuroimaging and utilized in other scientific fields. The method can be particularly useful in analyzing fMRI experiments to compute markers of pathological conditions resulting from neurodegeneration. We also showcase its potential for providing insights into brain dynamics in task-related experiments.",
      "code_url": "https://github.com/mark-kac-center/fsca"
    },
    "2501.16346v1": {
      "title": "Self-supervised Graph Transformer with Contrastive Learning for Brain Connectivity Analysis towards Improving Autism Detection",
      "url": "http://arxiv.org/abs/2501.16346v1",
      "authors": "Yicheng Leng, Syed Muhammad Anwar, Islem Rekik, Sen He, Eung-Joo Lee",
      "update_time": "2025-01-18",
      "abstract": "Functional Magnetic Resonance Imaging (fMRI) provides useful insights into the brain function both during task or rest. Representing fMRI data using correlation matrices is found to be a reliable method of analyzing the inherent connectivity of the brain in the resting and active states. Graph Neural Networks (GNNs) have been widely used for brain network analysis due to their inherent explainability capability. In this work, we introduce a novel framework using contrastive self-supervised learning graph transformers, incorporating a brain network transformer encoder with random graph alterations. The proposed network leverages both contrastive learning and graph alterations to effectively train the graph transformer for autism detection. Our approach, tested on Autism Brain Imaging Data Exchange (ABIDE) data, demonstrates superior autism detection, achieving an AUROC of 82.6 and an accuracy of 74%, surpassing current state-of-the-art methods."
    },
    "2501.16345v1": {
      "title": "Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity",
      "url": "http://arxiv.org/abs/2501.16345v1",
      "authors": "Bishal Thapaliya, Esra Akbas, Ram Sapkota, Bhaskar Ray, Vince Calhoun, Jingyu Liu",
      "update_time": "2025-01-17",
      "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers valuable insights into the human brain's functional organization and is a powerful tool for investigating the relationship between brain function and cognitive processes, as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this study, we introduce a novel attention mechanism for graphs with subnetworks, named Self-Clustering Graph Transformer (SCGT), designed to handle the issue of uniform node updates in graph transformers. By using static functional connectivity (FC) correlation features as input to the transformer model, SCGT effectively captures the sub-network structure of the brain by performing cluster-specific updates to the nodes, unlike uniform node updates in vanilla graph transformers, further allowing us to learn and interpret the subclusters. We validate our approach on the Adolescent Brain Cognitive Development (ABCD) dataset, comprising 7,957 participants, for the prediction of total cognitive score and gender classification. Our results demonstrate that SCGT outperforms the vanilla graph transformer method and other recent models, offering a promising tool for modeling brain functional connectivity and interpreting the underlying subnetwork structures."
    },
    "2501.09805v1": {
      "title": "Multiplex Nodal Modularity: A novel network metric for the regional analysis of amnestic mild cognitive impairment during a working memory binding task",
      "url": "http://arxiv.org/abs/2501.09805v1",
      "authors": "Avalon Campbell-Cousins, Federica Guazzo, Mark Bastin, Mario A. Parra, Javier Escudero",
      "update_time": "2025-01-16",
      "abstract": "Modularity is a well-established concept for assessing community structures in various single and multi-layer networks, including those in biological and social domains. Biological networks, such as the brain, are known to exhibit group structure at a variety of scales -- local, meso, and global scale. Modularity, while useful in describing mesoscale brain organization, is limited as a metric to a global scale describing the overall strength of community structure. This approach, while valuable, overlooks important localized variations in community structure at the node level. To address this limitation, we extended modularity to individual nodes. This novel measure of nodal modularity ($nQ$) captures both meso and local scale changes in modularity. We hypothesized that $nQ$ illuminates granular changes in the brain due to diseases such as Alzheimer's disease (AD), which are known to disrupt the brain's modular structure. We explored $nQ$ in multiplex networks of a visual short-term memory binding task in fMRI and DTI data in the early stages of AD. Observed changes in $nQ$ in fMRI and DTI networks aligned with known trajectories of AD and were linked to common biomarkers of the disease, including amyloid-$\\beta$ and tau. Additionally, $nQ$ clearly differentiated MCI from MCI converters showing indications that $nQ$ may be a useful diagnostic tool for characterizing disease stages. Our findings demonstrate the utility of $nQ$ as a measure of localized group structure, providing novel insights into temporal and disease related variability at the node level. Given the widespread application of modularity as a global measure, $nQ$ represents a significant advancement, providing a granular measure of network organization applicable to a wide range of disciplines.",
      "code_url": "https://github.com/avalonc-c/nodal_modularity"
    }
  },
  "MEG": {
    "2501.15664v1": {
      "title": "The Advanced Muon Facility: a proposed multi-purpose muon facility at Fermilab",
      "url": "http://arxiv.org/abs/2501.15664v1",
      "authors": "Sophie Middleton",
      "update_time": "2025-01-26",
      "abstract": "Charged lepton flavor violation (CLFV) is expected in a diverse set of new physics scenarios. The current generation of experiments probe CLFV in the muon sector in three complementary channels: $\\mu^-N \\rightarrow e^- N$ (Mu2e, COMET), $\\mu^+ \\rightarrow e^+ \\gamma$ (MEG-II), and $\\mu^+ \\rightarrow e^+e^+e^-$s (Mu3e). These experiments aim to enhance existing limits by several orders-of-magnitude in the coming decade and offer discovery potential to many new physics models. The proposed Advanced Muon Facility (AMF) would be a multi-purpose muon facility based at Fermilab and introduces an innovative approach based on a muon storage ring to enable a full suite of muon CLFV experiments. AMF would host CLFV experiments with sensitivities orders-of-magnitude beyond the present era. In the event of a signal in these currently planned experiments, AMF would enable additional measurements to elucidate the nature of the new physics observed. The design and R$\\&$D for AMF is in its infancy. This article outlines the motivations for AMF, detailing on-going R$\\&$D efforts, and highlighting potential synergies with the proposed muon collider."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.12184v1": {
      "title": "Probing Type II Seesaw Leptogenesis Through Lepton Flavor Violation",
      "url": "http://arxiv.org/abs/2501.12184v1",
      "authors": "Chengcheng Han, Yijun Han, Sihui Huang, Zhanhong Lei",
      "update_time": "2025-01-21",
      "abstract": "Lepton flavor violation (LFV) offers a powerful probe of physics beyond the Standard Model, particularly in models addressing neutrino masses and the baryon asymmetry of the universe. In this study, we investigate LFV processes within the framework of type II seesaw leptogenesis, where the Standard Model is extended by an $SU(2)_L$ triplet Higgs field. We focus on key LFV processes including $\\mu^+\\to e^+\\gamma$, $\\mu^+ \\to e^+e^-e^+$, and $\\mu \\rightarrow e$ conversion in nuclei, deriving stringent constraints on the parameter space from current experimental data. We scan the 3$\\sigma$ range of neutrino oscillation parameters and identify the most conservative bounds consistent with existing measurements. Our results reveal that the MEG experiment currently provides the strongest constraints in the normal ordering (NO) scenario, while the SINDRUM experiment offers comparable sensitivity in the inverted ordering (IO) case. Future experiments, such as MEG II, Mu3e, Mu2e, and COMET, are predicted to significantly improve the sensitivity, testing larger regions of the parameter space. This work underscores the crucial role of LFV experiments in probing type II seesaw leptogenesis, providing an avenue to explore the connections between neutrino mass generation, baryogenesis, and inflation at experimentally accessible energy scales."
    },
    "2501.11566v1": {
      "title": "Artificial Neural Networks for Magnetoencephalography: A review of an emerging field",
      "url": "http://arxiv.org/abs/2501.11566v1",
      "authors": "Arthur Dehgan, Hamza Abdelhedi, Vanessa Hadid, Irina Rish, Karim Jerbi",
      "update_time": "2025-01-20",
      "abstract": "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that measures the intricate brain dynamics underlying cognitive processes with an unparalleled combination of high temporal and spatial precision. MEG data analytics has always relied on advanced signal processing and mathematical and statistical tools for various tasks ranging from data cleaning to probing the signals' rich dynamics and estimating the neural sources underlying the surface-level recordings. Like in most domains, the surge in Artificial Intelligence (AI) has led to the increased use of Machine Learning (ML) methods for MEG data classification. More recently, an emerging trend in this field is using Artificial Neural Networks (ANNs) to address many MEG-related tasks. This review provides a comprehensive overview of how ANNs are being used with MEG data from three vantage points: First, we review work that employs ANNs for MEG signal classification, i.e., for brain decoding. Second, we report on work that has used ANNs as putative models of information processing in the human brain. Finally, we examine studies that use ANNs as techniques to tackle methodological questions in MEG, including artifact correction and source estimation. Furthermore, we assess the current strengths and limitations of using ANNs with MEG and discuss future challenges and opportunities in this field. Finally, by establishing a detailed portrait of the field and providing practical recommendations for the future, this review seeks to provide a helpful reference for both seasoned MEG researchers and newcomers to the field who are interested in using ANNs to enhance the exploration of the complex dynamics of the human brain with MEG."
    },
    "2501.07426v1": {
      "title": "MVICAD2: Multi-View Independent Component Analysis with Delays and Dilations",
      "url": "http://arxiv.org/abs/2501.07426v1",
      "authors": "Ambroise Heurtebise, Omar Chehab, Pierre Ablin, Alexandre Gramfort",
      "update_time": "2025-01-13",
      "abstract": "Machine learning techniques in multi-view settings face significant challenges, particularly when integrating heterogeneous data, aligning feature spaces, and managing view-specific biases. These issues are prominent in neuroscience, where data from multiple subjects exposed to the same stimuli are analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG), where signals are captured at the scalp level, estimating the brain's underlying sources is crucial, especially in group studies where sources are assumed to be similar for all subjects. Common methods, such as Multi-View Independent Component Analysis (MVICA), assume identical sources across subjects, but this assumption is often too restrictive due to individual variability and age-related changes. Multi-View Independent Component Analysis with Delays (MVICAD) addresses this by allowing sources to differ up to a temporal delay. However, temporal dilation effects, particularly in auditory stimuli, are common in brain dynamics, making the estimation of time delays alone insufficient. To address this, we propose Multi-View Independent Component Analysis with Delays and Dilations (MVICAD2), which allows sources to differ across subjects in both temporal delays and dilations. We present a model with identifiable sources, derive an approximation of its likelihood in closed form, and use regularization and optimization techniques to enhance performance. Through simulations, we demonstrate that MVICAD2 outperforms existing multi-view ICA methods. We further validate its effectiveness using the Cam-CAN dataset, and showing how delays and dilations are related to aging.",
      "code_url": "https://github.com/ambroiseheurtebise/mvicad"
    },
    "2501.07394v2": {
      "title": "Exploring the distribution of connectivity weights in resting-state EEG networks",
      "url": "http://arxiv.org/abs/2501.07394v2",
      "authors": "Shiang Hu, Xiao Gong, Xiaolong Huang, Jie Ruan, Pedro Antonio Valdes-Sosa",
      "update_time": "2025-01-18",
      "abstract": "The resting-state brain networks (RSNs) reflects the functional connectivity patterns between brain modules, providing essential foundations for decoding intrinsic neural information within the brain. It serves as one of the primary tools for describing the spatial dynamics of the brain using various neuroimaging techniques, such as electroencephalography (EEG) and magnetoencephalography (MEG). However, the distribution rules or potential modes of functional connectivity weights in the resting state remain unclear. In this context, we first start from simulation, using forward solving model to generate scalp EEG with four channel densities (19, 32, 64, 128). Subsequently, we construct scalp brain networks using five coupling measures, aiming to explore whether different channel density or coupling measures affect the distribution pattern of functional connectivity weights. Next, we quantify the distribution pattern by calculating the skewness, kurtosis, and Shannon entropy of the functional connectivity network weights. Finally, the results of the simulation were validated in a normative database. We observed that: 1) The functional connection weights exhibit a right-skewed distribution, and are not influenced by channel density or coupling measures; 2) The functional connection weights exhibit a relatively uniform distribution, with the potential for volume conduction to affect the degree of uniformity in the distribution; 3) Networks constructed using coupling measures influenced by volume conduction exhibit significant correlations between the average connection weight and measures of skewness, kurtosis, and Shannon entropy. This study contributes to a deeper understanding of RSNs, providing valuable insights for research in the field of neuroscience, and holds promise for being associated with brain cognition and disease diagnosis."
    },
    "2501.05507v1": {
      "title": "On the Atomki nuclear anomaly after the MEG-II result",
      "url": "http://arxiv.org/abs/2501.05507v1",
      "authors": "Daniele Barducci, Davide Germani, Marco Nardecchia, Stefano Scacco, Claudio Toni",
      "update_time": "2025-01-09",
      "abstract": "Recent experimental results from the Atomki collaboration have reported the observation of anomalous effects in Beryllium, Helium and Carbon nuclear transitions that could hint at physics beyond the Standard Model. However, the MEG-II experiment has recently found no significant anomalous signal in the Beryllium transition ${^8}\\text{Be}^\\star\\to{^8}\\text{Be}+e^+e^-$. In view of this result, we critically re-examine the possible theoretical interpretations of the anomalies observed by the Atomki experiment in terms of a new boson $X$ with mass around $17\\;$MeV. The present work aims to study the phenomenology of a spin-2 state and revisit the possibility of a pure CP-even scalar, which was initially dismissed due to its inability to explain the Beryllium anomalous signal. Our analysis shows that a spin-2 state is highly disfavoured by the SINDRUM constraint while a scalar boson could explain the Helium and Carbon anomalies while being compatible with other experimental constraints."
    },
    "2501.05128v2": {
      "title": "Development of the high-rate capable DLC-RPC based on the current evacuation pattern",
      "url": "http://arxiv.org/abs/2501.05128v2",
      "authors": "Masato Takahashi, Sei Ban, Weiyuan Li, Atsuhiko Ochi, Wataru Ootani, Atsushi Oya, Hiromu Suzuki, Kensuke Yamamoto",
      "update_time": "2025-01-10",
      "abstract": "The Resistive Plate Chamber using Diamond-Like Carbon electrodes (DLC-RPC) has been developed as a background tagging detector in the MEG$~$II experiment. The DLC-RPC is planned to be installed in a high-intensity and low-momentum muon beam. This detector is required to have a detection efficiency of above 90 % with four active gaps in the muon beam due to the limitation of the material budget. In such an environment, the high current flowing through the resistive electrodes causes a voltage drop, which reduces the performance of the DLC-RPC. This voltage drop can be suppressed by implementing a current evacuation pattern, though discharges are more likely to occur near the pattern. Therefore the pattern must be covered by a protection cover made of an insulator. In this study, electrode samples with the current evacuation pattern and different widths of protection cover (0.2 mm and 0.8 mm) have been produced, and their performance and stability were measured. The detection efficiency of the single-gap for $\\beta$-ray from a $^{90}$Sr source was measured to be up to approximately 60 % in both electrode samples. The target efficiency can be achieved even with a drop of 100 $-$ 150 V. On the other hand, after more than a dozen hours of operation, discharges suddenly occurred and the detector was prevented from further operation. These discharges created current paths on the spacing pillars. This serious problem must be investigated and solved in the future."
    },
    "2501.10404v1": {
      "title": "Automated Detection of Epileptic Spikes and Seizures Incorporating a Novel Spatial Clustering Prior",
      "url": "http://arxiv.org/abs/2501.10404v1",
      "authors": "Hanyang Dong, Shurong Sheng, Xiongfei Wang, Jiahong Gao, Yi Sun, Wanli Yang, Kuntao Xiao, Pengfei Teng, Guoming Luan, Zhao Lv",
      "update_time": "2025-01-05",
      "abstract": "A Magnetoencephalography (MEG) time-series recording consists of multi-channel signals collected by superconducting sensors, with each signal's intensity reflecting magnetic field changes over time at the sensor location. Automating epileptic MEG spike detection significantly reduces manual assessment time and effort, yielding substantial clinical benefits. Existing research addresses MEG spike detection by encoding neural network inputs with signals from all channel within a time segment, followed by classification. However, these methods overlook simultaneous spiking occurred from nearby sensors. We introduce a simple yet effective paradigm that first clusters MEG channels based on their sensor's spatial position. Next, a novel convolutional input module is designed to integrate the spatial clustering and temporal changes of the signals. This module is fed into a custom MEEG-ResNet3D developed by the authors, which learns to extract relevant features and classify the input as a spike clip or not. Our method achieves an F1 score of 94.73% on a large real-world MEG dataset Sanbo-CMR collected from two centers, outperforming state-of-the-art approaches by 1.85%. Moreover, it demonstrates efficacy and stability in the Electroencephalographic (EEG) seizure detection task, yielding an improved weighted F1 score of 1.4% compared to current state-of-the-art techniques evaluated on TUSZ, whch is the largest EEG seizure dataset."
    },
    "2412.19622v1": {
      "title": "Signatures of prediction during natural listening in MEG data?",
      "url": "http://arxiv.org/abs/2412.19622v1",
      "authors": "Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut G\u00fc\u00e7l\u00fc, Linda Geerligs",
      "update_time": "2024-12-27",
      "abstract": "The brain uses contextual information and prior knowledge to anticipate upcoming content during language comprehension. Recent research has shown predictive signals can be revealed in pre-onset ECoG activity during naturalistic narrative listening, by building encoding models based on word embeddings from Large Language Models (LLMs). Similarly, evidence for long-range predictive encoding has been observed in fMRI data, where incorporating embeddings for multiple upcoming words in a narrative improves alignment with brain activity. This study examines whether similar predictive information can be detected in MEG, a technique with higher temporal resolution than fMRI but a lower signal-to-noise ratio than ECoG. Our findings indicate that MEG captures pre-onset representations up to 1 second before word onset, consistent with ECoG results. However, unlike fMRI findings, incorporating future word embeddings did not enhance MEG encoding, even for one word into the future, which suggests that the pre-onset encoding may not reflect predictive processing. This work demonstrates that MEG combined with LLMs is a valuable approach for studying language processing in naturalistic narratives and highlights the need to study further what constitutes evidence for prediction during natural listening."
    }
  },
  "neuroAI": {
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": "https://github.com/henri-edinb/async_learning"
    },
    "2411.18526v1": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v1",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias",
      "update_time": "2024-11-27",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety."
    },
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research."
    },
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2302.07243v4": {
      "title": "A Deep Probabilistic Spatiotemporal Framework for Dynamic Graph Representation Learning with Application to Brain Disorder Identification",
      "url": "http://arxiv.org/abs/2302.07243v4",
      "authors": "Sin-Yee Yap, Junn Yong Loo, Chee-Ming Ting, Fuad Noman, Raphael C. -W. Phan, Adeel Razi, David L. Dowe",
      "update_time": "2024-11-09",
      "abstract": "Recent applications of pattern recognition techniques on brain connectome classification using functional connectivity (FC) are shifting towards acknowledging the non-Euclidean topology and dynamic aspects of brain connectivity across time. In this paper, a deep spatiotemporal variational Bayes (DSVB) framework is proposed to learn time-varying topological structures in dynamic FC networks for identifying autism spectrum disorder (ASD) in human participants. The framework incorporates a spatial-aware recurrent neural network with an attention-based message passing scheme to capture rich spatiotemporal patterns across dynamic FC networks. To overcome model overfitting on limited training datasets, an adversarial training strategy is introduced to learn graph embedding models that generalize well to unseen brain networks. Evaluation on the ABIDE resting-state functional magnetic resonance imaging dataset shows that our proposed framework substantially outperforms state-of-the-art methods in identifying patients with ASD. Dynamic FC analyses with DSVB-learned embeddings reveal apparent group differences between ASD and healthy controls in brain network connectivity patterns and switching dynamics of brain states. The code is available at https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes.",
      "code_url": "https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes"
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    }
  },
  "medical": {
    "2501.17160v1": {
      "title": "A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images",
      "url": "http://arxiv.org/abs/2501.17160v1",
      "authors": "Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham",
      "update_time": "2025-01-28",
      "abstract": "Early detection of COVID-19 is crucial for effective treatment and controlling its spread. This study proposes a novel hybrid deep learning model for detecting COVID-19 from CT scan images, designed to assist overburdened medical professionals. Our proposed model leverages the strengths of VGG16, DenseNet121, and MobileNetV2 to extract features, followed by Principal Component Analysis (PCA) for dimensionality reduction, after which the features are stacked and classified using a Support Vector Classifier (SVC). We conducted comparative analysis between the proposed hybrid model and individual pre-trained CNN models, using a dataset of 2,108 training images and 373 test images comprising both COVID-positive and non-COVID images. Our proposed hybrid model achieved an accuracy of 98.93%, outperforming the individual models in terms of precision, recall, F1 scores, and ROC curve performance."
    },
    "2501.17158v1": {
      "title": "Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain Research",
      "url": "http://arxiv.org/abs/2501.17158v1",
      "authors": "Fahad Salman, Abhisri Ramesh, Thomas Jochmann, Mirjam Prayer, Ademola Adegbemigun, Jack A. Reeves, Gregory E. Wilding, Junghun Cho, Dejan Jakimovski, Niels Bergsland, Michael G. Dwyer, Robert Zivadinov, Ferdinand Schweser",
      "update_time": "2025-01-28",
      "abstract": "Background: Quantitative susceptibility mapping (QSM) of the brain is an advanced MRI technique for assessing tissue characteristics based on magnetic susceptibility, which varies with the composition of the tissue, such as iron, calcium, and myelin levels. QSM consists of multiple processing steps, with various choices for each step. Despite its increasing application in detecting and monitoring neurodegenerative diseases, the impact of algorithmic choices in QSM's workflow on clinical outcomes has not been thoroughly quantified.   Objective: This study aimed to evaluate how choices in background field removal (BFR), dipole inversion algorithms, and anatomical referencing impact the sensitivity and reproducibility error of QSM in detecting group-level and longitudinal changes in deep gray matter susceptibility in a clinical setting.   Methods: We compared 378 different QSM pipelines using a 10-year follow-up dataset of healthy adults. We analyzed the sensitivity of pipelines to detect known aging-related susceptibility changes in the DGM over time.   Results: We found high variability in the sensitivity of QSM pipelines to detect susceptibility changes. The study highlighted that while most pipelines could detect changes reliably, the choice of BFR algorithm and the referencing strategy substantially influenced the outcome reproducibility error and sensitivity. Notably, pipelines using RESHARP with AMP-PE, HEIDI or LSQR inversion showed the highest overall sensitivity.   Conclusions: The findings underscore the critical influence of algorithmic choices in QSM processing on the accuracy and reliability of detecting physiological changes in the brain. This has profound implications for clinical research and trials where QSM is used as a biomarker for disease progression, highlighting that careful consideration should be given to pipeline configuration to optimize clinical outcomes."
    },
    "2501.17152v1": {
      "title": "Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model",
      "url": "http://arxiv.org/abs/2501.17152v1",
      "authors": "Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani",
      "update_time": "2025-01-28",
      "abstract": "Three-dimensional (3D) multi-slab acquisition is a technique frequently employed in high-resolution diffusion-weighted MRI in order to achieve the best signal-to-noise ratio (SNR) efficiency. However, this technique is limited by slab boundary artifacts that cause intensity fluctuations and aliasing between slabs which reduces the accuracy of anatomical imaging. Addressing this issue is crucial for advancing diffusion MRI quality and making high-resolution imaging more feasible for clinical and research applications. In this work, we propose a regularized slab profile encoding (PEN) method within a Plug-and-Play ADMM framework, incorporating multi-scale energy (MuSE) regularization to effectively improve the slab combined reconstruction. Experimental results demonstrate that the proposed method significantly improves image quality compared to non-regularized and TV-regularized PEN approaches. The regularized PEN framework provides a more robust and efficient solution for high-resolution 3D diffusion MRI, potentially enabling clearer, more reliable anatomical imaging across various applications."
    },
    "2501.17083v1": {
      "title": "Experimental Outdoor Performance Evaluation of TVWS Narrowband Data Communication using SDR Platform",
      "url": "http://arxiv.org/abs/2501.17083v1",
      "authors": "Muneer M. AlZubi, Mohamed-Slim Alouini",
      "update_time": "2025-01-28",
      "abstract": "Large-scale deployment of Internet of Things (IoT) networks in the industrial, scientific, and medical (ISM) band leads to spectrum congestion and requires multiple gateways to cover wide areas. This will increase cost, complexity, and energy consumption. TV White Spaces (TVWS) provides an abundant spectrum that is sufficient for low data rate IoT applications. This low-frequency band offers coverage over larger areas due to the ability of wireless signals to penetrate obstacles and terrain. In this paper, we examine the performance of narrowband data communications in TVWS through an outdoor experiment in a suburban area with line-of-sight (LOS) and non-line-of-sight (NLOS) propagation scenarios. We implement a software-defined radio (SDR) testbed and develop a GNU radio benchmark tool to perform outdoor experiments for TVWS narrowband data communication between a gateway and wireless nodes at various locations. The results reveal that the system can achieve a throughput of up to 97 Kbps with a packet error rate (PER) and packet loss rate (PLR) under 1% over NLOS paths, making it suitable for low-data rate applications. This work offers valuable insights for designing the physical layer of narrowband white space devices (WSDs). The developed benchmark tool will also greatly assist other researchers in evaluating the performance of SDR-based communication systems."
    },
    "2501.16992v1": {
      "title": "FedEFM: Federated Endovascular Foundation Model with Unseen Data",
      "url": "http://arxiv.org/abs/2501.16992v1",
      "authors": "Tuong Do, Nghia Vu, Tudor Jianu, Baoru Huang, Minh Vu, Jionglong Su, Erman Tjiputra, Quang D. Tran, Te-Chuan Chiu, Anh Nguyen",
      "update_time": "2025-01-28",
      "abstract": "In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain."
    },
    "2501.16959v1": {
      "title": "Assessing ultrasonic and optical flow velocimetry in a millifluidic device using oil-in-water emulsions as blood mimicking fluid",
      "url": "http://arxiv.org/abs/2501.16959v1",
      "authors": "Estelle Lu, Williams Flores Cisternas, H\u00e9lo\u00efse Uhl, Alexandre Chargueraud, Quentin Grimal, Guillaume Renaud, Jean-Gabriel Minonzio, Jacques Fattaccioli",
      "update_time": "2025-01-28",
      "abstract": "Blood-mimicking fluids (BMFs) play a critical role in ultrasonic imaging and Doppler flow studies by replicating the physical and acoustic properties of blood. This study introduces a novel soybean oil-in-water emulsion as a BMF with particle size and deformability akin to red blood cells. Using a millifluidic device, we cross-validated flow profiles through both Doppler velocimetry and optical particle tracking, demonstrating compatibility with theoretical Poiseuille flow models. The millifluidic chip, fabricated via stereolithography, provided an optimized platform for dual optical and ultrasonic assessments. Results showed strong agreement between the two methods across a range of flow rates, affirming the suitability of the emulsion for velocimetry applications. Furthermore, the acoustic properties of soybean oil droplets support their potential as an echogenic and stable alternative to conventional BMFs."
    },
    "2501.16910v1": {
      "title": "A Probabilistic Model of Bilateral Lymphatic Spread in Head and Neck Cancer",
      "url": "http://arxiv.org/abs/2501.16910v1",
      "authors": "Roman Ludwig, Yoel Perez Haas, Sergi Benavente, Panagiotis Balermpas, Jan Unkelbach",
      "update_time": "2025-01-28",
      "abstract": "Current guidelines for elective nodal irradiation in oropharyngeal squamous cell carcinoma (OPSCC) recommend including large portions of the contralateral lymph system in the clinical target volume (CTV-N), even for lateralized tumors with no clinical lymph node involvement in the contralateral neck. This study introduces a probabilistic model of bilateral lymphatic tumor progression in OPSCC to estimate personalized risks of occult disease in specific lymph node levels (LNLs) based on clinical involvement, T-stage, and tumor lateralization. Building on a previously developed hidden Markov model for ipsilateral spread, we extend the approach to the contralateral neck. The model represents LNLs I, II, III, IV, V, and VII on both sides of the neck as binary hidden variables (healthy/involved), connected via arcs representing spread probabilities. These probabilities are learned using Markov chain Monte Carlo (MCMC) sampling from a dataset of 833 OPSCC patients, enabling the model to reflect the underlying lymphatic progression dynamics. The model accurately and precisely describes observed patterns of involvement with a compact set of interpretable parameters. Midline extension of the primary tumor is identified as the primary risk factor for contralateral involvement, with advanced T-stage and extensive ipsilateral involvement further increasing risk. Occult disease in contralateral LNL III is highly unlikely if upstream LNL II is clinically negative, and in contralateral LNL IV, occult disease is exceedingly rare without LNL III involvement. For lateralized tumors not crossing the midline, the model suggests the contralateral neck may safely be excluded from the CTV-N. For tumors extending across the midline but with a clinically negative contralateral neck, the CTV-N could be limited to LNL II, reducing unnecessary exposure of normal tissue while maintaining regional tumor control."
    },
    "2501.16906v1": {
      "title": "Medical Physics Dataset Article: a database of FLASH Murine In-Vivo Studies",
      "url": "http://arxiv.org/abs/2501.16906v1",
      "authors": "Mathilde Toschini, Isabella Colizzi, Antony John Lomax, Serena Psoroulas",
      "update_time": "2025-01-28",
      "abstract": "The FLASH effect refers to a lower normal tissue damage for an equivalent tumour response, potentially widening the therapeutic window for radiotherapy. Although this effect has been demonstrated in various experiments using different types of particles and irradiation parameters, the underlying mechanism is not yet clearly understood. Uncertainties surround the conducted experiments, the explored parameter space, and the variability of reported results. To gain a better overview, we created a dataset that includes in-vivo FLASH experiments. This dataset documents all machine and biological dosimetric parameters, and for determined endpoints, it includes the outcome of the experiment. Our goal is to increase awareness of the results and their variability and provide a useful research and analysis tool for the community. The database contains peer-reviewed papers published until March 2024 on the FLASH in-vivo (murine) experiments. From each paper, previously defined parameters have been manually extracted and/or recalculated to ensure compatibility within the database entries. We provide two types of datasets: a user-friendly web-based Notion database and spreadsheets on a Zenodo repository. The database contains all the reviewed papers with extracted information in text or numeric form. Users can duplicate the database or view, search, filter, and reorganise online entries. The spreadsheets contain the data for the most analysed endpoints, allowing a comparative analysis. The study has two main applications. The web-based database will allow for a user-friendly search of information and meta-data of all published FLASH murine data. This will facilitate future research efforts to better understand the FLASH effect. The spreadsheets are a simple and useful tool for the community to conduct statistical analysis and determine the parameters associated with the FLASH effect."
    },
    "2501.16864v1": {
      "title": "A methodology and a platform for high-quality rich personal data collection",
      "url": "http://arxiv.org/abs/2501.16864v1",
      "authors": "Ivan Kayongo, Leonardo Malcotti, Haonan Zhao, Fausto Giunchiglia",
      "update_time": "2025-01-28",
      "abstract": "In the last years the pervasive use of sensors, as they exist in smart devices, e.g., phones, watches, medical devices, has increased dramatically the availability of personal data. However, existing research on data collection primarily focuses on the objective view of reality, as provided, for instance, by sensors, often neglecting the integration of subjective human input, as provided, for instance, by user answers to questionnaires. This limits substantially the exploitability of the collected data. In this paper we present a methodology and a platform specifically designed for the collection of a combination of large-scale sensor data and qualitative human feedback. The methodology has been designed to be deployed on top, and enriches the functionalities of, an existing data collection APP, called iLog, which has been used in large scale, worldwide data collection experiments. The main goal is to put the key actors involved in an experiment, i.e., the researcher in charge, the participant, and iLog in better control of the experiment itself, thus enabling a much improved quality and richness of the data collected. The novel functionalities of the resulting platform are: (i) a time-wise representation of the situational context within which the data collection is performed, (ii) an explicit representation of the temporal context within which the data collection is performed, (iii) a calendar-based dashboard for the real-time monitoring of the data collection context(s), and, finally, (iv) a mechanism for the run-time revision of the data collection plan. The practicality and utility of the proposed functionalities are demonstrated by showing how they apply to a case study involving 350 University students."
    },
    "2501.16840v1": {
      "title": "Dosimetric impact of real-time re-optimization of proton pencil-beam scanning for moving targets",
      "url": "http://arxiv.org/abs/2501.16840v1",
      "authors": "Ivar Bengtsson, Anders Forsgren, Albin Fredriksson",
      "update_time": "2025-01-28",
      "abstract": "When treating moving tumors, the precise delivery of proton therapy by pencil beam scanning (PBS) is challenged by the interplay effect. Although several 4D-optimization methods have been proposed, what is the most beneficial motion management technique is still an open question. In this study, we wish to investigate the dosimetric impact of re-optimizing the PBS spot weights during the treatment delivery in response to, and in anticipation of, variations in the patient's breathing pattern. We simulate for PBS the implementation of a real-time adaptive framework based on principles from receding horizon control. We consider the patient motion as characterized by a one-dimensional amplitude signal and a 4DCT, to simulate breathing of variable frequency. The framework tracks the signal and predicts the future motion with uncertainty increasing with the length of the prediction horizon. After each delivered energy layer, the framework re-optimizes the spot weights of the next layer based on the delivered dose and the predicted motion. For three lung patients, we generate 500 variable breathing patterns to evaluate the dosimetric results of the framework and compare them to those of implementations of previously proposed non-adaptive methods. Compared to the best non-adaptive method, the adaptive framework improves the CTV D98 in the near-worst breathing scenario (5th percentile), from 96.4 to 98.9 % of the prescribed dose and considerably reduces the variation as measured by a mean decrease in the inter-quartile range by more than 80 %. The target coverage improvements are achieved without generally compromising target dose homogeneity or OAR dose. The study indicates that a motion-adaptive approach based on re-optimization of spot weights during delivery has the potential to substantially improve the dosimetric performance of PBS given fast and accurate models of patient motion."
    }
  }
}