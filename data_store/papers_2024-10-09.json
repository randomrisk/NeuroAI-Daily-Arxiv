{
  "Brain": {
    "2410.05266v1": {
      "title": "Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers",
      "url": "http://arxiv.org/abs/2410.05266v1",
      "authors": "Andrew F. Luo, Jacob Yeung, Rushikesh Zawar, Shaurya Dewan, Margaret M. Henderson, Leila Wehbe, Michael J. Tarr",
      "update_time": "2024-10-07",
      "abstract": "Advances in large-scale artificial neural networks have facilitated novel insights into the functional topology of the brain. Here, we leverage this approach to study how semantic categories are organized in the human visual cortex. To overcome the challenge presented by the co-occurrence of multiple categories in natural images, we introduce BrainSAIL (Semantic Attribution and Image Localization), a method for isolating specific neurally-activating visual concepts in images. BrainSAIL exploits semantically consistent, dense spatial features from pre-trained vision models, building upon their demonstrated ability to robustly predict neural activity. This method derives clean, spatially dense embeddings without requiring any additional training, and employs a novel denoising process that leverages the semantic consistency of images under random augmentations. By unifying the space of whole-image embeddings and dense visual features and then applying voxel-wise encoding models to these features, we enable the identification of specific subregions of each image which drive selectivity patterns in different areas of the higher visual cortex. We validate BrainSAIL on cortical regions with known category selectivity, demonstrating its ability to accurately localize and disentangle selectivity to diverse visual concepts. Next, we demonstrate BrainSAIL's ability to characterize high-level visual selectivity to scene properties and low-level visual features such as depth, luminance, and saturation, providing insights into the encoding of complex visual information. Finally, we use BrainSAIL to directly compare the feature selectivity of different brain encoding models across different regions of interest in visual cortex. Our innovative method paves the way for significant advances in mapping and decomposing high-level visual representations in the human brain."
    },
    "2410.05245v1": {
      "title": "Rosette spectroscopic imaging for whole-brain metabolite mapping at 7T: acceleration potential and reproducibility",
      "url": "http://arxiv.org/abs/2410.05245v1",
      "authors": "Zhiwei Huang, Uzay Emir, Andre Doring, Antoine Klauser, Ying Xiao, Mark Widmaier, Lijing Xin",
      "update_time": "2024-10-07",
      "abstract": "Whole-brain proton magnetic resonance spectroscopic imaging (1H-MRSI) is a non-invasive technique for assessing neurochemical distribution in the brain, offering valuable insights into brain functions and neural diseases. It greatly benefits from the improved SNR at ultrahigh field strengths ($\\geq$7T). However, 1H-MRSI still faces several challenges, such as long acquisition time and severe signal contaminations from water and lipids. In this study, 2D and 3D short TR/TE 1H-FID-MRSI sequences using rosette trajectories were developed with spatial resolutions of 4.48$\\times$4.48 mm$^2$ and 4.48$\\times$4.48$\\times$4.50 mm$^3$, respectively. Water signals were suppressed using an optimized Five-variable-Angle-gaussian-pulses-with-ShorT-total-duration of 76 ms (FAST) water suppression scheme, and lipid signals were removed using the L2 regularization method. Metabolic maps of major 1H metabolites were obtained within 5:40 min with 16 averages and 1 average for the 2D and 3D acquisitions, respectively. Excellent inter-session reproducibility was shown, with the coefficients of variance (CV) being lower than 6% for N-Acetyle-L-aspartic acid (NAA), Glutamate (Glu), Choline Chloride and glycerophosphocholine (tCho), Creatine and Phosphocreatine (tCr), and Glycine and Myo-inositol (Gly+Ins). To explore the potential of further accelerating the acquisition, compressed sensing was applied retrospectively to the 3D datasets. The structural similarity index (SSIM) remained above 0.85 and 0.8 until $R = 2$ and $R = 3$ for the metabolite maps of Glu, NAA, tCr, and tCho, indicating the possibility for further reduction of acquisition time to around 2min."
    },
    "2410.05027v1": {
      "title": "Bi-Directional MS Lesion Filling and Synthesis Using Denoising Diffusion Implicit Model-based Lesion Repainting",
      "url": "http://arxiv.org/abs/2410.05027v1",
      "authors": "Jinwei Zhang, Lianrui Zuo, Yihao Liu, Samuel Remedios, Bennett A. Landman, Jerry L. Prince, Aaron Carass",
      "update_time": "2024-10-07",
      "abstract": "Automatic magnetic resonance (MR) image processing pipelines are widely used to study people with multiple sclerosis (PwMS), encompassing tasks such as lesion segmentation and brain parcellation. However, the presence of lesion often complicates these analysis, particularly in brain parcellation. Lesion filling is commonly used to mitigate this issue, but existing lesion filling algorithms often fall short in accurately reconstructing realistic lesion-free images, which are vital for consistent downstream analysis. Additionally, the performance of lesion segmentation algorithms is often limited by insufficient data with lesion delineation as training labels. In this paper, we propose a novel approach leveraging Denoising Diffusion Implicit Models (DDIMs) for both MS lesion filling and synthesis based on image inpainting. Our modified DDIM architecture, once trained, enables both MS lesion filing and synthesis. Specifically, it can generate lesion-free T1-weighted or FLAIR images from those containing lesions; Or it can add lesions to T1-weighted or FLAIR images of healthy subjects. The former is essential for downstream analyses that require lesion-free images, while the latter is valuable for augmenting training datasets for lesion segmentation tasks. We validate our approach through initial experiments in this paper and demonstrate promising results in both lesion filling and synthesis, paving the way for future work."
    },
    "2410.04992v1": {
      "title": "MC-QDSNN: Quantized Deep evolutionary SNN with Multi-Dendritic Compartment Neurons for Stress Detection using Physiological Signals",
      "url": "http://arxiv.org/abs/2410.04992v1",
      "authors": "Ajay B. S., Phani Pavan K, Madhav Rao",
      "update_time": "2024-10-07",
      "abstract": "Long short-term memory (LSTM) has emerged as a definitive network for analyzing and inferring time series data. LSTM has the capability to extract spectral features and a mixture of temporal features. Due to this benefit, a similar feature extraction method is explored for the spiking counterparts targeting time-series data. Though LSTMs perform well in their spiking form, they tend to be compute and power intensive. Addressing this issue, this work proposes Multi-Compartment Leaky (MCLeaky) neuron as a viable alternative for efficient processing of time series data. The MCLeaky neuron, derived from the Leaky Integrate and Fire (LIF) neuron model, contains multiple memristive synapses interlinked to form a memory component, which emulates the human brain's Hippocampus region. The proposed MCLeaky neuron based Spiking Neural Network model and its quantized variant were benchmarked against state-of-the-art (SOTA) Spiking LSTMs to perform human stress detection, by comparing compute requirements, latency and real-world performances on unseen data with models derived through Neural Architecture Search (NAS). Results show that networks with MCLeaky activation neuron managed a superior accuracy of 98.8% to detect stress based on Electrodermal Activity (EDA) signals, better than any other investigated models, while using 20% less parameters on average. MCLeaky neuron was also tested for various signals including EDA Wrist and Chest, Temperature, ECG, and combinations of them. Quantized MCLeaky model was also derived and validated to forecast their performance on hardware architectures, which resulted in 91.84% accuracy. The neurons were evaluated for multiple modalities of data towards stress detection, which resulted in energy savings of 25.12x to 39.20x and EDP gains of 52.37x to 81.9x over ANNs, while offering a best accuracy of 98.8% when compared with the rest of the SOTA implementations."
    },
    "2410.04785v1": {
      "title": "Towards Ultra-Low-Power Neuromorphic Speech Enhancement with Spiking-FullSubNet",
      "url": "http://arxiv.org/abs/2410.04785v1",
      "authors": "Xiang Hao, Chenxiang Ma, Qu Yang, Jibin Wu, Kay Chen Tan",
      "update_time": "2024-10-07",
      "abstract": "Speech enhancement is critical for improving speech intelligibility and quality in various audio devices. In recent years, deep learning-based methods have significantly improved speech enhancement performance, but they often come with a high computational cost, which is prohibitive for a large number of edge devices, such as headsets and hearing aids. This work proposes an ultra-low-power speech enhancement system based on the brain-inspired spiking neural network (SNN) called Spiking-FullSubNet. Spiking-FullSubNet follows a full-band and sub-band fusioned approach to effectively capture both global and local spectral information. To enhance the efficiency of computationally expensive sub-band modeling, we introduce a frequency partitioning method inspired by the sensitivity profile of the human peripheral auditory system. Furthermore, we introduce a novel spiking neuron model that can dynamically control the input information integration and forgetting, enhancing the multi-scale temporal processing capability of SNN, which is critical for speech denoising. Experiments conducted on the recent Intel Neuromorphic Deep Noise Suppression (N-DNS) Challenge dataset show that the Spiking-FullSubNet surpasses state-of-the-art methods by large margins in terms of both speech quality and energy efficiency metrics. Notably, our system won the championship of the Intel N-DNS Challenge (Algorithmic Track), opening up a myriad of opportunities for ultra-low-power speech enhancement at the edge. Our source code and model checkpoints are publicly available at https://github.com/haoxiangsnr/spiking-fullsubnet."
    },
    "2410.04497v1": {
      "title": "Generalizability analysis of deep learning predictions of human brain responses to augmented and semantically novel visual stimuli",
      "url": "http://arxiv.org/abs/2410.04497v1",
      "authors": "Valentyn Piskovskyi, Riccardo Chimisso, Sabrina Patania, Tom Foulsham, Giuseppe Vizzari, Dimitri Ognibene",
      "update_time": "2024-10-06",
      "abstract": "The purpose of this work is to investigate the soundness and utility of a neural network-based approach as a framework for exploring the impact of image enhancement techniques on visual cortex activation. In a preliminary study, we prepare a set of state-of-the-art brain encoding models, selected among the top 10 methods that participated in The Algonauts Project 2023 Challenge [16]. We analyze their ability to make valid predictions about the effects of various image enhancement techniques on neural responses. Given the impossibility of acquiring the actual data due to the high costs associated with brain imaging procedures, our investigation builds up on a series of experiments. Specifically, we analyze the ability of brain encoders to estimate the cerebral reaction to various augmentations by evaluating the response to augmentations targeting objects (i.e., faces and words) with known impact on specific areas. Moreover, we study the predicted activation in response to objects unseen during training, exploring the impact of semantically out-of-distribution stimuli. We provide relevant evidence for the generalization ability of the models forming the proposed framework, which appears to be promising for the identification of the optimal visual augmentation filter for a given task, model-driven design strategies as well as for AR and VR applications."
    },
    "2410.04460v1": {
      "title": "U-net based prediction of cerebrospinal fluid distribution and ventricular reflux grading",
      "url": "http://arxiv.org/abs/2410.04460v1",
      "authors": "Melanie Rieff, Fabian Holzberger, Oksana Lapina, Geir Ringstad, Lars Magnus Valnes, Bogna Warsza, Kent-Andre Mardal, Per Kristian Eide, Barbara Wohlmuth",
      "update_time": "2024-10-06",
      "abstract": "Previous work shows evidence that cerebrospinal fluid (CSF) plays a crucial role in brain waste clearance processes, and that altered flow patterns are associated with various diseases of the central nervous system. In this study, we investigate the potential of deep learning to predict the distribution in human brain of a gadolinium-based CSF contrast agent (tracer) administered intrathecal. For this, T1-weighted magnetic resonance imaging (MRI) scans taken at multiple time points before and after intrathecal injection were utilized. We propose a U-net-based supervised learning model to predict pixel-wise signal increases at their peak after 24 hours. Its performance is evaluated based on different tracer distribution stages provided during training, including predictions from baseline scans taken before injection. Our findings indicate that using imaging data from just the first two hours post-injection for training yields tracer flow predictions comparable to those trained with additional later-stage scans. The model was further validated by comparing ventricular reflux gradings provided by neuroradiologists, and inter-rater grading among medical experts and the model showed excellent agreement. Our results demonstrate the potential of deep learning-based methods for CSF flow prediction, suggesting that fewer MRI scans could be sufficient for clinical analysis, which might significantly improve clinical efficiency, patient well-being, and lower healthcare costs."
    },
    "2410.04383v1": {
      "title": "BrainCodec: Neural fMRI codec for the decoding of cognitive brain states",
      "url": "http://arxiv.org/abs/2410.04383v1",
      "authors": "Yuto Nishimura, Masataka Sawayama, Ayumu Yamashita, Hideki Nakayama, Kaoru Amano",
      "update_time": "2024-10-06",
      "abstract": "Recently, leveraging big data in deep learning has led to significant performance improvements, as confirmed in applications like mental state decoding using fMRI data. However, fMRI datasets remain relatively small in scale, and the inherent issue of low signal-to-noise ratios (SNR) in fMRI data further exacerbates these challenges. To address this, we apply compression techniques as a preprocessing step for fMRI data. We propose BrainCodec, a novel fMRI codec inspired by the neural audio codec. We evaluated BrainCodec's compression capability in mental state decoding, demonstrating further improvements over previous methods. Furthermore, we analyzed the latent representations obtained through BrainCodec, elucidating the similarities and differences between task and resting state fMRI, highlighting the interpretability of BrainCodec. Additionally, we demonstrated that fMRI reconstructions using BrainCodec can enhance the visibility of brain activity by achieving higher SNR, suggesting its potential as a novel denoising method. Our study shows that BrainCodec not only enhances performance over previous methods but also offers new analytical possibilities for neuroscience. Our codes, dataset, and model weights are available at https://github.com/amano-k-lab/BrainCodec.",
      "code_url": "https://github.com/amano-k-lab/braincodec"
    },
    "2410.04128v1": {
      "title": "Optimizing Medical Image Segmentation with Advanced Decoder Design",
      "url": "http://arxiv.org/abs/2410.04128v1",
      "authors": "Weibin Yang, Zhiqi Dong, Mingyuan Xu, Longwei Xu, Dehua Geng, Yusong Li, Pengwei Wang",
      "update_time": "2024-10-05",
      "abstract": "U-Net is widely used in medical image segmentation due to its simple and flexible architecture design. To address the challenges of scale and complexity in medical tasks, several variants of U-Net have been proposed. In particular, methods based on Vision Transformer (ViT), represented by Swin UNETR, have gained widespread attention in recent years. However, these improvements often focus on the encoder, overlooking the crucial role of the decoder in optimizing segmentation details. This design imbalance limits the potential for further enhancing segmentation performance. To address this issue, we analyze the roles of various decoder components, including upsampling method, skip connection, and feature extraction module, as well as the shortcomings of existing methods. Consequently, we propose Swin DER (i.e., Swin UNETR Decoder Enhanced and Refined) by specifically optimizing the design of these three components. Swin DER performs upsampling using learnable interpolation algorithm called offset coordinate neighborhood weighted up sampling (Onsampling) and replaces traditional skip connection with spatial-channel parallel attention gate (SCP AG). Additionally, Swin DER introduces deformable convolution along with attention mechanism in the feature extraction module of the decoder. Our model design achieves excellent results, surpassing other state-of-the-art methods on both the Synapse and the MSD brain tumor segmentation task.   Code is available at: https://github.com/WillBeanYang/Swin-DER"
    },
    "2410.04097v1": {
      "title": "TV-based Deep 3D Self Super-Resolution for fMRI",
      "url": "http://arxiv.org/abs/2410.04097v1",
      "authors": "Fernando P\u00e9rez-Bueno, Hongwei Bran Li, Shahin Nasr, Cesar Caballero-Gaudes, Juan Eugenio Iglesias",
      "update_time": "2024-10-05",
      "abstract": "While functional Magnetic Resonance Imaging (fMRI) offers valuable insights into cognitive processes, its inherent spatial limitations pose challenges for detailed analysis of the fine-grained functional architecture of the brain. More specifically, MRI scanner and sequence specifications impose a trade-off between temporal resolution, spatial resolution, signal-to-noise ratio, and scan time. Deep Learning (DL) Super-Resolution (SR) methods have emerged as a promising solution to enhance fMRI resolution, generating high-resolution (HR) images from low-resolution (LR) images typically acquired with lower scanning times. However, most existing SR approaches depend on supervised DL techniques, which require training ground truth (GT) HR data, which is often difficult to acquire and simultaneously sets a bound for how far SR can go. In this paper, we introduce a novel self-supervised DL SR model that combines a DL network with an analytical approach and Total Variation (TV) regularization. Our method eliminates the need for external GT images, achieving competitive performance compared to supervised DL techniques and preserving the functional maps."
    }
  },
  "EEG": {
    "2410.03385v1": {
      "title": "From Epilepsy Seizures Classification to Detection: A Deep Learning-based Approach for Raw EEG Signals",
      "url": "http://arxiv.org/abs/2410.03385v1",
      "authors": "Davy Darankoum, Manon Villalba, Clelia Allioux, Baptiste Caraballo, Carine Dumont, Eloise Gronlier, Corinne Roucard, Yann Roche, Chloe Habermacher, Sergei Grudinin, Julien Volle",
      "update_time": "2024-10-04",
      "abstract": "Epilepsy represents the most prevalent neurological disease in the world. One-third of people suffering from mesial temporal lobe epilepsy (MTLE) exhibit drug resistance, urging the need to develop new treatments. A key part in anti-seizure medication (ASM) development is the capability of detecting and quantifying epileptic seizures occurring in electroencephalogram (EEG) signals, which is crucial for treatment efficacy evaluation. In this study, we introduced a seizure detection pipeline based on deep learning models applied to raw EEG signals. This pipeline integrates: a new pre-processing technique which segments continuous raw EEG signals without prior distinction between seizure and seizure-free activities; a post-processing algorithm developed to reassemble EEG segments and allow the identification of seizures start/end; and finally, a new evaluation procedure based on a strict seizure events comparison between predicted and real labels. Models training have been performed using a data splitting strategy which addresses the potential for data leakage. We demonstrated the fundamental differences between a seizure classification and a seizure detection task and showed the differences in performance between the two tasks. Finally, we demonstrated the generalization capabilities across species of our best architecture, combining a Convolutional Neural Network and a Transformer encoder. The model was trained on animal EEGs and tested on human EEGs with a F1-score of 93% on a balanced Bonn dataset."
    },
    "2410.03261v1": {
      "title": "Simulated Eyeblink Artifact Removal with ICA: Effect of Measurement Uncertainty",
      "url": "http://arxiv.org/abs/2410.03261v1",
      "authors": "Jennie Couchman, Orestis Kaparounakis, Chatura Samarakoon, Phillip Stanley-Marbell",
      "update_time": "2024-10-04",
      "abstract": "Independent Component Analysis (ICA) is commonly-used in electroencephalogram (EEG) signal processing to remove non-cerebral artifacts from cerebral data. Despite the ubiquity of ICA, the effect of measurement uncertainty on the artifact removal process has not been thoroughly investigated. We first characterize the measurement uncertainty distribution of a common ADC and show that it quantitatively conforms to a Gaussian distribution. We then evaluate the effect of measurement uncertainty on the artifact identification process through several computer simulations. These computer simulations evaluate the performance of two different ICA algorithms, FastICA and Infomax, in removing eyeblink artifacts from five different electrode configurations with varying levels of measurement uncertainty. FastICA and Infomax show similar performance in identifying the eyeblink artifacts for a given uncertainty level and electrode configuration. We quantify the correlation performance degradation with respect to SNR and show that in general, an SNR of greater than 15 dB results in less than a 5% degradation in performance. The biggest difference in performance between the two algorithms is in their execution time. FastICA's execution time is dependent on the amount of measurement uncertainty, with a 50% to 85% reduction in execution time over an SNR range of 20 dB. This contrasts with Infomax's execution time, which is unaffected by measurement uncertainty."
    },
    "2410.03191v1": {
      "title": "Nested Deep Learning Model: A Foundation Model for Brain Signal Data",
      "url": "http://arxiv.org/abs/2410.03191v1",
      "authors": "Fangyi Wei, Jiajie Mo, Kai Zhang, Haipeng Shen, Srikantan Nagarajan, Fei Jiang",
      "update_time": "2024-10-04",
      "abstract": "Epilepsy affects over 50 million people globally, with EEG/MEG-based spike detection playing a crucial role in diagnosis and treatment. Manual spike identification is time-consuming and requires specialized training, limiting the number of professionals available to analyze EEG/MEG data. To address this, various algorithmic approaches have been developed. However, current methods face challenges in handling varying channel configurations and in identifying the specific channels where spikes originate. This paper introduces a novel Nested Deep Learning (NDL) framework designed to overcome these limitations. NDL applies a weighted combination of signals across all channels, ensuring adaptability to different channel setups, and allows clinicians to identify key channels more accurately. Through theoretical analysis and empirical validation on real EEG/MEG datasets, NDL demonstrates superior accuracy in spike detection and channel localization compared to traditional methods. The results show that NDL improves prediction accuracy, supports cross-modality data integration, and can be fine-tuned for various neurophysiological applications."
    },
    "2410.03057v1": {
      "title": "How to evaluate your medical time series classification?",
      "url": "http://arxiv.org/abs/2410.03057v1",
      "authors": "Yihe Wang, Taida Li, Yujun Yan, Wenzhan Song, Xiang Zhang",
      "update_time": "2024-10-04",
      "abstract": "Medical time series (MedTS) play a critical role in many healthcare applications, such as vital sign monitoring and the diagnosis of brain and heart diseases. However, the existence of subject-specific features poses unique challenges in MedTS evaluation. Inappropriate evaluation setups that either exploit or overlook these features can lead to artificially inflated classification performance (by up to 50% in accuracy on ADFTD dataset): this concern has received little attention in current research. Here, we categorize the existing evaluation setups into two primary categories: subject-dependent and subject-independent. We show the subject-independent setup is more appropriate for different datasets and tasks. Our theoretical analysis explores the feature components of MedTS, examining how different evaluation setups influence the features that a model learns. Through experiments on six datasets (spanning EEG, ECG, and fNIRS modalities) using four different methods, we demonstrate step-by-step how subject-dependent utilizes subject-specific features as a shortcut for classification and leads to a deceptive high performance, suggesting that the subject-independent setup is more precise and practicable evaluation setup in real-world. This comprehensive analysis aims to establish clearer guidelines for evaluating MedTS models in different healthcare applications. Code to reproduce this work in \\url{https://github.com/DL4mHealth/MedTS_Evaluation}."
    },
    "2410.02141v1": {
      "title": "E2H: A Two-Stage Non-Invasive Neural Signal Driven Humanoid Robotic Whole-Body Control Framework",
      "url": "http://arxiv.org/abs/2410.02141v1",
      "authors": "Yiqun Duan, Jinzhao Zhou, Xiaowei Jiang, Qiang Zhang, Jingkai Sun, Jiahang Cao, Jiaxu Wang, Yiqian Yang, Wen Zhao, Gang Han, Yijie Guo, Chin-Teng Lin",
      "update_time": "2024-10-03",
      "abstract": "Recent advancements in humanoid robotics, including the integration of hierarchical reinforcement learning-based control and the utilization of LLM planning, have significantly enhanced the ability of robots to perform complex tasks. In contrast to the highly developed humanoid robots, the human factors involved remain relatively unexplored. Directly controlling humanoid robots with the brain has already appeared in many science fiction novels, such as Pacific Rim and Gundam. In this work, we present E2H (EEG-to-Humanoid), an innovative framework that pioneers the control of humanoid robots using high-frequency non-invasive neural signals. As the none-invasive signal quality remains low in decoding precise spatial trajectory, we decompose the E2H framework in an innovative two-stage formation: 1) decoding neural signals (EEG) into semantic motion keywords, 2) utilizing LLM facilitated motion generation with a precise motion imitation control policy to realize humanoid robotics control. The method of directly driving robots with brainwave commands offers a novel approach to human-machine collaboration, especially in situations where verbal commands are impractical, such as in cases of speech impairments, space exploration, or underwater exploration, unlocking significant potential. E2H offers an exciting glimpse into the future, holding immense potential for human-computer interaction."
    },
    "2410.01409v1": {
      "title": "Hexahedral mesh of anatomical atlas for construction of computational human brain models: Applications to modeling biomechanics and bioelectric field propagation",
      "url": "http://arxiv.org/abs/2410.01409v1",
      "authors": "Andy Huynh, Benjamin Zwick, Mostafa Jamshidian, Michael Halle, Adam Wittek, Karol Miller",
      "update_time": "2024-10-02",
      "abstract": "Numerical simulations rely on constructing accurate and detailed models to produce reliable results - a task that is often challenging. This task becomes notably more difficult when the model is of the human brain, the most complex organ of the human body. We create an anatomically comprehensive hexahedral mesh of the human brain using an open-source digital brain atlas from the Open Anatomy Project. This atlas currently includes over three hundred labelled anatomical structures of the brain and represents over two decades of development. It is a valuable tool currently used by medical professionals, medical students, and researchers for gathering, presenting, and discovering knowledge about the human brain. We demonstrate that this atlas can be used to efficiently create a detailed hexahedral finite element mesh of the brain for scientific computing. The two-way correspondence between the mesh and the atlas facilitates the construction of computational models and the communication and analysis of results. We present two case studies. The first case study constructs a biomechanical model of the brain to compute brain deformations and predict traumatic brain injury risk due to violent impact. In the second case study, we construct a bioelectric model of the brain to solve the electroencephalography (EEG) forward problem, a frequent simulation process used in electrophysiology to study electromagnetic fields generated by the nervous system. These techniques are often used to help understand the behavior and functionality of the brain or for treating neurological disorders such as epilepsy. We demonstrate efficient and accurate model construction using the meshed anatomical brain atlas, as well as emphasize the importance of effective communication and contextual analysis of results for enabling multi-disciplinary scientific computing research."
    },
    "2410.00712v2": {
      "title": "NECOMIMI: Neural-Cognitive Multimodal EEG-informed Image Generation with Diffusion Models",
      "url": "http://arxiv.org/abs/2410.00712v2",
      "authors": "Chi-Sheng Chen",
      "update_time": "2024-10-03",
      "abstract": "NECOMIMI (NEural-COgnitive MultImodal EEG-Informed Image Generation with Diffusion Models) introduces a novel framework for generating images directly from EEG signals using advanced diffusion models. Unlike previous works that focused solely on EEG-image classification through contrastive learning, NECOMIMI extends this task to image generation. The proposed NERV EEG encoder demonstrates state-of-the-art (SoTA) performance across multiple zero-shot classification tasks, including 2-way, 4-way, and 200-way, and achieves top results in our newly proposed Category-based Assessment Table (CAT) Score, which evaluates the quality of EEG-generated images based on semantic concepts. A key discovery of this work is that the model tends to generate abstract or generalized images, such as landscapes, rather than specific objects, highlighting the inherent challenges of translating noisy and low-resolution EEG data into detailed visual outputs. Additionally, we introduce the CAT Score as a new metric tailored for EEG-to-image evaluation and establish a benchmark on the ThingsEEG dataset. This study underscores the potential of EEG-to-image generation while revealing the complexities and challenges that remain in bridging neural activity with visual representation."
    },
    "2410.01847v2": {
      "title": "Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation",
      "url": "http://arxiv.org/abs/2410.01847v2",
      "authors": "Omkar Kulkarni, Rohitash Chandra",
      "update_time": "2024-10-04",
      "abstract": "Medical time series datasets feature missing values that need data imputation methods, however, conventional machine learning models fall short due to a lack of uncertainty quantification in predictions. Among these models, the CATSI (Context-Aware Time Series Imputation) stands out for its effectiveness by incorporating a context vector into the imputation process, capturing the global dependencies of each patient. In this paper, we propose a Bayesian Context-Aware Time Series Imputation (Bayes-CATSI) framework which leverages uncertainty quantification offered by variational inference. We consider the time series derived from electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), electrocardiology (EKG). Variational Inference assumes the shape of the posterior distribution and through minimization of the Kullback-Leibler(KL) divergence it finds variational densities that are closest to the true posterior distribution. Thus , we integrate the variational Bayesian deep learning layers into the CATSI model. Our results show that Bayes-CATSI not only provides uncertainty quantification but also achieves superior imputation performance compared to the CATSI model. Specifically, an instance of Bayes-CATSI outperforms CATSI by 9.57 %. We provide an open-source code implementation for applying Bayes-CATSI to other medical data imputation problems.",
      "code_url": "https://github.com/pingala-institute/Bayes-medicaldataimputation"
    },
    "2410.00370v1": {
      "title": "Covariate Adjusted Functional Mixed Membership Models",
      "url": "http://arxiv.org/abs/2410.00370v1",
      "authors": "Nicholas Marco, Damla \u015eent\u00fcrk, Shafali Jeste, Charlotte DiStefano, Abigail Dickinson, Donatello Telesca",
      "update_time": "2024-10-01",
      "abstract": "Mixed membership models are a flexible class of probabilistic data representations used for unsupervised and semi-supervised learning, allowing each observation to partially belong to multiple clusters or features. In this manuscript, we extend the framework of functional mixed membership models to allow for covariate-dependent adjustments. The proposed model utilizes a multivariate Karhunen-Lo\\`eve decomposition, which allows for a scalable and flexible model. Within this framework, we establish a set of sufficient conditions ensuring the identifiability of the mean, covariance, and allocation structure up to a permutation of the labels. This manuscript is primarily motivated by studies on functional brain imaging through electroencephalography (EEG) of children with autism spectrum disorder (ASD). Specifically, we are interested in characterizing the heterogeneity of alpha oscillations for typically developing (TD) children and children with ASD. Since alpha oscillations are known to change as children develop, we aim to characterize the heterogeneity of alpha oscillations conditionally on the age of the child. Using the proposed framework, we were able to gain novel information on the developmental trajectories of alpha oscillations for children with ASD and how the developmental trajectories differ between TD children and children with ASD."
    },
    "2410.00166v1": {
      "title": "EEG Emotion Copilot: Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation",
      "url": "http://arxiv.org/abs/2410.00166v1",
      "authors": "Hongyu Chen, Weiming Zeng, Chengcheng Chen, Luhui Cai, Fei Wang, Lei Wang, Wei Zhang, Yueyang Li, Hongjie Yan, Wai Ting Siok, Nizhuan Wang",
      "update_time": "2024-09-30",
      "abstract": "In the fields of affective computing (AC) and brain-machine interface (BMI), the analysis of physiological and behavioral signals to discern individual emotional states has emerged as a critical research frontier. While deep learning-based approaches have made notable strides in EEG emotion recognition, particularly in feature extraction and pattern recognition, significant challenges persist in achieving end-to-end emotion computation, including real-time processing, individual adaptation, and seamless user interaction. This paper presents the EEG Emotion Copilot, a system leveraging a lightweight large language model (LLM) operating in a local setting. The system is designed to first recognize emotional states directly from EEG signals, subsequently generate personalized diagnostic and treatment suggestions, and finally support the automation of electronic medical records. The proposed solution emphasizes both the accuracy of emotion recognition and an enhanced user experience, facilitated by an intuitive interface for participant interaction. We further discuss the construction of the data framework, model pruning, training, and deployment strategies aimed at improving real-time performance and computational efficiency. Privacy concerns are also addressed, with a focus on ethical data collection, processing, and the protection of users' personal information. Through these efforts, we aim to advance the application of AC in the medical domain, offering innovative approaches to mental health diagnostics and treatment."
    }
  },
  "BCI": {
    "2410.01408v1": {
      "title": "SHAP-CAT: A interpretable multi-modal framework enhancing WSI classification via virtual staining and shapley-value-based multimodal fusion",
      "url": "http://arxiv.org/abs/2410.01408v1",
      "authors": "Jun Wang, Yu Mao, Nan Guan, Chun Jason Xue",
      "update_time": "2024-10-02",
      "abstract": "The multimodal model has demonstrated promise in histopathology. However, most multimodal models are based on H\\&E and genomics, adopting increasingly complex yet black-box designs. In our paper, we propose a novel interpretable multimodal framework named SHAP-CAT, which uses a Shapley-value-based dimension reduction technique for effective multimodal fusion. Starting with two paired modalities -- H\\&E and IHC images, we employ virtual staining techniques to enhance limited input data by generating a new clinical-related modality. Lightweight bag-level representations are extracted from image modalities and a Shapley-value-based mechanism is used for dimension reduction. For each dimension of the bag-level representation, attribution values are calculated to indicate how changes in the specific dimensions of the input affect the model output. In this way, we select a few top important dimensions of bag-level representation for each image modality to late fusion. Our experimental results demonstrate that the proposed SHAP-CAT framework incorporating synthetic modalities significantly enhances model performance, yielding a 5\\% increase in accuracy for the BCI, an 8\\% increase for IHC4BC-ER, and an 11\\% increase for the IHC4BC-PR dataset."
    },
    "2409.20158v1": {
      "title": "Professor X: Manipulating EEG BCI with Invisible and Robust Backdoor Attack",
      "url": "http://arxiv.org/abs/2409.20158v1",
      "authors": "Xuan-Hao Liu, Xinhao Song, Dexuan He, Bao-Liang Lu, Wei-Long Zheng",
      "update_time": "2024-09-30",
      "abstract": "While electroencephalogram (EEG) based brain-computer interface (BCI) has been widely used for medical diagnosis, health care, and device control, the safety of EEG BCI has long been neglected. In this paper, we propose Professor X, an invisible and robust \"mind-controller\" that can arbitrarily manipulate the outputs of EEG BCI through backdoor attack, to alert the EEG community of the potential hazard. However, existing EEG attacks mainly focus on single-target class attacks, and they either require engaging the training stage of the target BCI, or fail to maintain high stealthiness. Addressing these limitations, Professor X exploits a three-stage clean label poisoning attack: 1) selecting one trigger for each class; 2) learning optimal injecting EEG electrodes and frequencies strategy with reinforcement learning for each trigger; 3) generating poisoned samples by injecting the corresponding trigger's frequencies into poisoned data for each class by linearly interpolating the spectral amplitude of both data according to previously learned strategies. Experiments on datasets of three common EEG tasks demonstrate the effectiveness and robustness of Professor X, which also easily bypasses existing backdoor defenses."
    },
    "2409.18375v1": {
      "title": "AM-MTEEG: Multi-task EEG classification based on impulsive associative memory",
      "url": "http://arxiv.org/abs/2409.18375v1",
      "authors": "Junyan Li, Bin Hu, Zhi-Hong Guan",
      "update_time": "2024-09-27",
      "abstract": "Electroencephalogram-based brain-computer interface (BCI) has potential applications in various fields, but their development is hindered by limited data and significant cross-individual variability. Inspired by the principles of learning and memory in the human hippocampus, we propose a multi-task (MT) classification model, called AM-MTEEG, which combines learning-based impulsive neural representations with bidirectional associative memory (AM) for cross-individual BCI classification tasks. The model treats the EEG classification of each individual as an independent task and facilitates feature sharing across individuals. Our model consists of an impulsive neural population coupled with a convolutional encoder-decoder to extract shared features and a bidirectional associative memory matrix to map features to class. Experimental results in two BCI competition datasets show that our model improves average accuracy compared to state-of-the-art models and reduces performance variance across individuals, and the waveforms reconstructed by the bidirectional associative memory provide interpretability for the model's classification results. The neuronal firing patterns in our model are highly coordinated, similarly to the neural coding of hippocampal neurons, indicating that our model has biological similarities."
    },
    "2409.17496v1": {
      "title": "Towards Forever Access for Implanted Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2409.17496v1",
      "authors": "Muhammed Ugur, Raghavendra Pradyumna Pothukuchi, Abhishek Bhattacharjee",
      "update_time": "2024-09-26",
      "abstract": "Designs for implanted brain-computer interfaces (BCIs) have increased significantly in recent years. Each device promises better clinical outcomes and quality-of-life improvements, yet due to severe and inflexible safety constraints, progress requires tight co-design from materials to circuits and all the way up the stack to applications and algorithms. This trend has become more aggressive over time, forcing clinicians and patients to rely on vendor-specific hardware and software for deployment, maintenance, upgrades, and replacement. This over-reliance is ethically problematic, especially if companies go out-of-business or business objectives diverge from clinical promises. Device heterogeneity additionally burdens clinicians and healthcare facilities, adding complexity and costs for in-clinic visits, monitoring, and continuous access.   Reliability, interoperability, portability, and future-proofed design is needed, but this unfortunately comes at a cost. These system features sap resources that would have otherwise been allocated to reduce power/energy and improve performance. Navigating this trade-off in a systematic way is critical to providing patients with forever access to their implants and reducing burdens placed on healthcare providers and caretakers. We study the integration of on-device storage to highlight the sensitivity of this trade-off and establish other points of interest within BCI design that require careful investigation. In the process, we revisit relevant problems in computer architecture and medical devices from the current era of hardware specialization and modern neurotechnology."
    },
    "2409.17445v1": {
      "title": "The Interplay of Computing, Ethics, and Policy in Brain-Computer Interface Design",
      "url": "http://arxiv.org/abs/2409.17445v1",
      "authors": "Muhammed Ugur, Raghavendra Pradyumna Pothukuchi, Abhishek Bhattacharjee",
      "update_time": "2024-09-26",
      "abstract": "Brain-computer interfaces (BCIs) connect biological neurons in the brain with external systems like prosthetics and computers. They are increasingly incorporating processing capabilities to analyze and stimulate neural activity, and consequently, pose unique design challenges related to ethics, law, and policy. For the first time, this paper articulates how ethical, legal, and policy considerations can shape BCI architecture design, and how the decisions that architects make constrain or expand the ethical, legal, and policy frameworks that can be applied to them."
    },
    "2409.16896v1": {
      "title": "Sense of Agency in Closed-loop Muscle Stimulation",
      "url": "http://arxiv.org/abs/2409.16896v1",
      "authors": "Lukas Gehrke, Leonie Terfurth, Klaus Gramann",
      "update_time": "2024-09-25",
      "abstract": "To maintain a user's sense of agency (SoA) when working with a physical motor augmentation device, the actuation must align with the user's intentions. In experiments, this is often achieved using stimulus-response paradigms where the motor augmentation can be optimally timed. However, in the everyday world users primarily act at their own volition. We designed a closed-loop system for motor augmentation using an EEG-based brain-computer interface (BCI) to cue users' volitional finger tapping. Relying on the readiness potentials, the system autonomously cued the finger movement at the time of the intent to interact via electrical muscle stimulation (EMS). The prototype discriminated pre-movement from idle EEG segments with an average F1 score of 0.7. However, we found only weak evidence for a maintained SoA. Still, participants reported a higher level of control when working with the system instead of being passively moved."
    },
    "2409.16816v1": {
      "title": "Translating Mental Imaginations into Characters with Codebooks and Dynamics-Enhanced Decoding",
      "url": "http://arxiv.org/abs/2409.16816v1",
      "authors": "Jingyuan Li, Yansen Wang, Nie Lin, Dongsheng Li",
      "update_time": "2024-09-25",
      "abstract": "Advancements in non-invasive electroencephalogram (EEG)-based Brain-Computer Interface (BCI) technology have enabled communication through brain activity, offering significant potential for individuals with motor impairments. Existing methods for decoding characters or words from EEG recordings either rely on continuous external stimulation for high decoding accuracy or depend on direct intention imagination, which suffers from reduced discrimination ability. To overcome these limitations, we introduce a novel EEG paradigm based on mental tasks that achieves high discrimination accuracy without external stimulation. Specifically, we propose a codebook in which each letter or number is associated with a unique code that integrates three mental tasks, interleaved with eye-open and eye-closed states. This approach allows individuals to internally reference characters without external stimuli while maintaining reasonable accuracy. For enhanced decoding performance, we apply a Temporal-Spatial-Latent-Dynamics (TSLD) network to capture latent dynamics of spatiotemporal EEG signals. Experimental results demonstrate the effectiveness of our proposed EEG paradigm which achieves five times higher accuracy over direct imagination. Additionally, the TSLD network improves baseline methods by approximately 8.5%. Further more, we observe consistent performance improvement throughout the data collection process, suggesting that the proposed paradigm has potential for further optimization with continued use."
    },
    "2409.16081v1": {
      "title": "Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition",
      "url": "http://arxiv.org/abs/2409.16081v1",
      "authors": "Zhili Lai, Chunmei Qing, Junpeng Tan, Wanxiang Luo, Xiangmin Xu",
      "update_time": "2024-09-24",
      "abstract": "Utilizing functional near-infrared spectroscopy (fNIRS) signals for emotion recognition is a significant advancement in understanding human emotions. However, due to the lack of artificial intelligence data and algorithms in this field, current research faces the following challenges: 1) The portable wearable devices have higher requirements for lightweight models; 2) The objective differences of physiology and psychology among different subjects aggravate the difficulty of emotion recognition. To address these challenges, we propose a novel cross-subject fNIRS emotion recognition method, called the Online Multi-level Contrastive Representation Distillation framework (OMCRD). Specifically, OMCRD is a framework designed for mutual learning among multiple lightweight student networks. It utilizes multi-level fNIRS feature extractor for each sub-network and conducts multi-view sentimental mining using physiological signals. The proposed Inter-Subject Interaction Contrastive Representation (IS-ICR) facilitates knowledge transfer for interactions between student models, enhancing cross-subject emotion recognition performance. The optimal student network can be selected and deployed on a wearable device. Some experimental results demonstrate that OMCRD achieves state-of-the-art results in emotional perception and affective imagery tasks."
    },
    "2409.11751v1": {
      "title": "Accelerated Algorithms for Source Orientation Detection (AORI) and Spatiotemporal LCMV (ALCMV) Beamforming in EEG Source Localization",
      "url": "http://arxiv.org/abs/2409.11751v1",
      "authors": "Ava Yektaeian Vaziri, Bahador Makkiabadi",
      "update_time": "2024-09-18",
      "abstract": "This paper illustrates the development of two efficient source localization algorithms for electroencephalography (EEG) data, aimed at enhancing real-time brain signal reconstruction while addressing the computational challenges of traditional methods. Accurate EEG source localization is crucial for applications in cognitive neuroscience, neurorehabilitation, and brain-computer interfaces (BCIs). To make significant progress toward precise source orientation detection and improved signal reconstruction, we introduce the Accelerated Linear Constrained Minimum Variance (ALCMV) beamforming toolbox and the Accelerated Brain Source Orientation Detection (AORI) toolbox. The ALCMV algorithm speeds up EEG source reconstruction by utilizing recursive covariance matrix calculations, while AORI simplifies source orientation detection from three dimensions to one, reducing computational load by 66% compared to conventional methods. Using both simulated and real EEG data, we demonstrate that these algorithms maintain high accuracy, with orientation errors below 0.2% and signal reconstruction accuracy within 2%. These findings suggest that the proposed toolboxes represent a substantial advancement in the efficiency and speed of EEG source localization, making them well-suited for real-time neurotechnological applications."
    },
    "2410.02780v1": {
      "title": "Guess What I Think: Streamlined EEG-to-Image Generation with Latent Diffusion Models",
      "url": "http://arxiv.org/abs/2410.02780v1",
      "authors": "Eleonora Lopez, Luigi Sigillo, Federica Colonnese, Massimo Panella, Danilo Comminiello",
      "update_time": "2024-09-17",
      "abstract": "Generating images from brain waves is gaining increasing attention due to its potential to advance brain-computer interface (BCI) systems by understanding how brain signals encode visual cues. Most of the literature has focused on fMRI-to-Image tasks as fMRI is characterized by high spatial resolution. However, fMRI is an expensive neuroimaging modality and does not allow for real-time BCI. On the other hand, electroencephalography (EEG) is a low-cost, non-invasive, and portable neuroimaging technique, making it an attractive option for future real-time applications. Nevertheless, EEG presents inherent challenges due to its low spatial resolution and susceptibility to noise and artifacts, which makes generating images from EEG more difficult. In this paper, we address these problems with a streamlined framework based on the ControlNet adapter for conditioning a latent diffusion model (LDM) through EEG signals. We conduct experiments and ablation studies on popular benchmarks to demonstrate that the proposed method beats other state-of-the-art models. Unlike these methods, which often require extensive preprocessing, pretraining, different losses, and captioning models, our approach is efficient and straightforward, requiring only minimal preprocessing and a few components. Code will be available after publication."
    }
  },
  "fMRI": {
    "2410.04383v1": {
      "title": "BrainCodec: Neural fMRI codec for the decoding of cognitive brain states",
      "url": "http://arxiv.org/abs/2410.04383v1",
      "authors": "Yuto Nishimura, Masataka Sawayama, Ayumu Yamashita, Hideki Nakayama, Kaoru Amano",
      "update_time": "2024-10-06",
      "abstract": "Recently, leveraging big data in deep learning has led to significant performance improvements, as confirmed in applications like mental state decoding using fMRI data. However, fMRI datasets remain relatively small in scale, and the inherent issue of low signal-to-noise ratios (SNR) in fMRI data further exacerbates these challenges. To address this, we apply compression techniques as a preprocessing step for fMRI data. We propose BrainCodec, a novel fMRI codec inspired by the neural audio codec. We evaluated BrainCodec's compression capability in mental state decoding, demonstrating further improvements over previous methods. Furthermore, we analyzed the latent representations obtained through BrainCodec, elucidating the similarities and differences between task and resting state fMRI, highlighting the interpretability of BrainCodec. Additionally, we demonstrated that fMRI reconstructions using BrainCodec can enhance the visibility of brain activity by achieving higher SNR, suggesting its potential as a novel denoising method. Our study shows that BrainCodec not only enhances performance over previous methods but also offers new analytical possibilities for neuroscience. Our codes, dataset, and model weights are available at https://github.com/amano-k-lab/BrainCodec.",
      "code_url": "https://github.com/amano-k-lab/braincodec"
    },
    "2410.04097v1": {
      "title": "TV-based Deep 3D Self Super-Resolution for fMRI",
      "url": "http://arxiv.org/abs/2410.04097v1",
      "authors": "Fernando P\u00e9rez-Bueno, Hongwei Bran Li, Shahin Nasr, Cesar Caballero-Gaudes, Juan Eugenio Iglesias",
      "update_time": "2024-10-05",
      "abstract": "While functional Magnetic Resonance Imaging (fMRI) offers valuable insights into cognitive processes, its inherent spatial limitations pose challenges for detailed analysis of the fine-grained functional architecture of the brain. More specifically, MRI scanner and sequence specifications impose a trade-off between temporal resolution, spatial resolution, signal-to-noise ratio, and scan time. Deep Learning (DL) Super-Resolution (SR) methods have emerged as a promising solution to enhance fMRI resolution, generating high-resolution (HR) images from low-resolution (LR) images typically acquired with lower scanning times. However, most existing SR approaches depend on supervised DL techniques, which require training ground truth (GT) HR data, which is often difficult to acquire and simultaneously sets a bound for how far SR can go. In this paper, we introduce a novel self-supervised DL SR model that combines a DL network with an analytical approach and Total Variation (TV) regularization. Our method eliminates the need for external GT images, achieving competitive performance compared to supervised DL techniques and preserving the functional maps."
    },
    "2410.03143v1": {
      "title": "ECHOPulse: ECG controlled echocardio-grams video generation",
      "url": "http://arxiv.org/abs/2410.03143v1",
      "authors": "Yiwei Li, Sekeun Kim, Zihao Wu, Hanqi Jiang, Yi Pan, Pengfei Jin, Sifan Song, Yucheng Shi, Tianze Yang, Tianming Liu, Quanzheng Li, Xiang Li",
      "update_time": "2024-10-04",
      "abstract": "Echocardiography (ECHO) is essential for cardiac assessments, but its video quality and interpretation heavily relies on manual expertise, leading to inconsistent results from clinical and portable devices. ECHO video generation offers a solution by improving automated monitoring through synthetic data and generating high-quality videos from routine health data. However, existing models often face high computational costs, slow inference, and rely on complex conditional prompts that require experts' annotations. To address these challenges, we propose ECHOPULSE, an ECG-conditioned ECHO video generation model. ECHOPULSE introduces two key advancements: (1) it accelerates ECHO video generation by leveraging VQ-VAE tokenization and masked visual token modeling for fast decoding, and (2) it conditions on readily accessible ECG signals, which are highly coherent with ECHO videos, bypassing complex conditional prompts. To the best of our knowledge, this is the first work to use time-series prompts like ECG signals for ECHO video generation. ECHOPULSE not only enables controllable synthetic ECHO data generation but also provides updated cardiac function information for disease monitoring and prediction beyond ECG alone. Evaluations on three public and private datasets demonstrate state-of-the-art performance in ECHO video generation across both qualitative and quantitative measures. Additionally, ECHOPULSE can be easily generalized to other modality generation tasks, such as cardiac MRI, fMRI, and 3D CT generation. Demo can seen from \\url{https://github.com/levyisthebest/ECHOPulse_Prelease}.",
      "code_url": "https://github.com/levyisthebest/echopulse_prelease"
    },
    "2410.02965v1": {
      "title": "BSNMani: Bayesian Scalar-on-network Regression with Manifold Learning",
      "url": "http://arxiv.org/abs/2410.02965v1",
      "authors": "Yijun Li, Ki Sueng Choi, Boadie W. Dunlop, Wade Edward Craighead, Helen S. Mayberg, Lana Garmire, Ying Guo, Jian Kang",
      "update_time": "2024-10-03",
      "abstract": "Brain connectivity analysis is crucial for understanding brain structure and neurological function, shedding light on the mechanisms of mental illness. To study the association between individual brain connectivity networks and the clinical characteristics, we develop BSNMani: a Bayesian scalar-on-network regression model with manifold learning. BSNMani comprises two components: the network manifold learning model for brain connectivity networks, which extracts shared connectivity structures and subject-specific network features, and the joint predictive model for clinical outcomes, which studies the association between clinical phenotypes and subject-specific network features while adjusting for potential confounding covariates. For posterior computation, we develop a novel two-stage hybrid algorithm combining Metropolis-Adjusted Langevin Algorithm (MALA) and Gibbs sampling. Our method is not only able to extract meaningful subnetwork features that reveal shared connectivity patterns, but can also reveal their association with clinical phenotypes, further enabling clinical outcome prediction. We demonstrate our method through simulations and through its application to real resting-state fMRI data from a study focusing on Major Depressive Disorder (MDD). Our approach sheds light on the intricate interplay between brain connectivity and clinical features, offering insights that can contribute to our understanding of psychiatric and neurological disorders, as well as mental health."
    },
    "2410.02087v1": {
      "title": "HyperBrain: Anomaly Detection for Temporal Hypergraph Brain Networks",
      "url": "http://arxiv.org/abs/2410.02087v1",
      "authors": "Sadaf Sadeghian, Xiaoxiao Li, Margo Seltzer",
      "update_time": "2024-10-02",
      "abstract": "Identifying unusual brain activity is a crucial task in neuroscience research, as it aids in the early detection of brain disorders. It is common to represent brain networks as graphs, and researchers have developed various graph-based machine learning methods for analyzing them. However, the majority of existing graph learning tools for the brain face a combination of the following three key limitations. First, they focus only on pairwise correlations between regions of the brain, limiting their ability to capture synchronized activity among larger groups of regions. Second, they model the brain network as a static network, overlooking the temporal changes in the brain. Third, most are designed only for classifying brain networks as healthy or disordered, lacking the ability to identify abnormal brain activity patterns linked to biomarkers associated with disorders. To address these issues, we present HyperBrain, an unsupervised anomaly detection framework for temporal hypergraph brain networks. HyperBrain models fMRI time series data as temporal hypergraphs capturing dynamic higher-order interactions. It then uses a novel customized temporal walk (BrainWalk) and neural encodings to detect abnormal co-activations among brain regions. We evaluate the performance of HyperBrain in both synthetic and real-world settings for Autism Spectrum Disorder and Attention Deficit Hyperactivity Disorder(ADHD). HyperBrain outperforms all other baselines on detecting abnormal co-activations in brain networks. Furthermore, results obtained from HyperBrain are consistent with clinical research on these brain disorders. Our findings suggest that learning temporal and higher-order connections in the brain provides a promising approach to uncover intricate connectivity patterns in brain networks, offering improved diagnosis.",
      "code_url": "https://github.com/ubc-systopia/HyperBrain"
    },
    "2410.00812v1": {
      "title": "A generative framework to bridge data-driven models and scientific theories in language neuroscience",
      "url": "http://arxiv.org/abs/2410.00812v1",
      "authors": "Richard Antonello, Chandan Singh, Shailee Jain, Aliyah Hsu, Jianfeng Gao, Bin Yu, Alexander Huth",
      "update_time": "2024-10-01",
      "abstract": "Representations from large language models are highly effective at predicting BOLD fMRI responses to language stimuli. However, these representations are largely opaque: it is unclear what features of the language stimulus drive the response in each brain area. We present generative explanation-mediated validation, a framework for generating concise explanations of language selectivity in the brain and then validating those explanations in follow-up experiments that use synthetic stimuli. This approach is successful at explaining selectivity both in individual voxels and cortical regions of interest (ROIs).We show that explanatory accuracy is closely related to the predictive power and stability of the underlying statistical models. These results demonstrate that LLMs can be used to bridge the widening gap between data-driven models and formal scientific theories.",
      "code_url": "https://github.com/microsoft/automated-explanations"
    },
    "2410.00183v1": {
      "title": "Generalised mixed effects models for changepoint analysis of biomedical time series data",
      "url": "http://arxiv.org/abs/2410.00183v1",
      "authors": "Mark B. Fiecas, Kathryn R. Cullen, Rebecca Killick",
      "update_time": "2024-09-30",
      "abstract": "Motivated by two distinct types of biomedical time series data, digital health monitoring and neuroimaging, we develop a novel approach for changepoint analysis that uses a generalised linear mixed model framework. The generalised linear mixed model framework lets us incorporate structure that is usually present in biomedical time series data. We embed the mixed model in a dynamic programming algorithm for detecting multiple changepoints in the fMRI data. We evaluate the performance of our proposed method across several scenarios using simulations. Finally, we show the utility of our proposed method on our two distinct motivating applications."
    },
    "2409.20428v1": {
      "title": "Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information",
      "url": "http://arxiv.org/abs/2409.20428v1",
      "authors": "Runze Xia, Congchi Yin, Piji Li",
      "update_time": "2024-09-30",
      "abstract": "The human visual system is capable of processing continuous streams of visual information, but how the brain encodes and retrieves recent visual memories during continuous visual processing remains unexplored. This study investigates the capacity of working memory to retain past information under continuous visual stimuli. And then we propose a new task Memory Disentangling, which aims to extract and decode past information from fMRI signals. To address the issue of interference from past memory information, we design a disentangled contrastive learning method inspired by the phenomenon of proactive interference. This method separates the information between adjacent fMRI signals into current and past components and decodes them into image descriptions. Experimental results demonstrate that this method effectively disentangles the information within fMRI signals. This research could advance brain-computer interfaces and mitigate the problem of low temporal resolution in fMRI."
    },
    "2410.00068v1": {
      "title": "Denoising Variational Autoencoder as a Feature Reduction Pipeline for the diagnosis of Autism based on Resting-state fMRI",
      "url": "http://arxiv.org/abs/2410.00068v1",
      "authors": "Xinyuan Zheng, Orren Ravid, Robert A. J. Barry, Yoojean Kim, Qian Wang, Young-geun Kim, Xi Zhu, Xiaofu He",
      "update_time": "2024-09-30",
      "abstract": "Autism spectrum disorders (ASDs) are developmental conditions characterized by restricted interests and difficulties in communication. The complexity of ASD has resulted in a deficiency of objective diagnostic biomarkers. Deep learning methods have gained recognition for addressing these challenges in neuroimaging analysis, but finding and interpreting such diagnostic biomarkers are still challenging computationally. We propose an ASD feature reduction pipeline using resting-state fMRI (rs-fMRI). We used Ncuts parcellations and Power atlas to extract functional connectivity data, resulting in over 30 thousand features. Then the pipeline further compresses the connectivities into 5 latent Gaussian distributions, providing is a low-dimensional representation of the data, using a denoising variational autoencoder (DVAE). To test the method, we employed the extracted latent features from the DVAE to classify ASD using traditional classifiers such as support vector machine (SVM) on a large multi-site dataset. The 95% confidence interval for the prediction accuracy of the SVM is [0.63, 0.76] after site harmonization using the extracted latent distributions. Without using DVAE, the prediction accuracy is 0.70, which falls within the interval. This implies that the model successfully encodes the diagnostic information in rs-fMRI data to 5 Gaussian distributions (10 features) without sacrificing prediction performance. The runtime for training the DVAE and obtaining classification results from its extracted latent features (37 minutes) was 7 times shorter compared to training classifiers directly on the raw connectivity matrices (5-6 hours). Our findings also suggest that the Power atlas provides more effective brain connectivity insights for diagnosing ASD than Ncuts parcellations. The encoded features can be used for the help of diagnosis and interpretation of the disease."
    },
    "2409.19710v1": {
      "title": "A multimodal LLM for the non-invasive decoding of spoken text from brain recordings",
      "url": "http://arxiv.org/abs/2409.19710v1",
      "authors": "Youssef Hmamouche, Ismail Chihab, Lahoucine Kdouri, Amal El Fallah Seghrouchni",
      "update_time": "2024-09-29",
      "abstract": "Brain-related research topics in artificial intelligence have recently gained popularity, particularly due to the expansion of what multimodal architectures can do from computer vision to natural language processing. Our main goal in this work is to explore the possibilities and limitations of these architectures in spoken text decoding from non-invasive fMRI recordings. Contrary to vision and textual data, fMRI data represent a complex modality due to the variety of brain scanners, which implies (i) the variety of the recorded signal formats, (ii) the low resolution and noise of the raw signals, and (iii) the scarcity of pretrained models that can be leveraged as foundation models for generative learning. These points make the problem of the non-invasive decoding of text from fMRI recordings very challenging. In this paper, we propose and end-to-end multimodal LLM for decoding spoken text from fMRI signals. The proposed architecture is founded on (i) an encoder derived from a specific transformer incorporating an augmented embedding layer for the encoder and a better-adjusted attention mechanism than that present in the state of the art, and (ii) a frozen large language model adapted to align the embedding of the input text and the encoded embedding of brain activity to decode the output text. A benchmark in performed on a corpus consisting of a set of interactions human-human and human-robot interactions where fMRI and conversational signals are recorded synchronously. The obtained results are very promising, as our proposal outperforms the evaluated models, and is able to generate text capturing more accurate semantics present in the ground truth. The implementation code is provided in https://github.com/Hmamouche/brain_decode."
    }
  },
  "MEG": {
    "2410.03191v1": {
      "title": "Nested Deep Learning Model: A Foundation Model for Brain Signal Data",
      "url": "http://arxiv.org/abs/2410.03191v1",
      "authors": "Fangyi Wei, Jiajie Mo, Kai Zhang, Haipeng Shen, Srikantan Nagarajan, Fei Jiang",
      "update_time": "2024-10-04",
      "abstract": "Epilepsy affects over 50 million people globally, with EEG/MEG-based spike detection playing a crucial role in diagnosis and treatment. Manual spike identification is time-consuming and requires specialized training, limiting the number of professionals available to analyze EEG/MEG data. To address this, various algorithmic approaches have been developed. However, current methods face challenges in handling varying channel configurations and in identifying the specific channels where spikes originate. This paper introduces a novel Nested Deep Learning (NDL) framework designed to overcome these limitations. NDL applies a weighted combination of signals across all channels, ensuring adaptability to different channel setups, and allows clinicians to identify key channels more accurately. Through theoretical analysis and empirical validation on real EEG/MEG datasets, NDL demonstrates superior accuracy in spike detection and channel localization compared to traditional methods. The results show that NDL improves prediction accuracy, supports cross-modality data integration, and can be fine-tuned for various neurophysiological applications."
    },
    "2409.10346v1": {
      "title": "MEGS: Morphological Evaluation of Galactic Structure",
      "url": "http://arxiv.org/abs/2409.10346v1",
      "authors": "Ufuk \u00c7ak\u0131r, Tobias Buck",
      "update_time": "2024-09-16",
      "abstract": "Understanding the morphology of galaxies is a critical aspect of astrophysics research, providing insight into the formation, evolution, and physical properties of these vast cosmic structures. Various observational and computational methods have been developed to quantify galaxy morphology, and with the advent of large galaxy simulations, the need for automated and effective classification methods has become increasingly important. This paper investigates the use of Principal Component Analysis (PCA) as an interpretable dimensionality reduction algorithm for galaxy morphology using the IllustrisTNG cosmological simulation dataset with the aim of developing a generative model for galaxies. We first generate a dataset of 2D images and 3D cubes of galaxies from the IllustrisTNG simulation, focusing on the mass, metallicity, and stellar age distribution of each galaxy. PCA is then applied to this data, transforming it into a lower-dimensional image space, where closeness of data points corresponds to morphological similarity. We find that PCA can effectively capture the key morphological features of galaxies, with a significant proportion of the variance in the data being explained by a small number of components. With our method we achieve a dimensionality reduction by a factor of $\\sim200$ for 2D images and $\\sim3650$ for 3D cubes at a reconstruction accuracy below five percent. Our results illustrate the potential of PCA in compressing large cosmological simulations into an interpretable generative model for galaxies that can easily be used in various downstream tasks such as galaxy classification and analysis.",
      "code_url": "https://github.com/ufuk-cakir/MEGS"
    },
    "2409.09116v1": {
      "title": "Characterizing the Molecular Gas in Infrared Bright Galaxies with CARMA",
      "url": "http://arxiv.org/abs/2409.09116v1",
      "authors": "Katherine Alatalo, Andreea O. Petric, Lauranne Lanz, Kate Rowlands, Vivian U, Kirsten L. Larson, Lee Armus, Loreto Barcos-Mu\u00f1oz, Aaron S. Evans, Jin Koda, Yuanze Luo, Anne M. Medling, Kristina E. Nyland, Justin A. Otter, Pallavi Patil, Fernando Pe\u00f1aloza, Diane Salim, David B. Sanders, Elizaveta Sazonova, Maya Skarbinski, Yiqing Song, Ezequiel Treister, C. Meg Urry",
      "update_time": "2024-09-13",
      "abstract": "We present the CO(1-0) maps of 28 infrared-bright galaxies from the Great Observatories All-Sky Luminous Infrared Galaxy Survey (GOALS) taken with the Combined Array for Research in Millimeter Astronomy (CARMA). We detect 100GHz continuum in 16 of 28 galaxies, which trace both active galactic nuclei (AGNs) and compact star-forming cores. The GOALS galaxies show a variety of molecular gas morphologies, though in the majority of cases, the average velocity fields show a gradient consistent with rotation. We fit the full continuum SEDs of each of the source using either MAGPHYS or SED3FIT (if there are signs of an AGN) to derive the total stellar mass, dust mass, and star formation rates of each object. We adopt a value determined from luminous and ultraluminous infrared galaxies (LIRGs and ULIRGs) of $\\alpha_{\\rm CO}=1.5^{+1.3}_{-0.8}~M_\\odot$ (K km s$^{-1}$ pc$^2)^{-1}$, which leads to more physical values for $f_{\\rm mol}$ and the gas-to-dust ratio. Mergers tend to have the highest gas-to-dust ratios. We assume the cospatiality of the molecular gas and star formation, and plot the sample on the Schmidt-Kennicutt relation, we find that they preferentially lie above the line set by normal star-forming galaxies. This hyper-efficiency is likely due to the increased turbulence in these systems, which decreases the freefall time compared to star-forming galaxies, leading to \"enhanced\" star formation efficiency. Line wings are present in a non-negligible subsample (11/28) of the CARMA GOALS sources and are likely due to outflows driven by AGNs or star formation, gas inflows, or additional decoupled gas components."
    },
    "2409.03952v1": {
      "title": "Lepton-flavor changing decays and non-unitarity in the inverse seesaw mechanism",
      "url": "http://arxiv.org/abs/2409.03952v1",
      "authors": "Adri\u00e1n Gonz\u00e1lez-Quiterio, H\u00e9ctor Novales-S\u00e1nchez",
      "update_time": "2024-09-06",
      "abstract": "The pursuit of the genuine fundamental description, governing nature at some high-energy scale, must invariably consider the yet-unknown mechanism behind the generation of neutrino mass. Lepton-flavor violating decays $l_\\alpha\\to\\gamma\\,l_\\beta$, allowed in the presence of neutrino mass and mixing, provide a mean to look for physics beyond the Standard Model. In the present work we consider the inverse seesaw mechanism and then revisit the calculation of its contributions to the branching ratios of the aforementioned decay processes, among which we find $\\mu\\to\\gamma\\,e$ to be more promising, in the light of current bounds by the MEG Collaboration. Deviations from unitarity in the mixing of light neutrinos are related to the branching ratios ${\\rm Br}\\big( l_\\alpha\\to\\gamma\\,l_\\beta \\big)$ in a simple manner, which we address, then finding that, while experimental data are consistent with current bounds on non-unitarity effects, the upcoming MEG II update shall be able to improve restrictions on such effects by a factor $\\sim\\frac{1}{3}$."
    },
    "2408.15419v3": {
      "title": "Bayesian Inference General Procedures for A Single-subject Test Study",
      "url": "http://arxiv.org/abs/2408.15419v3",
      "authors": "Jie Li, Gary Green, Sarah J. A. Carr, Peng Liu, Jian Zhang",
      "update_time": "2024-09-10",
      "abstract": "Abnormality detection in the identification of a single-subject which deviates from the majority of the dataset that comes from a control group is a critical problem. A common approach is to assume that the control group can be characterised in terms of standard Normal statistics and the detection of single abnormal subject is in that context. But in many situations the control group can not be described in terms of Normal statistics and the use of standard statistics is inappropriate. This paper presents a Bayesian Inference General Procedures for A Single-Subject Test (BIGPAST), designed to mitigate the effects of skewness under the assumption that the dataset of control group comes from the skewed Student's \\( t \\) distribution. BIGPAST operates under the null hypothesis that the single-subject follows the same distribution as the control group. We assess BIGPAST's performance against other methods through a series of simulation studies. The results demonstrate that BIGPAST is robust against deviations from normality and outperforms the existing approaches in terms of accuracy. This is because BIGPAST can effectively reduce model misspecification errors under the skewed Student's \\( t \\) assumption. We apply BIGPAST to a MEG dataset consisting of an individual with mild traumatic brain injury and an age and gender-matched control group, demonstrating its effectiveness in detecting abnormalities in the single-subject."
    },
    "2409.05870v1": {
      "title": "Enabling Distributed Generative Artificial Intelligence in 6G: Mobile Edge Generation",
      "url": "http://arxiv.org/abs/2409.05870v1",
      "authors": "Ruikang Zhong, Xidong Mu, Mona Jaber, Yuanwei Liu",
      "update_time": "2024-08-23",
      "abstract": "Mobile edge generation (MEG) is an emerging technology that allows the network to meet the challenging traffic load expectations posed by the rise of generative artificial intelligence~(GAI). A novel MEG model is proposed for deploying GAI models on edge servers (ES) and user equipment~(UE) to jointly complete text-to-image generation tasks. In the generation task, the ES and UE will cooperatively generate the image according to the text prompt given by the user. To enable the MEG, a pre-trained latent diffusion model (LDM) is invoked to generate the latent feature, and an edge-inferencing MEG protocol is employed for data transmission exchange between the ES and the UE. A compression coding technique is proposed for compressing the latent features to produce seeds. Based on the above seed-enabled MEG model, an image quality optimization problem with transmit power constraint is formulated. The transmitting power of the seed is dynamically optimized by a deep reinforcement learning agent over the fading channel. The proposed MEG enabled text-to-image generation system is evaluated in terms of image quality and transmission overhead. The numerical results indicate that, compared to the conventional centralized generation-and-downloading scheme, the symbol number of the transmission of MEG is materially reduced. In addition, the proposed compression coding approach can improve the quality of generated images under low signal-to-noise ratio (SNR) conditions."
    },
    "2408.04815v1": {
      "title": "Towards improving Alzheimer's intervention: a machine learning approach for biomarker detection through combining MEG and MRI pipelines",
      "url": "http://arxiv.org/abs/2408.04815v1",
      "authors": "Alwani Liyana Ahmad, Jose Sanchez-Bornot, Roberto C. Sotero, Damien Coyle, Zamzuri Idris, Ibrahima Faye",
      "update_time": "2024-08-09",
      "abstract": "MEG are non invasive neuroimaging techniques with excellent temporal and spatial resolution, crucial for studying brain function in dementia and Alzheimer Disease. They identify changes in brain activity at various Alzheimer stages, including preclinical and prodromal phases. MEG may detect pathological changes before clinical symptoms, offering potential biomarkers for intervention. This study evaluates classification techniques using MEG features to distinguish between healthy controls and mild cognitive impairment participants from the BioFIND study. We compare MEG based biomarkers with MRI based anatomical features, both independently and combined. We used 3 Tesla MRI and MEG data from 324 BioFIND participants;158 MCI and 166 HC. Analyses were performed using MATLAB with SPM12 and OSL toolboxes. Machine learning analyses, including 100 Monte Carlo replications of 10 fold cross validation, were conducted on sensor and source spaces. Combining MRI with MEG features achieved the best performance; 0.76 accuracy and AUC of 0.82 for GLMNET using LCMV source based MEG. MEG only analyses using LCMV and eLORETA also performed well, suggesting that combining uncorrected MEG with z-score-corrected MRI features is optimal."
    },
    "2408.02760v1": {
      "title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis",
      "url": "http://arxiv.org/abs/2408.02760v1",
      "authors": "Adri\u00e0 Solana, Erik Frans\u00e9n, Gonzalo Uribarri",
      "update_time": "2024-08-05",
      "abstract": "Multivariate Time Series Classification (MTSC) is a ubiquitous problem in science and engineering, particularly in neuroscience, where most data acquisition modalities involve the simultaneous time-dependent recording of brain activity in multiple brain regions. In recent years, Random Convolutional Kernel models such as ROCKET and MiniRocket have emerged as highly effective time series classification algorithms, capable of achieving state-of-the-art accuracy results with low computational load. Despite their success, these types of models face two major challenges when employed in neuroscience: 1) they struggle to deal with high-dimensional data such as EEG and MEG, and 2) they are difficult to interpret. In this work, we present a novel ROCKET-based algorithm, named Detach-Rocket Ensemble, that is specifically designed to address these two problems in MTSC. Our algorithm leverages pruning to provide an integrated estimation of channel importance, and ensembles to achieve better accuracy and provide a label probability. Using a synthetic multivariate time series classification dataset in which we control the amount of information carried by each of the channels, we first show that our algorithm is able to correctly recover the channel importance for classification. Then, using two real-world datasets, a MEG dataset and an EEG dataset, we show that Detach-Rocket Ensemble is able to provide both interpretable channel relevance and competitive classification accuracy, even when applied directly to the raw brain data, without the need for feature engineering.",
      "code_url": "https://github.com/gon-uri/detach_rocket"
    },
    "2408.08877v1": {
      "title": "Hotspots and Trends in Magnetoencephalography Research (2013-2022): A Bibliometric Analysis",
      "url": "http://arxiv.org/abs/2408.08877v1",
      "authors": "Shen Liu, Jingwen Zhao",
      "update_time": "2024-08-02",
      "abstract": "This study aimed to utilize bibliometric methods to analyze trends in international Magnetoencephalography (MEG) research from 2013 to 2022. Due to the limited volume of domestic literature on MEG, this analysis focuses solely on the global research landscape, providing insights from the past decade as a representative sample. This study utilized bibliometric methods to explore and analyze the progress, hotspots and developmental trends in international MEG research spanning from 1995 to 2022. The results indicated a dynamic and steady growth trend in the overall number of publications in MEG. Ryusuke Kakigi emerged as the most prolific author, while Neuroimage led as the most prolific journal. Current hotspots in MEG research encompass resting state, networks, functional connectivity, phase dynamics, oscillation, and more. Future trends in MEG research are poised to advance across three key aspects: disease treatment and practical applications, experimental foundations and technical advancements, and fundamental and advanced human cognition. In the future, there should be a focus on enhancing cross-integration and utilization of MEG with other instruments to diversify research methodologies in this field"
    },
    "2408.00118v3": {
      "title": "Gemma 2: Improving Open Language Models at a Practical Size",
      "url": "http://arxiv.org/abs/2408.00118v3",
      "authors": "Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, L\u00e9onard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ram\u00e9, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozi\u0144ska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Pluci\u0144ska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin G\u00f6rner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Cogan, Sarah Perrin, S\u00e9bastien M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev",
      "update_time": "2024-10-02",
      "abstract": "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community."
    }
  },
  "neuroAI": {
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    },
    "2112.15459v3": {
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "authors": "Samuele Bolotta, Guillaume Dumas",
      "update_time": "2022-04-11",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied."
    },
    "2011.07464v2": {
      "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
      "url": "http://arxiv.org/abs/2011.07464v2",
      "authors": "Joseph Marino",
      "update_time": "2021-10-23",
      "abstract": "This paper reviews predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (non-linear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field."
    },
    "1909.02603v2": {
      "title": "Additive function approximation in the brain",
      "url": "http://arxiv.org/abs/1909.02603v2",
      "authors": "Kameron Decker Harris",
      "update_time": "2019-09-13",
      "abstract": "Many biological learning systems such as the mushroom body, hippocampus, and cerebellum are built from sparsely connected networks of neurons. For a new understanding of such networks, we study the function spaces induced by sparse random features and characterize what functions may and may not be learned. A network with $d$ inputs per neuron is found to be equivalent to an additive model of order $d$, whereas with a degree distribution the network combines additive terms of different orders. We identify three specific advantages of sparsity: additive function approximation is a powerful inductive bias that limits the curse of dimensionality, sparse networks are stable to outlier noise in the inputs, and sparse random features are scalable. Thus, even simple brain architectures can be powerful function approximators. Finally, we hope that this work helps popularize kernel theories of networks among computational neuroscientists.",
      "code_url": "https://github.com/kharris/sparse-random-features"
    }
  },
  "medical": {
    "2410.05251v1": {
      "title": "Block MedCare: Advancing healthcare through blockchain integration",
      "url": "http://arxiv.org/abs/2410.05251v1",
      "authors": "Oliver Simonoski, Dijana Capeska Bogatinoska",
      "update_time": "2024-10-07",
      "abstract": "In an era driven by information exchange, transparency and security hold crucial importance, particularly within the healthcare industry, where data integrity and confidentiality are paramount. This paper investigates the integration of blockchain technology in healthcare, focusing on its potential to revolutionize Electronic Health Records (EHR) management and data sharing. By leveraging Ethereum-based blockchain implementations and smart contracts, we propose a novel system that empowers patients to securely store and manage their medical data. Our research addresses critical challenges in implementing blockchain in healthcare, including scalability, user privacy, and regulatory compliance. We propose a solution that combines digital signatures, Role-Based Access Control, and a multi-layered architecture to enhance security and ensure controlled access. The system's key functions, including user registration, data append, and data retrieval, are facilitated through smart contracts, providing a secure and efficient mechanism for managing health information. To validate our approach, we developed a decentralized application (dApp) that demonstrates the practical implementation of our blockchain-based healthcare solution. The dApp incorporates user-friendly interfaces for patients, doctors, and administrators, showcasing the system's potential to streamline healthcare processes while maintaining data security and integrity. Additionally, we conducted a survey to gain insights into the perceived benefits and challenges of blockchain adoption in healthcare. The results indicate strong interest among healthcare professionals and IT experts, while also highlighting concerns about integration costs and technological complexity. Our findings..."
    },
    "2410.05245v1": {
      "title": "Rosette spectroscopic imaging for whole-brain metabolite mapping at 7T: acceleration potential and reproducibility",
      "url": "http://arxiv.org/abs/2410.05245v1",
      "authors": "Zhiwei Huang, Uzay Emir, Andre Doring, Antoine Klauser, Ying Xiao, Mark Widmaier, Lijing Xin",
      "update_time": "2024-10-07",
      "abstract": "Whole-brain proton magnetic resonance spectroscopic imaging (1H-MRSI) is a non-invasive technique for assessing neurochemical distribution in the brain, offering valuable insights into brain functions and neural diseases. It greatly benefits from the improved SNR at ultrahigh field strengths ($\\geq$7T). However, 1H-MRSI still faces several challenges, such as long acquisition time and severe signal contaminations from water and lipids. In this study, 2D and 3D short TR/TE 1H-FID-MRSI sequences using rosette trajectories were developed with spatial resolutions of 4.48$\\times$4.48 mm$^2$ and 4.48$\\times$4.48$\\times$4.50 mm$^3$, respectively. Water signals were suppressed using an optimized Five-variable-Angle-gaussian-pulses-with-ShorT-total-duration of 76 ms (FAST) water suppression scheme, and lipid signals were removed using the L2 regularization method. Metabolic maps of major 1H metabolites were obtained within 5:40 min with 16 averages and 1 average for the 2D and 3D acquisitions, respectively. Excellent inter-session reproducibility was shown, with the coefficients of variance (CV) being lower than 6% for N-Acetyle-L-aspartic acid (NAA), Glutamate (Glu), Choline Chloride and glycerophosphocholine (tCho), Creatine and Phosphocreatine (tCr), and Glycine and Myo-inositol (Gly+Ins). To explore the potential of further accelerating the acquisition, compressed sensing was applied retrospectively to the 3D datasets. The structural similarity index (SSIM) remained above 0.85 and 0.8 until $R = 2$ and $R = 3$ for the metabolite maps of Glu, NAA, tCr, and tCho, indicating the possibility for further reduction of acquisition time to around 2min."
    },
    "2410.05239v1": {
      "title": "TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation Models",
      "url": "http://arxiv.org/abs/2410.05239v1",
      "authors": "Rabin Adhikari, Safal Thapaliya, Manish Dhakal, Bishesh Khanal",
      "update_time": "2024-10-07",
      "abstract": "Vision-Language Models (VLMs) have shown impressive performance in vision tasks, but adapting them to new domains often requires expensive fine-tuning. Prompt tuning techniques, including textual, visual, and multimodal prompting, offer efficient alternatives by leveraging learnable prompts. However, their application to Vision-Language Segmentation Models (VLSMs) and evaluation under significant domain shifts remain unexplored. This work presents an open-source benchmarking framework, TuneVLSeg, to integrate various unimodal and multimodal prompt tuning techniques into VLSMs, making prompt tuning usable for downstream segmentation datasets with any number of classes. TuneVLSeg includes $6$ prompt tuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$ different combinations. We test various prompt tuning on $8$ diverse medical datasets, including $3$ radiology datasets (breast tumor, echocardiograph, chest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skin cancer), and two natural domain segmentation datasets. Our study found that textual prompt tuning struggles under significant domain shifts, from natural-domain images to medical data. Furthermore, visual prompt tuning, with fewer hyperparameters than multimodal prompt tuning, often achieves performance competitive to multimodal approaches, making it a valuable first attempt. Our work advances the understanding and applicability of different prompt-tuning techniques for robust domain-specific segmentation. The source code is available at https://github.com/naamiinepal/tunevlseg.",
      "code_url": "https://github.com/naamiinepal/tunevlseg"
    },
    "2410.05235v1": {
      "title": "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures",
      "url": "http://arxiv.org/abs/2410.05235v1",
      "authors": "katerina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri",
      "update_time": "2024-10-07",
      "abstract": "Explaining Artificial Intelligence (AI) decisions is a major challenge nowadays in AI, in particular when applied to sensitive scenarios like medicine and law. However, the need to explain the rationale behind decisions is a main issue also for human-based deliberation as it is important to justify \\textit{why} a certain decision has been taken. Resident medical doctors for instance are required not only to provide a (possibly correct) diagnosis, but also to explain how they reached a certain conclusion. Developing new tools to aid residents to train their explanation skills is therefore a central objective of AI in education. In this paper, we follow this direction, and we present, to the best of our knowledge, the first multilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are enriched with a natural language explanation written by doctors. These explanations have been manually annotated with argument components (i.e., premise, claim) and argument relations (i.e., attack, support), resulting in the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases in four languages (English, Spanish, French, Italian) with explanations, where we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106 attack relations. We conclude by showing how competitive baselines perform over this challenging dataset for the argument mining task."
    },
    "2410.05234v1": {
      "title": "DiffuseReg: Denoising Diffusion Model for Obtaining Deformation Fields in Unsupervised Deformable Image Registration",
      "url": "http://arxiv.org/abs/2410.05234v1",
      "authors": "Yongtai Zhuo, Yiqing Shen",
      "update_time": "2024-10-07",
      "abstract": "Deformable image registration aims to precisely align medical images from different modalities or times. Traditional deep learning methods, while effective, often lack interpretability, real-time observability and adjustment capacity during registration inference. Denoising diffusion models present an alternative by reformulating registration as iterative image denoising. However, existing diffusion registration approaches do not fully harness capabilities, neglecting the critical sampling phase that enables continuous observability during the inference. Hence, we introduce DiffuseReg, an innovative diffusion-based method that denoises deformation fields instead of images for improved transparency. We also propose a novel denoising network upon Swin Transformer, which better integrates moving and fixed images with diffusion time step throughout the denoising process. Furthermore, we enhance control over the denoising registration process with a novel similarity consistency regularization. Experiments on ACDC datasets demonstrate DiffuseReg outperforms existing diffusion registration methods by 1.32 in Dice score. The sampling process in DiffuseReg enables real-time output observability and adjustment unmatched by previous deep models."
    },
    "2410.05180v1": {
      "title": "Enhancing Equity in Large Language Models for Medical Applications",
      "url": "http://arxiv.org/abs/2410.05180v1",
      "authors": "Yuelyu Ji, Wenhe Ma, Sonish Sivarajkumar, Hang Zhang, Eugene Mathew Sadhu, Zhuochun Li, Xizhi Wu, Shyam Visweswaran, Yanshan Wang",
      "update_time": "2024-10-07",
      "abstract": "Recent advancements have highlighted the potential of large language models (LLMs) in medical applications, notably in automating Clinical Trial Matching for translational research and providing medical question-answering for clinical decision support. However, our study reveals significant inequities in the use of LLMs, particularly for individuals from specific racial, gender, and underrepresented groups influenced by social determinants of health. These disparities could worsen existing health inequities if LLMs are broadly adopted in healthcare. To address this, we propose and evaluate a novel framework, EquityGuard, designed to detect and mitigate biases in LLM-based medical applications. EquityGuard incorporates a Bias Detection Mechanism capable of identifying and correcting unfair predictions, thus enhancing outcomes and promoting equity across diverse population groups."
    },
    "2410.05114v1": {
      "title": "Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization",
      "url": "http://arxiv.org/abs/2410.05114v1",
      "authors": "Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip \u00dcmit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek",
      "update_time": "2024-10-07",
      "abstract": "In the realm of dermatological diagnoses, where the analysis of dermatoscopic and microscopic skin lesion images is pivotal for the accurate and early detection of various medical conditions, the costs associated with creating diverse and high-quality annotated datasets have hampered the accuracy and generalizability of machine learning models. We propose an innovative unsupervised augmentation solution that harnesses Generative Adversarial Network (GAN) based models and associated techniques over their latent space to generate controlled semiautomatically-discovered semantic variations in dermatoscopic images. We created synthetic images to incorporate the semantic variations and augmented the training data with these images. With this approach, we were able to increase the performance of machine learning models and set a new benchmark amongst non-ensemble based models in skin lesion classification on the HAM10000 dataset; and used the observed analytics and generated models for detailed studies on model explainability, affirming the effectiveness of our solution."
    },
    "2410.05086v1": {
      "title": "Laser-FLASH: radiobiology at high dose, ultra-high dose-rate, single pulse laser-driven proton source",
      "url": "http://arxiv.org/abs/2410.05086v1",
      "authors": "A. Flacco, E. Bayart, C. Giaccaglia, J. Monzac, L. Romagnani, M. Cavallone, A. Patriarca, L. DeMarzi, S. Heinrich, I. Lamarre-Jouenne, K. Parodi, T. R\u00f6sch, J. Schreiber, L. Tischendorf",
      "update_time": "2024-10-07",
      "abstract": "Laser-driven proton sources have long been developed with an eye on their potential for medical application to radiation therapy. These sources are compact, versatile, and show peculiar characteristics such as extreme instantaneous dose rates, short duration and broad energy spectrum. Typical temporal modality of laser-driven irradiation, the so-called fast-fractionation, results from the composition of multiple, temporally separated, ultra-short dose fractions. In this paper we present the use of a high-energy laser system for delivering the target dose in a single nanosecond pulse, for ultra-fast irradiation of biological samples. A transport line composed by two permanent magnet quadrupoles and a scattering system is used to improve the dose profile and to control the delivered dose-per-pulse. A single-shot dosimetry protocol for the broad-spectrum proton source using Monte Carlo simulations was developed. Doses as high as 20Gy could be delivered in a single shot, lasting less than 10ns over a 1.0cm diameter sample holder, at a dose-rate exceeding 10^9 Gy/s. Exploratory application of extreme laser-driven irradiation conditions, falling within the FLASH irradiation protocol, are presented for in vitro and in vivo irradiation are presented. A reduction of radiation-induced oxidative stress in-vitro and radiation-induced developmental damage in vivo were observed, whereas anti-tumoral efficacy was confirmed by cell survival assay."
    },
    "2410.05046v1": {
      "title": "Named Clinical Entity Recognition Benchmark",
      "url": "http://arxiv.org/abs/2410.05046v1",
      "authors": "Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Cl\u00e9ment Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan",
      "update_time": "2024-10-07",
      "abstract": "This technical report introduces a Named Clinical Entity Recognition Benchmark for evaluating language models in healthcare, addressing the crucial natural language processing (NLP) task of extracting structured information from clinical narratives to support applications like automated coding, clinical trial cohort identification, and clinical decision support.   The leaderboard provides a standardized platform for assessing diverse language models, including encoder and decoder architectures, on their ability to identify and classify clinical entities across multiple medical domains. A curated collection of openly available clinical datasets is utilized, encompassing entities such as diseases, symptoms, medications, procedures, and laboratory measurements. Importantly, these entities are standardized according to the Observational Medical Outcomes Partnership (OMOP) Common Data Model, ensuring consistency and interoperability across different healthcare systems and datasets, and a comprehensive evaluation of model performance. Performance of models is primarily assessed using the F1-score, and it is complemented by various assessment modes to provide comprehensive insights into model performance. The report also includes a brief analysis of models evaluated to date, highlighting observed trends and limitations.   By establishing this benchmarking framework, the leaderboard aims to promote transparency, facilitate comparative analyses, and drive innovation in clinical entity recognition tasks, addressing the need for robust evaluation methods in healthcare NLP."
    },
    "2410.04843v1": {
      "title": "Real-time cardiac cine MRI -- A comparison of a diffusion probabilistic model with alternative state-of-the-art image reconstruction techniques for undersampled spiral acquisitions",
      "url": "http://arxiv.org/abs/2410.04843v1",
      "authors": "Oliver Schad, Julius Frederik Heidenreich, Nils-Christian Petri, Jonas Kleineisel, Simon Sauer, Thorsten Bley, Peter Nordbeck, Bernhard Petritsch, Tobias Wech",
      "update_time": "2024-10-07",
      "abstract": "ECG-gated cine imaging in breath-hold enables high-quality diagnostics in most patients, arrhythmia and inability to hold breath, however, can severely corrupt outcomes. Real-time cardiac MRI in free-breathing leverages robust and faster investigations regardless of these confounding factors. With the need for sufficient acceleration, adequate reconstruction methods, which transfer data into high quality images, are required. Undersampled spiral real-time acquisitions in free-breathing were conducted in a study with 16 healthy volunteers and 5 patients. Image reconstructions were performed using a novel score-based diffusion model, as well as a variational network and different compressed sensing approaches. The techniques were compared by means of an expert reader study, by calculating scalar metrics and difference images with respect to a segmented reference, and by a Bland-Altman analysis of cardiac functional parameters. In participants with irregular RR-cycles, spiral real-time acquisitions showed superior image quality with respect to the clinical reference standard. Reconstructions using the diffusion model, the variational network and l1-wavelets offered an overall comparable image quality, however sharpness was slightly increased by the diffusion approach. While slightly larger ejection fractions for the real-time acquisitions were exhibited with a bias of 1.6% for healthy subjects, differences in the data acquisition procedure resulted in uncertainties of 7.4%. The proposed real-time technique enables free-breathing acquisitions of spatio-temporal images with high-quality, covering the entire heart in less than one minute. Evaluation of the ejection fractions using the segmented reference can be significantly corrupted due to arrhythmias and averaging effects. Prolonged inference times of the diffusion model represent the main obstacle to overcome for clinical translation."
    }
  }
}