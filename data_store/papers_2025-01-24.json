{
  "Brain": {
    "2501.13010v1": {
      "title": "Learning accurate rigid registration for longitudinal brain MRI from synthetic data",
      "url": "http://arxiv.org/abs/2501.13010v1",
      "authors": "Jingru Fu, Adrian V. Dalca, Bruce Fischl, Rodrigo Moreno, Malte Hoffmann",
      "update_time": "2025-01-22",
      "abstract": "Rigid registration aims to determine the translations and rotations necessary to align features in a pair of images. While recent machine learning methods have become state-of-the-art for linear and deformable registration across subjects, they have demonstrated limitations when applied to longitudinal (within-subject) registration, where achieving precise alignment is critical. Building on an existing framework for anatomy-aware, acquisition-agnostic affine registration, we propose a model optimized for longitudinal, rigid brain registration. By training the model with synthetic within-subject pairs augmented with rigid and subtle nonlinear transforms, the model estimates more accurate rigid transforms than previous cross-subject networks and performs robustly on longitudinal registration pairs within and across magnetic resonance imaging (MRI) contrasts."
    },
    "2501.12840v1": {
      "title": "AMM-Diff: Adaptive Multi-Modality Diffusion Network for Missing Modality Imputation",
      "url": "http://arxiv.org/abs/2501.12840v1",
      "authors": "Aghiles Kebaili, J\u00e9r\u00f4me Lapuyade-Lahorgue, Pierre Vera, Su Ruan",
      "update_time": "2025-01-22",
      "abstract": "In clinical practice, full imaging is not always feasible, often due to complex acquisition protocols, stringent privacy regulations, or specific clinical needs. However, missing MR modalities pose significant challenges for tasks like brain tumor segmentation, especially in deep learning-based segmentation, as each modality provides complementary information crucial for improving accuracy. A promising solution is missing data imputation, where absent modalities are generated from available ones. While generative models have been widely used for this purpose, most state-of-the-art approaches are limited to single or dual target translations, lacking the adaptability to generate missing modalities based on varying input configurations. To address this, we propose an Adaptive Multi-Modality Diffusion Network (AMM-Diff), a novel diffusion-based generative model capable of handling any number of input modalities and generating the missing ones. We designed an Image-Frequency Fusion Network (IFFN) that learns a unified feature representation through a self-supervised pretext task across the full input modalities and their selected high-frequency Fourier components. The proposed diffusion model leverages this representation, encapsulating prior knowledge of the complete modalities, and combines it with an adaptive reconstruction strategy to achieve missing modality completion. Experimental results on the BraTS 2021 dataset demonstrate the effectiveness of our approach."
    },
    "2501.12810v1": {
      "title": "Machine Learning Modeling for Multi-order Human Visual Motion Processing",
      "url": "http://arxiv.org/abs/2501.12810v1",
      "authors": "Zitang Sun, Yen-Ju Chen, Yung-Hao Yang, Yuan Li, Shin'ya Nishida",
      "update_time": "2025-01-22",
      "abstract": "Our research aims to develop machines that learn to perceive visual motion as do humans. While recent advances in computer vision (CV) have enabled DNN-based models to accurately estimate optical flow in naturalistic images, a significant disparity remains between CV models and the biological visual system in both architecture and behavior. This disparity includes humans' ability to perceive the motion of higher-order image features (second-order motion), which many CV models fail to capture because of their reliance on the intensity conservation law. Our model architecture mimics the cortical V1-MT motion processing pathway, utilizing a trainable motion energy sensor bank and a recurrent graph network. Supervised learning employing diverse naturalistic videos allows the model to replicate psychophysical and physiological findings about first-order (luminance-based) motion perception. For second-order motion, inspired by neuroscientific findings, the model includes an additional sensing pathway with nonlinear preprocessing before motion energy sensing, implemented using a simple multilayer 3D CNN block. When exploring how the brain acquired the ability to perceive second-order motion in natural environments, in which pure second-order signals are rare, we hypothesized that second-order mechanisms were critical when estimating robust object motion amidst optical fluctuations, such as highlights on glossy surfaces. We trained our dual-pathway model on novel motion datasets with varying material properties of moving objects. We found that training to estimate object motion from non-Lambertian materials naturally endowed the model with the capacity to perceive second-order motion, as can humans. The resulting model effectively aligns with biological systems while generalizing to both first- and second-order motion phenomena in natural scenes.",
      "code_url": "https://github.com/anoymized/multi-order-motion-model"
    },
    "2501.12615v1": {
      "title": "GATE: Adaptive Learning with Working Memory by Information Gating in Multi-lamellar Hippocampal Formation",
      "url": "http://arxiv.org/abs/2501.12615v1",
      "authors": "Yuechen Liu, Zishun Wang, Chen Qiao, Zongben Xu",
      "update_time": "2025-01-22",
      "abstract": "Hippocampal formation (HF) can rapidly adapt to varied environments and build flexible working memory (WM). To mirror the HF's mechanism on generalization and WM, we propose a model named Generalization and Associative Temporary Encoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV) architecture, and learns to build up internally representation from externally driven information layer-wisely. In each lamella, regions of HF: EC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains information by EC3 persistent activity, and selectively readouts the retained information by CA1 neurons. CA3 and EC5 further provides gating function that controls these processes. After learning complex WM tasks, GATE forms neuron representations that align with experimental records, including splitter, lap, evidence, trace, delay-active cells, as well as conventional place cells. Crucially, DV architecture in GATE also captures information, range from detailed to abstract, which enables a rapid generalization ability when cue, environment or task changes, with learned representations inherited. GATE promises a viable framework for understanding the HF's flexible memory mechanisms and for progressively developing brain-inspired intelligent systems."
    },
    "2501.12547v1": {
      "title": "Human-like conceptual representations emerge from language prediction",
      "url": "http://arxiv.org/abs/2501.12547v1",
      "authors": "Ningyu Xu, Qi Zhang, Chao Du, Qiang Luo, Xipeng Qiu, Xuanjing Huang, Menghan Zhang",
      "update_time": "2025-01-21",
      "abstract": "Recent advances in large language models (LLMs) provide a new opportunity to address the long-standing question of how concepts are represented and organized in the mind, which is central to unravelling the nature of human cognition. Here, we reframed the classic reverse dictionary task to simulate human concept inference in context and investigated the emergence of human-like conceptual representations within LLMs. We found that LLMs were able to infer concepts from definitional descriptions and construct representation spaces that converge towards a shared, context-independent structure. These representations effectively predicted human behavioural judgments and aligned well with neural activity patterns in the human brain, offering evidence for biological plausibility. These findings demonstrate that human-like conceptual representations and organization can naturally emerge from language prediction, even without real-world grounding. Our work supports the view that LLMs serve as valuable tools for understanding complex human cognition and paves the way for better alignment between artificial and human intelligence."
    },
    "2501.12488v1": {
      "title": "Bidirectional Brain Image Translation using Transfer Learning from Generic Pre-trained Models",
      "url": "http://arxiv.org/abs/2501.12488v1",
      "authors": "Fatima Haimour, Rizik Al-Sayyed, Waleed Mahafza, Omar S. Al-Kadi",
      "update_time": "2025-01-21",
      "abstract": "Brain imaging plays a crucial role in the diagnosis and treatment of various neurological disorders, providing valuable insights into the structure and function of the brain. Techniques such as magnetic resonance imaging (MRI) and computed tomography (CT) enable non-invasive visualization of the brain, aiding in the understanding of brain anatomy, abnormalities, and functional connectivity. However, cost and radiation dose may limit the acquisition of specific image modalities, so medical image synthesis can be used to generate required medical images without actual addition. In the medical domain, where obtaining labeled medical images is labor-intensive and expensive, addressing data scarcity is a major challenge. Recent studies propose using transfer learning to overcome this issue. This involves adapting pre-trained CycleGAN models, initially trained on non-medical data, to generate realistic medical images. In this work, transfer learning was applied to the task of MR-CT image translation and vice versa using 18 pre-trained non-medical models, and the models were fine-tuned to have the best result. The models' performance was evaluated using four widely used image quality metrics: Peak-signal-to-noise-ratio, Structural Similarity Index, Universal Quality Index, and Visual Information Fidelity. Quantitative evaluation and qualitative perceptual analysis by radiologists demonstrate the potential of transfer learning in medical imaging and the effectiveness of the generic pre-trained model. The results provide compelling evidence of the model's exceptional performance, which can be attributed to the high quality and similarity of the training images to actual human brain images. These results underscore the significance of carefully selecting appropriate and representative training images to optimize performance in brain image analysis tasks."
    },
    "2501.12139v1": {
      "title": "Discontinuous phase transition of feature detection in lateral predictive coding",
      "url": "http://arxiv.org/abs/2501.12139v1",
      "authors": "Zhen-Ye Huang, Weikang Wang, Hai-Jun Zhou",
      "update_time": "2025-01-21",
      "abstract": "The brain adopts the strategy of lateral predictive coding (LPC) to construct optimal internal representations for salient features in input sensory signals to reduce the energetic cost of information transmission. Here we consider the task of distinguishing a non-Gaussian signal by LPC from $(N-1)$ Gaussian background signals of the same magnitude, which is intractable by principal component decomposition. We study the emergence of feature detection function from the perspective of statistical mechanics, and formulate a thermodynamic free energy to implement the tradeoff between energetic cost $E$ and information robustness. We define $E$ as the mean $L_1$-norm of the internal state vectors, and quantify the level of information robustness by an entropy measure $S$. We demonstrate that energy--information tradeoff may induce a discontinuous phase transition of the optimal matrix, from a very weak one with $S \\approx 0$ to a functional LPC system with moderate synaptic weights in which a single unit responds selectively to the input non-Gaussian feature with high signal-to-noise ratio."
    },
    "2501.12111v1": {
      "title": "Using Space-Filling Curves and Fractals to Reveal Spatial and Temporal Patterns in Neuroimaging Data",
      "url": "http://arxiv.org/abs/2501.12111v1",
      "authors": "Jacek Grela, Zbigniew Drogosz, Jakub Janarek, Jeremi K. Ochab, Ignacio Cifre, Ewa Gudowska-Nowak, Maciej A. Nowak, Pawe\u0142 O\u015bwi\u0119cimka, Dante R. Chialvo",
      "update_time": "2025-01-21",
      "abstract": "We present a novel method, Fractal Space-Curve Analysis (FSCA), which combines Space-Filling Curve (SFC) mapping for dimensionality reduction with fractal Detrended Fluctuation Analysis (DFA). The method is suitable for multidimensional geometrically embedded data, especially for neuroimaging data which is highly correlated temporally and spatially. We conduct extensive feasibility studies on diverse, artificially generated data with known fractal characteristics: the fractional Brownian motion, Cantor sets, and Gaussian processes. We compare the suitability of dimensionality reduction via Hilbert SFC and a data-driven alternative. FSCA is then successfully applied to real-world magnetic resonance imaging (MRI) and functional MRI (fMRI) scans.   The method utilizing Hilbert curves is optimized for computational efficiency, proven robust against boundary effects typical in experimental data analysis, and resistant to data sub-sampling. It is able to correctly quantify and discern correlations in both stationary and dynamic two-dimensional images. In MRI Alzheimer's dataset, patients reveal a progression of the disease associated with a systematic decrease of the Hurst exponent. In fMRI recording of breath-holding task, the change in the exponent allows distinguishing different experimental phases.   This study introduces a robust method for fractal characterization of spatial and temporal correlations in many types of multidimensional neuroimaging data. Very few assumptions allow it to be generalized to more dimensions than typical for neuroimaging and utilized in other scientific fields. The method can be particularly useful in analyzing fMRI experiments to compute markers of pathological conditions resulting from neurodegeneration. We also showcase its potential for providing insights into brain dynamics in task-related experiments."
    },
    "2501.12081v1": {
      "title": "SPM 25: open source neuroimaging analysis software",
      "url": "http://arxiv.org/abs/2501.12081v1",
      "authors": "Tim M. Tierney, Nicholas A. Alexander, Nicole Labra Avila, Yael Balbastre, Gareth Barnes, Yulia Bezsudnova, Mikael Brudfors, Korbinian Eckstein, Guillaume Flandin, Karl Friston, Amirhossein Jafarian, Olivia S. Kowalczyk, Vladimir Litvak, Johan Medrano, Stephanie Mellor, George O'Neill, Thomas Parr, Adeel Razi, Ryan Timms, Peter Zeidman",
      "update_time": "2025-01-21",
      "abstract": "Statistical Parametric Mapping (SPM) is an integrated set of methods for testing hypotheses about the brain's structure and function, using data from imaging devices. These methods are implemented in an open source software package, SPM, which has been in continuous development for more than 30 years by an international community of developers. This paper reports the release of SPM 25.01, a major new version of the software that incorporates novel analysis methods, optimisations of existing methods, as well as improved practices for open science and software development."
    },
    "2501.12057v2": {
      "title": "Unified 3D MRI Representations via Sequence-Invariant Contrastive Learning",
      "url": "http://arxiv.org/abs/2501.12057v2",
      "authors": "Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner",
      "update_time": "2025-01-22",
      "abstract": "Self-supervised deep learning has accelerated 2D natural image analysis but remains difficult to translate into 3D MRI, where data are scarce and pre-trained 2D backbones cannot capture volumetric context. We present a sequence-invariant self-supervised framework leveraging quantitative MRI (qMRI). By simulating multiple MRI contrasts from a single 3D qMRI scan and enforcing consistent representations across these contrasts, we learn anatomy-centric rather than sequence-specific features. This yields a robust 3D encoder that performs strongly across varied tasks and protocols. Experiments on healthy brain segmentation (IXI), stroke lesion segmentation (ARC), and MRI denoising show significant gains over baseline SSL approaches, especially in low-data settings (up to +8.3% Dice, +4.2 dB PSNR). Our model also generalises effectively to unseen sites, demonstrating potential for more scalable and clinically reliable volumetric analysis. All code and trained models are publicly available."
    }
  },
  "EEG": {
    "2501.11081v1": {
      "title": "Robust Functional Ward's Linkages with Applications in EEG data Clustering",
      "url": "http://arxiv.org/abs/2501.11081v1",
      "authors": "Tianbo Chen",
      "update_time": "2025-01-19",
      "abstract": "This paper proposes two new distance measures, called functional Ward's linkages, for functional data clustering that are robust against outliers. Conventional Ward's linkage defines the distance between two clusters as the increase in sum of squared errors (SSE) upon merging, which can be interpreted graphically as an increase in the diameter. Analogously, functional Ward's linkage defines the distance of two clusters as the increased width of the band delimited by the merged clusters. To address the limitations of conventional Ward's linkage in handling outliers and contamination, the proposed linkages focus exclusively on the most central curves by leveraging magnitude-shape outlyingness measures and modified band depth, respectively. Simulations and real-world electroencephalogram (EEG) data analysis demonstrate that the proposed methods outperform other competitive approaches, particularly in the presence of various types of outliers and contamination."
    },
    "2501.10885v1": {
      "title": "CEReBrO: Compact Encoder for Representations of Brain Oscillations Using Efficient Alternating Attention",
      "url": "http://arxiv.org/abs/2501.10885v1",
      "authors": "Alexandru Dimofte, Glenn Anta Bucagu, Thorir Mar Ingolfsson, Xiaying Wang, Andrea Cossettini, Luca Benini, Yawei Li",
      "update_time": "2025-01-18",
      "abstract": "Electroencephalograph (EEG) is a crucial tool for studying brain activity. Recently, self-supervised learning methods leveraging large unlabeled datasets have emerged as a potential solution to the scarcity of widely available annotated EEG data. However, current methods suffer from at least one of the following limitations: i) sub-optimal EEG signal modeling, ii) model sizes in the hundreds of millions of trainable parameters, and iii) reliance on private datasets and/or inconsistent public benchmarks, hindering reproducibility. To address these challenges, we introduce a Compact Encoder for Representations of Brain Oscillations using alternating attention (CEReBrO), a new small EEG foundation model. Our tokenization scheme represents EEG signals at a per-channel patch granularity. We propose an alternating attention mechanism that jointly models intra-channel temporal dynamics and inter-channel spatial correlations, achieving 2x speed improvement with 6x less memory required compared to standard self-attention. We present several model sizes ranging from 3.6 million to 85 million parameters. Pre-trained on over 20,000 hours of publicly available scalp EEG recordings with diverse channel configurations, our models set new benchmarks in emotion detection and seizure detection tasks, with competitive performance in anomaly classification and gait prediction. This validates our models' effectiveness and effictiveness."
    },
    "2501.10342v1": {
      "title": "Hybrid Deep Learning Model for epileptic seizure classification by using 1D-CNN with multi-head attention mechanism",
      "url": "http://arxiv.org/abs/2501.10342v1",
      "authors": "Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed",
      "update_time": "2025-01-17",
      "abstract": "Epilepsy is a prevalent neurological disorder globally, impacting around 50 million people \\cite{WHO_epilepsy_50million}. Epileptic seizures result from sudden abnormal electrical activity in the brain, which can be read as sudden and significant changes in the EEG signal of the brain. The signal can vary in severity and frequency, which results in loss of consciousness and muscle contractions for a short period of time \\cite{epilepsyfoundation_myoclonic}. Individuals with epilepsy often face significant employment challenges due to safety concerns in certain work environments. Many jobs that involve working at heights, operating heavy machinery, or in other potentially hazardous settings may be restricted for people with seizure disorders. This certainly limits job options and economic opportunities for those living with epilepsy."
    },
    "2501.09700v1": {
      "title": "Cueless EEG imagined speech for subject identification: dataset and benchmarks",
      "url": "http://arxiv.org/abs/2501.09700v1",
      "authors": "Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee",
      "update_time": "2025-01-16",
      "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for biometric identification. While previous studies have explored the use of imagined speech with semantically meaningful words for subject identification, most have relied on additional visual or auditory cues. In this study, we introduce a cueless EEG-based imagined speech paradigm, where subjects imagine the pronunciation of semantically meaningful words without any external cues. This innovative approach addresses the limitations of prior methods by requiring subjects to select and imagine words from a predefined list naturally. The dataset comprises over 4,350 trials from 11 subjects across five sessions. We assess a variety of classification methods, including traditional machine learning techniques such as Support Vector Machines (SVM) and XGBoost, as well as time-series foundation models and deep learning architectures specifically designed for EEG classification, such as EEG Conformer and Shallow ConvNet. A session-based hold-out validation strategy was employed to ensure reliable evaluation and prevent data leakage. Our results demonstrate outstanding classification accuracy, reaching 97.93%. These findings highlight the potential of cueless EEG paradigms for secure and reliable subject identification in real-world applications, such as brain-computer interfaces (BCIs).",
      "code_url": "https://github.com/alidr79/cueless_eeg_subject_identification"
    },
    "2501.09519v1": {
      "title": "Multi-task deep-learning for sleep event detection and stage classification",
      "url": "http://arxiv.org/abs/2501.09519v1",
      "authors": "Adriana Anido-Alonso, Diego Alvarez-Estevez",
      "update_time": "2025-01-16",
      "abstract": "Polysomnographic sleep analysis is the standard clinical method to accurately diagnose and treat sleep disorders. It is an intricate process which involves the manual identification, classification, and location of multiple sleep event patterns. This is complex, for which identification of different types of events involves focusing on different subsets of signals, resulting on an iterative time-consuming process entailing several visual analysis passes. In this paper we propose a multi-task deep-learning approach for the simultaneous detection of sleep events and hypnogram construction in one single pass. Taking as reference state-of-the-art methodology for object-detection in the field of Computer Vision, we reformulate the problem for the analysis of multi-variate time sequences, and more specifically for pattern detection in the sleep analysis scenario. We investigate the performance of the resulting method in identifying different assembly combinations of EEG arousals, respiratory events (apneas and hypopneas) and sleep stages, also considering different input signal montage configurations. Furthermore, we evaluate our approach using two independent datasets, assessing true-generalization effects involving local and external validation scenarios. Based on our results, we analyze and discuss our method's capabilities and its potential wide-range applicability across different settings and datasets.",
      "code_url": "https://github.com/adrania/sleep-events-detection"
    },
    "2501.08693v1": {
      "title": "Subject Disentanglement Neural Network for Speech Envelope Reconstruction from EEG",
      "url": "http://arxiv.org/abs/2501.08693v1",
      "authors": "Li Zhang, Jiyao Liu",
      "update_time": "2025-01-15",
      "abstract": "Reconstructing speech envelopes from EEG signals is essential for exploring neural mechanisms underlying speech perception. Yet, EEG variability across subjects and physiological artifacts complicate accurate reconstruction. To address this problem, we introduce Subject Disentangling Neural Network (SDN-Net), which disentangles subject identity information from reconstructed speech envelopes to enhance cross-subject reconstruction accuracy. SDN-Net integrates three key components: MLA-Codec, MPN-MI, and CTA-MTDNN. The MLA-Codec, a fully convolutional neural network, decodes EEG signals into speech envelopes. The CTA-MTDNN module, a multi-scale time-delay neural network with channel and temporal attention, extracts subject identity features from EEG signals. Lastly, the MPN-MI module, a mutual information estimator with a multi-layer perceptron, supervises the removal of subject identity information from the reconstructed speech envelope. Experiments on the Auditory EEG Decoding Dataset demonstrate that SDN-Net achieves superior performance in inner- and cross-subject speech envelope reconstruction compared to recent state-of-the-art methods."
    },
    "2501.08518v1": {
      "title": "Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface",
      "url": "http://arxiv.org/abs/2501.08518v1",
      "authors": "Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li",
      "update_time": "2025-01-15",
      "abstract": "Seasickness is a prevalent issue that adversely impacts both passenger experiences and the operational efficiency of maritime crews. While techniques that redirect attention have proven effective in alleviating motion sickness symptoms in terrestrial environments, applying similar strategies to manage seasickness poses unique challenges due to the prolonged and intense motion environment associated with maritime travel. In this study, we propose a mindfulness brain-computer interface (BCI), specifically designed to redirect attention with the aim of mitigating seasickness symptoms in real-world settings. Our system utilizes a single-channel headband to capture prefrontal EEG signals, which are then wirelessly transmitted to computing devices for the assessment of mindfulness states. The results are transferred into real-time feedback as mindfulness scores and audiovisual stimuli, facilitating a shift in attentional focus from physiological discomfort to mindfulness practices. A total of 43 individuals participated in a real-world maritime experiment consisted of three sessions: a real-feedback mindfulness session, a resting session, and a pseudofeedback mindfulness session. Notably, 81.39% of participants reported that the mindfulness BCI intervention was effective, and there was a significant reduction in the severity of seasickness, as measured by the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in the theta/beta ratio, corresponding with the alleviation of seasickness symptoms. A decrease in overall EEG band power during the real-feedback mindfulness session suggests that the mindfulness BCI fosters a more tranquil and downregulated state of brain activity. Together, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, with the potential to enhance the cruising experience for both passengers and crews."
    },
    "2501.08237v1": {
      "title": "Cognitive Assessment and Training in Extended Reality: Multimodal Systems, Clinical Utility, and Current Challenges",
      "url": "http://arxiv.org/abs/2501.08237v1",
      "authors": "Palmira Victoria Gonz\u00e1lez-Erena, Sara Fern\u00e1ndez-Guinea, Panagiotis Kourtesis",
      "update_time": "2025-01-14",
      "abstract": "Extended reality (XR) technologies-encompassing virtual reality (VR), augmented reality (AR), and mixed reality (MR) are transforming cognitive assessment and training by offering immersive, interactive environments that simulate real-world tasks. XR enhances ecological validity while enabling real-time, multimodal data collection through tools such as galvanic skin response (GSR), electroencephalography (EEG), eye tracking (ET), hand tracking, and body tracking. This allows for a more comprehensive understanding of cognitive and emotional processes, as well as adaptive, personalized interventions for users. Despite these advancements, current XR applications often underutilize the full potential of multimodal integration, relying primarily on visual and auditory inputs. Challenges such as cybersickness, usability concerns, and accessibility barriers further limit the widespread adoption of XR tools in cognitive science and clinical practice. This review examines XR-based cognitive assessment and training, focusing on its advantages over traditional methods, including ecological validity, engagement, and adaptability. It also explores unresolved challenges such as system usability, cost, and the need for multimodal feedback integration. The review concludes by identifying opportunities for optimizing XR tools to improve cognitive evaluation and rehabilitation outcomes, particularly for diverse populations, including older adults and individuals with cognitive impairments."
    },
    "2501.08139v1": {
      "title": "EEG-ReMinD: Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics",
      "url": "http://arxiv.org/abs/2501.08139v1",
      "authors": "Zirui Wang, Zhenxi Song, Yi Guo, Yuxin Liu, Guoyang Xu, Min Zhang, Zhiguo Zhang",
      "update_time": "2025-01-14",
      "abstract": "The development of EEG decoding algorithms confronts challenges such as data sparsity, subject variability, and the need for precise annotations, all of which are vital for advancing brain-computer interfaces and enhancing the diagnosis of diseases. To address these issues, we propose a novel two-stage approach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics (EEG-ReMinD) , which mitigates reliance on supervised learning and integrates inherent geometric features. This approach efficiently handles EEG data corruptions and reduces the dependency on labels. EEG-ReMinD utilizes self-supervised and geometric learning techniques, along with an attention mechanism, to analyze the temporal dynamics of EEG features within the framework of Riemannian geometry, referred to as Riemannian dynamics. Comparative analyses on both intact and corrupted datasets from two different neurodegenerative disorders underscore the enhanced performance of EEG-ReMinD."
    },
    "2501.08124v1": {
      "title": "Neural Speech Tracking in a Virtual Acoustic Environment: Audio-Visual Benefit for Unscripted Continuous Speech",
      "url": "http://arxiv.org/abs/2501.08124v1",
      "authors": "Mareike Daeglau, Juergen Otten, Giso Grimm, Bojana Mirkovic, Volker Hohmann, Stefan Debener",
      "update_time": "2025-01-14",
      "abstract": "The audio visual benefit in speech perception, where congruent visual input enhances auditory processing, is well documented across age groups, particularly in challenging listening conditions and among individuals with varying hearing abilities. However, most studies rely on highly controlled laboratory environments with scripted stimuli. Here, we examine the audio visual benefit using unscripted, natural speech from untrained speakers within a virtual acoustic environment. Using electroencephalography (EEG) and cortical speech tracking, we assessed neural responses across audio visual, audio only, visual only, and masked lip conditions to isolate the role of lip movements. Additionally, we analysed individual differences in acoustic and visual features of the speakers, including pitch, jitter, and lip openness, to explore their influence on the audio visual speech tracking benefit. Results showed a significant audio visual enhancement in speech tracking with background noise, with the masked lip condition performing similarly to the audio-only condition, emphasizing the importance of lip movements in adverse listening situations. Our findings reveal the feasibility of cortical speech tracking with naturalistic stimuli and underscore the impact of individual speaker characteristics on audio-visual integration in real world listening contexts."
    }
  },
  "BCI": {
    "2501.09700v1": {
      "title": "Cueless EEG imagined speech for subject identification: dataset and benchmarks",
      "url": "http://arxiv.org/abs/2501.09700v1",
      "authors": "Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee",
      "update_time": "2025-01-16",
      "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for biometric identification. While previous studies have explored the use of imagined speech with semantically meaningful words for subject identification, most have relied on additional visual or auditory cues. In this study, we introduce a cueless EEG-based imagined speech paradigm, where subjects imagine the pronunciation of semantically meaningful words without any external cues. This innovative approach addresses the limitations of prior methods by requiring subjects to select and imagine words from a predefined list naturally. The dataset comprises over 4,350 trials from 11 subjects across five sessions. We assess a variety of classification methods, including traditional machine learning techniques such as Support Vector Machines (SVM) and XGBoost, as well as time-series foundation models and deep learning architectures specifically designed for EEG classification, such as EEG Conformer and Shallow ConvNet. A session-based hold-out validation strategy was employed to ensure reliable evaluation and prevent data leakage. Our results demonstrate outstanding classification accuracy, reaching 97.93%. These findings highlight the potential of cueless EEG paradigms for secure and reliable subject identification in real-world applications, such as brain-computer interfaces (BCIs).",
      "code_url": "https://github.com/alidr79/cueless_eeg_subject_identification"
    },
    "2501.09459v1": {
      "title": "Teaching Wav2Vec2 the Language of the Brain",
      "url": "http://arxiv.org/abs/2501.09459v1",
      "authors": "Tobias Fiedler, Leon Hermann, Florian M\u00fcller, Sarel Cohen, Peter Chin, Tobias Friedrich, Eilon Vaadia",
      "update_time": "2025-01-16",
      "abstract": "The decoding of continuously spoken speech from neuronal activity has the potential to become an important clinical solution for paralyzed patients. Deep Learning Brain Computer Interfaces (BCIs) have recently successfully mapped neuronal activity to text contents in subjects who attempted to formulate speech. However, only small BCI datasets are available. In contrast, labeled data and pre-trained models for the closely related task of speech recognition from audio are widely available. One such model is Wav2Vec2 which has been trained in a self-supervised fashion to create meaningful representations of speech audio data. In this study, we show that patterns learned by Wav2Vec2 are transferable to brain data. Specifically, we replace its audio feature extractor with an untrained Brain Feature Extractor (BFE) model. We then execute full fine-tuning with pre-trained weights for Wav2Vec2, training ''from scratch'' without pre-trained weights as well as freezing a pre-trained Wav2Vec2 and training only the BFE each for 45 different BFE architectures. Across these experiments, the best run is from full fine-tuning with pre-trained weights, achieving a Character Error Rate (CER) of 18.54\\%, outperforming the best training from scratch run by 20.46\\% and that of frozen Wav2Vec2 training by 15.92\\% percentage points. These results indicate that knowledge transfer from audio speech recognition to brain decoding is possible and significantly improves brain decoding performance for the same architectures. Related source code is available at https://github.com/tfiedlerdev/Wav2Vec2ForBrain.",
      "code_url": "https://github.com/tfiedlerdev/wav2vec2forbrain"
    },
    "2501.08518v1": {
      "title": "Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface",
      "url": "http://arxiv.org/abs/2501.08518v1",
      "authors": "Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li",
      "update_time": "2025-01-15",
      "abstract": "Seasickness is a prevalent issue that adversely impacts both passenger experiences and the operational efficiency of maritime crews. While techniques that redirect attention have proven effective in alleviating motion sickness symptoms in terrestrial environments, applying similar strategies to manage seasickness poses unique challenges due to the prolonged and intense motion environment associated with maritime travel. In this study, we propose a mindfulness brain-computer interface (BCI), specifically designed to redirect attention with the aim of mitigating seasickness symptoms in real-world settings. Our system utilizes a single-channel headband to capture prefrontal EEG signals, which are then wirelessly transmitted to computing devices for the assessment of mindfulness states. The results are transferred into real-time feedback as mindfulness scores and audiovisual stimuli, facilitating a shift in attentional focus from physiological discomfort to mindfulness practices. A total of 43 individuals participated in a real-world maritime experiment consisted of three sessions: a real-feedback mindfulness session, a resting session, and a pseudofeedback mindfulness session. Notably, 81.39% of participants reported that the mindfulness BCI intervention was effective, and there was a significant reduction in the severity of seasickness, as measured by the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in the theta/beta ratio, corresponding with the alleviation of seasickness symptoms. A decrease in overall EEG band power during the real-feedback mindfulness session suggests that the mindfulness BCI fosters a more tranquil and downregulated state of brain activity. Together, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, with the potential to enhance the cruising experience for both passengers and crews."
    },
    "2501.06326v1": {
      "title": "On Creating A Brain-To-Text Decoder",
      "url": "http://arxiv.org/abs/2501.06326v1",
      "authors": "Zenon Lamprou, Yashar Moshfeghi",
      "update_time": "2025-01-10",
      "abstract": "Brain decoding has emerged as a rapidly advancing and extensively utilized technique within neuroscience. This paper centers on the application of raw electroencephalogram (EEG) signals for decoding human brain activity, offering a more expedited and efficient methodology for enhancing our understanding of the human brain. The investigation specifically scrutinizes the efficacy of brain-computer interfaces (BCI) in deciphering neural signals associated with speech production, with particular emphasis on the impact of vocabulary size, electrode density, and training data on the framework's performance. The study reveals the competitive word error rates (WERs) achievable on the Librispeech benchmark through pre-training on unlabelled data for speech processing. Furthermore, the study evaluates the efficacy of voice recognition under configurations with limited labeled data, surpassing previous state-of-the-art techniques while utilizing significantly fewer labels. Additionally, the research provides a comprehensive analysis of error patterns in voice recognition and the influence of model size and unlabelled training data. It underscores the significance of factors such as vocabulary size and electrode density in enhancing BCI performance, advocating for an increase in microelectrodes and refinement of language models."
    },
    "2501.05610v1": {
      "title": "Towards Probabilistic Inference of Human Motor Intentions by Assistive Mobile Robots Controlled via a Brain-Computer Interface",
      "url": "http://arxiv.org/abs/2501.05610v1",
      "authors": "Xiaoshan Zhou, Carol M. Menassa, Vineet R. Kamat",
      "update_time": "2025-01-09",
      "abstract": "Assistive mobile robots are a transformative technology that helps persons with disabilities regain the ability to move freely. Although autonomous wheelchairs significantly reduce user effort, they still require human input to allow users to maintain control and adapt to changing environments. Brain Computer Interface (BCI) stands out as a highly user-friendly option that does not require physical movement. Current BCI systems can understand whether users want to accelerate or decelerate, but they implement these changes in discrete speed steps rather than allowing for smooth, continuous velocity adjustments. This limitation prevents the systems from mimicking the natural, fluid speed changes seen in human self-paced motion. The authors aim to address this limitation by redesigning the perception-action cycle in a BCI controlled robotic system: improving how the robotic agent interprets the user's motion intentions (world state) and implementing these actions in a way that better reflects natural physical properties of motion, such as inertia and damping. The scope of this paper focuses on the perception aspect. We asked and answered a normative question \"what computation should the robotic agent carry out to optimally perceive incomplete or noisy sensory observations?\" Empirical EEG data were collected, and probabilistic representation that served as world state distributions were learned and evaluated in a Generative Adversarial Network framework. The ROS framework was established that connected with a Gazebo environment containing a digital twin of an indoor space and a virtual model of a robotic wheelchair. Signal processing and statistical analyses were implemented to identity the most discriminative features in the spatial-spectral-temporal dimensions, which are then used to construct the world model for the robotic agent to interpret user motion intentions as a Bayesian observer."
    },
    "2501.05589v1": {
      "title": "LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric Learning",
      "url": "http://arxiv.org/abs/2501.05589v1",
      "authors": "Jianchao Lu, Yuzhe Tian, Yang Zhang, Quan Z. Sheng, Xi Zheng",
      "update_time": "2025-01-09",
      "abstract": "Brain--computer interfaces are groundbreaking technology whereby brain signals are used to control external devices. Despite some advances in recent years, electroencephalogram (EEG)-based motor-imagery tasks face challenges, such as amplitude and phase variability and complex spatial correlations, with a need for smaller models and faster inference. In this study, we develop a prototype, called the Lightweight Geometric Learning Brain--Computer Interface (LGL-BCI), which uses our customized geometric deep learning architecture for swift model inference without sacrificing accuracy. LGL-BCI contains an EEG channel selection module via a feature decomposition algorithm to reduce the dimensionality of a symmetric positive definite matrix, providing adaptiveness among the continuously changing EEG signal. Meanwhile, a built-in lossless transformation helps boost the inference speed. The performance of our solution was evaluated using two real-world EEG devices and two public EEG datasets. LGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54% compared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses fewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency. These findings underscore both the superior accuracy and computational efficiency of LGL-BCI, demonstrating the feasibility and robustness of geometric deep learning in motor-imagery brain--computer interface applications."
    },
    "2501.05525v1": {
      "title": "MECASA: Motor Execution Classification using Additive Self-Attention for Hybrid EEG-fNIRS Data",
      "url": "http://arxiv.org/abs/2501.05525v1",
      "authors": "Gourav Siddhad, Juhi Singh, Partha Pratim Roy",
      "update_time": "2025-01-09",
      "abstract": "Motor execution, a fundamental aspect of human behavior, has been extensively studied using BCI technologies. EEG and fNIRS have been utilized to provide valuable insights, but their individual limitations have hindered performance. This study investigates the effectiveness of fusing electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) data for classifying rest versus task states in a motor execution paradigm. Using the SMR Hybrid BCI dataset, this work compares unimodal (EEG and fNIRS) classifiers with a multimodal fusion approach. It proposes Motor Execution using Convolutional Additive Self-Attention Mechanisms (MECASA), a novel architecture leveraging convolutional operations and self-attention to capture complex patterns in multimodal data. MECASA, built upon the CAS-ViT architecture, employs a computationally efficient, convolutional-based self-attention module (CASA), a hybrid block design, and a dedicated fusion network to combine features from separate EEG and fNIRS processing streams. Experimental results demonstrate that MECASA consistently outperforms established methods across all modalities (EEG, fNIRS, and fused), with fusion consistently improving accuracy compared to single-modality approaches. fNIRS generally achieved higher accuracy than EEG alone. Ablation studies revealed optimal configurations for MECASA, with embedding dimensions of 64-128 providing the best performance for EEG data and OD128 (upsampled optical density) yielding superior results for fNIRS data. This work highlights the potential of deep learning, specifically MECASA, to enhance EEG-fNIRS fusion for BCI applications."
    },
    "2501.04844v1": {
      "title": "Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction",
      "url": "http://arxiv.org/abs/2501.04844v1",
      "authors": "Jihwan Lee, Tiantian Feng, Aditya Kommineni, Sudarsana Reddy Kadiri, Shrikanth Narayanan",
      "update_time": "2025-01-08",
      "abstract": "Brain-computer interfaces (BCI) offer numerous human-centered application possibilities, particularly affecting people with neurological disorders. Text or speech decoding from brain activities is a relevant domain that could augment the quality of life for people with impaired speech perception. We propose a novel approach to enhance listened speech decoding from electroencephalography (EEG) signals by utilizing an auxiliary phoneme predictor that simultaneously decodes textual phoneme sequences. The proposed model architecture consists of three main parts: EEG module, speech module, and phoneme predictor. The EEG module learns to properly represent EEG signals into EEG embeddings. The speech module generates speech waveforms from the EEG embeddings. The phoneme predictor outputs the decoded phoneme sequences in text modality. Our proposed approach allows users to obtain decoded listened speech from EEG signals in both modalities (speech waveforms and textual phoneme sequences) simultaneously, eliminating the need for a concatenated sequential pipeline for each modality. The proposed approach also outperforms previous methods in both modalities. The source code and speech samples are publicly available.",
      "code_url": "https://github.com/lee-jhwn/icassp25-fesde-phoneme"
    },
    "2501.04359v1": {
      "title": "Decoding EEG Speech Perception with Transformers and VAE-based Data Augmentation",
      "url": "http://arxiv.org/abs/2501.04359v1",
      "authors": "Terrance Yu-Hao Chen, Yulin Chen, Pontus Soederhaell, Sadrishya Agrawal, Kateryna Shapovalenko",
      "update_time": "2025-01-08",
      "abstract": "Decoding speech from non-invasive brain signals, such as electroencephalography (EEG), has the potential to advance brain-computer interfaces (BCIs), with applications in silent communication and assistive technologies for individuals with speech impairments. However, EEG-based speech decoding faces major challenges, such as noisy data, limited datasets, and poor performance on complex tasks like speech perception. This study attempts to address these challenges by employing variational autoencoders (VAEs) for EEG data augmentation to improve data quality and applying a state-of-the-art (SOTA) sequence-to-sequence deep learning architecture, originally successful in electromyography (EMG) tasks, to EEG-based speech decoding. Additionally, we adapt this architecture for word classification tasks. Using the Brennan dataset, which contains EEG recordings of subjects listening to narrated speech, we preprocess the data and evaluate both classification and sequence-to-sequence models for EEG-to-words/sentences tasks. Our experiments show that VAEs have the potential to reconstruct artificial EEG data for augmentation. Meanwhile, our sequence-to-sequence model achieves more promising performance in generating sentences compared to our classification model, though both remain challenging tasks. These findings lay the groundwork for future research on EEG speech perception decoding, with possible extensions to speech production tasks such as silent or imagined speech."
    },
    "2501.03596v1": {
      "title": "Exploring EEG and Eye Movement Fusion for Multi-Class Target RSVP-BCI",
      "url": "http://arxiv.org/abs/2501.03596v1",
      "authors": "Xujin Li, Wei Wei, Kun Zhao, Jiayu Mao, Yizhuo Lu, Shuang Qiu, Huiguang He",
      "update_time": "2025-01-07",
      "abstract": "Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interfaces (BCIs) facilitate high-throughput target image detection by identifying event-related potentials (ERPs) evoked in EEG signals. The RSVP-BCI systems effectively detect single-class targets within a stream of images but have limited applicability in scenarios that require detecting multiple target categories. Multi-class RSVP-BCI systems address this limitation by simultaneously identifying the presence of a target and distinguishing its category. However, existing multi-class RSVP decoding algorithms predominantly rely on single-modality EEG decoding, which restricts their performance improvement due to the high similarity between ERPs evoked by different target categories. In this work, we introduce eye movement (EM) modality into multi-class RSVP decoding and explore EEG and EM fusion to enhance decoding performance. First, we design three independent multi-class target RSVP tasks and build an open-source dataset comprising EEG and EM signals from 43 subjects. Then, we propose the Multi-class Target RSVP EEG and EM fusion Network (MTREE-Net) to enhance multi-class RSVP decoding. Specifically, a dual-complementary module is proposed to strengthen the differentiation of uni-modal features across categories. To improve multi-modal fusion performance, we adopt a dynamic reweighting fusion strategy guided by theoretically derived modality contribution ratios. Furthermore, we reduce the misclassification of non-target samples through knowledge transfer between two hierarchical classifiers. Extensive experiments demonstrate the feasibility of integrating EM signals into multi-class RSVP decoding and highlight the superior performance of MTREE-Net compared to existing RSVP decoding methods. The proposed MTREE-Net and open-source dataset provide a promising framework for developing practical multi-class RSVP-BCI systems."
    }
  },
  "fMRI": {
    "2501.12111v1": {
      "title": "Using Space-Filling Curves and Fractals to Reveal Spatial and Temporal Patterns in Neuroimaging Data",
      "url": "http://arxiv.org/abs/2501.12111v1",
      "authors": "Jacek Grela, Zbigniew Drogosz, Jakub Janarek, Jeremi K. Ochab, Ignacio Cifre, Ewa Gudowska-Nowak, Maciej A. Nowak, Pawe\u0142 O\u015bwi\u0119cimka, Dante R. Chialvo",
      "update_time": "2025-01-21",
      "abstract": "We present a novel method, Fractal Space-Curve Analysis (FSCA), which combines Space-Filling Curve (SFC) mapping for dimensionality reduction with fractal Detrended Fluctuation Analysis (DFA). The method is suitable for multidimensional geometrically embedded data, especially for neuroimaging data which is highly correlated temporally and spatially. We conduct extensive feasibility studies on diverse, artificially generated data with known fractal characteristics: the fractional Brownian motion, Cantor sets, and Gaussian processes. We compare the suitability of dimensionality reduction via Hilbert SFC and a data-driven alternative. FSCA is then successfully applied to real-world magnetic resonance imaging (MRI) and functional MRI (fMRI) scans.   The method utilizing Hilbert curves is optimized for computational efficiency, proven robust against boundary effects typical in experimental data analysis, and resistant to data sub-sampling. It is able to correctly quantify and discern correlations in both stationary and dynamic two-dimensional images. In MRI Alzheimer's dataset, patients reveal a progression of the disease associated with a systematic decrease of the Hurst exponent. In fMRI recording of breath-holding task, the change in the exponent allows distinguishing different experimental phases.   This study introduces a robust method for fractal characterization of spatial and temporal correlations in many types of multidimensional neuroimaging data. Very few assumptions allow it to be generalized to more dimensions than typical for neuroimaging and utilized in other scientific fields. The method can be particularly useful in analyzing fMRI experiments to compute markers of pathological conditions resulting from neurodegeneration. We also showcase its potential for providing insights into brain dynamics in task-related experiments."
    },
    "2501.09805v1": {
      "title": "Multiplex Nodal Modularity: A novel network metric for the regional analysis of amnestic mild cognitive impairment during a working memory binding task",
      "url": "http://arxiv.org/abs/2501.09805v1",
      "authors": "Avalon Campbell-Cousins, Federica Guazzo, Mark Bastin, Mario A. Parra, Javier Escudero",
      "update_time": "2025-01-16",
      "abstract": "Modularity is a well-established concept for assessing community structures in various single and multi-layer networks, including those in biological and social domains. Biological networks, such as the brain, are known to exhibit group structure at a variety of scales -- local, meso, and global scale. Modularity, while useful in describing mesoscale brain organization, is limited as a metric to a global scale describing the overall strength of community structure. This approach, while valuable, overlooks important localized variations in community structure at the node level. To address this limitation, we extended modularity to individual nodes. This novel measure of nodal modularity ($nQ$) captures both meso and local scale changes in modularity. We hypothesized that $nQ$ illuminates granular changes in the brain due to diseases such as Alzheimer's disease (AD), which are known to disrupt the brain's modular structure. We explored $nQ$ in multiplex networks of a visual short-term memory binding task in fMRI and DTI data in the early stages of AD. Observed changes in $nQ$ in fMRI and DTI networks aligned with known trajectories of AD and were linked to common biomarkers of the disease, including amyloid-$\\beta$ and tau. Additionally, $nQ$ clearly differentiated MCI from MCI converters showing indications that $nQ$ may be a useful diagnostic tool for characterizing disease stages. Our findings demonstrate the utility of $nQ$ as a measure of localized group structure, providing novel insights into temporal and disease related variability at the node level. Given the widespread application of modularity as a global measure, $nQ$ represents a significant advancement, providing a granular measure of network organization applicable to a wide range of disciplines."
    },
    "2501.09350v1": {
      "title": "Making Your Dreams A Reality: Decoding the Dreams into a Coherent Video Story from fMRI Signals",
      "url": "http://arxiv.org/abs/2501.09350v1",
      "authors": "Yanwei Fu, Jianxiong Gao, Baofeng Yang, Jianfeng Feng",
      "update_time": "2025-01-16",
      "abstract": "This paper studies the brave new idea for Multimedia community, and proposes a novel framework to convert dreams into coherent video narratives using fMRI data. Essentially, dreams have intrigued humanity for centuries, offering glimpses into our subconscious minds. Recent advancements in brain imaging, particularly functional magnetic resonance imaging (fMRI), have provided new ways to explore the neural basis of dreaming. By combining subjective dream experiences with objective neurophysiological data, we aim to understand the visual aspects of dreams and create complete video narratives. Our process involves three main steps: reconstructing visual perception, decoding dream imagery, and integrating dream stories. Using innovative techniques in fMRI analysis and language modeling, we seek to push the boundaries of dream research and gain deeper insights into visual experiences during sleep. This technical report introduces a novel approach to visually decoding dreams using fMRI signals and weaving dream visuals into narratives using language models. We gather a dataset of dreams along with descriptions to assess the effectiveness of our framework."
    },
    "2501.08958v1": {
      "title": "Kolmogorov-Arnold Networks for Time Series Granger Causality Inference",
      "url": "http://arxiv.org/abs/2501.08958v1",
      "authors": "Meiliang Liu, Yunfang Xu, Zijin Li, Zhengye Si, Xiaoxiao Yang, Xinyue Yang, Zhiwen Zhao",
      "update_time": "2025-01-15",
      "abstract": "We introduce Granger Causality Kolmogorov-Arnold Networks (GCKAN), an innovative architecture that extends the recently proposed Kolmogorov-Arnold Networks (KAN) to the domain of causal inference. By extracting base weights from KAN layers and incorporating the sparsity-inducing penalty along with ridge regularization, GCKAN infers the Granger causality from time series while enabling automatic time lag selection. Additionally, we propose an algorithm leveraging time-reversed Granger causality to enhance inference accuracy. The algorithm compares prediction and sparse-inducing losses derived from the original and time-reversed series, automatically selecting the casual relationship with the higher score or integrating the results to mitigate spurious connectivities. Comprehensive experiments conducted on Lorenz-96, gene regulatory networks, fMRI BOLD signals, and VAR datasets demonstrate that the proposed model achieves competitive performance to state-of-the-art methods in inferring Granger causality from nonlinear, high-dimensional, and limited-sample time series."
    },
    "2501.08567v2": {
      "title": "A new perspective on brain stimulation interventions: Optimal stochastic tracking control of brain network dynamics",
      "url": "http://arxiv.org/abs/2501.08567v2",
      "authors": "Kangli Dong, Siya Chen, Ying Dan, Lu Zhang, Xinyi Li, Wei Liang, Yue Zhao, Yu Sun",
      "update_time": "2025-01-16",
      "abstract": "Network control theory (NCT) has recently been utilized in neuroscience to facilitate our understanding of brain stimulation effects. A particularly useful branch of NCT is optimal control, which focuses on applying theoretical and computational principles of control theory to design optimal strategies to achieve specific goals in neural processes. However, most existing research focuses on optimally controlling brain network dynamics from the original state to a target state at a specific time point. In this paper, we present the first investigation of introducing optimal stochastic tracking control strategy to synchronize the dynamics of the brain network to a target dynamics rather than to a target state at a specific time point. We utilized fMRI data from healthy groups, and cases of stroke and post-stroke aphasia. For all participants, we utilized a gradient descent optimization method to estimate the parameters for the brain network dynamic system. We then utilized optimal stochastic tracking control techniques to drive original unhealthy dynamics by controlling a certain number of nodes to synchronize with target healthy dynamics. Results show that the energy associated with optimal stochastic tracking control is negatively correlated with the intrinsic average controllability of the brain network system, while the energy of the optimal state approaching control is significantly related to the target state value. For a 100-dimensional brain network system, controlling the five nodes with the lowest tracking energy can achieve relatively acceptable dynamics control effects. Our results suggest that stochastic tracking control is more aligned with the objective of brain stimulation interventions, and is closely related to the intrinsic characteristics of the brain network system, potentially representing a new direction for future brain network optimal control research."
    },
    "2501.03381v1": {
      "title": "THOI: An efficient and accessible library for computing higher-order interactions enhanced by batch-processing",
      "url": "http://arxiv.org/abs/2501.03381v1",
      "authors": "Laouen Belloli, Pedro Mediano, Rodrigo Cofr\u00e9, Diego Fernandez Slezak, Rub\u00e9n Herzog",
      "update_time": "2025-01-06",
      "abstract": "Complex systems are characterized by nonlinear dynamics, multi-level interactions, and emergent collective behaviors. Traditional analyses that focus solely on pairwise interactions often oversimplify these systems, neglecting the higher-order interactions critical for understanding their full collective dynamics. Recent advances in multivariate information theory provide a principled framework for quantifying these higher-order interactions, capturing key properties such as redundancy, synergy, shared randomness, and collective constraints. However, two major challenges persist: accurately estimating joint entropies and addressing the combinatorial explosion of interacting terms. To overcome these challenges, we introduce THOI (Torch-based High-Order Interactions), a novel, accessible, and efficient Python library for computing high-order interactions in continuous-valued systems. THOI leverages the well-established Gaussian copula method for joint entropy estimation, combined with state-of-the-art batch and parallel processing techniques to optimize performance across CPU, GPU, and TPU environments. Our results demonstrate that THOI significantly outperforms existing tools in terms of speed and scalability. For larger systems, where exhaustive analysis is computationally impractical, THOI integrates optimization strategies that make higher-order interaction analysis feasible. We validate THOI accuracy using synthetic datasets with parametrically controlled interactions and further illustrate its utility by analyzing fMRI data from human subjects in wakeful resting states and under deep anesthesia. Finally, we analyzed over 900 real-world and synthetic datasets, establishing a comprehensive framework for applying higher-order interaction (HOI) analysis in complex systems."
    },
    "2501.02570v1": {
      "title": "Decoding fMRI Data into Captions using Prefix Language Modeling",
      "url": "http://arxiv.org/abs/2501.02570v1",
      "authors": "Vyacheslav Shen, Kassymzhomart Kunanbayev, Dae-Shik Kim",
      "update_time": "2025-01-05",
      "abstract": "With the advancements in Large Language and Latent Diffusion models, brain decoding has achieved remarkable results in recent years. The works on the NSD dataset, with stimuli images from the COCO dataset, leverage the embeddings from the CLIP model for image reconstruction and GIT for captioning. However, the current captioning approach introduces the challenge of potential data contamination given that the GIT model was trained on the COCO dataset. In this work, we present an alternative method for decoding brain signals into image captions by predicting a DINOv2 model's embedding of an image from the corresponding fMRI signal and then providing its [CLS] token as the prefix to the GPT-2 language model which decreases computational requirements considerably. Additionally, instead of commonly used Linear Regression, we explore 3D Convolutional Neural Network mapping of fMRI signals to image embedding space for better accounting positional information of voxels.",
      "code_url": "https://github.com/slavaheroes/brain-captioning-with-gpt2"
    },
    "2501.01476v1": {
      "title": "Sparse identification of evolution equations via Bayesian model selection",
      "url": "http://arxiv.org/abs/2501.01476v1",
      "authors": "Tim W. Kroll, Oliver Kamps",
      "update_time": "2025-01-01",
      "abstract": "The quantitative formulation of evolution equations is the backbone for prediction, control, and understanding of dynamical systems across diverse scientific fields. Besides deriving differential equations for dynamical systems based on basic scientific reasoning or prior knowledge in recent times a growing interest emerged to infer these equations purely from data. In this article, we introduce a novel method for the sparse identification of nonlinear dynamical systems from observational data, based on the observation how the key challenges of the quality of time derivatives and sampling rates influence this problem. Our approach combines system identification based on thresholded least squares minimization with additional error measures that account for both the deviation between the model and the time derivative of the data, and the integrated performance of the model in forecasting dynamics. Specifically, we integrate a least squares error as well as the Wasserstein metric for estimated models and combine them within a Bayesian optimization framework to efficiently determine optimal hyperparameters for thresholding and weighting of the different error norms. Additionally, we employ distinct regularization parameters for each differential equation in the system, enhancing the method's precision and flexibility. We demonstrate the capabilities of our approach through applications to dynamical fMRI data and the prototypical example of a wake flow behind a cylinder. In the wake flow problem, our method identifies a sparse, accurate model that correctly captures transient dynamics, oscillation periods, and phase information, outperforming existing methods. In the fMRI example, we show how our approach extracts insights from a trained recurrent neural network, offering a novel avenue for explainable AI by inferring differential equations that capture potentially causal relationships."
    },
    "2501.00504v2": {
      "title": "The Algonauts Project 2025 Challenge: How the Human Brain Makes Sense of Multimodal Movies",
      "url": "http://arxiv.org/abs/2501.00504v2",
      "authors": "Alessandro T. Gifford, Domenic Bersch, Marie St-Laurent, Basile Pinsard, Julie Boyle, Lune Bellec, Aude Oliva, Gemma Roig, Radoslaw M. Cichy",
      "update_time": "2025-01-06",
      "abstract": "There is growing symbiosis between artificial and biological intelligence sciences: neural principles inspire new intelligent machines, which are in turn used to advance our theoretical understanding of the brain. To promote further collaboration between biological and artificial intelligence researchers, we introduce the 2025 edition of the Algonauts Project challenge: How the Human Brain Makes Sense of Multimodal Movies (https://algonautsproject.com/). In collaboration with the Courtois Project on Neuronal Modelling (CNeuroMod), this edition aims to bring forth a new generation of brain encoding models that are multimodal and that generalize well beyond their training distribution, by training them on the largest dataset of fMRI responses to movie watching available to date. Open to all, the 2025 challenge provides transparent, directly comparable results through a public leaderboard that is updated automatically after each submission to facilitate rapid model assessment and guide development. The challenge will end with a session at the 2025 Cognitive Computational Neuroscience (CCN) conference that will feature winning models. We welcome researchers interested in collaborating with the Algonauts Project by contributing ideas and datasets for future challenges."
    },
    "2501.00378v1": {
      "title": "STARFormer: A Novel Spatio-Temporal Aggregation Reorganization Transformer of FMRI for Brain Disorder Diagnosis",
      "url": "http://arxiv.org/abs/2501.00378v1",
      "authors": "Wenhao Dong, Yueyang Li, Weiming Zeng, Lei Chen, Hongjie Yan, Wai Ting Siok, Nizhuan Wang",
      "update_time": "2024-12-31",
      "abstract": "Many existing methods that use functional magnetic resonance imaging (fMRI) classify brain disorders, such as autism spectrum disorder (ASD) and attention deficit hyperactivity disorder (ADHD), often overlook the integration of spatial and temporal dependencies of the blood oxygen level-dependent (BOLD) signals, which may lead to inaccurate or imprecise classification results. To solve this problem, we propose a Spatio-Temporal Aggregation eorganization ransformer (STARFormer) that effectively captures both spatial and temporal features of BOLD signals by incorporating three key modules. The region of interest (ROI) spatial structure analysis module uses eigenvector centrality (EC) to reorganize brain regions based on effective connectivity, highlighting critical spatial relationships relevant to the brain disorder. The temporal feature reorganization module systematically segments the time series into equal-dimensional window tokens and captures multiscale features through variable window and cross-window attention. The spatio-temporal feature fusion module employs a parallel transformer architecture with dedicated temporal and spatial branches to extract integrated features. The proposed STARFormer has been rigorously evaluated on two publicly available datasets for the classification of ASD and ADHD. The experimental results confirm that the STARFormer achieves state-of-the-art performance across multiple evaluation metrics, providing a more accurate and reliable tool for the diagnosis of brain disorders and biomedical research. The codes will be available at: https://github.com/NZWANG/STARFormer."
    }
  },
  "MEG": {
    "2501.12184v1": {
      "title": "Probing Type II Seesaw Leptogenesis Through Lepton Flavor Violation",
      "url": "http://arxiv.org/abs/2501.12184v1",
      "authors": "Chengcheng Han, Yijun Han, Sihui Huang, Zhanhong Lei",
      "update_time": "2025-01-21",
      "abstract": "Lepton flavor violation (LFV) offers a powerful probe of physics beyond the Standard Model, particularly in models addressing neutrino masses and the baryon asymmetry of the universe. In this study, we investigate LFV processes within the framework of type II seesaw leptogenesis, where the Standard Model is extended by an $SU(2)_L$ triplet Higgs field. We focus on key LFV processes including $\\mu^+\\to e^+\\gamma$, $\\mu^+ \\to e^+e^-e^+$, and $\\mu \\rightarrow e$ conversion in nuclei, deriving stringent constraints on the parameter space from current experimental data. We scan the 3$\\sigma$ range of neutrino oscillation parameters and identify the most conservative bounds consistent with existing measurements. Our results reveal that the MEG experiment currently provides the strongest constraints in the normal ordering (NO) scenario, while the SINDRUM experiment offers comparable sensitivity in the inverted ordering (IO) case. Future experiments, such as MEG II, Mu3e, Mu2e, and COMET, are predicted to significantly improve the sensitivity, testing larger regions of the parameter space. This work underscores the crucial role of LFV experiments in probing type II seesaw leptogenesis, providing an avenue to explore the connections between neutrino mass generation, baryogenesis, and inflation at experimentally accessible energy scales."
    },
    "2501.11566v1": {
      "title": "Artificial Neural Networks for Magnetoencephalography: A review of an emerging field",
      "url": "http://arxiv.org/abs/2501.11566v1",
      "authors": "Arthur Dehgan, Hamza Abdelhedi, Vanessa Hadid, Irina Rish, Karim Jerbi",
      "update_time": "2025-01-20",
      "abstract": "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that measures the intricate brain dynamics underlying cognitive processes with an unparalleled combination of high temporal and spatial precision. MEG data analytics has always relied on advanced signal processing and mathematical and statistical tools for various tasks ranging from data cleaning to probing the signals' rich dynamics and estimating the neural sources underlying the surface-level recordings. Like in most domains, the surge in Artificial Intelligence (AI) has led to the increased use of Machine Learning (ML) methods for MEG data classification. More recently, an emerging trend in this field is using Artificial Neural Networks (ANNs) to address many MEG-related tasks. This review provides a comprehensive overview of how ANNs are being used with MEG data from three vantage points: First, we review work that employs ANNs for MEG signal classification, i.e., for brain decoding. Second, we report on work that has used ANNs as putative models of information processing in the human brain. Finally, we examine studies that use ANNs as techniques to tackle methodological questions in MEG, including artifact correction and source estimation. Furthermore, we assess the current strengths and limitations of using ANNs with MEG and discuss future challenges and opportunities in this field. Finally, by establishing a detailed portrait of the field and providing practical recommendations for the future, this review seeks to provide a helpful reference for both seasoned MEG researchers and newcomers to the field who are interested in using ANNs to enhance the exploration of the complex dynamics of the human brain with MEG."
    },
    "2501.07426v1": {
      "title": "MVICAD2: Multi-View Independent Component Analysis with Delays and Dilations",
      "url": "http://arxiv.org/abs/2501.07426v1",
      "authors": "Ambroise Heurtebise, Omar Chehab, Pierre Ablin, Alexandre Gramfort",
      "update_time": "2025-01-13",
      "abstract": "Machine learning techniques in multi-view settings face significant challenges, particularly when integrating heterogeneous data, aligning feature spaces, and managing view-specific biases. These issues are prominent in neuroscience, where data from multiple subjects exposed to the same stimuli are analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG), where signals are captured at the scalp level, estimating the brain's underlying sources is crucial, especially in group studies where sources are assumed to be similar for all subjects. Common methods, such as Multi-View Independent Component Analysis (MVICA), assume identical sources across subjects, but this assumption is often too restrictive due to individual variability and age-related changes. Multi-View Independent Component Analysis with Delays (MVICAD) addresses this by allowing sources to differ up to a temporal delay. However, temporal dilation effects, particularly in auditory stimuli, are common in brain dynamics, making the estimation of time delays alone insufficient. To address this, we propose Multi-View Independent Component Analysis with Delays and Dilations (MVICAD2), which allows sources to differ across subjects in both temporal delays and dilations. We present a model with identifiable sources, derive an approximation of its likelihood in closed form, and use regularization and optimization techniques to enhance performance. Through simulations, we demonstrate that MVICAD2 outperforms existing multi-view ICA methods. We further validate its effectiveness using the Cam-CAN dataset, and showing how delays and dilations are related to aging.",
      "code_url": "https://github.com/ambroiseheurtebise/mvicad"
    },
    "2501.07394v2": {
      "title": "Exploring the distribution of connectivity weights in resting-state EEG networks",
      "url": "http://arxiv.org/abs/2501.07394v2",
      "authors": "Shiang Hu, Xiao Gong, Xiaolong Huang, Jie Ruan, Pedro Antonio Valdes-Sosa",
      "update_time": "2025-01-18",
      "abstract": "The resting-state brain networks (RSNs) reflects the functional connectivity patterns between brain modules, providing essential foundations for decoding intrinsic neural information within the brain. It serves as one of the primary tools for describing the spatial dynamics of the brain using various neuroimaging techniques, such as electroencephalography (EEG) and magnetoencephalography (MEG). However, the distribution rules or potential modes of functional connectivity weights in the resting state remain unclear. In this context, we first start from simulation, using forward solving model to generate scalp EEG with four channel densities (19, 32, 64, 128). Subsequently, we construct scalp brain networks using five coupling measures, aiming to explore whether different channel density or coupling measures affect the distribution pattern of functional connectivity weights. Next, we quantify the distribution pattern by calculating the skewness, kurtosis, and Shannon entropy of the functional connectivity network weights. Finally, the results of the simulation were validated in a normative database. We observed that: 1) The functional connection weights exhibit a right-skewed distribution, and are not influenced by channel density or coupling measures; 2) The functional connection weights exhibit a relatively uniform distribution, with the potential for volume conduction to affect the degree of uniformity in the distribution; 3) Networks constructed using coupling measures influenced by volume conduction exhibit significant correlations between the average connection weight and measures of skewness, kurtosis, and Shannon entropy. This study contributes to a deeper understanding of RSNs, providing valuable insights for research in the field of neuroscience, and holds promise for being associated with brain cognition and disease diagnosis."
    },
    "2501.05507v1": {
      "title": "On the Atomki nuclear anomaly after the MEG-II result",
      "url": "http://arxiv.org/abs/2501.05507v1",
      "authors": "Daniele Barducci, Davide Germani, Marco Nardecchia, Stefano Scacco, Claudio Toni",
      "update_time": "2025-01-09",
      "abstract": "Recent experimental results from the Atomki collaboration have reported the observation of anomalous effects in Beryllium, Helium and Carbon nuclear transitions that could hint at physics beyond the Standard Model. However, the MEG-II experiment has recently found no significant anomalous signal in the Beryllium transition ${^8}\\text{Be}^\\star\\to{^8}\\text{Be}+e^+e^-$. In view of this result, we critically re-examine the possible theoretical interpretations of the anomalies observed by the Atomki experiment in terms of a new boson $X$ with mass around $17\\;$MeV. The present work aims to study the phenomenology of a spin-2 state and revisit the possibility of a pure CP-even scalar, which was initially dismissed due to its inability to explain the Beryllium anomalous signal. Our analysis shows that a spin-2 state is highly disfavoured by the SINDRUM constraint while a scalar boson could explain the Helium and Carbon anomalies while being compatible with other experimental constraints."
    },
    "2501.05128v2": {
      "title": "Development of the high-rate capable DLC-RPC based on the current evacuation pattern",
      "url": "http://arxiv.org/abs/2501.05128v2",
      "authors": "Masato Takahashi, Sei Ban, Weiyuan Li, Atsuhiko Ochi, Wataru Ootani, Atsushi Oya, Hiromu Suzuki, Kensuke Yamamoto",
      "update_time": "2025-01-10",
      "abstract": "The Resistive Plate Chamber using Diamond-Like Carbon electrodes (DLC-RPC) has been developed as a background tagging detector in the MEG$~$II experiment. The DLC-RPC is planned to be installed in a high-intensity and low-momentum muon beam. This detector is required to have a detection efficiency of above 90 % with four active gaps in the muon beam due to the limitation of the material budget. In such an environment, the high current flowing through the resistive electrodes causes a voltage drop, which reduces the performance of the DLC-RPC. This voltage drop can be suppressed by implementing a current evacuation pattern, though discharges are more likely to occur near the pattern. Therefore the pattern must be covered by a protection cover made of an insulator. In this study, electrode samples with the current evacuation pattern and different widths of protection cover (0.2 mm and 0.8 mm) have been produced, and their performance and stability were measured. The detection efficiency of the single-gap for $\\beta$-ray from a $^{90}$Sr source was measured to be up to approximately 60 % in both electrode samples. The target efficiency can be achieved even with a drop of 100 $-$ 150 V. On the other hand, after more than a dozen hours of operation, discharges suddenly occurred and the detector was prevented from further operation. These discharges created current paths on the spacing pillars. This serious problem must be investigated and solved in the future."
    },
    "2501.10404v1": {
      "title": "Automated Detection of Epileptic Spikes and Seizures Incorporating a Novel Spatial Clustering Prior",
      "url": "http://arxiv.org/abs/2501.10404v1",
      "authors": "Hanyang Dong, Shurong Sheng, Xiongfei Wang, Jiahong Gao, Yi Sun, Wanli Yang, Kuntao Xiao, Pengfei Teng, Guoming Luan, Zhao Lv",
      "update_time": "2025-01-05",
      "abstract": "A Magnetoencephalography (MEG) time-series recording consists of multi-channel signals collected by superconducting sensors, with each signal's intensity reflecting magnetic field changes over time at the sensor location. Automating epileptic MEG spike detection significantly reduces manual assessment time and effort, yielding substantial clinical benefits. Existing research addresses MEG spike detection by encoding neural network inputs with signals from all channel within a time segment, followed by classification. However, these methods overlook simultaneous spiking occurred from nearby sensors. We introduce a simple yet effective paradigm that first clusters MEG channels based on their sensor's spatial position. Next, a novel convolutional input module is designed to integrate the spatial clustering and temporal changes of the signals. This module is fed into a custom MEEG-ResNet3D developed by the authors, which learns to extract relevant features and classify the input as a spike clip or not. Our method achieves an F1 score of 94.73% on a large real-world MEG dataset Sanbo-CMR collected from two centers, outperforming state-of-the-art approaches by 1.85%. Moreover, it demonstrates efficacy and stability in the Electroencephalographic (EEG) seizure detection task, yielding an improved weighted F1 score of 1.4% compared to current state-of-the-art techniques evaluated on TUSZ, whch is the largest EEG seizure dataset."
    },
    "2412.19622v1": {
      "title": "Signatures of prediction during natural listening in MEG data?",
      "url": "http://arxiv.org/abs/2412.19622v1",
      "authors": "Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut G\u00fc\u00e7l\u00fc, Linda Geerligs",
      "update_time": "2024-12-27",
      "abstract": "The brain uses contextual information and prior knowledge to anticipate upcoming content during language comprehension. Recent research has shown predictive signals can be revealed in pre-onset ECoG activity during naturalistic narrative listening, by building encoding models based on word embeddings from Large Language Models (LLMs). Similarly, evidence for long-range predictive encoding has been observed in fMRI data, where incorporating embeddings for multiple upcoming words in a narrative improves alignment with brain activity. This study examines whether similar predictive information can be detected in MEG, a technique with higher temporal resolution than fMRI but a lower signal-to-noise ratio than ECoG. Our findings indicate that MEG captures pre-onset representations up to 1 second before word onset, consistent with ECoG results. However, unlike fMRI findings, incorporating future word embeddings did not enhance MEG encoding, even for one word into the future, which suggests that the pre-onset encoding may not reflect predictive processing. This work demonstrates that MEG combined with LLMs is a valuable approach for studying language processing in naturalistic narratives and highlights the need to study further what constitutes evidence for prediction during natural listening."
    },
    "2412.18353v1": {
      "title": "Low count of optically pumped magnetometers furnishes a reliable real-time access to sensorimotor rhythm",
      "url": "http://arxiv.org/abs/2412.18353v1",
      "authors": "Nikita Fedosov, Daria Medvedeva, Oleg Shevtsov, Alexei Ossadtchi",
      "update_time": "2024-12-24",
      "abstract": "This study presents an analysis of sensorimotor rhythms using an advanced, optically-pumped magnetoencephalography (OPM-MEG) system - a novel and rapidly developing technology. We conducted real-movement and motor imagery experiments with nine participants across two distinct magnetically-shielded environments: one featuring an analog active suppression system and the other a digital implementation. Our findings demonstrate that, under optimal recording conditions, OPM sensors provide highly informative signals, suitable for use in practical motor imagery brain-computer interface (BCI) applications. We further examine the feasibility of a portable, low-sensor-count OPM-based BCI under varied experimental setups, highlighting its potential for real-time control of external devices via user intentions."
    },
    "2501.03246v1": {
      "title": "Bridging Auditory Perception and Language Comprehension through MEG-Driven Encoding Models",
      "url": "http://arxiv.org/abs/2501.03246v1",
      "authors": "Matteo Ciferri, Matteo Ferrante, Nicola Toschi",
      "update_time": "2024-12-22",
      "abstract": "Understanding the neural mechanisms behind auditory and linguistic processing is key to advancing cognitive neuroscience. In this study, we use Magnetoencephalography (MEG) data to analyze brain responses to spoken language stimuli. We develop two distinct encoding models: an audio-to-MEG encoder, which uses time-frequency decompositions (TFD) and wav2vec2 latent space representations, and a text-to-MEG encoder, which leverages CLIP and GPT-2 embeddings. Both models successfully predict neural activity, demonstrating significant correlations between estimated and observed MEG signals. However, the text-to-MEG model outperforms the audio-based model, achieving higher Pearson Correlation (PC) score. Spatially, we identify that auditory-based embeddings (TFD and wav2vec2) predominantly activate lateral temporal regions, which are responsible for primary auditory processing and the integration of auditory signals. In contrast, textual embeddings (CLIP and GPT-2) primarily engage the frontal cortex, particularly Broca's area, which is associated with higher-order language processing, including semantic integration and language production, especially in the 8-30 Hz frequency range. The strong involvement of these regions suggests that auditory stimuli are processed through more direct sensory pathways, while linguistic information is encoded via networks that integrate meaning and cognitive control. Our results reveal distinct neural pathways for auditory and linguistic information processing, with higher encoding accuracy for text representations in the frontal regions. These insights refine our understanding of the brain's functional architecture in processing auditory and textual information, offering quantitative advancements in the modelling of neural responses to complex language stimuli."
    }
  },
  "neuroAI": {
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": "https://github.com/henri-edinb/async_learning"
    },
    "2411.18526v1": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v1",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias",
      "update_time": "2024-11-27",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety."
    },
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research."
    },
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2302.07243v4": {
      "title": "A Deep Probabilistic Spatiotemporal Framework for Dynamic Graph Representation Learning with Application to Brain Disorder Identification",
      "url": "http://arxiv.org/abs/2302.07243v4",
      "authors": "Sin-Yee Yap, Junn Yong Loo, Chee-Ming Ting, Fuad Noman, Raphael C. -W. Phan, Adeel Razi, David L. Dowe",
      "update_time": "2024-11-09",
      "abstract": "Recent applications of pattern recognition techniques on brain connectome classification using functional connectivity (FC) are shifting towards acknowledging the non-Euclidean topology and dynamic aspects of brain connectivity across time. In this paper, a deep spatiotemporal variational Bayes (DSVB) framework is proposed to learn time-varying topological structures in dynamic FC networks for identifying autism spectrum disorder (ASD) in human participants. The framework incorporates a spatial-aware recurrent neural network with an attention-based message passing scheme to capture rich spatiotemporal patterns across dynamic FC networks. To overcome model overfitting on limited training datasets, an adversarial training strategy is introduced to learn graph embedding models that generalize well to unseen brain networks. Evaluation on the ABIDE resting-state functional magnetic resonance imaging dataset shows that our proposed framework substantially outperforms state-of-the-art methods in identifying patients with ASD. Dynamic FC analyses with DSVB-learned embeddings reveal apparent group differences between ASD and healthy controls in brain network connectivity patterns and switching dynamics of brain states. The code is available at https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes.",
      "code_url": "https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes"
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    }
  },
  "medical": {
    "2501.13053v1": {
      "title": "Evaluation of patient activation and dosimetry after Boron Neutron Capture Therapy",
      "url": "http://arxiv.org/abs/2501.13053v1",
      "authors": "Giovanni Garini, Chiara Magni, Ian Postuma, Setareh Fatemi, Ricardo Ramos, Barbara Marcaccio, Cristina Pezzi, Laura Bagnale, Sandro Sandri, Gianfranco De Matteis, Giuseppe Paolisso, Valerio Vercesi, Silva Bortolussi",
      "update_time": "2025-01-22",
      "abstract": "Boron Neutron Capture Therapy (BNCT) is a form of radiotherapy based on the irradiation of the tumour with a low energy neutron beam, after the administration of a selective drug enriched in boron-10. The therapy exploits the high cross section of thermal neutron capture in boron, generating two low-range charged particles. The availability of accelerators able to generate high-intensity neutron beams via proton nuclear interaction is boosting the construction of new clinical centres. One of these is under development in Italy, using a 5 MeV, 30 mA proton radiofrequency accelerator coupled to a beryllium target, funded by the Complementary Plan to the Recovery and Resilience National Plan, under the project ANTHEM. The present study focuses on radiation protection aspects of patients undergoing BNCT, specifically on the activation of their organs and tissues. A criterion to establish the relevance of such activation after BNCT has been proposed. Based on the current Italian regulatory framework, the level of patient activation following BNCT treatment does not pose a significant radiological concern, even shortly after irradiation. Another aspect is the activation of patient's excretions, which can impact on the design of the building and requires a process for the discharge. The described study contributes to the radiation protection study for the ANTHEM BNCT centre in Italy."
    },
    "2501.12911v1": {
      "title": "A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning",
      "url": "http://arxiv.org/abs/2501.12911v1",
      "authors": "Abdulkadir Korkmaz, Praveen Rao",
      "update_time": "2025-01-22",
      "abstract": "Federated learning is a machine learning method that supports training models on decentralized devices or servers, where each holds its local data, removing the need for data exchange. This approach is especially useful in healthcare, as it enables training on sensitive data without needing to share them. The nature of federated learning necessitates robust security precautions due to data leakage concerns during communication. To address this issue, we propose a new approach that employs selective encryption, homomorphic encryption, differential privacy, and bit-wise scrambling to minimize data leakage while achieving good execution performance. Our technique , FAS (fast and secure federated learning) is used to train deep learning models on medical imaging data. We implemented our technique using the Flower framework and compared with a state-of-the-art federated learning approach that also uses selective homomorphic encryption. Our experiments were run in a cluster of eleven physical machines to create a real-world federated learning scenario on different datasets. We observed that our approach is up to 90\\% faster than applying fully homomorphic encryption on the model weights. In addition, we can avoid the pretraining step that is required by our competitor and can save up to 20\\% in terms of total execution time. While our approach was faster, it obtained similar security results as the competitor."
    },
    "2501.12892v1": {
      "title": "Closed-loop robust control of long-term diabetes progression via physical activity management",
      "url": "http://arxiv.org/abs/2501.12892v1",
      "authors": "Pierluigi Francesco De Paola, Alessandro Borri, Fabrizio Dabbene, Pasquale Palumbo, Alessia Paglialonga",
      "update_time": "2025-01-22",
      "abstract": "Large clinical evidence acknowledges the crucial role played by physical activity in delaying the progression of type-2 diabetes. However, the literature lacks control approaches that leverage exercise for type-2 diabetes control and more in general lacks a quantitative assessment of medical guidelines on the recommended amount of physical activity to be performed, mainly due to the absence of mathematical models that suitably estimate its benefits on diabetes progression. In this work, in order to provide a control-theoretical formulation of the exercise, we design a feedback law in terms of recommended physical activity, following a model predictive control approach, based on a widespread compact diabetes progression model, suitably modified to properly account for the long-term effect of the exercise. Moreover we illustrate how the proposed approach proves to show reliable robustness properties with respect to initial conditions and parameter perturbations, which may be used to reflect inter-patient variability. Results are encouraging in view of the validation of the control law on comprehensive high-dimensional models of diabetes progression, with the aim of translating the prediction of the controller into reasonable recommendations and to quantitatively support medical decision-making."
    },
    "2501.12797v1": {
      "title": "A double multi-turn injection scheme for generating mixed helium and carbon ion beams at medical synchrotron facilities",
      "url": "http://arxiv.org/abs/2501.12797v1",
      "authors": "Matthias Kausel, Claus Schmitzer, Andreas Gsponer, Markus Wolf, Hermann Fuchs, Felix Ulrich-Pur, Thomas Bergauer, Albert Hirtl, Nadia Gambino, Elisabeth Renner",
      "update_time": "2025-01-22",
      "abstract": "The almost identical charge-to-mass ratios of fully ionized helium-4 and carbon-12 ions enable simultaneous acceleration in hadron therapy synchrotrons. At the same energy per mass, helium ions exhibit a stopping range approximately three times greater than carbon ions. They can therefore be exploited for online range verification downstream of the patient during carbon ion beam irradiation. One possibility for creating this mixed beam is accelerating the two ion species sequentially through the LINAC and subsequently \"mixing\" them at injection energy in the synchrotron with a double injection scheme. This work reports the first successful generation, acceleration, and extraction of a mixed helium and carbon ion beam using this double multi-turn injection scheme, which was achieved at the MedAustron therapy accelerator in Austria. A description of the double multi-turn injection scheme, particle tracking simulations, and details on the implementation at the MedAustron accelerator facility are presented and discussed. Finally, measurements of the mixed beam at delivery in the irradiation room using a radiochromic film and a low-gain avalanche diode (LGAD) detector are presented."
    },
    "2501.12794v1": {
      "title": "Generation of Standardized E-Learning Contents from Digital Medical Collections",
      "url": "http://arxiv.org/abs/2501.12794v1",
      "authors": "Felix Buend\u00eda, Joaqu\u00edn Gayoso-Cabada, Jos\u00e9-Luis Sierra",
      "update_time": "2025-01-22",
      "abstract": "In this paper, we describe an approach to transforming the huge amount of medical knowledge available in existing online medical collections into standardized learning packages ready to be integrated into the most popular e-learning platforms. The core of our approach is a tool called Clavy, which makes it possible to retrieve pieces of content in medical collections, to transform this content into meaningful learning units, and to export it in the form of standardized learning packages. In addition to describing the approach, we demonstrate its feasibility by applying it to the generation of IMS content packages from MedPix, a popular online database of medical cases in the domain of radiology."
    },
    "2501.12749v1": {
      "title": "Estimating the Conformal Prediction Threshold from Noisy Labels",
      "url": "http://arxiv.org/abs/2501.12749v1",
      "authors": "Coby Penso, Jacob Goldberger, Ethan Fetaya",
      "update_time": "2025-01-22",
      "abstract": "Conformal Prediction (CP) is a method to control prediction uncertainty by producing a small prediction set, ensuring a predetermined probability that the true class lies within this set. This is commonly done by defining a score, based on the model predictions, and setting a threshold on this score using a validation set. In this study, we address the problem of CP calibration when we only have access to a validation set with noisy labels. We show how we can estimate the noise-free conformal threshold based on the noisy labeled data. Our solution is flexible and can accommodate various modeling assumptions regarding the label contamination process, without needing any information about the underlying data distribution or the internal mechanisms of the machine learning classifier. We develop a coverage guarantee for uniform noise that is effective even in tasks with a large number of classes. We dub our approach Noise-Aware Conformal Prediction (NACP) and show on several natural and medical image classification datasets, including ImageNet, that it significantly outperforms current noisy label methods and achieves results comparable to those obtained with a clean validation set.",
      "code_url": "https://github.com/cobypenso/noise-aware-conformal-prediction"
    },
    "2501.12691v1": {
      "title": "Efficient treatment of heterogeneous malignant cell populations",
      "url": "http://arxiv.org/abs/2501.12691v1",
      "authors": "Uzi Harush, Ravid Straussman, Baruch Barzel",
      "update_time": "2025-01-22",
      "abstract": "When confronted with an undesired cell population, such as bacterial infections or tumors, we seek the most effective treatment, designed to eliminate the population as rapidly as possible. A common practice is to monitor the cells short-term response to the treatment, and from that, extrapolate the eventual treatment outcome, i.e. will it eradicate the cells, and if yes at what timescales. Underlying this approach is the assumption that the cells exhibit a homogeneous response to the treatment, and hence the early response patterns can be naturally extended to later times. Recent experiments on cancer cell populations, however, indicate a significant level of cellular heterogeneity, undermining this classic assessment protocol of treatment efficacy. We, therefore, develop here a stochastic framework, to analytically predict the temporal dynamics of a heterogeneous cell population. Quite often, we find, the average cellular parameters, governing the short-term response, fail to predict the actual treatment outcome. In contrast, our analysis, which also incorporates the populations variability, helps identify the relevant statistical parameters, which in turn, enable us to predict the full trajectory of the cell population, and specifically - the likelihood and typical timescales for remission."
    },
    "2501.12560v1": {
      "title": "Improved Detection and Diagnosis of Faults in Deep Neural Networks Using Hierarchical and Explainable Classification",
      "url": "http://arxiv.org/abs/2501.12560v1",
      "authors": "Sigma Jahan, Mehil B Shah, Parvez Mahbub, Mohammad Masudur Rahman",
      "update_time": "2025-01-22",
      "abstract": "Deep Neural Networks (DNN) have found numerous applications in various domains, including fraud detection, medical diagnosis, facial recognition, and autonomous driving. However, DNN-based systems often suffer from reliability issues due to their inherent complexity and the stochastic nature of their underlying models. Unfortunately, existing techniques to detect faults in DNN programs are either limited by the types of faults (e.g., hyperparameter or layer) they support or the kind of information (e.g., dynamic or static) they use. As a result, they might fall short of comprehensively detecting and diagnosing the faults. In this paper, we present DEFault (Detect and Explain Fault) -- a novel technique to detect and diagnose faults in DNN programs. It first captures dynamic (i.e., runtime) features during model training and leverages a hierarchical classification approach to detect all major fault categories from the literature. Then, it captures static features (e.g., layer types) from DNN programs and leverages explainable AI methods (e.g., SHAP) to narrow down the root cause of the fault. We train and evaluate DEFault on a large, diverse dataset of ~14.5K DNN programs and further validate our technique using a benchmark dataset of 52 real-life faulty DNN programs. Our approach achieves ~94% recall in detecting real-world faulty DNN programs and ~63% recall in diagnosing the root causes of the faults, demonstrating 3.92% - 11.54% higher performance than that of state-of-the-art techniques. Thus, DEFault has the potential to significantly improve the reliability of DNN programs by effectively detecting and diagnosing the faults."
    },
    "2501.12538v1": {
      "title": "Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition",
      "url": "http://arxiv.org/abs/2501.12538v1",
      "authors": "Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi",
      "update_time": "2025-01-21",
      "abstract": "Understanding the prevalence, disparities, and symptom variations of Post COVID-19 Condition (PCC) for vulnerable populations is crucial to improving care and addressing intersecting inequities. This study aims to develop a comprehensive framework for integrating social determinants of health (SDOH) into PCC research by leveraging NLP techniques to analyze disparities and variations in SDOH representation within PCC case reports. Following construction of a PCC Case Report Corpus, comprising over 7,000 case reports from the LitCOVID repository, a subset of 709 reports were annotated with 26 core SDOH-related entity types using pre-trained named entity recognition (NER) models, human review, and data augmentation to improve quality, diversity and representation of entity types. An NLP pipeline integrating NER, natural language inference (NLI), trigram and frequency analyses was developed to extract and analyze these entities. Both encoder-only transformer models and RNN-based models were assessed for the NER objective.   Fine-tuned encoder-only BERT models outperformed traditional RNN-based models in generalizability to distinct sentence structures and greater class sparsity. Exploratory analysis revealed variability in entity richness, with prevalent entities like condition, age, and access to care, and underrepresentation of sensitive categories like race and housing status. Trigram analysis highlighted frequent co-occurrences among entities, including age, gender, and condition. The NLI objective (entailment and contradiction analysis) showed attributes like \"Experienced violence or abuse\" and \"Has medical insurance\" had high entailment rates (82.4%-80.3%), while attributes such as \"Is female-identifying,\" \"Is married,\" and \"Has a terminal condition\" exhibited high contradiction rates (70.8%-98.5%)."
    },
    "2501.12527v1": {
      "title": "Analyzer-less X-ray Interferometry with Super-Resolution Methods",
      "url": "http://arxiv.org/abs/2501.12527v1",
      "authors": "Joyoni Dey, Hunter C. Meyer, Murtuza S. Taqi",
      "update_time": "2025-01-21",
      "abstract": "We propose the use of super-resolution methods for X-ray grating interferometry without an analyzer with detectors that fail to meet the Nyquist sampling rate needed for traditional image recovery algorithms. This method enables Talbot-Lau interferometry without the X-ray absorbing analyzer and allows for higher autocorrelation lengths for the analyzer-less Modulated Phase Grating Interferometer. This will allow for reduced X-ray dose and higher autocorrelation lengths than previously accessible. We demonstrate the use of super-resolution methods to iteratively reconstruct attenuation, differential-phase, and dark-field images using simulations of a one-dimensional lung phantom with tumors. For a fringe period of pD = 22 {\\mu}m, we compare the simulated imaging performance of interferometers with a 30 {\\mu}m and 50 {\\mu}m detector for various signal-to-noise ratios. We show that our super-resolution iterative reconstruction methods are highly robust and can be used to improve grating interferometry for cases where traditional algorithms cannot be used."
    }
  }
}