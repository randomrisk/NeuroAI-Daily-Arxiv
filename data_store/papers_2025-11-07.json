{
  "Brain": {
    "2511.03605v1": {
      "title": "Bayesian Topological Analysis of Functional Brain Networks",
      "url": "http://arxiv.org/abs/2511.03605v1",
      "authors": "Xukun Zhu, Michael W Lutz, Tananun Songdechakraiwut",
      "update_time": "2025-11-05",
      "abstract": "Subtle alterations in brain network topology often evade detection by traditional statistical methods. To address this limitation, we introduce a Bayesian inference framework for topological comparison of brain networks that probabilistically models within- and between-group dissimilarities. The framework employs Markov chain Monte Carlo sampling to estimate posterior distributions of test statistics and Bayes factors, enabling graded evidence assessment beyond binary significance testing. Simulations confirmed statistical consistency to permutation testing. Applied to fMRI data from the Duke-UNC Alzheimer's Disease Research Center, the framework detected topology-based network differences that conventional permutation tests failed to reveal, highlighting its enhanced sensitivity to early or subtle brain network alterations in clinical neuroimaging.",
      "code_url": null
    },
    "2511.03564v1": {
      "title": "ENDF/B-VIII.1: Updated Nuclear Reaction Data Library for Science and Applications",
      "url": "http://arxiv.org/abs/2511.03564v1",
      "authors": "G. P. A. Nobre, R. Capote, M. T. Pigni, A. Trkov, C. M. Mattoon, D. Neudecker, D. A. Brown, M. B. Chadwick, A. C. Kahler, N. A. Kleedtke, M. Zerkle, A. I. Hawari, C. W. Chapman, N. C. Fleming, J. L. Wormald, K. Rami\u0107, Y. Danon, N. A. Gibson, P. Brain, M. W. Paris, G. M. Hale, I. J. Thompson, D. P. Barry, I. Stetcu, W. Haeck, A. E. Lovell, M. R. Mumpower, G. Potel, K. Kravvaris, G. Noguere, J. D. McDonnell, A. D. Carlson, M. Dunn, T. Kawano, D. Wiarda, I. Al-Qasir, G. Arbanas, R. Arcilla, B. Beck, D. Bernard, R. Beyer, J. M. Brown, O. Cabellos, R. J. Casperson, Y. Cheng, E. V. Chimanski, R. Coles, M. Cornock, J. Cotchen, J. P. W. Crozier, D. E. Cullen, A. Daskalakis, M. -A. Descalle, D. D. DiJulio, P. Dimitriou, A. C. Dreyfuss, I. Dur\u00e1n, R. Ferrer, T. Gaines, V. Gillette, G. Gert, K. H. Guber, J. D. Haverkamp, M. W. Herman, J. Holmes, M. Hursin, N. Jisrawi, A. R. Junghans, K. J. Kelly, H. I. Kim, K. S. Kim, A. J. Koning, M. Ko\u0161t\u00e1l, B. K. Laramee, A. Lauer-Coles, L. Leal, H. Y. Lee, A. M. Lewis, J. Malec, J. I. M\u00e1rquez Dami\u00e1n, W. J. Marshall, A. Mattera, G. Muhrer, A. Ney, W. E. Ormand, D. K. Parsons, C. M. Percher, V. G. Pronyaev, A. Qteish, S. Quaglioni, M. Rapp, J. J. Ressler, M. Rising, D. Rochman, P. K. Romano, D. Roubtsov, G. Schnabel, M. Schulc, G. J. Siemers, A. A. Sonzogni, P. Talou, J. Thompson, T. H. Trumbull, S. C. van der Marck, M. Vorabbi, C. Wemple, K. A. Wendt, M. White, R. Q. Wright",
      "update_time": "2025-11-05",
      "abstract": "The ENDF/B-VIII.1 library is the newest recommended evaluated nuclear data file by the Cross Section Evaluation Working Group (CSEWG) for use in nuclear science and technology applications, and incorporates advances made in the six years since the release of ENDF/B-VIII.0. Among key advances made are that the $^{239}$Pu file was reevaluated by a joint international effort and that updated $^{16,18}$O, $^{19}$F, $^{28-30}$Si, $^{50-54}$Cr, $^{55}$Mn, $^{54,56,57}$Fe, $^{63,65}$Cu, $^{139}$La, $^{233,235,238}$U, and $^{240,241}$Pu neutron nuclear data from the IAEA coordinated INDEN collaboration were adopted. Over 60 neutron dosimetry cross sections were adopted from the IAEA's IRDFF-II library. In addition, the new library includes significant changes for $^3$He, $^6$Li,$^9$Be, $^{51}$V, $^{88}$Sr, $^{103}$Rh, $^{140,142}$Ce, Dy, $^{181}$Ta, Pt, $^{206-208}$Pb, and $^{234,236}$U neutron data, and new nuclear data for the photonuclear, charged-particle and atomic sublibraries. Numerous thermal neutron scattering kernels were reevaluated or provided for the very first time. On the covariance side, work was undertaken to introduce better uncertainty quantification standards and testing for nuclear data covariances. The significant effort to reevaluate important nuclides has reduced bias in the simulations of many integral experiments with particular progress noted for fluorine, copper, and stainless steel containing benchmarks. Data issues hindered the successful deployment of the previous ENDF/B-VIII.0 for commercial nuclear power applications in high burnup situations. These issues were addressed by improving the $^{238}$U and $^{239,240,241}$Pu evaluated data in the resonance region. The new library performance as a function of burnup is similar to the reference ENDF/B-VII.1 library. The ENDF/B-VIII.1 data are available in ENDF-6 and GNDS format at https://doi.org/10.11578/endf/2571019.",
      "code_url": null
    },
    "2511.03503v1": {
      "title": "Beta frequency shifts in decision making: Spectral fingerprints or communication channels?",
      "url": "http://arxiv.org/abs/2511.03503v1",
      "authors": "Saskia Haegens, Julio Rodriguez-Larios, Elie Rassi",
      "update_time": "2025-11-05",
      "abstract": "Recent evidence suggests that beta-band activity plays a key role in decision-making. Here we review our recent work in humans and non-human primates showing that beta-band frequency shifts in frontal cortex signal categorical decision outcomes. We revisit our previous proposal suggesting that content-specific beta reflects the flexible recruiting of transient neural ensembles and update it to emphasize frequency as the relevant parameter. We argue that beta frequency shifts arise from changes in connectivity between weakly coupled oscillators and that, more than a spectral fingerprint, they reflect an active mechanism to (re)-activate behaviorally relevant communication channels in the brain.",
      "code_url": null
    },
    "2511.03376v1": {
      "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas",
      "url": "http://arxiv.org/abs/2511.03376v1",
      "authors": "Syed Muqeem Mahmood, Hassan Mohy-ud-Din",
      "update_time": "2025-11-05",
      "abstract": "We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM.",
      "code_url": null
    },
    "2511.03014v1": {
      "title": "A Foundation Model for Brain MRI with Dynamic Modality Integration",
      "url": "http://arxiv.org/abs/2511.03014v1",
      "authors": "Minh Sao Khue Luu, Bair N. Tuchinov",
      "update_time": "2025-11-04",
      "abstract": "We present a foundation model for brain MRI that can work with different combinations of imaging sequences. The model uses one encoder with learnable modality embeddings, conditional layer normalization, and a masked autoencoding objective that accounts for missing modalities. A variance-covariance regularizer is applied to stabilize feature learning and improve representation diversity. This design removes the need for separate models for each modality and allows the network to adapt when some sequences are missing or unseen. It is trained on about 60,000 multi-center MRIs using self-supervised reconstruction and modality imputation to learn flexible representations. A learnable modality embedding guides feature extraction so the encoder can adjust to different inputs. We describe our planned evaluation on brain tumor and multiple sclerosis segmentation, as well as lesion classification, under various modality settings. Preliminary results show that the method works feasibly, and further experiments are planned to study its performance in more detail. All code and pretrained models are available at https://github.com/BrainFM/brainfm",
      "code_url": null
    },
    "2511.02766v2": {
      "title": "Microbes in the Moonlight: How the Gut Microbiota Influences Sleep",
      "url": "http://arxiv.org/abs/2511.02766v2",
      "authors": "Enso Onill Torres Alegre",
      "update_time": "2025-11-05",
      "abstract": "The gut microbiota has emerged as a fundamental regulator of sleep physiology, influencing neural, endocrine, and immune pathways through the gut-microbiota-brain axis (GMBA). This bidirectional communication system modulates neurotransmitter production, circadian rhythms, and metabolic homeostasis, while disruptions in microbial composition have been linked to sleep disorders, neuroinflammation, and systemic immune dysfunction. Recent findings suggest that gut dysbiosis contributes to sleep disturbances by altering serotonin, GABA, and short-chain fatty acid (SCFA) metabolism, with implications for neurodegenerative diseases, metabolic syndromes, and mood disorders. Additionally, the gut microbiota interacts with the endocrine and immune systems, shaping inflammatory responses and stress adaptation mechanisms. This review explores the intricate connections between sleep and the gut microbiota, integrating emerging research on microbiota-targeted therapies, such as probiotics, fecal microbiota transplantation (FMT), and chrononutrition, as potential interventions to restore sleep homeostasis and improve health outcomes",
      "code_url": null
    },
    "2511.02735v1": {
      "title": "Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2511.02735v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-11-04",
      "abstract": "EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial specificity limitations in detecting single-trial P300 potentials, a neurophysiological hallmark leveraged for both BCI control and neurodegenerative disease diagnostics. We present a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable regions of interest (ROIs) across sessions. Analyzing 62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we demonstrate that phase-lagged connectivity metrics can reliably isolate task-relevant hubs in deeper cortical-subcortical structures like the insula and parietal regions - critical for Alzheimer's disease biomarkers. By integrating spatially stable ROIs with dynamic temporal agreement, our hybrid classification systematically outperforms whole-brain approaches in different frequency bands (up to 5.4% depending on the connectivity method and the spectral range) while maintaining millisecond-level temporal precision.   To the best of our knowledge, this is the first study to establish cross-subject ROI consensus through source-space connectivity, bypassing scalp EEG's depth constraints to probe Alzheimer's-relevant networks. The framework's robustness to noise and compatibility with portable systems offer significant potential for global deployment in early neurodegenerative disease detection. Future integration of individualized anatomical data or adaptive parameter optimization could refine this tool for clinical deployment, enhancing the current max accuracy of 81.57% in the 1-15 Hz range.",
      "code_url": null
    },
    "2511.02722v1": {
      "title": "Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia",
      "url": "http://arxiv.org/abs/2511.02722v1",
      "authors": "Subati Abulikemu, Puria Radmard, Michail Mamalakis, John Suckling",
      "update_time": "2025-11-04",
      "abstract": "The human neocortex is functionally organised at its highest level along a continuous sensory-to-association (AS) hierarchy. This study characterises the AS hierarchy of patients with schizophrenia in a comparison with controls. Using a large fMRI dataset (N=355), we extracted individual AS gradients via spectral analysis of brain connectivity, quantified hierarchical specialisation by gradient spread, and related this spread with connectivity geometry. We found that schizophrenia compresses the AS hierarchy indicating reduced functional differentiation. By modelling neural timescale with the Ornstein-Uhlenbeck process, we observed that the most specialised, locally cohesive regions at the gradient extremes exhibit dynamics with a longer time constant, an effect that is attenuated in schizophrenia. To study computation, we used the gradients to regularise subject-specific recurrent neural networks (RNNs) trained on working memory tasks. Networks endowed with greater gradient spread learned more efficiently, plateaued at lower task loss, and maintained stronger alignment to the prescribed AS hierarchical geometry. Fixed point linearisation showed that high-range networks settled into more stable neural states during memory delay, evidenced by lower energy and smaller maximal Jacobian eigenvalues. This gradient-regularised RNN framework therefore links large-scale cortical architecture with fixed point stability, providing a mechanistic account of how gradient de-differentiation could destabilise neural computations in schizophrenia, convergently supported by empirical timescale flattening and model-based evidence of less stable fixed points.",
      "code_url": null
    },
    "2511.02893v1": {
      "title": "Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using a BraTS Sub-Saharan Africa (SSA) dataset",
      "url": "http://arxiv.org/abs/2511.02893v1",
      "authors": "Chukwuemeka Arua Kalu, Adaobi Chiazor Emegoakor, Fortune Okafor, Augustine Okoh Uchenna, Chijioke Kelvin Ukpai, Godsent Erere Onyeugbo",
      "update_time": "2025-11-04",
      "abstract": "Medical image segmentation is a critical achievement in modern medical science, developed over decades of research. It allows for the exact delineation of anatomical and pathological features in two- or three-dimensional pictures by utilizing notions like pixel intensity, texture, and anatomical context. With the advent of automated segmentation, physicians and radiologists may now concentrate on diagnosis and treatment planning while intelligent computers perform routine image processing tasks.   This study used the BraTS Sub-Saharan Africa dataset, a selected subset of the BraTS dataset that included 60 multimodal MRI cases from patients with glioma. Surprisingly, the nnU Net model trained on the initial 60 instances performed better than the network trained on an offline-augmented dataset of 360 cases. Hypothetically, the offline augmentations introduced artificial anatomical variances or intensity distributions, reducing generalization. In contrast, the original dataset, when paired with nnU Net's robust online augmentation procedures, maintained realistic variability and produced better results. The study achieved a Dice score of 0.84 for whole tumor segmentation. These findings highlight the significance of data quality and proper augmentation approaches in constructing accurate, generalizable medical picture segmentation models, particularly for under-represented locations.",
      "code_url": null
    },
    "2511.02565v1": {
      "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding",
      "url": "http://arxiv.org/abs/2511.02565v1",
      "authors": "Jingyu Lu, Haonan Wang, Qixiang Zhang, Xiaomeng Li",
      "update_time": "2025-11-04",
      "abstract": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual experiences from fMRI without subject-specific training, holds great potential for clinical applications. However, this direction remains underexplored due to challenges in cross-subject generalization and the complex nature of brain signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework that explicitly models the ventral-dorsal architecture of the human visual system to learn multi-dimensional representations. By disentangling and leveraging features from early visual cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary cognitive information essential for visual reconstruction. Furthermore, we introduce a feature-level contrastive learning strategy to enhance the extraction of subject-invariant semantic representations, thereby enhancing subject-agnostic applicability to previously unseen subjects. Unlike conventional pipelines that need more than 12 hours of per-subject data and heavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates each reconstructed video in 10 seconds without any retraining, offering a fast and clinically scalable solution. The source code will be released upon acceptance of the paper.",
      "code_url": null
    }
  },
  "EEG": {
    "2511.03488v1": {
      "title": "NAP: Attention-Based Late Fusion for Automatic Sleep Staging",
      "url": "http://arxiv.org/abs/2511.03488v1",
      "authors": "Alvise Dei Rossi, Julia van der Meer, Markus H. Schmidt, Claudio L. A. Bassetti, Luigi Fiorillo, Francesca Faraci",
      "update_time": "2025-11-05",
      "abstract": "Polysomnography signals are highly heterogeneous, varying in modality composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal, occipital EEG), and acquisition protocols across datasets and clinical sites. Most existing models that process polysomnography data rely on a fixed subset of modalities or channels and therefore neglect to fully exploit its inherently multimodal nature. We address this limitation by introducing NAP (Neural Aggregator of Predictions), an attention-based model which learns to combine multiple prediction streams using a tri-axial attention mechanism that captures temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to different input dimensions. By aggregating outputs from frozen, pretrained single-channel models, NAP consistently outperforms individual predictors and simple ensembles, achieving state-of-the-art zero-shot generalization across multiple datasets. While demonstrated in the context of automated sleep staging from polysomnography, the proposed approach could be extended to other multimodal physiological applications.",
      "code_url": null
    },
    "2511.03263v1": {
      "title": "FAPEX: Fractional Amplitude-Phase Expressor for Robust Cross-Subject Seizure Prediction",
      "url": "http://arxiv.org/abs/2511.03263v1",
      "authors": "Ruizhe Zheng, Lingyan Mao, Dingding Han, Tian Luo, Yi Wang, Jing Ding, Yuguo Yu",
      "update_time": "2025-11-05",
      "abstract": "Precise, generalizable subject-agnostic seizure prediction (SASP) remains a fundamental challenge due to the intrinsic complexity and significant spectral variability of electrophysiological signals across individuals and recording modalities. We propose FAPEX, a novel architecture that introduces a learnable fractional neural frame operator (FrNFO) for adaptive time-frequency decomposition. Unlike conventional models that exhibit spectral bias toward low frequencies, our FrNFO employs fractional-order convolutions to capture both high and low-frequency dynamics, achieving approximately 10% improvement in F1-score and sensitivity over state-of-the-art baselines. The FrNFO enables the extraction of instantaneous phase and amplitude representations that are particularly informative for preictal biomarker discovery and enhance out-of-distribution generalization. FAPEX further integrates structural state-space modeling and channelwise attention, allowing it to handle heterogeneous electrode montages. Evaluated across 12 benchmarks spanning species (human, rat, dog, macaque) and modalities (Scalp-EEG, SEEG, ECoG, LFP), FAPEX consistently outperforms 23 supervised and 10 self-supervised baselines under nested cross-validation, with gains of up to 15% in sensitivity on complex cross-domain scenarios. It further demonstrates superior performance in several external validation cohorts. To our knowledge, these establish FAPEX as the first epilepsy model to show consistent superiority in SASP, offering a promising solution for discovering epileptic biomarker evidence supporting the existence of a distinct and identifiable preictal state and clinical translation.",
      "code_url": null
    },
    "2511.02735v1": {
      "title": "Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2511.02735v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-11-04",
      "abstract": "EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial specificity limitations in detecting single-trial P300 potentials, a neurophysiological hallmark leveraged for both BCI control and neurodegenerative disease diagnostics. We present a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable regions of interest (ROIs) across sessions. Analyzing 62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we demonstrate that phase-lagged connectivity metrics can reliably isolate task-relevant hubs in deeper cortical-subcortical structures like the insula and parietal regions - critical for Alzheimer's disease biomarkers. By integrating spatially stable ROIs with dynamic temporal agreement, our hybrid classification systematically outperforms whole-brain approaches in different frequency bands (up to 5.4% depending on the connectivity method and the spectral range) while maintaining millisecond-level temporal precision.   To the best of our knowledge, this is the first study to establish cross-subject ROI consensus through source-space connectivity, bypassing scalp EEG's depth constraints to probe Alzheimer's-relevant networks. The framework's robustness to noise and compatibility with portable systems offer significant potential for global deployment in early neurodegenerative disease detection. Future integration of individualized anatomical data or adaptive parameter optimization could refine this tool for clinical deployment, enhancing the current max accuracy of 81.57% in the 1-15 Hz range.",
      "code_url": null
    },
    "2511.02457v1": {
      "title": "Investigating Brain Connectivity and Information Flow in Mental Workload Using EEG and fNIRS Integration",
      "url": "http://arxiv.org/abs/2511.02457v1",
      "authors": "Mohaddese Qaremohammadlou, Mohammad Bagher Shamsollahi",
      "update_time": "2025-11-04",
      "abstract": "This study investigates brain connectivity and information flow during mental workload (MWL) by integrating electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) signals. Utilizing the N-back task to induce varying levels of MWL in 26 participants, we analyzed both functional and effective connectivity across 25 cortical regions derived from combined EEG and fNIRS signals. Functional connectivity was assessed using Pearson Correlation Coefficient (PCC), Phase Locking Value (PLV), and Magnitude Squared Coherence (MSC), while effective connectivity was evaluated using directed Directed Transfer Function (dDTF) and generalized Partial Directed Coherence (gPDC). Our findings reveal increased functional connectivity in frontal regions during higher MWL conditions (3-back compared to 0-back). Furthermore, effective connectivity analysis demonstrates a significant directional information flow from EEG to fNIRS, indicating a dominant influence of neural activity on hemodynamic responses. Statistical tests confirm significant differences in connectivity patterns between low and high MWL states. These results underscore the utility of EEG-fNIRS integration for characterizing brain network dynamics under varying cognitive demands and provide insights into neurovascular coupling mechanisms during mental workload.",
      "code_url": null
    },
    "2511.01784v1": {
      "title": "Variational Representational Similarity Analysis (vRSA) for M/EEG",
      "url": "http://arxiv.org/abs/2511.01784v1",
      "authors": "Alex Lepauvre, Lucia Melloni, Karl Friston, Peter Zeidman",
      "update_time": "2025-11-03",
      "abstract": "This paper introduces variational representational similarity analysis RSA (vRSA) for electromagnetic recordings of neural responses (e.g., EEG, MEG, ECoG or LFP). Variational RSA is a Bayesian approach for testing whether the similarity of stimuli or experimental conditions is expressed in univariate or multivariate neural recordings. Extending an approach previously introduced in the context of functional MRI, vRSA decomposes the condition-by-condition data covariance matrix into hypothesised effects and observation noise, thereby casting RSA as a covariance component estimation problem. In this context, peristimulus time may be treated as an experimental factor, enabling one to test for the probability that different experimental effects are expressed in data at different times. Variational Bayesian methods are used for model estimation and model comparison, which confer a number of advantages over classical approaches, including statistically efficient hypothesis testing, quantification of uncertainty using Bayesian credible intervals and computational efficiency. After introducing the theory, we provide a worked example using openly available EEG data. Software functions implementing vRSA for the SPM software package accompany this paper, together with exemplar analysis scripts.",
      "code_url": null
    },
    "2511.01951v1": {
      "title": "NeuroClean: A Generalized Machine-Learning Approach to Neural Time-Series Conditioning",
      "url": "http://arxiv.org/abs/2511.01951v1",
      "authors": "Manuel A. Hernandez Alonso, Michael Depass, Stephan Quessy, Numa Dancause, Ignasi Cos",
      "update_time": "2025-11-03",
      "abstract": "Electroencephalography (EEG) and local field potentials (LFP) are two widely used techniques to record electrical activity from the brain. These signals are used in both the clinical and research domains for multiple applications. However, most brain data recordings suffer from a myriad of artifacts and noise sources other than the brain itself. Thus, a major requirement for their use is proper and, given current volumes of data, a fully automatized conditioning. As a means to this end, here we introduce an unsupervised, multipurpose EEG/LFP preprocessing method, the NeuroClean pipeline. In addition to its completeness and reliability, NeuroClean is an unsupervised series of algorithms intended to mitigate reproducibility issues and biases caused by human intervention. The pipeline is designed as a five-step process, including the common bandpass and line noise filtering, and bad channel rejection. However, it incorporates an efficient independent component analysis with an automatic component rejection based on a clustering algorithm. This machine learning classifier is used to ensure that task-relevant information is preserved after each step of the cleaning process. We used several data sets to validate the pipeline. NeuroClean removed several common types of artifacts from the signal. Moreover, in the context of motor tasks of varying complexity, it yielded more than 97% accuracy (vs. a chance-level of 33.3%) in an optimized Multinomial Logistic Regression model after cleaning the data, compared to the raw data, which performed at 74% accuracy. These results show that NeuroClean is a promising pipeline and workflow that can be applied to future work and studies to achieve better generalization and performance on machine learning pipelines.",
      "code_url": null
    },
    "2511.01334v1": {
      "title": "Embodied Cognition Augmented End2End Autonomous Driving",
      "url": "http://arxiv.org/abs/2511.01334v1",
      "authors": "Ling Niu, Xiaoji Zheng, Han Wang, Chen Zheng, Ziyuan Yang, Bokui Chen, Jiangtao Gong",
      "update_time": "2025-11-03",
      "abstract": "In recent years, vision-based end-to-end autonomous driving has emerged as a new paradigm. However, popular end-to-end approaches typically rely on visual feature extraction networks trained under label supervision. This limited supervision framework restricts the generality and applicability of driving models. In this paper, we propose a novel paradigm termed $E^{3}AD$, which advocates for comparative learning between visual feature extraction networks and the general EEG large model, in order to learn latent human driving cognition for enhancing end-to-end planning. In this work, we collected a cognitive dataset for the mentioned contrastive learning process. Subsequently, we investigated the methods and potential mechanisms for enhancing end-to-end planning with human driving cognition, using popular driving models as baselines on publicly available autonomous driving datasets. Both open-loop and closed-loop tests are conducted for a comprehensive evaluation of planning performance. Experimental results demonstrate that the $E^{3}AD$ paradigm significantly enhances the end-to-end planning performance of baseline models. Ablation studies further validate the contribution of driving cognition and the effectiveness of comparative learning process. To the best of our knowledge, this is the first work to integrate human driving cognition for improving end-to-end autonomous driving planning. It represents an initial attempt to incorporate embodied cognitive data into end-to-end autonomous driving, providing valuable insights for future brain-inspired autonomous driving systems. Our code will be made available at Github",
      "code_url": null
    },
    "2511.01275v1": {
      "title": "Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting",
      "url": "http://arxiv.org/abs/2511.01275v1",
      "authors": "Zan Li, Kyongmin Yeo, Wesley Gifford, Lara Marcuse, Madeline Fields, B\u00fclent Yener",
      "update_time": "2025-11-03",
      "abstract": "Forecasting epileptic seizures from multivariate EEG signals represents a critical challenge in healthcare time series prediction, requiring high sensitivity, low false alarm rates, and subject-specific adaptability. We present STAN, an Adversarial Spatio-Temporal Attention Network that jointly models spatial brain connectivity and temporal neural dynamics through cascaded attention blocks with alternating spatial and temporal modules. Unlike existing approaches that assume fixed preictal durations or separately process spatial and temporal features, STAN captures bidirectional dependencies between spatial and temporal patterns through a unified cascaded architecture. Adversarial training with gradient penalty enables robust discrimination between interictal and preictal states learned from clearly defined 15-minute preictal windows. Continuous 90-minute pre-seizure monitoring reveals that the learned spatio-temporal attention patterns enable early detection: reliable alarms trigger at subject-specific times (typically 15-45 minutes before onset), reflecting the model's capacity to capture subtle preictal dynamics without requiring individualized training. Experiments on two benchmark EEG datasets (CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14 events) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011 false detections per hour and 94.2% sensitivity with 0.063 false detections per hour, respectively, while maintaining computational efficiency (2.3M parameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond epilepsy, the proposed framework provides a general paradigm for spatio-temporal forecasting in healthcare and other time series domains where individual heterogeneity and interpretability are crucial.",
      "code_url": null
    },
    "2511.00369v1": {
      "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet",
      "url": "http://arxiv.org/abs/2511.00369v1",
      "authors": "Farjana Aktar, Mohd Ruhul Ameen, Akif Islam, Md Ekramul Hamid",
      "update_time": "2025-11-01",
      "abstract": "Achieving both accurate and interpretable classification of motor imagery EEG remains a key challenge in brain computer interface (BCI) research. This paper compares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep learning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS pipeline combines filter bank common spatial pattern feature extraction with fuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet learns hierarchical spatial temporal representations directly from raw EEG data. In within-subject experiments, the fuzzy neural model performed better (68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43), while in cross-subject (LOSO) tests, the deep model exhibited stronger generalization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent +/- 16.22). The study provides practical guidance for selecting MI-BCI systems according to design goals: interpretability or robustness across users. Future investigations into transformer based and hybrid neuro symbolic frameworks are expected to advance transparent EEG decoding.",
      "code_url": null
    },
    "2511.00259v1": {
      "title": "Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial",
      "url": "http://arxiv.org/abs/2511.00259v1",
      "authors": "Andria J. Farrens, Luis Garcia-Fernandez, Raymond Diaz Rojas, Jillian Obeso Estrada, Dylan Reinsdorf, Vicky Chan, Disha Gupta, Joel Perry, Eric Wolbrecht, An Do, Steven C. Cramer, David J. Reinkensmeyer",
      "update_time": "2025-10-31",
      "abstract": "Precision rehabilitation aims to tailor movement training to improve outcomes. We tested whether proprioceptively-tailored robotic training improves hand function and neural processing in stroke survivors. Using a robotic finger exoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel Training, which uses robot-facilitated, gamified movements to enhance proprioceptive processing, and Virtual Assistance Training, which reduces robotic aid to increase reliance on self-generated feedback. In a randomized controlled trial, forty-six chronic stroke survivors completed nine 2-hour sessions of Standard, Propriopixel or Virtual training. Among participants with proprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002) and Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand function (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with improvements in hand function. Tailored training enhanced neural sensitivity to proprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive Contingent Negative Variation. These findings support proprioceptively-tailored training as a pathway to precision neurorehabilitation.",
      "code_url": null
    }
  },
  "BCI": {
    "2511.02735v1": {
      "title": "Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2511.02735v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-11-04",
      "abstract": "EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial specificity limitations in detecting single-trial P300 potentials, a neurophysiological hallmark leveraged for both BCI control and neurodegenerative disease diagnostics. We present a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable regions of interest (ROIs) across sessions. Analyzing 62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we demonstrate that phase-lagged connectivity metrics can reliably isolate task-relevant hubs in deeper cortical-subcortical structures like the insula and parietal regions - critical for Alzheimer's disease biomarkers. By integrating spatially stable ROIs with dynamic temporal agreement, our hybrid classification systematically outperforms whole-brain approaches in different frequency bands (up to 5.4% depending on the connectivity method and the spectral range) while maintaining millisecond-level temporal precision.   To the best of our knowledge, this is the first study to establish cross-subject ROI consensus through source-space connectivity, bypassing scalp EEG's depth constraints to probe Alzheimer's-relevant networks. The framework's robustness to noise and compatibility with portable systems offer significant potential for global deployment in early neurodegenerative disease detection. Future integration of individualized anatomical data or adaptive parameter optimization could refine this tool for clinical deployment, enhancing the current max accuracy of 81.57% in the 1-15 Hz range.",
      "code_url": null
    },
    "2511.00369v1": {
      "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet",
      "url": "http://arxiv.org/abs/2511.00369v1",
      "authors": "Farjana Aktar, Mohd Ruhul Ameen, Akif Islam, Md Ekramul Hamid",
      "update_time": "2025-11-01",
      "abstract": "Achieving both accurate and interpretable classification of motor imagery EEG remains a key challenge in brain computer interface (BCI) research. This paper compares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep learning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS pipeline combines filter bank common spatial pattern feature extraction with fuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet learns hierarchical spatial temporal representations directly from raw EEG data. In within-subject experiments, the fuzzy neural model performed better (68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43), while in cross-subject (LOSO) tests, the deep model exhibited stronger generalization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent +/- 16.22). The study provides practical guidance for selecting MI-BCI systems according to design goals: interpretability or robustness across users. Future investigations into transformer based and hybrid neuro symbolic frameworks are expected to advance transparent EEG decoding.",
      "code_url": null
    },
    "2510.27075v1": {
      "title": "Functional connectivity guided deep neural network for decoding high-level visual imagery",
      "url": "http://arxiv.org/abs/2510.27075v1",
      "authors": "Byoung-Hee Kwon, Minji Lee, Seong-Whan Lee",
      "update_time": "2025-10-31",
      "abstract": "This study introduces a pioneering approach in brain-computer interface (BCI) technology, featuring our novel concept of high-level visual imagery for non-invasive electroencephalography (EEG)-based communication. High-level visual imagery, as proposed in our work, involves the user engaging in the mental visualization of complex upper limb movements. This innovative approach significantly enhances the BCI system, facilitating the extension of its applications to more sophisticated tasks such as EEG-based robotic arm control. By leveraging this advanced form of visual imagery, our study opens new horizons for intricate and intuitive mind-controlled interfaces. We developed an advanced deep learning architecture that integrates functional connectivity metrics with a convolutional neural network-image transformer. This framework is adept at decoding subtle user intentions, addressing the spatial variability in high-level visual tasks, and effectively translating these into precise commands for robotic arm control. Our comprehensive offline and pseudo-online evaluations demonstrate the framework's efficacy in real-time applications, including the nuanced control of robotic arms. The robustness of our approach is further validated through leave-one-subject-out cross-validation, marking a significant step towards versatile, subject-independent BCI applications. This research highlights the transformative impact of advanced visual imagery and deep learning in enhancing the usability and adaptability of BCI systems, particularly in robotic arm manipulation.",
      "code_url": null
    },
    "2511.02848v1": {
      "title": "EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding",
      "url": "http://arxiv.org/abs/2511.02848v1",
      "authors": "Shantanu Sarkar, Piotr Nabrzyski, Saurabh Prasad, Jose Luis Contreras-Vidal",
      "update_time": "2025-10-26",
      "abstract": "Electroencephalography (EEG) is a widely used non-invasive technique for monitoring brain activity, but low signal-to-noise ratios (SNR) due to various artifacts often compromise its utility. Conventional artifact removal methods require manual intervention or risk suppressing critical neural features during filtering/reconstruction. Recent advances in generative models, including Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), have shown promise for EEG reconstruction; however, these approaches often lack integrated temporal-spectral-spatial sensitivity and are computationally intensive, limiting their suitability for real-time applications like brain-computer interfaces (BCIs). To overcome these challenges, we introduce EEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction via cross-subject transfer learning - developed using Keras TensorFlow (v2.15.1). EEGReXferNet employs a modular architecture that leverages volume conduction across neighboring channels, band-specific convolution encoding, and dynamic latent feature extraction through sliding windows. By integrating reference-based scaling, the framework ensures continuity across successive windows and generalizes effectively across subjects. This design improves spatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean spectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate overfitting, and maintains computational efficiency for robust, real-time EEG preprocessing in neurophysiological and BCI applications.",
      "code_url": null
    },
    "2510.22262v1": {
      "title": "Lateral Ventricular Brain-Computer Interface System with Lantern-Inspired Electrode for Stable Performance and Memory Decoding",
      "url": "http://arxiv.org/abs/2510.22262v1",
      "authors": "Yike Sun, Yaxuan Gao, Kewei Wang, Jingnan Sun, Yuzhen Chen, Yanan Yang, Tianhua Zhao, Haochen Zhu, Ran Liu, Xiaogang Chen, Bai Lu, Xiaorong Gao",
      "update_time": "2025-10-25",
      "abstract": "We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an \"action-memory T-maze\" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience.",
      "code_url": null
    },
    "2510.22095v1": {
      "title": "Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies",
      "url": "http://arxiv.org/abs/2510.22095v1",
      "authors": "Yankai Chen, Xinni Zhang, Yifei Zhang, Yangning Li, Henry Peng Zou, Chunyu Miao, Weizhi Zhang, Xue Liu, Philip S. Yu",
      "update_time": "2025-10-25",
      "abstract": "Brain-Computer Interfaces (BCIs) offer a direct communication pathway between the human brain and external devices, holding significant promise for individuals with severe neurological impairments. However, their widespread adoption is hindered by critical limitations, such as low information transfer rates and extensive user-specific calibration. To overcome these challenges, recent research has explored the integration of Large Language Models (LLMs), extending the focus from simple command decoding to understanding complex cognitive states. Despite these advancements, deploying agentic AI faces technical hurdles and ethical concerns. Due to the lack of comprehensive discussion on this emerging direction, this position paper argues that the field is poised for a paradigm extension from BCI to Brain-Agent Collaboration (BAC). We emphasize reframing agents as active and collaborative partners for intelligent assistance rather than passive brain signal data processors, demanding a focus on ethical data handling, model reliability, and a robust human-agent collaboration framework to ensure these systems are safe, trustworthy, and effective.",
      "code_url": null
    },
    "2510.21038v2": {
      "title": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset",
      "url": "http://arxiv.org/abs/2510.21038v2",
      "authors": "Gereon Elvers, Gilad Landau, Oiwi Parker Jones",
      "update_time": "2025-10-30",
      "abstract": "Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from large, public benchmarks. However, current benchmarks target relatively simple, foundational tasks like Speech Detection and Phoneme Classification, while application-ready results on tasks like Brain-to-Text remain elusive. We propose Keyword Spotting (KWS) as a practically applicable, privacy-aware intermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we provide standardized train/validation/test splits for reproducible benchmarking, and adopt an evaluation protocol tailored to extreme class imbalance. Concretely, we use area under the precision-recall curve (AUPRC) as a robust evaluation metric, complemented by false alarms per hour (FA/h) at fixed recall to capture user-facing trade-offs. To simplify deployment and further experimentation within the research community, we are releasing an updated version of the pnpl library with word-level dataloaders and Colab-ready tutorials. As an initial reference model, we present a compact 1-D Conv/ResNet baseline with focal loss and top-k pooling that is trainable on a single consumer-class GPU. The reference model achieves approximately 13x the permutation baseline AUPRC on held-out sessions, demonstrating the viability of the task. Exploratory analyses reveal: (i) predictable within-subject scaling - performance improves log-linearly with more training hours - and (ii) the existence of word-level factors (frequency and duration) that systematically modulate detectability.",
      "code_url": null
    },
    "2510.20958v2": {
      "title": "NeuroPilot: A Realtime Brain-Computer Interface system to enhance concentration of students in online learning",
      "url": "http://arxiv.org/abs/2510.20958v2",
      "authors": "Asif Islam, Farhan Ishtiaque, Md. Muhyminul Haque, Farhana Sarker, Ravi Vaidyanathan, Khondaker A. Mamun",
      "update_time": "2025-10-28",
      "abstract": "The prevalence of online learning poses a vital challenge in real-time monitoring of students' concentration. Traditional methods such as questionnaire assessments require manual intervention, and webcam-based monitoring fails to provide accurate insights about learners' mental focus as it is deceived by mere screen fixation without cognitive engagement. Existing BCI-based approaches lack real-time validation and evaluation procedures. To address these limitations, a Brain-Computer Interface (BCI) system is developed using a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record brainwave activity under attentive and non-attentive states. 20 minutes of data were collected from each of 20 participants watching a pre-recorded educational video. The data validation employed a novel intra-video questionnaire assessment. Subsequently, collected signals were segmented (sliding window), filtered (Butterworth bandpass), and cleaned (removal of high-amplitude and EOG artifacts such as eye blinks). Time, frequency, wavelet, and statistical features were extracted, followed by recursive feature elimination (RFE) with support vector machines (SVMs) to classify attention and non-attention states. The leave-one-subject-out (LOSO) cross-validation accuracy was found to be 88.77%. The system provides feedback alerts upon detection of a non-attention state and maintains focus profile logs. A pilot study was conducted to evaluate the effectiveness of real-time feedback. Five participants underwent a 10-minute session comprising a 5-minute baseline phase devoid of feedback, succeeded by a 5-minute feedback phase, during which alerts were activated if participants exhibited inattention for approximately 8 consecutive seconds. A paired t-test (t = 5.73, p = 0.007) indicated a statistically significant improvement in concentration during the feedback phase.",
      "code_url": null
    },
    "2510.20683v1": {
      "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks",
      "url": "http://arxiv.org/abs/2510.20683v1",
      "authors": "Georgios Mentzelopoulos, Ioannis Asmanis, Konrad P. Kording, Eva L. Dyer, Kostas Daniilidis, Flavia Vitale",
      "update_time": "2025-10-23",
      "abstract": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.",
      "code_url": null
    },
    "2510.21841v1": {
      "title": "RatioWaveNet: A Learnable RDWT Front-End for Robust and Interpretable EEG Motor-Imagery Classification",
      "url": "http://arxiv.org/abs/2510.21841v1",
      "authors": "Marco Siino, Giuseppe Bonomo, Rosario Sorbello, Ilenia Tinnirello",
      "update_time": "2025-10-22",
      "abstract": "Brain-computer interfaces (BCIs) based on motor imagery (MI) translate covert movement intentions into actionable commands, yet reliable decoding from non-invasive EEG remains challenging due to nonstationarity, low SNR, and subject variability. We present RatioWaveNet, which augments a strong temporal CNN-Transformer backbone (TCFormer) with a trainable, Rationally-Dilated Wavelet Transform (RDWT) front end. The RDWT performs an undecimated, multi-resolution subband decomposition that preserves temporal length and shift-invariance, enhancing sensorimotor rhythms while mitigating jitter and mild artifacts; subbands are fused via lightweight grouped 1-D convolutions and passed to a multi-kernel CNN for local temporal-spatial feature extraction, a grouped-query attention encoder for long-range context, and a compact TCN head for causal temporal integration.   Our goal is to test whether this principled wavelet front end improves robustness precisely where BCIs typically fail - on the hardest subjects - and whether such gains persist on average across seeds under both intra- and inter-subject protocols. On BCI-IV-2a and BCI-IV-2b, across five seeds, RatioWaveNet improves worst-subject accuracy over the Transformer backbone by +0.17 / +0.42 percentage points (Sub-Dependent / LOSO) on 2a and by +1.07 / +2.54 percentage points on 2b, with consistent average-case gains and modest computational overhead. These results indicate that a simple, trainable wavelet front end is an effective plug-in to strengthen Transformer-based BCIs, improving worst-case reliability without sacrificing efficiency.",
      "code_url": null
    }
  },
  "fMRI": {
    "2511.03605v1": {
      "title": "Bayesian Topological Analysis of Functional Brain Networks",
      "url": "http://arxiv.org/abs/2511.03605v1",
      "authors": "Xukun Zhu, Michael W Lutz, Tananun Songdechakraiwut",
      "update_time": "2025-11-05",
      "abstract": "Subtle alterations in brain network topology often evade detection by traditional statistical methods. To address this limitation, we introduce a Bayesian inference framework for topological comparison of brain networks that probabilistically models within- and between-group dissimilarities. The framework employs Markov chain Monte Carlo sampling to estimate posterior distributions of test statistics and Bayes factors, enabling graded evidence assessment beyond binary significance testing. Simulations confirmed statistical consistency to permutation testing. Applied to fMRI data from the Duke-UNC Alzheimer's Disease Research Center, the framework detected topology-based network differences that conventional permutation tests failed to reveal, highlighting its enhanced sensitivity to early or subtle brain network alterations in clinical neuroimaging.",
      "code_url": null
    },
    "2511.02722v1": {
      "title": "Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia",
      "url": "http://arxiv.org/abs/2511.02722v1",
      "authors": "Subati Abulikemu, Puria Radmard, Michail Mamalakis, John Suckling",
      "update_time": "2025-11-04",
      "abstract": "The human neocortex is functionally organised at its highest level along a continuous sensory-to-association (AS) hierarchy. This study characterises the AS hierarchy of patients with schizophrenia in a comparison with controls. Using a large fMRI dataset (N=355), we extracted individual AS gradients via spectral analysis of brain connectivity, quantified hierarchical specialisation by gradient spread, and related this spread with connectivity geometry. We found that schizophrenia compresses the AS hierarchy indicating reduced functional differentiation. By modelling neural timescale with the Ornstein-Uhlenbeck process, we observed that the most specialised, locally cohesive regions at the gradient extremes exhibit dynamics with a longer time constant, an effect that is attenuated in schizophrenia. To study computation, we used the gradients to regularise subject-specific recurrent neural networks (RNNs) trained on working memory tasks. Networks endowed with greater gradient spread learned more efficiently, plateaued at lower task loss, and maintained stronger alignment to the prescribed AS hierarchical geometry. Fixed point linearisation showed that high-range networks settled into more stable neural states during memory delay, evidenced by lower energy and smaller maximal Jacobian eigenvalues. This gradient-regularised RNN framework therefore links large-scale cortical architecture with fixed point stability, providing a mechanistic account of how gradient de-differentiation could destabilise neural computations in schizophrenia, convergently supported by empirical timescale flattening and model-based evidence of less stable fixed points.",
      "code_url": null
    },
    "2511.02565v1": {
      "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding",
      "url": "http://arxiv.org/abs/2511.02565v1",
      "authors": "Jingyu Lu, Haonan Wang, Qixiang Zhang, Xiaomeng Li",
      "update_time": "2025-11-04",
      "abstract": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual experiences from fMRI without subject-specific training, holds great potential for clinical applications. However, this direction remains underexplored due to challenges in cross-subject generalization and the complex nature of brain signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework that explicitly models the ventral-dorsal architecture of the human visual system to learn multi-dimensional representations. By disentangling and leveraging features from early visual cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary cognitive information essential for visual reconstruction. Furthermore, we introduce a feature-level contrastive learning strategy to enhance the extraction of subject-invariant semantic representations, thereby enhancing subject-agnostic applicability to previously unseen subjects. Unlike conventional pipelines that need more than 12 hours of per-subject data and heavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates each reconstructed video in 10 seconds without any retraining, offering a fast and clinically scalable solution. The source code will be released upon acceptance of the paper.",
      "code_url": null
    },
    "2511.02422v1": {
      "title": "Cluster Size Matters: A Comparative Study of Notip and pARI for Post Hoc Inference in fMRI",
      "url": "http://arxiv.org/abs/2511.02422v1",
      "authors": "Nils Peyrouset, Pierre Neuvial, Bertrand Thirion",
      "update_time": "2025-11-04",
      "abstract": "All Resolutions Inference (ARI) is a post hoc inference method for functional Magnetic Resonance Imaging (fMRI) data analysis that provides valid lower bounds on the proportion of truly active voxels within any, possibly data-driven, cluster. As such, it addresses the paradox of spatial specificity encountered with more classical cluster-extent thresholding methods. It allows the cluster-forming threshold to be increased in order to locate the signal with greater spatial precision without overfitting, also known as the drill-down approach. Notip and pARI are two recent permutation-based extensions of ARI designed to increase statistical power by accounting for the strong dependence structure typical of fMRI data. A recent comparison between these papers based on large voxel clusters concluded that pARI outperforms Notip. We revisit this conclusion by conducting a systematic comparison of the two. Our reanalysis of the same fMRI data sets from the Neurovault database demonstrates the existence of complementary performance regimes: while pARI indeed achieves higher sensitivity for large clusters, Notip provides more informative and robust results for smaller clusters. In particular, while Notip supports informative ``drill-down'' exploration into subregions of activation, pARI often yields non-informative bounds in such cases, and can even underperform the baseline ARI method.",
      "code_url": null
    },
    "2511.00443v1": {
      "title": "Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model",
      "url": "http://arxiv.org/abs/2511.00443v1",
      "authors": "Ruthwik Reddy Doodipala, Pankaj Pandey, Carolina Torres Rojas, Manob Jyoti Saikia, Ranganatha Sitaram",
      "update_time": "2025-11-01",
      "abstract": "The emergence of foundation models in neuroimaging is driven by the increasing availability of large-scale and heterogeneous brain imaging datasets. Recent advances in self-supervised learning, particularly reconstruction-based objectives, have demonstrated strong potential for pretraining models that generalize effectively across diverse downstream functional MRI (fMRI) tasks. In this study, we explore region-aware reconstruction strategies for a foundation model in resting-state fMRI, moving beyond approaches that rely on random region masking. Specifically, we introduce an ROI-guided masking strategy using the Automated Anatomical Labelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively mask semantically coherent brain regions during self-supervised pretraining. Using the ADHD-200 dataset comprising 973 subjects with resting-state fMRI scans, we show that our method achieves a 4.23% improvement in classification accuracy for distinguishing healthy controls from individuals diagnosed with ADHD, compared to conventional random masking. Region-level attribution analysis reveals that brain volumes within the limbic region and cerebellum contribute most significantly to reconstruction fidelity and model representation. Our results demonstrate that masking anatomical regions during model pretraining not only enhances interpretability but also yields more robust and discriminative representations. In future work, we plan to extend this approach by evaluating it on additional neuroimaging datasets, and developing new loss functions explicitly derived from region-aware reconstruction objectives. These directions aim to further improve the robustness and interpretability of foundation models for functional neuroimaging.",
      "code_url": null
    },
    "2511.00395v1": {
      "title": "Is Representational Similarity Analysis Reliable? A Comparison with Regression",
      "url": "http://arxiv.org/abs/2511.00395v1",
      "authors": "Chuanji Gao, Gang Chen, Svetlana V. Shinkareva, Rutvik H. Desai",
      "update_time": "2025-11-01",
      "abstract": "Representational Similarity Analysis (RSA) is a popular method for analyzing neuroimaging and behavioral data. Here we evaluate the accuracy and reliability of RSA in the context of model selection, and compare it to that of regression. Although RSA offers flexibility in handling high-dimensional, cross-modal, and cross-species data, its reliance on a transformation of raw data into similarity structures may result in the loss of critical stimulus-response information. Across extensive simulation studies and empirical analyses, we show that RSA leads to lower model selection accuracy, regardless of sample size, noise level, feature dimensionality, or multicollinearity, relative to regression. While principal component analysis and feature reweighting mitigate RSA's deficits driven by multicollinearity, regression remains superior in accurately distinguishing between models. Empirical data and a follow-up fMRI simulation further support these conclusions. Our findings suggest that researchers should carefully consider which approach to use: RSA is less effective than linear regression for model selection and fitting when direct stimulus-response mappings are available.",
      "code_url": null
    },
    "2510.27128v1": {
      "title": "ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding",
      "url": "http://arxiv.org/abs/2510.27128v1",
      "authors": "Haonan Wang, Jingyu Lu, Hongrui Li, Xiaomeng Li",
      "update_time": "2025-10-31",
      "abstract": "Recent advances in neural decoding have enabled the reconstruction of visual experiences from brain activity, positioning fMRI-to-image reconstruction as a promising bridge between neuroscience and computer vision. However, current methods predominantly rely on subject-specific models or require subject-specific fine-tuning, limiting their scalability and real-world applicability. In this work, we introduce ZEBRA, the first zero-shot brain visual decoding framework that eliminates the need for subject-specific adaptation. ZEBRA is built on the key insight that fMRI representations can be decomposed into subject-related and semantic-related components. By leveraging adversarial training, our method explicitly disentangles these components to isolate subject-invariant, semantic-specific representations. This disentanglement allows ZEBRA to generalize to unseen subjects without any additional fMRI data or retraining. Extensive experiments show that ZEBRA significantly outperforms zero-shot baselines and achieves performance comparable to fully finetuned models on several metrics. Our work represents a scalable and practical step toward universal neural decoding. Code and model weights are available at: https://github.com/xmed-lab/ZEBRA.",
      "code_url": null
    },
    "2510.26120v1": {
      "title": "Functional Connectome Fingerprinting Using Convolutional and Dictionary Learning",
      "url": "http://arxiv.org/abs/2510.26120v1",
      "authors": "Yashaswini, Sanjay Ghosh",
      "update_time": "2025-10-30",
      "abstract": "Advances in data analysis and machine learning have revolutionized the study of brain signatures using fMRI, enabling non-invasive exploration of cognition and behavior through individual neural patterns. Functional connectivity (FC), which quantifies statistical relationships between brain regions, has emerged as a key metric for studying individual variability and developing biomarkers for personalized medicine in neurological and psychiatric disorders. The concept of subject fingerprinting, introduced by Finn et al. (2015), leverages neural connectivity variability to identify individuals based on their unique patterns. While traditional FC methods perform well on small datasets, machine learning techniques are more effective with larger datasets, isolating individual-specific features and maximizing inter-subject differences. In this study, we propose a framework combining convolutional autoencoders and sparse dictionary learning to enhance fingerprint accuracy. Autoencoders capture shared connectivity patterns while isolating subject-specific features in residual FC matrices, which are analyzed using sparse coding to identify distinctive features. Tested on the Human Connectome Project dataset, this approach achieved a 10% improvement over baseline group-averaged FC models. Our results highlight the potential of integrating deep learning and sparse coding techniques for scalable and robust functional connectome fingerprinting, advancing personalized neuroscience applications and biomarker development.",
      "code_url": null
    },
    "2510.25976v1": {
      "title": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer",
      "url": "http://arxiv.org/abs/2510.25976v1",
      "authors": "Roman Beliy, Amit Zalcher, Jonathan Kogman, Navve Wasserman, Michal Irani",
      "update_time": "2025-10-29",
      "abstract": "Reconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present \"Brain-IT\", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters & subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings.",
      "code_url": null
    },
    "2510.24025v2": {
      "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis",
      "url": "http://arxiv.org/abs/2510.24025v2",
      "authors": "Tianqi Guo, Liping Chen, Ciyuan Peng, Jingjing Zhou, Jing Ren",
      "update_time": "2025-10-29",
      "abstract": "Understanding the evolution of brain functional networks over time is of great significance for the analysis of cognitive mechanisms and the diagnosis of neurological diseases. Existing methods often have difficulty in capturing the temporal evolution characteristics of connections between specific functional communities. To this end, this paper proposes a new path-level trajectory modeling framework (NeuroPathNet) to characterize the dynamic behavior of connection pathways between brain functional partitions. Based on medically supported static partitioning schemes (such as Yeo and Smith ICA), we extract the time series of connection strengths between each pair of functional partitions and model them using a temporal neural network. We validate the model performance on three public functional Magnetic Resonance Imaging (fMRI) datasets, and the results show that it outperforms existing mainstream methods in multiple indicators. This study can promote the development of dynamic graph learning methods for brain network analysis, and provide possible clinical applications for the diagnosis of neurological diseases.",
      "code_url": null
    }
  },
  "MEG": {
    "2511.01784v1": {
      "title": "Variational Representational Similarity Analysis (vRSA) for M/EEG",
      "url": "http://arxiv.org/abs/2511.01784v1",
      "authors": "Alex Lepauvre, Lucia Melloni, Karl Friston, Peter Zeidman",
      "update_time": "2025-11-03",
      "abstract": "This paper introduces variational representational similarity analysis RSA (vRSA) for electromagnetic recordings of neural responses (e.g., EEG, MEG, ECoG or LFP). Variational RSA is a Bayesian approach for testing whether the similarity of stimuli or experimental conditions is expressed in univariate or multivariate neural recordings. Extending an approach previously introduced in the context of functional MRI, vRSA decomposes the condition-by-condition data covariance matrix into hypothesised effects and observation noise, thereby casting RSA as a covariance component estimation problem. In this context, peristimulus time may be treated as an experimental factor, enabling one to test for the probability that different experimental effects are expressed in data at different times. Variational Bayesian methods are used for model estimation and model comparison, which confer a number of advantages over classical approaches, including statistically efficient hypothesis testing, quantification of uncertainty using Bayesian credible intervals and computational efficiency. After introducing the theory, we provide a worked example using openly available EEG data. Software functions implementing vRSA for the SPM software package accompany this paper, together with exemplar analysis scripts.",
      "code_url": null
    },
    "2511.00697v1": {
      "title": "Smooth Models of Fibered Partially Hyperbolic Systems",
      "url": "http://arxiv.org/abs/2511.00697v1",
      "authors": "Jonathan DeWitt, Meg Doucette, Oliver Wang",
      "update_time": "2025-11-01",
      "abstract": "We study fibered partially hyperbolic diffeomorphisms. We show that as long as certain topological obstructions vanish and as long as homological minimum expansion dominates the distortion on the fibers that a fibered partially hyperbolic system can be homotoped to a fibered partially hyperbolic system with a $C^{\\infty}$-center fibering. In addition, we study obstructions to the existence of smooth lifts of Anosov diffeomorphisms to bundles. In particular, we give an example of smooth topologically trivial bundle over a torus, where an Anosov diffeomorphism can lift continuously but not smoothly to the bundle.",
      "code_url": null
    },
    "2510.25913v1": {
      "title": "Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields",
      "url": "http://arxiv.org/abs/2510.25913v1",
      "authors": "Gilbert Bahati, Ryan M. Bena, Meg Wilkinson, Pol Mestres, Ryan K. Cosner, Aaron D. Ames",
      "update_time": "2025-10-29",
      "abstract": "Robotic systems navigating in real-world settings require a semantic understanding of their environment to properly determine safe actions. This work aims to develop the mathematical underpinnings of such a representation -- specifically, the goal is to develop safety filters that are risk-aware. To this end, we take a two step approach: encoding an understanding of the environment via Poisson's equation, and associated risk via Laplace guidance fields. That is, we first solve a Dirichlet problem for Poisson's equation to generate a safety function that encodes system safety as its 0-superlevel set. We then separately solve a Dirichlet problem for Laplace's equation to synthesize a safe \\textit{guidance field} that encodes variable levels of caution around obstacles -- by enforcing a tunable flux boundary condition. The safety function and guidance fields are then combined to define a safety constraint and used to synthesize a risk-aware safety filter which, given a semantic understanding of an environment with associated risk levels of environmental features, guarantees safety while prioritizing avoidance of higher risk obstacles. We demonstrate this method in simulation and discuss how \\textit{a priori} understandings of obstacle risk can be directly incorporated into the safety filter to generate safe behaviors that are risk-aware.",
      "code_url": null
    },
    "2510.24979v1": {
      "title": "Breaking the Timescale Barrier: Generative Discovery of Conformational Free-Energy Landscapes and Transition Pathways",
      "url": "http://arxiv.org/abs/2510.24979v1",
      "authors": "Chenyu Tang, Mayank Prakash Pandey, Cheng Giuseppe Chen, Alberto Meg\u00edas, Fran\u00e7ois Dehez, Christophe Chipot",
      "update_time": "2025-10-28",
      "abstract": "Molecular transitions -- such as protein folding, allostery, and membrane transport -- are central to biology yet remain notoriously difficult to simulate. Their intrinsic rarity pushes them beyond reach of standard molecular dynamics, while enhanced-sampling methods are costly and often depend on arbitrary variables that bias outcomes. We introduce Gen-COMPAS, a generative committor-guided path sampling framework that reconstructs transition pathways without predefined variables and at a fraction of the cost. Gen-COMPAS couples a generative diffusion model, which produces physically realistic intermediates, with committor-based filtering to pinpoint transition states. Short unbiased simulations from these intermediates rapidly yield full transition-path ensembles that converge within nanoseconds, where conventional methods require orders of magnitude more sampling. Applied to systems from a miniprotein to a ribose-binding protein to a mitochondrial carrier, Gen-COMPAS retrieves committors, transition states, and free-energy landscapes efficiently, uniting machine learning and molecular dynamics for broad mechanistic and practical insight.",
      "code_url": null
    },
    "2510.23742v1": {
      "title": "Molecular Gas in Major Mergers Hosting Dual and Single AGN at <10 kpc Nuclear Separations",
      "url": "http://arxiv.org/abs/2510.23742v1",
      "authors": "Makoto A. Johnstone, Ezequiel Treister, Franz E. Bauer, Chin-Shin Chang, Claudia Cicone, Michael J. Koss, Ignacio del Moral-Castro, Francisco Muller-Sanchez, George C. Privon, Claudio Ricci, Nick Scoville, Giacomo Venturi, Loreto Barcos-Mu\u00f1oz, Lee Armus, Laura Blecha, Caitlin Casey, Julia Comerford, Aaron Evans, Taiki Kawamuro, Anne M. Medling, Hugo Messias, Neil Nagar, Alejandra Rojas, David Sanders, Benny Trakhtenbrot, Vivian U, Meg Urry",
      "update_time": "2025-10-27",
      "abstract": "We present high-resolution ($\\sim$50$-$100 pc) Atacama Large Millimeter Array (ALMA) observations of $^{12}$CO(2-1) or $^{12}$CO(1-0) emission in seven local ($z$ $\\lesssim$ 0.05) major mergers -- five of which are dual active galactic nuclei (AGN) systems, and two of which are single AGN systems. We model the molecular gas kinematics through rotating disk profiles using a Bayesian Markov chain Monte Carlo approach. The residuals were then used to isolate non-rotating components of the molecular gas -- the most likely contributor to future SMBH growth. We find that more massive SMBHs have higher surface densities of non-rotating molecular gas within their sphere of influence. This potential molecular gas supply, however, does not correlate with the current accretion efficiency of the SMBHs, suggesting that only a fraction of the observed non-rotating gas is currently reaching the SMBH. Finally, we tentatively find no significant differences in the nuclear molecular gas masses of single AGN and dual AGN hosts, both within the SMBH sphere of influence and within the central kiloparsec. Our results indicate that the probability of occurrence of the dual AGN phenomenon is likely dependent on AGN variability and/or obscuration rather than the availability of molecular gas in the nuclear regions.",
      "code_url": null
    },
    "2510.21596v1": {
      "title": "Automated interictal epileptic spike detection from simple and noisy annotations in MEG data",
      "url": "http://arxiv.org/abs/2510.21596v1",
      "authors": "Pauline Mouches, Julien Jung, Armand Demasson, Agn\u00e8s Guinard, Romain Bouet, Rosalie Marchal, Romain Quentin",
      "update_time": "2025-10-24",
      "abstract": "In drug-resistant epilepsy, presurgical evaluation of epilepsy can be considered. Magnetoencephalography (MEG) has been shown to be an effective exam to inform the localization of the epileptogenic zone through the localization of interictal epileptic spikes. Manual detection of these pathological biomarkers remains a fastidious and error-prone task due to the high dimensionality of MEG recordings, and interrater agreement has been reported to be only moderate. Current automated methods are unsuitable for clinical practice, either requiring extensively annotated data or lacking robustness on non-typical data. In this work, we demonstrate that deep learning models can be used for detecting interictal spikes in MEG recordings, even when only temporal and single-expert annotations are available, which represents real-world clinical practice. We propose two model architectures: a feature-based artificial neural network (ANN) and a convolutional neural network (CNN), trained on a database of 59 patients, and evaluated against a state-of-the-art model to classify short time windows of signal. In addition, we employ an interactive machine learning strategy to iteratively improve our data annotation quality using intermediary model outputs. Both proposed models outperform the state-of-the-art model (F1-scores: CNN=0.46, ANN=0.44) when tested on 10 holdout test patients. The interactive machine learning strategy demonstrates that our models are robust to noisy annotations. Overall, results highlight the robustness of models with simple architectures when analyzing complex and imperfectly annotated data. Our method of interactive machine learning offers great potential for faster data annotation, while our models represent useful and efficient tools for automated interictal spikes detection.",
      "code_url": null
    },
    "2510.19702v1": {
      "title": "Dictionary learning methods for brain activity mapping with MEG data",
      "url": "http://arxiv.org/abs/2510.19702v1",
      "authors": "Daniela Calvetti, Erkki Somersalo",
      "update_time": "2025-10-22",
      "abstract": "A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.",
      "code_url": null
    },
    "2510.18080v1": {
      "title": "MEG-GPT: A transformer-based foundation model for magnetoencephalography data",
      "url": "http://arxiv.org/abs/2510.18080v1",
      "authors": "Rukuang Huang, Sungjun Cho, Chetan Gohil, Oiwi Parker Jones, Mark Woolrich",
      "update_time": "2025-10-20",
      "abstract": "Modelling the complex spatiotemporal patterns of large-scale brain dynamics is crucial for neuroscience, but traditional methods fail to capture the rich structure in modalities such as magnetoencephalography (MEG). Recent advances in deep learning have enabled significant progress in other domains, such as language and vision, by using foundation models at scale. Here, we introduce MEG-GPT, a transformer based foundation model that uses time-attention and next time-point prediction. To facilitate this, we also introduce a novel data-driven tokeniser for continuous MEG data, which preserves the high temporal resolution of continuous MEG signals without lossy transformations. We trained MEG-GPT on tokenised brain region time-courses extracted from a large-scale MEG dataset (N=612, eyes-closed rest, Cam-CAN data), and show that the learnt model can generate data with realistic spatio-spectral properties, including transient events and population variability. Critically, it performs well in downstream decoding tasks, improving downstream supervised prediction task, showing improved zero-shot generalisation across sessions (improving accuracy from 0.54 to 0.59) and subjects (improving accuracy from 0.41 to 0.49) compared to a baseline methods. Furthermore, we show the model can be efficiently fine-tuned on a smaller labelled dataset to boost performance in cross-subject decoding scenarios. This work establishes a powerful foundation model for electrophysiological data, paving the way for applications in computational neuroscience and neural decoding.",
      "code_url": null
    },
    "2510.26804v1": {
      "title": "EARS-UDE: Evaluating Auditory Response in Sensory Overload with Universal Differential Equations",
      "url": "http://arxiv.org/abs/2510.26804v1",
      "authors": "Miheer Salunke, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat",
      "update_time": "2025-10-16",
      "abstract": "Auditory sensory overload affects 50-70% of individuals with Autism Spectrum Disorder (ASD), yet existing approaches, such as mechanistic models (Hodgkin Huxley type, Wilson Cowan, excitation inhibition balance), clinical tools (EEG/MEG, Sensory Profile scales), and ML methods (Neural ODEs, predictive coding), either assume fixed parameters or lack interpretability, missing autism heterogeneity. We present a Scientific Machine Learning approach using Universal Differential Equations (UDEs) to model sensory adaptation dynamics in autism. Our framework combines ordinary differential equations grounded in biophysics with neural networks to capture both mechanistic understanding and individual variability. We demonstrate that UDEs achieve a 90.8% improvement over pure Neural ODEs while using 73.5% fewer parameters. The model successfully recovers physiological parameters within the 2% error and provides a quantitative risk assessment for sensory overload, predicting 17.2% risk for pulse stimuli with specific temporal patterns. This framework establishes foundations for personalized, evidence-based interventions in autism, with direct applications to wearable technology and clinical practice.",
      "code_url": null
    },
    "2510.24733v1": {
      "title": "Decoding non-invasive brain activity with novel deep-learning approaches",
      "url": "http://arxiv.org/abs/2510.24733v1",
      "authors": "Richard Csaky",
      "update_time": "2025-10-13",
      "abstract": "This thesis delves into the world of non-invasive electrophysiological brain signals like electroencephalography (EEG) and magnetoencephalography (MEG), focusing on modelling and decoding such data. The research aims to investigate what happens in the brain when we perceive visual stimuli or engage in covert speech (inner speech) and enhance the decoding performance of such stimuli. The thesis is divided into two main sections, methodological and experimental work. A central concern in both sections is the large variability present in electrophysiological recordings, whether it be within-subject or between-subject variability, and to a certain extent between-dataset variability. In the methodological sections, we explore the potential of deep learning for brain decoding. We present advancements in decoding visual stimuli using linear models at the individual subject level. We then explore how deep learning techniques can be employed for group decoding, introducing new methods to deal with between-subject variability. Finally, we also explores novel forecasting models of MEG data based on convolutional and Transformer-based architectures. In particular, Transformer-based models demonstrate superior capabilities in generating signals that closely match real brain data, thereby enhancing the accuracy and reliability of modelling the brain's electrophysiology. In the experimental section, we present a unique dataset containing high-trial inner speech EEG, MEG, and preliminary optically pumped magnetometer (OPM) data. Our aim is to investigate different types of inner speech and push decoding performance by collecting a high number of trials and sessions from a few participants. However, the decoding results are found to be mostly negative, underscoring the difficulty of decoding inner speech.",
      "code_url": null
    }
  },
  "neuroAI": {
    "2510.22178v1": {
      "title": "Dopamine-driven synaptic credit assignment in neural networks",
      "url": "http://arxiv.org/abs/2510.22178v1",
      "authors": "Saranraj Nambusubramaniyan, Shervin Safavi, Raja Guru, Andreas Knoblauch",
      "update_time": "2025-10-25",
      "abstract": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in both biological and artificial neural systems. Finding an optimal solution for synaptic CAP means setting the synaptic weights that assign credit to each neuron for influencing the final output and behavior of neural networks or animals. Gradient-based methods solve this problem in artificial neural networks using back-propagation, however, not in the most efficient way. For instance, back-propagation requires a chain of top-down gradient computations. This leads to an expensive optimization process in terms of computing power and memory linked with well-known weight transport and update locking problems. To address these shortcomings, we take a NeuroAI approach and draw inspiration from neural Reinforcement Learning to develop a derivative-free optimizer for training neural networks, Dopamine. Dopamine is developed for Weight Perturbation (WP) learning that exploits stochastic updating of weights towards optima. It achieves this by minimizing the regret, a form of Reward Prediction Error (RPE) between the expected outcome from the perturbed model and the actual outcome from the unperturbed model. We use this RPE to adjust the learning rate in the network (i.e., creating an adaptive learning rate strategy, similar to the role of dopamine in the brain). We tested the Dopamine optimizer for training multi-layered perceptrons for XOR tasks, and recurrent neural networks for chaotic time series forecasting. Dopamine-trained models demonstrate accelerated convergence and outperform standard WP, and give comparable performance to gradient-based algorithms, while consuming significantly less computation and memory. Overall, the Dopamine optimizer not only finds robust solutions and comparable performance to the state-of-the-art Machine Learning optimizers but is also neurobiologically more plausible.",
      "code_url": null
    },
    "2509.23896v2": {
      "title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence",
      "url": "http://arxiv.org/abs/2509.23896v2",
      "authors": "Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang",
      "update_time": "2025-10-09",
      "abstract": "NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",
      "code_url": null
    },
    "2507.06645v1": {
      "title": "Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers",
      "url": "http://arxiv.org/abs/2507.06645v1",
      "authors": "Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding",
      "update_time": "2025-07-09",
      "abstract": "Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as e.g. accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.",
      "code_url": null
    },
    "2507.02103v1": {
      "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
      "url": "http://arxiv.org/abs/2507.02103v1",
      "authors": "Daniel Durstewitz, Bruno Averbeck, Georgia Koppe",
      "update_time": "2025-07-02",
      "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
      "code_url": null
    },
    "2506.04536v3": {
      "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models",
      "url": "http://arxiv.org/abs/2506.04536v3",
      "authors": "Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar",
      "update_time": "2025-10-27",
      "abstract": "Characterizing the cellular properties of neurons is fundamental to understanding their function in the brain. In this quest, the generation of bio-realistic models is central towards integrating multimodal cellular data sets and establishing causal relationships. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. The deterministic formalism of bio-realistic models currently precludes accounting for the natural variability observed experimentally. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on synthetic data generated from bio-realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE enables the efficient generation of synthetic neurons that closely resemble experimental data and exhibit trial-to-trial variability, offering a $4200\\times$ speedup over the numerical solver. NOBLE is the first scaled-up deep learning framework that validates its generalization with real experimental data. To this end, NOBLE captures fundamental neural properties in a unique and emergent manner that opens the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.",
      "code_url": null
    },
    "2505.16080v1": {
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "url": "http://arxiv.org/abs/2505.16080v1",
      "authors": "Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang",
      "update_time": "2025-05-21",
      "abstract": "Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.",
      "code_url": null
    },
    "2502.16238v1": {
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "url": "http://arxiv.org/abs/2502.16238v1",
      "authors": "Jenelle Feather, Meenakshi Khosla, N. Apurva Ratan Murty, Aran Nayebi",
      "update_time": "2025-02-22",
      "abstract": "What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \\emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development.",
      "code_url": null
    },
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": null
    },
    "2411.18526v2": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v2",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias, Anthony Zador",
      "update_time": "2025-04-03",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety.",
      "code_url": null
    },
    "2411.14633v2": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v2",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2025-09-14",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research.",
      "code_url": null
    }
  },
  "medical": {
    "2511.03661v1": {
      "title": "SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection",
      "url": "http://arxiv.org/abs/2511.03661v1",
      "authors": "Mahek Desai, Apoorva Rumale, Marjan Asadinia",
      "update_time": "2025-11-05",
      "abstract": "The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.",
      "code_url": null
    },
    "2511.03656v1": {
      "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation",
      "url": "http://arxiv.org/abs/2511.03656v1",
      "authors": "Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng",
      "update_time": "2025-11-05",
      "abstract": "With the rapid advancement of natural language processing (NLP) technologies, the demand for high-quality Chinese document question-answering datasets is steadily growing. To address this issue, we present the Chinese Multi-Document Question Answering Dataset(ChiMDQA), specifically designed for downstream business scenarios across prevalent domains including academic, education, finance, law, medical treatment, and news. ChiMDQA encompasses long-form documents from six distinct fields, consisting of 6,068 rigorously curated, high-quality question-answer (QA) pairs further classified into ten fine-grained categories. Through meticulous document screening and a systematic question-design methodology, the dataset guarantees both diversity and high quality, rendering it applicable to various NLP tasks such as document comprehension, knowledge extraction, and intelligent QA systems. Additionally, this paper offers a comprehensive overview of the dataset's design objectives, construction methodologies, and fine-grained evaluation system, supplying a substantial foundation for future research and practical applications in Chinese QA. The code and data are available at: https://anonymous.4open.science/r/Foxit-CHiMDQA/.",
      "code_url": null
    },
    "2511.03542v1": {
      "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties",
      "url": "http://arxiv.org/abs/2511.03542v1",
      "authors": "Roberta Di Marino, Giovanni Dioguardi, Antonio Romano, Giuseppe Riccio, Mariano Barone, Marco Postiglione, Flora Amato, Vincenzo Moscato",
      "update_time": "2025-11-05",
      "abstract": "Medical question answering systems face deployment challenges including hallucinations, bias, computational demands, privacy concerns, and the need for specialized expertise across diverse domains. Here, we present SOLVE-Med, a multi-agent architecture combining domain-specialized small language models for complex medical queries. The system employs a Router Agent for dynamic specialist selection, ten specialized models (1B parameters each) fine-tuned on specific medical domains, and an Orchestrator Agent that synthesizes responses. Evaluated on Italian medical forum data across ten specialties, SOLVE-Med achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697, outperforming standalone models up to 14B parameters while enabling local deployment. Our code is publicly available on GitHub: https://github.com/PRAISELab-PicusLab/SOLVE-Med.",
      "code_url": null
    },
    "2511.03493v1": {
      "title": "Performance Evaluation of a Position-Sensitive SiPM-based Gamma Camera for Intraoperative Imaging",
      "url": "http://arxiv.org/abs/2511.03493v1",
      "authors": "Aramis Raiola, Fabio Acerbi, Cyril Alispach, Domenico della Volpe, Hossein Arabi, Alberto Gola, Habib Zaidi",
      "update_time": "2025-11-05",
      "abstract": "The POSiCS camera is a handheld, small field-of-view gamma camera developed for multipurpose use in radio-guided surgery (RGS), with sentinel lymph node biopsy (SLNB) as its benchmark application. This compact and lightweight detector (weighing approximately 350 g) can map tissues labeled with Tc-99m nanocolloids and guide surgeons to the location of target lesions. By enabling intraoperative visualization in close proximity to the surgical field, its primary objective is to minimize surgical interventional invasiveness and operative time, thereby enhancing localization accuracy and reducing the incidence of post-operative complications. The design and components of the POSiCS camera emphasize ergonomic handling and compactness, providing, at the same time, rapid image formation and a spatial resolution of a few millimeters. These features are compatible with routine operating-room workflow, including wireless communication with the computer and a real-time display to support surgeon decision-making.   The spatial resolution measured at a source-detector distance of 0 cm was 1.9 +/- 0.1 mm for the high-sensitivity mode and 1.4 +/- 0.1 mm for the high-resolution mode. The system sensitivity at 2 cm was evaluated as 481 +/- 14 cps/MBq (high sensitivity) and 134 +/- 8 cps/MBq (high resolution). For both working modes, we report an energy resolution of approximately 20 percent, even though the high-resolution collimator exhibits an increased scattered component due to the larger amount of tungsten.",
      "code_url": null
    },
    "2511.03441v1": {
      "title": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field",
      "url": "http://arxiv.org/abs/2511.03441v1",
      "authors": "Doria Bonzi, Alexandre Guiggi, Fr\u00e9d\u00e9ric B\u00e9chet, Carlos Ramisch, Benoit Favre",
      "update_time": "2025-11-05",
      "abstract": "Critical appraisal of scientific literature is an essential skill in the biomedical field. While large language models (LLMs) can offer promising support in this task, their reliability remains limited, particularly for critical reasoning in specialized domains. We introduce CareMedEval, an original dataset designed to evaluate LLMs on biomedical critical appraisal and reasoning tasks. Derived from authentic exams taken by French medical students, the dataset contains 534 questions based on 37 scientific articles. Unlike existing benchmarks, CareMedEval explicitly evaluates critical reading and reasoning grounded in scientific papers. Benchmarking state-of-the-art generalist and biomedical-specialized LLMs under various context conditions reveals the difficulty of the task: open and commercial models fail to exceed an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens considerably improves the results. Yet, models remain challenged especially on questions about study limitations and statistical analysis. CareMedEval provides a challenging benchmark for grounded reasoning, exposing current LLM limitations and paving the way for future development of automated support for critical appraisal.",
      "code_url": null
    },
    "2511.03328v1": {
      "title": "Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks",
      "url": "http://arxiv.org/abs/2511.03328v1",
      "authors": "Jindong Hong, Tianjie Chen, Lingjie Luo, Chuanyang Zheng, Ting Xu, Haibao Yu, Jianing Qiu, Qianzhong Chen, Suning Huang, Yan Xu, Yong Gui, Yijun He, Jiankai Sun",
      "update_time": "2025-11-05",
      "abstract": "A recent advancement in Multimodal Large Language Models (MLLMs) research is the emergence of \"reasoning MLLMs\" that offer explicit control over their internal thinking processes (normally referred as the \"thinking mode\") alongside the standard \"non-thinking mode\". This capability allows these models to engage in a step-by-step process of internal deliberation before generating a final response. With the rapid transition to and adoption of these \"dual-state\" MLLMs, this work rigorously evaluated how the enhanced reasoning processes of these MLLMs impact model performance and reliability in clinical tasks. This paper evaluates the active \"thinking mode\" capabilities of two leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We assessed their performance on four visual medical tasks using VQA-RAD and ROCOv2 datasets. Our findings reveal that the improvement from activating the thinking mode remains marginal compared to the standard non-thinking mode for the majority of the tasks. Their performance on complex medical tasks such as open-ended VQA and medical image interpretation remains suboptimal, highlighting the need for domain-specific medical data and more advanced methods for medical knowledge integration.",
      "code_url": null
    },
    "2511.03287v1": {
      "title": "Structural Stress as a Predictor of the Rate and Spatial Location of Aortic Growth in Uncomplicated Type B Aortic Dissection",
      "url": "http://arxiv.org/abs/2511.03287v1",
      "authors": "Yuhang Du, Yuxuan Wu, Hannah L. Cebull, Bangquan Liao, Rishika Agarwal, Alan Meraz, Hai Dong, Asanish Kalyanasundaram, John N. Oshinski, Rudolph L. Gleason Jr, John A. Elefteriades, Bradley G. Leshnower, Minliang Liu",
      "update_time": "2025-11-05",
      "abstract": "Accurate prediction of aortic expansion in uncomplicated type B aortic dissection (TBAD) can help identify patients who may benefit from timely thoracic endovascular aortic repair. This study investigates associations between biomechanical predictors derived from reduced-order fluid-structure interaction (FSI) analysis and aortic growth outcomes. Baseline and follow-up CT images from 30 patients with uncomplicated TBAD were obtained. For each patient, a reduced-order FSI analysis using the forward penalty stress computation method was performed on the baseline geometry. Aortic growth was quantified by registering baseline and follow-up surfaces using nonrigid registration. Mixed-effects linear and logistic regression analyses were performed to assess relationships between structural stress, wall shear stress (WSS), pressure and growth rate while accounting for inter-patient variability. Group comparison analyses were performed to evaluate spatial distributions of these biomechanical variables along the dissected aorta between patient groups categorized by optimal medical therapy (OMT) and aortic growth outcomes. Linear regression revealed a positive association between structural stress and aortic growth rate (p = 0.0003) and a negative association for WSS (p = 0.0227). Logistic regression yielded area under the receiver operator characteristic curve (AUCs) of 0.7414, 0.5953, 0.4991, and 0.6845 for structural stress, WSS, pressure, and aortic diameter, respectively. Group comparisons showed significant regional differences in structural stress, but not in diameter, WSS, or pressure, between groups defined by aortic growth and OMT outcomes. These results indicate that structural stress is a promising predictor of both the rate and location of aortic growth in uncomplicated TBAD, which supports its use in risk stratification models to identify patients at higher risk of TBAD progression.",
      "code_url": null
    },
    "2511.03260v1": {
      "title": "Enhancing Medical Image Segmentation via Heat Conduction Equation",
      "url": "http://arxiv.org/abs/2511.03260v1",
      "authors": "Rong Wu, Yim-Sang Yu",
      "update_time": "2025-11-05",
      "abstract": "Medical image segmentation has been significantly advanced by deep learning architectures, notably U-Net variants. However, existing models struggle to achieve efficient global context modeling and long-range dependency reasoning under practical computational budgets simultaneously. In this work, we propose a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation. Our model combines Mamba-based state-space modules for efficient long-range reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers, simulating frequency-domain thermal diffusion for enhanced semantic abstraction. Experimental results on multimodal abdominal CT and MRI datasets demonstrate that the proposed model consistently outperforms strong baselines, validating its effectiveness and generalizability. It suggest that blending state-space dynamics with heat-based global diffusion offers a scalable and interpretable solution for medical segmentation tasks.",
      "code_url": null
    },
    "2511.03255v1": {
      "title": "Generative deep learning for foundational video translation in ultrasound",
      "url": "http://arxiv.org/abs/2511.03255v1",
      "authors": "Nikolina Tomic Roshni Bhatnagar, Sarthak Jain, Connor Lau, Tien-Yu Liu, Laura Gambini, Rima Arnaout",
      "update_time": "2025-11-05",
      "abstract": "Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.",
      "code_url": null
    },
    "2511.03212v1": {
      "title": "MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction",
      "url": "http://arxiv.org/abs/2511.03212v1",
      "authors": "Ruting Cheng, Boyuan Feng, Yijiang Zheng, Chuhui Qiu, Aizierjiang Aiersilan, Joaquin A. Calderon, Wentao Zhao, Qing Pan, James K. Hahn",
      "update_time": "2025-11-05",
      "abstract": "Accurately assessing the risk of cesarean section (CS) delivery is critical, especially in settings with limited medical resources, where access to healthcare is often restricted. Early and reliable risk prediction allows better-informed prenatal care decisions and can improve maternal and neonatal outcomes. However, most existing predictive models are tailored for in-hospital use during labor and rely on parameters that are often unavailable in resource-limited or home-based settings. In this study, we conduct a pilot investigation to examine the feasibility of using 3D body shape for CS risk assessment for future applications with more affordable general devices. We propose a novel multi-view-based Transformer network, MvBody, which predicts CS risk using only self-reported medical data and 3D optical body scans obtained between the 31st and 38th weeks of gestation. To enhance training efficiency and model generalizability in data-scarce environments, we incorporate a metric learning loss into the network. Compared to widely used machine learning models and the latest advanced 3D analysis methods, our method demonstrates superior performance, achieving an accuracy of 84.62% and an Area Under the Receiver Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set. To improve transparency and trust in the model's predictions, we apply the Integrated Gradients algorithm to provide theoretically grounded explanations of the model's decision-making process. Our results indicate that pre-pregnancy weight, maternal age, obstetric history, previous CS history, and body shape, particularly around the head and shoulders, are key contributors to CS risk prediction.",
      "code_url": null
    }
  }
}