{
  "Brain": {
    "2508.12808v1": {
      "title": "Image Inpainting based on Visual-Neural-Inspired Specific Object-of-Interest Imaging Technology",
      "url": "http://arxiv.org/abs/2508.12808v1",
      "authors": "Yonghao Wu, Jun Li",
      "update_time": "2025-08-18",
      "abstract": "This study addresses the bottlenecks of conventional holistic image inpainting methods -- susceptibility to informational redundancy and low computational efficiency under occlusions and complex backgrounds -- by proposing a novel three-stage framework: \"Specific Object-of-Interest Imaging -- Coarse Structural imaging -- Fine Textural Refinement\". First, the Network with Object-Imaging Module (NOIM) precisely delineates target structures from degraded inputs while actively suppressing background interference. Subsequently, the Structural Recovery Module (SRM) employs multi-scale dilated convolutions and feature pyramid fusion to complete shape reconstruction from preliminary imaging. Finally, the Global Detail Refinement Module (GDRM) utilizes sub-pixel convolution with skip connections to map structural priors into high-fidelity RGB outputs. We design a triple-branch hybrid loss (weighted reconstruction, perceptual, and stylistic components) alongside a phased training strategy to enforce structural coherence, semantic consistency, and visual stylization. Experimental validation demonstrates competitive performance against state-of-the-art inpainting models across metrics including SSIM (0.978), PSNR (33.86 dB), MAE (1.605), and LPIPS (0.018), while maintaining robustness in extreme scenarios (low illumination, high noise, multi-object occlusion, motion blur). Theoretical analysis integrated with cognitive neuroscience perspectives reveals profound correlations between the \"object precedence perception\" mechanism and dynamic feature modulation in visual cortices (V1--V4). This approach not only achieves efficient and precise target-centric imaging but also pioneers interdisciplinary pathways bridging brain-inspired computational frameworks with advanced image inpainting techniques.",
      "code_url": null
    },
    "2508.12702v1": {
      "title": "A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance",
      "url": "http://arxiv.org/abs/2508.12702v1",
      "authors": "Jie Su, Weiwei Wang, Zhaotian Gu, Dahui Wang, Tianyi Qian",
      "update_time": "2025-08-18",
      "abstract": "Robust information representation and its persistent maintenance are fundamental for higher cognitive functions. Existing models employ distinct neural mechanisms to separately address noise-resistant processing or information maintenance, yet a unified framework integrating both operations remains elusive -- a critical gap in understanding cortical computation. Here, we introduce a recurrent neural circuit that combines divisive normalization with self-excitation to achieve both robust encoding and stable retention of normalized inputs. Mathematical analysis shows that, for suitable parameter regimes, the system forms a continuous attractor with two key properties: (1) input-proportional stabilization during stimulus presentation; and (2) self-sustained memory states persisting after stimulus offset. We demonstrate the model's versatility in two canonical tasks: (a) noise-robust encoding in a random-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief updating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work establishes a unified mathematical framework that bridges noise suppression, working memory, and approximate Bayesian inference within a single cortical microcircuit, offering fresh insights into the brain's canonical computation and guiding the design of biologically plausible artificial neural architectures.",
      "code_url": null
    },
    "2508.12670v1": {
      "title": "Discerning and quantifying high frequency activities in EEG under normal and epileptic conditions",
      "url": "http://arxiv.org/abs/2508.12670v1",
      "authors": "Jyotiraj Nath, Shreya Banerjee, Bhaswati Singha Deo, Mayukha Pal, Prasanta K. Panigrahi",
      "update_time": "2025-08-18",
      "abstract": "We investigate the nature of the modifications in the temporal dynamics manifested in the high-frequency EEG spectra of the normal human brain in comparison to the diseased brain undergoing epilepsy. For this purpose, the Fourier reconstruction is efficaciously made use of after Welch's transform, which helped identify the relevant frequency components undergoing significant changes in the case of epilepsy. The temporal dynamics involved in the EEG signals and their associated variations showed a well-structured periodic pattern characterized by bi-stability and significant quantifiable structural changes during epileptic episodes. In particular, we demonstrate and quantify the precise differences in the high-frequency gamma band (40-100 Hz) present in EEG recordings from neurologically normal participants compared to those with epilepsy. The periodic modulations at two dominant frequencies around 50 Hz and 76 Hz in power spectral density are isolated from high frequency noise through the use of Welch's transform, pinpointing their collective behaviors through a phase-space approach. The reconstructed signals from these restricted frequency domains revealed oscillatory motions showing a bi-stability and bi-furcations with distinct differences between normal and seizure conditions. These differences in the phase space images, when analyzed through linear regression and SVM-based machine learning models, support a classification accuracy of around 94-95% between healthy and ictal states using a publicly available EEG dataset from the University of Bonn (Germany). The partial reconstruction of the dynamics as compared to the earlier studies of the full phase space accurately pinpointed the destabilization of the collective high-frequency synchronous behavior and their precise differences in the normal and diseased conditions, avoiding the other chaotic components of the EEG signals.",
      "code_url": null
    },
    "2508.12640v1": {
      "title": "Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow",
      "url": "http://arxiv.org/abs/2508.12640v1",
      "authors": "Bastian Brandst\u00f6tter, Erich Kobler",
      "update_time": "2025-08-18",
      "abstract": "Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic diagnosis but requires gadolinium-based agents, which add cost and scan time, raise environmental concerns, and may pose risks to patients. In this work, we propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for synthesizing volumetric CE brain MRI from non-contrast inputs. First, a patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE). Then, this initial estimate is refined by a time-conditioned 3D rectified flow to incorporate realistic textures without compromising structural fidelity. We train this model on a multi-institutional collection of paired pre- and post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360 diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and KID of $0.007$ ($\\sim 68.7\\%$ lower FID than the posterior mean) while maintaining low volumetric MSE of $0.057$ ($\\sim 27\\%$ higher than the posterior mean). Qualitative comparisons confirm that our method restores lesion margins and vascular details realistically, effectively navigating the perception-distortion trade-off for clinical deployment.",
      "code_url": null
    },
    "2508.12571v1": {
      "title": "Cyber Risks to Next-Gen Brain-Computer Interfaces: Analysis and Recommendations",
      "url": "http://arxiv.org/abs/2508.12571v1",
      "authors": "Tyler Schroder, Renee Sirbu, Sohee Park, Jessica Morley, Sam Street, Luciano Floridi",
      "update_time": "2025-08-18",
      "abstract": "Brain-computer interfaces (BCIs) show enormous potential for advancing personalized medicine. However, BCIs also introduce new avenues for cyber-attacks or security compromises. In this article, we analyze the problem and make recommendations for device manufacturers to better secure devices and to help regulators understand where more guidance is needed to protect patient safety and data confidentiality. Device manufacturers should implement the prior suggestions in their BCI products. These recommendations help protect BCI users from undue risks, including compromised personal health and genetic information, unintended BCI-mediated movement, and many other cybersecurity breaches. Regulators should mandate non-surgical device update methods, strong authentication and authorization schemes for BCI software modifications, encryption of data moving to and from the brain, and minimize network connectivity where possible. We also design a hypothetical, average-case threat model that identifies possible cybersecurity threats to BCI patients and predicts the likeliness of risk for each category of threat. BCIs are at less risk of physical compromise or attack, but are vulnerable to remote attack; we focus on possible threats via network paths to BCIs and suggest technical controls to limit network connections.",
      "code_url": null
    },
    "2508.12533v1": {
      "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction",
      "url": "http://arxiv.org/abs/2508.12533v1",
      "authors": "Qinwen Ge, Roza G. Bayrak, Anwar Said, Catie Chang, Xenofon Koutsoukos, Tyler Derr",
      "update_time": "2025-08-17",
      "abstract": "The construction of brain graphs from functional Magnetic Resonance Imaging (fMRI) data plays a crucial role in enabling graph machine learning for neuroimaging. However, current practices often rely on rigid pipelines that overlook critical data-centric choices in how brain graphs are constructed. In this work, we adopt a Data-Centric AI perspective and systematically define and benchmark a data-centric design space for brain graph construction, constrasting with primarily model-centric prior work. We organize this design space into three stages: temporal signal processing, topology extraction, and graph featurization. Our contributions lie less in novel components and more in evaluating how combinations of existing and modified techniques influence downstream performance. Specifically, we study high-amplitude BOLD signal filtering, sparsification and unification strategies for connectivity, alternative correlation metrics, and multi-view node and edge features, such as incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets show that thoughtful data-centric configurations consistently improve classification accuracy over standard pipelines. These findings highlight the critical role of upstream data decisions and underscore the importance of systematically exploring the data-centric design space for graph-based neuroimaging. Our code is available at https://github.com/GeQinwen/DataCentricBrainGraphs.",
      "code_url": null
    },
    "2508.12508v1": {
      "title": "Segmenting Thalamic Nuclei: T1 Maps Provide a Reliable and Efficient Solution",
      "url": "http://arxiv.org/abs/2508.12508v1",
      "authors": "Anqi Feng, Zhangxing Bian, Samuel W. Remedios, Savannah P. Hays, Blake E. Dewey, Jiachen Zhuo, Dan Benjamini, Jerry L. Prince",
      "update_time": "2025-08-17",
      "abstract": "Accurate thalamic nuclei segmentation is crucial for understanding neurological diseases, brain functions, and guiding clinical interventions. However, the optimal inputs for segmentation remain unclear. This study systematically evaluates multiple MRI contrasts, including MPRAGE and FGATIR sequences, quantitative PD and T1 maps, and multiple T1-weighted images at different inversion times (multi-TI), to determine the most effective inputs. For multi-TI images, we employ a gradient-based saliency analysis with Monte Carlo dropout and propose an Overall Importance Score to select the images contributing most to segmentation. A 3D U-Net is trained on each of these configurations. Results show that T1 maps alone achieve strong quantitative performance and superior qualitative outcomes, while PD maps offer no added value. These findings underscore the value of T1 maps as a reliable and efficient input among the evaluated options, providing valuable guidance for optimizing imaging protocols when thalamic structures are of clinical or research interest.",
      "code_url": null
    },
    "2508.12483v1": {
      "title": "Simultaneous estimation of connectivity and dimensionality in samples of networks",
      "url": "http://arxiv.org/abs/2508.12483v1",
      "authors": "Wenlong Jiang, Chris McKennan, Jes\u00fas Arroyo, Joshua Cape",
      "update_time": "2025-08-17",
      "abstract": "An overarching objective in contemporary statistical network analysis is extracting salient information from datasets consisting of multiple networks. To date, considerable attention has been devoted to node and network clustering, while comparatively less attention has been devoted to downstream connectivity estimation and parsimonious embedding dimension selection. Given a sample of potentially heterogeneous networks, this paper proposes a method to simultaneously estimate a latent matrix of connectivity probabilities and its embedding dimensionality or rank after first pre-estimating the number of communities and the node community memberships. The method is formulated as a convex optimization problem and solved using an alternating direction method of multipliers algorithm. We establish estimation error bounds under the Frobenius norm and nuclear norm for settings in which observable networks have blockmodel structure, even when node memberships are imperfectly recovered. When perfect membership recovery is possible and dimensionality is much smaller than the number of communities, the proposed method outperforms conventional averaging-based methods for estimating connectivity and dimensionality. Numerical studies empirically demonstrate the accuracy of our method across various scenarios. Additionally, analysis of a primate brain dataset demonstrates that posited connectivity is not necessarily full rank in practice, illustrating the need for flexible methodology.",
      "code_url": null
    },
    "2508.12478v1": {
      "title": "An Iterative Bayesian Robbins--Monro Sequence",
      "url": "http://arxiv.org/abs/2508.12478v1",
      "authors": "Siwei Liu, Ke Ma, Stephan M. Goetz",
      "update_time": "2025-08-17",
      "abstract": "This study introduces an iterative Bayesian Robbins--Monro (IBRM) sequence, which unites the classical Robbins--Monro sequence with statistical estimation for faster root-finding under noisy observations. Although the standard Robbins--Monro method iteratively approaches solutions, its convergence speed is limited by noisy measurements and naivety to any prior information about the objective function. The proposed Bayesian sequence dynamically updates the prior distribution with newly obtained observations to accelerate convergence rates and robustness. The paper demonstrates almost sure convergence of the sequence and analyses its convergence rates for both one-dimensional and multi-dimensional problems. We evaluate the method in a practical application that suffers from large variability and allows only a few function evaluations, specifically estimating thresholds in noninvasive brain stimulation, where the method is more robust and accurate than conventional alternatives. Simulations involving 25,000 virtual subjects illustrate reduced error margins and decreased outlier frequency with direct impact on clinical use.",
      "code_url": null
    },
    "2508.12063v2": {
      "title": "Generalized invariants meet constitutive neural networks: A novel framework for hyperelastic materials",
      "url": "http://arxiv.org/abs/2508.12063v2",
      "authors": "Denisa Martonov\u00e1, Alain Goriely, Ellen Kuhl",
      "update_time": "2025-08-19",
      "abstract": "The major challenge in determining a hyperelastic model for a given material is the choice of invariants and the selection how the strain energy function depends functionally on these invariants. Here we introduce a new data-driven framework that simultaneously discovers appropriate invariants and constitutive models for isotropic incompressible hyperelastic materials. Our approach identifies both the most suitable invariants in a class of generalized invariants and the corresponding strain energy function directly from experimental observations. Unlike previous methods that rely on fixed invariant choices or sequential fitting procedures, our method integrates the discovery process into a single neural network architecture. By looking at a continuous family of possible invariants, the model can flexibly adapt to different material behaviors. We demonstrate the effectiveness of this approach using popular benchmark datasets for rubber and brain tissue. For rubber, the method recovers a stretch-dominated formulation consistent with classical models. For brain tissue, it identifies a formulation sensitive to small stretches, capturing the nonlinear shear response characteristic of soft biological matter. Compared to traditional and neural-network-based models, our framework provides improved predictive accuracy and interpretability across a wide range of deformation states. This unified strategy offers a robust tool for automated and physically meaningful model discovery in hyperelasticity.",
      "code_url": null
    }
  },
  "EEG": {
    "2508.12670v1": {
      "title": "Discerning and quantifying high frequency activities in EEG under normal and epileptic conditions",
      "url": "http://arxiv.org/abs/2508.12670v1",
      "authors": "Jyotiraj Nath, Shreya Banerjee, Bhaswati Singha Deo, Mayukha Pal, Prasanta K. Panigrahi",
      "update_time": "2025-08-18",
      "abstract": "We investigate the nature of the modifications in the temporal dynamics manifested in the high-frequency EEG spectra of the normal human brain in comparison to the diseased brain undergoing epilepsy. For this purpose, the Fourier reconstruction is efficaciously made use of after Welch's transform, which helped identify the relevant frequency components undergoing significant changes in the case of epilepsy. The temporal dynamics involved in the EEG signals and their associated variations showed a well-structured periodic pattern characterized by bi-stability and significant quantifiable structural changes during epileptic episodes. In particular, we demonstrate and quantify the precise differences in the high-frequency gamma band (40-100 Hz) present in EEG recordings from neurologically normal participants compared to those with epilepsy. The periodic modulations at two dominant frequencies around 50 Hz and 76 Hz in power spectral density are isolated from high frequency noise through the use of Welch's transform, pinpointing their collective behaviors through a phase-space approach. The reconstructed signals from these restricted frequency domains revealed oscillatory motions showing a bi-stability and bi-furcations with distinct differences between normal and seizure conditions. These differences in the phase space images, when analyzed through linear regression and SVM-based machine learning models, support a classification accuracy of around 94-95% between healthy and ictal states using a publicly available EEG dataset from the University of Bonn (Germany). The partial reconstruction of the dynamics as compared to the earlier studies of the full phase space accurately pinpointed the destabilization of the collective high-frequency synchronous behavior and their precise differences in the normal and diseased conditions, avoiding the other chaotic components of the EEG signals.",
      "code_url": null
    },
    "2508.11357v1": {
      "title": "PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding",
      "url": "http://arxiv.org/abs/2508.11357v1",
      "authors": "Changhong Jing, Yan Liu, Shuqiang Wang, Bruce X. B. Yu, Gong Chen, Zhejing Hu, Zhi Zhang, Yanyan Shen",
      "update_time": "2025-08-15",
      "abstract": "Cross-subject electroencephalography (EEG) decoding remains a fundamental challenge in brain-computer interface (BCI) research due to substantial inter-subject variability and the scarcity of subject-invariant representations. This paper proposed PTSM (Physiology-aware and Task-invariant Spatio-temporal Modeling), a novel framework for interpretable and robust EEG decoding across unseen subjects. PTSM employs a dual-branch masking mechanism that independently learns personalized and shared spatio-temporal patterns, enabling the model to preserve individual-specific neural characteristics while extracting task-relevant, population-shared features. The masks are factorized across temporal and spatial dimensions, allowing fine-grained modulation of dynamic EEG patterns with low computational overhead. To further address representational entanglement, PTSM enforces information-theoretic constraints that decompose latent embeddings into orthogonal task-related and subject-related subspaces. The model is trained end-to-end via a multi-objective loss integrating classification, contrastive, and disentanglement objectives. Extensive experiments on cross-subject motor imagery datasets demonstrate that PTSM achieves strong zero-shot generalization, outperforming state-of-the-art baselines without subject-specific calibration. Results highlight the efficacy of disentangled neural representations for achieving both personalized and transferable decoding in non-stationary neurophysiological settings.",
      "code_url": null
    },
    "2508.11312v1": {
      "title": "Repetitive TMS-based Identification of Methamphetamine-Dependent Individuals Using EEG Spectra",
      "url": "http://arxiv.org/abs/2508.11312v1",
      "authors": "Ziyi Zeng, Yun-Hsuan Chen, Xurong Gao, Wenyao Zheng, Hemmings Wu, Zhoule Zhu, Jie Yang, Chengkai Wang, Lihua Zhong, Weiwei Cheng, Mohamad Sawan",
      "update_time": "2025-08-15",
      "abstract": "The impact of repetitive transcranial magnetic stimulation (rTMS) on methamphetamine (METH) users' craving levels is often assessed using questionnaires. This study explores the feasibility of using neural signals to obtain more objective results. EEG signals recorded from 20 METH-addicted participants Before and After rTMS (MBT and MAT) and from 20 healthy participants (HC) are analyzed. In each EEG paradigm, participants are shown 15 METH-related and 15 neutral pictures randomly, and the relative band power (RBP) of each EEG sub-band frequency is derived. The average RBP across all 31 channels, as well as individual brain regions, is analyzed. Statistically, MAT's alpha, beta, and gamma RBPs are more like those of HC compared to MBT, as indicated by the power topographies. Utilizing a random forest (RF), the gamma RBP is identified as the optimal frequency band for distinguishing between MBT and HC with a 90% accuracy. The performance of classifying MAT versus HC is lower than that of MBT versus HC, suggesting that the efficacy of rTMS can be validated using RF with gamma RBP. Furthermore, the gamma RBP recorded by the TP10 and CP2 channels dominates the classification task of MBT versus HC when receiving METH-related image cues. The gamma RBP during exposure to METH-related cues can serve as a biomarker for distinguishing between MBT and HC and for evaluating the effectiveness of rTMS. Therefore, real-time monitoring of gamma RBP variations holds promise as a parameter for implementing a customized closed-loop neuromodulation system for treating METH addiction.",
      "code_url": null
    },
    "2508.10353v1": {
      "title": "Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG",
      "url": "http://arxiv.org/abs/2508.10353v1",
      "authors": "G. Kalyan Ramana, Sumit Yempalle, Prasad S. Onkar",
      "update_time": "2025-08-14",
      "abstract": "Conceptual design is a cognitively complex task, especially in the engineering design of products having relative motion between components. Designers prefer sketching as a medium for conceptual design and use gestures and annotations to represent such relative motion. Literature suggests that static representations of motion in sketches may not achieve the intended functionality when realised, because it primarily depends on the designers' mental capabilities for motion simulation. Thus, it is important to understand the cognitive phenomena when designers are exploring concepts of articulated products. The current work is an attempt to understand design neurocognition by categorising the tasks and measuring the mental effort involved in these tasks using EEG. The analysis is intended to validate design intervention tools to support the conceptual design involving motion exploration. A novel EEG-based metric, inter-Band Relative Power Difference (inter-BRPD), is introduced to quantify mental effort. A design experiment is conducted with 32 participants, where they have to perform one control task and 2 focus tasks corresponding to the motion exploration task (MET) and the concept generation task (CGT), respectively. EEG data is recorded during the 3 tasks, cleaned, processed and analysed using the MNE library in Python. It is observed from the results that inter-BRPD captures the essence of mental effort with half the number of conventionally used parameters. The reliability and efficacy of the inter-BRPD metric are also statistically validated against literature-based cognitive metrics. With these new insights, the study opens up possibilities for creating support for conceptual design and its evaluation.",
      "code_url": null
    },
    "2508.09402v1": {
      "title": "Realtime Multimodal Emotion Estimation using Behavioral and Neurophysiological Data",
      "url": "http://arxiv.org/abs/2508.09402v1",
      "authors": "Von Ralph Dane Marquez Herbuela, Yukie Nagai",
      "update_time": "2025-08-13",
      "abstract": "Many individuals especially those with autism spectrum disorder (ASD), alexithymia, or other neurodivergent profiles face challenges in recognizing, expressing, or interpreting emotions. To support more inclusive and personalized emotion technologies, we present a real-time multimodal emotion estimation system that combines neurophysiological EEG, ECG, blood volume pulse (BVP), and galvanic skin response (GSR/EDA) and behavioral modalities (facial expressions, and speech) in a unified arousal-valence 2D interface to track moment-to-moment emotional states. This architecture enables interpretable, user-specific analysis and supports applications in emotion education, neuroadaptive feedback, and interaction support for neurodiverse users. Two demonstration scenarios illustrate its application: (1) passive media viewing (2D or VR videos) reveals cortical and autonomic responses to affective content, and (2) semi-scripted conversations with a facilitator or virtual agent capture real-time facial and vocal expressions. These tasks enable controlled and naturalistic emotion monitoring, making the system well-suited for personalized feedback and neurodiversity-informed interaction design.",
      "code_url": null
    },
    "2508.10057v1": {
      "title": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning",
      "url": "http://arxiv.org/abs/2508.10057v1",
      "authors": "Christopher Pinier, Sonia Acu\u00f1a Vargas, Mariia Steeghs-Turchina, Dora Matzke, Claire E. Stevenson, Michael D. Nunez",
      "update_time": "2025-08-12",
      "abstract": "This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.",
      "code_url": null
    },
    "2508.11691v1": {
      "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception",
      "url": "http://arxiv.org/abs/2508.11691v1",
      "authors": "Mathis Rezzouk, Fabrice Gagnon, Alyson Champagne, Mathieu Roy, Philippe Albouy, Michel-Pierre Coll, Cem Subakan",
      "update_time": "2025-08-12",
      "abstract": "EEG-based analysis of pain perception, enhanced by machine learning, reveals how the brain encodes pain by identifying neural patterns evoked by noxious stimulation. However, a major challenge that remains is the generalization of machine learning models across individuals, given the high cross-participant variability inherent to EEG signals and the limited focus on direct pain perception identification in current research. In this study, we systematically evaluate the performance of cross-participant generalization of a wide range of models, including traditional classifiers and deep neural classifiers for identifying the sensory modality of thermal pain and aversive auditory stimulation from EEG recordings. Using a novel dataset of EEG recordings from 108 participants, we benchmark model performance under both within- and cross-participant evaluation settings. Our findings show that traditional models suffered the largest drop from within- to cross-participant performance, while deep learning models proved more resilient, underscoring their potential for subject-invariant EEG decoding. Even though performance variability remained high, the strong results of the graph-based model highlight its potential to capture subject-invariant structure in EEG signals. On the other hand, we also share the preprocessed dataset used in this study, providing a standardized benchmark for evaluating future algorithms under the same generalization constraints.",
      "code_url": null
    },
    "2508.08724v1": {
      "title": "Hierarchical Variable Importance with Statistical Control for Medical Data-Based Prediction",
      "url": "http://arxiv.org/abs/2508.08724v1",
      "authors": "Joseph Paillard, Antoine Collas, Denis A. Engemann, Bertrand Thirion",
      "update_time": "2025-08-12",
      "abstract": "Recent advances in machine learning have greatly expanded the repertoire of predictive methods for medical imaging. However, the interpretability of complex models remains a challenge, which limits their utility in medical applications. Recently, model-agnostic methods have been proposed to measure conditional variable importance and accommodate complex non-linear models. However, they often lack power when dealing with highly correlated data, a common problem in medical imaging. We introduce Hierarchical-CPI, a model-agnostic variable importance measure that frames the inference problem as the discovery of groups of variables that are jointly predictive of the outcome. By exploring subgroups along a hierarchical tree, it remains computationally tractable, yet also enjoys explicit family-wise error rate control. Moreover, we address the issue of vanishing conditional importance under high correlation with a tree-based importance allocation mechanism. We benchmarked Hierarchical-CPI against state-of-the-art variable importance methods. Its effectiveness is demonstrated in two neuroimaging datasets: classifying dementia diagnoses from MRI data (ADNI dataset) and analyzing the Berger effect on EEG data (TDBRAIN dataset), identifying biologically plausible variables.",
      "code_url": null
    },
    "2508.08602v1": {
      "title": "Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks",
      "url": "http://arxiv.org/abs/2508.08602v1",
      "authors": "Justin London",
      "update_time": "2025-08-12",
      "abstract": "Biomedical signal processing extract meaningful information from physiological signals like electrocardiograms (ECGs), electroencephalograms (EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical conditions and diseases such as seizures, cardiomyopathy, and neuromuscular disorders, respectively. Traditional manual physician analysis of electrical recordings is prone to human error as subtle anomolies may not be detected. Recently, advanced deep learning has significantly improved the accuracy of biomedical signal analysis. A multi-modal deep learning model is proposed that utilizes discrete wavelet transforms for signal pre-processing to reduce noise. A multi-modal image fusion and multimodal feature fusion framework is utilized that converts numeric biomedical signals into 2D and 3D images for image processing using Gramian angular fields, recurrency plots, and Markov transition fields. In this paper, deep learning models are applied to ECG, EEG, and human activity signals using actual medical datasets, brain, and heart recordings. The results demonstrate that using a multi-modal approach using wavelet transforms improves the accuracy of disease and disorder classification.",
      "code_url": null
    },
    "2508.08216v1": {
      "title": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion",
      "url": "http://arxiv.org/abs/2508.08216v1",
      "authors": "Nicole Lai-Tan, Xiao Gu, Marios G. Philiastides, Fani Deligianni",
      "update_time": "2025-08-11",
      "abstract": "Personalised music-based interventions offer a powerful means of supporting motor rehabilitation by dynamically tailoring auditory stimuli to provide external timekeeping cues, modulate affective states, and stabilise gait patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for adapting these interventions across individuals. However, inter-subject variability in EEG signals, further compounded by movement-induced artefacts and motor planning differences, hinders the generalisability of BCIs and results in lengthy calibration processes. We propose Individual Tangent Space Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific recentering, distribution matching, and supervised rotational alignment to enhance cross-subject generalisation. Our hybrid architecture fuses Regularised Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and sequential configurations, improving class separability while maintaining the geometric structure of covariance matrices for robust statistical computation. Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant performance improvements across subjects and conditions. The parallel fusion approach shows the greatest enhancement over its sequential counterpart, with robust performance maintained across varying data conditions and electrode configurations. The code will be made publicly available at the time of publication.",
      "code_url": null
    }
  },
  "BCI": {
    "2508.12571v1": {
      "title": "Cyber Risks to Next-Gen Brain-Computer Interfaces: Analysis and Recommendations",
      "url": "http://arxiv.org/abs/2508.12571v1",
      "authors": "Tyler Schroder, Renee Sirbu, Sohee Park, Jessica Morley, Sam Street, Luciano Floridi",
      "update_time": "2025-08-18",
      "abstract": "Brain-computer interfaces (BCIs) show enormous potential for advancing personalized medicine. However, BCIs also introduce new avenues for cyber-attacks or security compromises. In this article, we analyze the problem and make recommendations for device manufacturers to better secure devices and to help regulators understand where more guidance is needed to protect patient safety and data confidentiality. Device manufacturers should implement the prior suggestions in their BCI products. These recommendations help protect BCI users from undue risks, including compromised personal health and genetic information, unintended BCI-mediated movement, and many other cybersecurity breaches. Regulators should mandate non-surgical device update methods, strong authentication and authorization schemes for BCI software modifications, encryption of data moving to and from the brain, and minimize network connectivity where possible. We also design a hypothetical, average-case threat model that identifies possible cybersecurity threats to BCI patients and predicts the likeliness of risk for each category of threat. BCIs are at less risk of physical compromise or attack, but are vulnerable to remote attack; we focus on possible threats via network paths to BCIs and suggest technical controls to limit network connections.",
      "code_url": null
    },
    "2508.12040v1": {
      "title": "Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation",
      "url": "http://arxiv.org/abs/2508.12040v1",
      "authors": "Jinyi Han, Tingyun Li, Shisong Chen, Jie Shi, Xinyi Wang, Guanglei Yue, Jiaqing Liang, Xin Lin, Liqian Wen, Zulong Chen, Yanghua Xiao",
      "update_time": "2025-08-16",
      "abstract": "While large language models (LLMs) have demonstrated remarkable performance across diverse tasks, they fundamentally lack self-awareness and frequently exhibit overconfidence, assigning high confidence scores to incorrect predictions. Accurate confidence estimation is therefore critical for enhancing the trustworthiness and reliability of LLM-generated outputs. However, existing approaches suffer from coarse-grained scoring mechanisms that fail to provide fine-grained, continuous confidence estimates throughout the generation process. To address these limitations, we introduce FineCE, a novel confidence estimation method that delivers accurate, fine-grained confidence scores during text generation. Specifically, we first develop a comprehensive pipeline for constructing training data that effectively captures the underlying probabilistic distribution of LLM responses, and then train a model to predict confidence scores for arbitrary text sequences in a supervised manner. Furthermore, we propose a Backward Confidence Integration (BCI) strategy that leverages information from the subsequent text to enhance confidence estimation for the current sequence during inference. We also introduce three strategies for identifying optimal positions to perform confidence estimation within the generation process. Extensive experiments on multiple benchmark datasets demonstrate that FineCE consistently outperforms existing classical confidence estimation methods. Our code and all baselines used in the paper are available on GitHub.",
      "code_url": null
    },
    "2508.11805v1": {
      "title": "Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface",
      "url": "http://arxiv.org/abs/2508.11805v1",
      "authors": "Xinyun Zou, Jorge Gamez, Meghna Menon, Phillip Ring, Chadwick Boulay, Likhith Chitneni, Jackson Brennecke, Shana R. Melby, Gracy Kureel, Kelsie Pejsa, Emily R. Rosario, Ausaf A. Bari, Aniruddh Ravindran, Tyson Aflalo, Spencer S. Kellis, Dimitar Filev, Florian Solzbacher, Richard A. Andersen",
      "update_time": "2025-08-15",
      "abstract": "Brain-computer interfaces (BCIs) read neural signals directly from the brain to infer motor planning and execution. However, the implementation of this technology has been largely limited to laboratory settings, with few real-world applications. We developed a bimanual BCI system to drive a vehicle in both simulated and real-world environments. We demonstrate that an individual with tetraplegia, implanted with intracortical BCI electrodes in the posterior parietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts at least as fast and precisely as motor intact participants, and drives a simulated vehicle as proficiently as the same control group. This BCI participant, living in California, could also remotely drive a Ford Mustang Mach-E vehicle in Michigan. Our first teledriving task relied on cursor control for speed and steering in a closed urban test facility. However, the final BCI system added click control for full-stop braking and thus enabled bimanual cursor-and-click control for both simulated driving through a virtual town with traffic and teledriving through an obstacle course without traffic in the real world. We also demonstrate the safety and feasibility of BCI-controlled driving. This first-of-its-kind implantable BCI application not only highlights the versatility and innovative potentials of BCIs but also illuminates the promising future for the development of life-changing solutions to restore independence to those who suffer catastrophic neurological injury.",
      "code_url": null
    },
    "2508.11357v1": {
      "title": "PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding",
      "url": "http://arxiv.org/abs/2508.11357v1",
      "authors": "Changhong Jing, Yan Liu, Shuqiang Wang, Bruce X. B. Yu, Gong Chen, Zhejing Hu, Zhi Zhang, Yanyan Shen",
      "update_time": "2025-08-15",
      "abstract": "Cross-subject electroencephalography (EEG) decoding remains a fundamental challenge in brain-computer interface (BCI) research due to substantial inter-subject variability and the scarcity of subject-invariant representations. This paper proposed PTSM (Physiology-aware and Task-invariant Spatio-temporal Modeling), a novel framework for interpretable and robust EEG decoding across unseen subjects. PTSM employs a dual-branch masking mechanism that independently learns personalized and shared spatio-temporal patterns, enabling the model to preserve individual-specific neural characteristics while extracting task-relevant, population-shared features. The masks are factorized across temporal and spatial dimensions, allowing fine-grained modulation of dynamic EEG patterns with low computational overhead. To further address representational entanglement, PTSM enforces information-theoretic constraints that decompose latent embeddings into orthogonal task-related and subject-related subspaces. The model is trained end-to-end via a multi-objective loss integrating classification, contrastive, and disentanglement objectives. Extensive experiments on cross-subject motor imagery datasets demonstrate that PTSM achieves strong zero-shot generalization, outperforming state-of-the-art baselines without subject-specific calibration. Results highlight the efficacy of disentangled neural representations for achieving both personalized and transferable decoding in non-stationary neurophysiological settings.",
      "code_url": null
    },
    "2508.10510v1": {
      "title": "Codes on any Cayley Graph have an Interactive Oracle Proof of Proximity",
      "url": "http://arxiv.org/abs/2508.10510v1",
      "authors": "Hugo Delavenne, Louise Lallemand",
      "update_time": "2025-08-14",
      "abstract": "Interactive Oracle Proofs of Proximity (IOPP) are at the heart of code-based SNARKs, a family of zeroknowledge protocols. The first and most famous one is the FRI protocol [BBHR18a], that efficiently tests proximity to Reed-Solomon codes. This paper generalizes the flowering IOPP introduced in [DMR25] for some specific (2, n)-regular Tanner codes to a much broader variety of codes: any code with symbols indexed on the edges of a Cayley graph. The flowering protocol of [DMR25] had a soundness parameter much lower than the FRI protocol [BCI + 23], and complexity parameters that could compete with the FRI [BBHR18a]. The lower soundness and the absence of restriction on the base field may lead to other practical speedups, however the codes considered in [DMR25] have an o(1) minimum distance. The generalization proposed in this paper preserves the soundness parameter with a slight decrease of the complexity parameters, while allowing being applied on codes with constant rate and constant minimum distance thanks to the good expansion properties of some families of Cayley graphs.",
      "code_url": null
    },
    "2508.10474v1": {
      "title": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation",
      "url": "http://arxiv.org/abs/2508.10474v1",
      "authors": "Lisa Haxel, Jaivardhan Kapoor, Ulf Ziemann, Jakob H. Macke",
      "update_time": "2025-08-14",
      "abstract": "Brain-computer interfaces (BCIs) suffer from accuracy degradation as neural signals drift over time and vary across users, requiring frequent recalibration that limits practical deployment. We introduce EDAPT, a task- and model-agnostic framework that eliminates calibration through continual model adaptation. EDAPT first trains a baseline decoder using data from multiple users, then continually personalizes this model via supervised finetuning as the neural patterns evolve during use. We tested EDAPT across nine datasets covering three BCI tasks, and found that it consistently improved accuracy over conventional, static methods. These improvements primarily stem from combining population-level pretraining and online continual finetuning, with unsupervised domain adaptation providing further gains on some datasets. EDAPT runs efficiently, updating models within 200 milliseconds on consumer-grade hardware. Finally, decoding accuracy scales with total data budget rather than its allocation between subjects and trials. EDAPT provides a practical pathway toward calibration-free BCIs, reducing a major barrier to BCI deployment.",
      "code_url": null
    },
    "2508.09242v1": {
      "title": "Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications",
      "url": "http://arxiv.org/abs/2508.09242v1",
      "authors": "Gaojie Zhou, Junhua Li",
      "update_time": "2025-08-12",
      "abstract": "Classification models used in brain-computer interface (BCI) are usually designed for a single BCI paradigm. This requires the redevelopment of the model when applying it to a new BCI paradigm, resulting in repeated costs and effort. Moreover, less complex deep learning models are desired for practical usage, as well as for deployment on portable devices. In or-der to fill the above gaps, we, in this study, proposed a light-weight and unified decoding model for cross-BCI-paradigm classification. The proposed model starts with a tempo-spatial convolution. It is followed by a multi-scale local feature selec-tion module, aiming to extract local features shared across BCI paradigms and generate weighted features. Finally, a mul-ti-dimensional global feature extraction module is designed, in which multi-dimensional global features are extracted from the weighted features and fused with the weighted features to form high-level feature representations associated with BCI para-digms. The results, evaluated on a mixture of three classical BCI paradigms (i.e., MI, SSVEP, and P300), demon-strate that the proposed model achieves 88.39%, 82.36%, 80.01%, and 0.8092 for accuracy, macro-precision, mac-ro-recall, and macro-F1-score, respectively, significantly out-performing the compared models. This study pro-vides a feasible solution for cross-BCI-paradigm classifica-tion. It lays a technological foundation for de-veloping a new generation of unified decoding systems, paving the way for low-cost and universal practical applications.",
      "code_url": null
    },
    "2508.08763v1": {
      "title": "Quantifying the direct and indirect impact of COVID-19 vaccination: evidence from Victoria, Australia",
      "url": "http://arxiv.org/abs/2508.08763v1",
      "authors": "Lixin Lin, Haydar Demirhan, Peter Eizenberg, James M. Trauer, Lewi Stone",
      "update_time": "2025-08-12",
      "abstract": "Vaccines not only directly protect vaccinated individuals but also contribute to protect the entire population via indirect herd-immunity benefits. However, researchers have long struggled to quantify these indirect effects at the population level, hindering assessment of vaccination program effectiveness. We developed a new method to estimate these effects, thereby markedly improving measures of the number of infections, hospitalizations, and deaths averted by vaccination. Our population-based analysis of 6,440,000 residents of Victoria, Australia reveal strong indirect effects during the Delta outbreak (September-November 2021). By modelling a non-vaccination counterfactual, we conservatively estimate 316,000 infections were averted (95\\% BCI: 232k-406k), as well as 33,500 hospitalizations (95\\% BCI: 22.2k-46.2k), and 4,900 deaths (95\\% BCI: 2.9k-7.3k). These are 4.0, 7.5, and 8.0 times higher, respectively, than observed. Half of the averted infections and around one-quarter of hospitalizations and deaths were attributable to indirect protection. Homogeneous vaccination across LGAs could have reduced outcomes by approximately 25\\%.",
      "code_url": null
    },
    "2508.08681v1": {
      "title": "Multi-dimensional Neural Decoding with Orthogonal Representations for Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2508.08681v1",
      "authors": "Kaixi Tian, Shengjia Zhao, Yuhan Zhang, Shan Yu",
      "update_time": "2025-08-12",
      "abstract": "Current brain-computer interfaces primarily decode single motor variables, limiting their ability to support natural, high-bandwidth neural control that requires simultaneous extraction of multiple correlated motor dimensions. We introduce Multi-dimensional Neural Decoding (MND), a task formulation that simultaneously extracts multiple motor variables (direction, position, velocity, acceleration) from single neural population recordings. MND faces two key challenges: cross-task interference when decoding correlated motor dimensions from shared cortical representations, and generalization issues across sessions, subjects, and paradigms. To address these challenges, we propose OrthoSchema, a multi-task framework inspired by cortical orthogonal subspace organization and cognitive schema reuse. OrthoSchema enforces representation orthogonality to eliminate cross-task interference and employs selective feature reuse transfer for few-shot cross-session, subject and paradigm adaptation. Experiments on macaque motor cortex datasets demonstrate that OrthoSchema significantly improves decoding accuracy in cross-session, cross-subject and challenging cross-paradigm generalization tasks, with larger performance improvements when fine-tuning samples are limited. Ablation studies confirm the synergistic effects of all components are crucial, with OrthoSchema effectively modeling cross-task features and capturing session relationships for robust transfer. Our results provide new insights into scalable and robust neural decoding for real-world BCI applications.",
      "code_url": null
    },
    "2508.08216v1": {
      "title": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion",
      "url": "http://arxiv.org/abs/2508.08216v1",
      "authors": "Nicole Lai-Tan, Xiao Gu, Marios G. Philiastides, Fani Deligianni",
      "update_time": "2025-08-11",
      "abstract": "Personalised music-based interventions offer a powerful means of supporting motor rehabilitation by dynamically tailoring auditory stimuli to provide external timekeeping cues, modulate affective states, and stabilise gait patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for adapting these interventions across individuals. However, inter-subject variability in EEG signals, further compounded by movement-induced artefacts and motor planning differences, hinders the generalisability of BCIs and results in lengthy calibration processes. We propose Individual Tangent Space Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific recentering, distribution matching, and supervised rotational alignment to enhance cross-subject generalisation. Our hybrid architecture fuses Regularised Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and sequential configurations, improving class separability while maintaining the geometric structure of covariance matrices for robust statistical computation. Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant performance improvements across subjects and conditions. The parallel fusion approach shows the greatest enhancement over its sequential counterpart, with robust performance maintained across varying data conditions and electrode configurations. The code will be made publicly available at the time of publication.",
      "code_url": null
    }
  },
  "fMRI": {
    "2508.12533v1": {
      "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction",
      "url": "http://arxiv.org/abs/2508.12533v1",
      "authors": "Qinwen Ge, Roza G. Bayrak, Anwar Said, Catie Chang, Xenofon Koutsoukos, Tyler Derr",
      "update_time": "2025-08-17",
      "abstract": "The construction of brain graphs from functional Magnetic Resonance Imaging (fMRI) data plays a crucial role in enabling graph machine learning for neuroimaging. However, current practices often rely on rigid pipelines that overlook critical data-centric choices in how brain graphs are constructed. In this work, we adopt a Data-Centric AI perspective and systematically define and benchmark a data-centric design space for brain graph construction, constrasting with primarily model-centric prior work. We organize this design space into three stages: temporal signal processing, topology extraction, and graph featurization. Our contributions lie less in novel components and more in evaluating how combinations of existing and modified techniques influence downstream performance. Specifically, we study high-amplitude BOLD signal filtering, sparsification and unification strategies for connectivity, alternative correlation metrics, and multi-view node and edge features, such as incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets show that thoughtful data-centric configurations consistently improve classification accuracy over standard pipelines. These findings highlight the critical role of upstream data decisions and underscore the importance of systematically exploring the data-centric design space for graph-based neuroimaging. Our code is available at https://github.com/GeQinwen/DataCentricBrainGraphs.",
      "code_url": null
    },
    "2508.11920v1": {
      "title": "A Wavelet-Based Framework for Mapping Long Memory in Resting-State fMRI: Age-Related Changes in the Hippocampus from the ADHD-200 Dataset",
      "url": "http://arxiv.org/abs/2508.11920v1",
      "authors": "Yasaman Shahhosseini, C\u00e9dric Beaulac, Farouk S. Nathoo, Michelle F. Miranda",
      "update_time": "2025-08-16",
      "abstract": "Functional magnetic resonance imaging (fMRI) time series are known to exhibit long-range temporal dependencies that challenge traditional modeling approaches. In this study, we propose a novel computational pipeline to characterize and interpret these dependencies using a long-memory (LM) framework, which captures the slow, power-law decay of autocorrelation in resting-state fMRI (rs-fMRI) signals. The pipeline involves voxelwise estimation of LM parameters via a wavelet-based Bayesian method, yielding spatial maps that reflect temporal dependence across the brain. These maps are then projected onto a lower-dimensional space via a composite basis and are then related to individual-level covariates through group-level regression. We applied this approach to the ADHD-200 dataset and found significant positive associations between age in children and the LM parameter in the hippocampus, after adjusting for ADHD symptom severity and medication status. These findings complement prior neuroimaging work by linking long-range temporal dependence to developmental changes in memory-related brain regions. Overall, the proposed methodology enables detailed mapping of intrinsic temporal dynamics in rs-fMRI and offers new insights into the relationship between functional signal memory and brain development.",
      "code_url": null
    },
    "2508.11536v1": {
      "title": "Language models align with brain regions that represent concepts across modalities",
      "url": "http://arxiv.org/abs/2508.11536v1",
      "authors": "Maria Ryskina, Greta Tuckute, Alexander Fung, Ashley Malkin, Evelina Fedorenko",
      "update_time": "2025-08-15",
      "abstract": "Cognitive science and neuroscience have long faced the challenge of disentangling representations of language from representations of conceptual meaning. As the same problem arises in today's language models (LMs), we investigate the relationship between LM--brain alignment and two neural metrics: (1) the level of brain activation during processing of sentences, targeting linguistic processing, and (2) a novel measure of meaning consistency across input modalities, which quantifies how consistently a brain region responds to the same concept across paradigms (sentence, word cloud, image) using an fMRI dataset (Pereira et al., 2018). Our experiments show that both language-only and language-vision models predict the signal better in more meaning-consistent areas of the brain, even when these areas are not strongly sensitive to language processing, suggesting that LMs might internally represent cross-modal conceptual meaning.",
      "code_url": null
    },
    "2508.11732v1": {
      "title": "BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification",
      "url": "http://arxiv.org/abs/2508.11732v1",
      "authors": "Xiangxiang Cui, Min Zhao, Dongmei Zhi, Shile Qi, Vince D Calhoun, Jing Sui",
      "update_time": "2025-08-15",
      "abstract": "Existing deep learning models for functional MRI-based classification have limitations in network architecture determination (relying on experience) and feature space fusion (mostly simple concatenation, lacking mutual learning). Inspired by the human brain's mechanism of updating neural connections through learning and decision-making, we proposed a novel BRain-Inspired feature Fusion (BRIEF) framework, which is able to optimize network architecture automatically by incorporating an improved neural network connection search (NCS) strategy and a Transformer-based multi-feature fusion module. Specifically, we first extracted 4 types of fMRI temporal representations, i.e., time series (TCs), static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion entropy (MsDE), to construct four encoders. Within each encoder, we employed a modified Q-learning to dynamically optimize the NCS to extract high-level feature vectors, where the NCS is formulated as a Markov Decision Process. Then, all feature vectors were fused via a Transformer, leveraging both stable/time-varying connections and multi-scale dependencies across different brain regions to achieve the final classification. Additionally, an attention module was embedded to improve interpretability. The classification performance of our proposed BRIEF was compared with 21 state-of-the-art models by discriminating two mental disorders from healthy controls: schizophrenia (SZ, n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is the first attempt to incorporate a brain-inspired, reinforcement learning strategy to optimize fMRI-based mental disorder classification, showing significant potential for identifying precise neuroimaging biomarkers.",
      "code_url": null
    },
    "2508.11213v1": {
      "title": "Estimating Covariate Effects on Functional Connectivity using Voxel-Level fMRI Data",
      "url": "http://arxiv.org/abs/2508.11213v1",
      "authors": "Wei Zhao, Brian J. Reich, Emily C. Hector",
      "update_time": "2025-08-15",
      "abstract": "Functional connectivity (FC) analysis of resting-state fMRI data provides a framework for characterizing brain networks and their association with participant-level covariates. Due to the high dimensionality of neuroimaging data, standard approaches often average signals within regions of interest (ROIs), which ignores the underlying spatiotemporal dependence among voxels and can lead to biased or inefficient inference. We propose to use a summary statistic -- the empirical voxel-wise correlations between ROIs -- and, crucially, model the complex covariance structure among these correlations through a new positive definite covariance function. Building on this foundation, we develop a computationally efficient two-step estimation procedure that enables statistical inference on covariate effects on region-level connectivity. Simulation studies show calibrated uncertainty quantification, and substantial gains in validity of the statistical inference over the standard averaging method. With data from the Autism Brain Imaging Data Exchange, we show that autism spectrum disorder is associated with altered FC between attention-related ROIs after adjusting for age and gender. The proposed framework offers an interpretable and statistically rigorous approach to estimation of covariate effects on FC suitable for large-scale neuroimaging studies.",
      "code_url": null
    },
    "2508.10784v1": {
      "title": "Insights from the Algonauts 2025 Winners",
      "url": "http://arxiv.org/abs/2508.10784v1",
      "authors": "Paul S. Scotti, Mihir Tripathy",
      "update_time": "2025-08-14",
      "abstract": "The Algonauts 2025 Challenge just wrapped up a few weeks ago. It is a biennial challenge in computational neuroscience in which teams attempt to build models that predict human brain activity from carefully curated stimuli. Previous editions (2019, 2021, 2023) focused on still images and short videos; the 2025 edition, which concluded last month (late July), pushed the field further by using long, multimodal movies. Teams were tasked with predicting fMRI responses across 1,000 whole-brain parcels across four participants in the dataset who were scanned while watching nearly 80 hours of naturalistic movie stimuli. These recordings came from the CNeuroMod project and included 65 hours of training data, about 55 hours of Friends (seasons 1-6) plus four feature films (The Bourne Supremacy, Hidden Figures, Life, and The Wolf of Wall Street). The remaining data were used for validation: Season 7 of Friends for in-distribution tests, and the final winners for the Challenge were those who could best predict brain activity for six films in their held-out out-of-distribution (OOD) set. The winners were just announced and the top team reports are now publicly available. As members of the MedARC team which placed 4th in the competition, we reflect on the approaches that worked, what they reveal about the current state of brain encoding, and what might come next.",
      "code_url": null
    },
    "2508.10298v2": {
      "title": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning",
      "url": "http://arxiv.org/abs/2508.10298v2",
      "authors": "Weijian Mai, Jiamin Wu, Yu Zhu, Zhouheng Yao, Dongzhan Zhou, Andrew F. Luo, Qihao Zheng, Wanli Ouyang, Chunfeng Song",
      "update_time": "2025-08-15",
      "abstract": "Deciphering how visual stimuli are transformed into cortical responses is a fundamental challenge in computational neuroscience. This visual-to-neural mapping is inherently a one-to-many relationship, as identical visual inputs reliably evoke variable hemodynamic responses across trials, contexts, and subjects. However, existing deterministic methods struggle to simultaneously model this biological variability while capturing the underlying functional consistency that encodes stimulus information. To address these limitations, we propose SynBrain, a generative framework that simulates the transformation from visual semantics to neural responses in a probabilistic and biologically interpretable manner. SynBrain introduces two key components: (i) BrainVAE models neural representations as continuous probability distributions via probabilistic learning while maintaining functional consistency through visual semantic constraints; (ii) A Semantic-to-Neural Mapper acts as a semantic transmission pathway, projecting visual semantics into the neural response manifold to facilitate high-fidelity fMRI synthesis. Experimental results demonstrate that SynBrain surpasses state-of-the-art methods in subject-specific visual-to-fMRI encoding performance. Furthermore, SynBrain adapts efficiently to new subjects with few-shot data and synthesizes high-quality fMRI signals that are effective in improving data-limited fMRI-to-image decoding performance. Beyond that, SynBrain reveals functional consistency across trials and subjects, with synthesized signals capturing interpretable patterns shaped by biological neural variability. The code will be made publicly available.",
      "code_url": null
    },
    "2508.07106v1": {
      "title": "BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation",
      "url": "http://arxiv.org/abs/2508.07106v1",
      "authors": "Yiran Huang, Amirhossein Nouranizadeh, Christine Ahrends, Mengjia Xu",
      "update_time": "2025-08-09",
      "abstract": "Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely used to study human brain activity. fMRI signals in areas across the brain transiently synchronise and desynchronise their activity in a highly structured manner, even when an individual is at rest. These functional connectivity dynamics may be related to behaviour and neuropsychiatric disease. To model these dynamics, temporal brain connectivity representations are essential, as they reflect evolving interactions between brain regions and provide insight into transient neural states and network reconfigurations. However, conventional graph neural networks (GNNs) often struggle to capture long-range temporal dependencies in dynamic fMRI data. To address this challenge, we propose BrainATCL, an unsupervised, nonparametric framework for adaptive temporal brain connectivity learning, enabling functional link prediction and age estimation. Our method dynamically adjusts the lookback window for each snapshot based on the rate of newly added edges. Graph sequences are subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal representations of dynamic functional connectivity in resting-state fMRI data of 1,000 participants from the Human Connectome Project. To further improve spatial modeling, we incorporate brain structure and function-informed edge attributes, i.e., the left/right hemispheric identity and subnetwork membership of brain regions, enabling the model to capture biologically meaningful topological patterns. We evaluate our BrainATCL on two tasks: functional link prediction and age estimation. The experimental results demonstrate superior performance and strong generalization, including in cross-session prediction scenarios.",
      "code_url": null
    },
    "2508.06118v1": {
      "title": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification",
      "url": "http://arxiv.org/abs/2508.06118v1",
      "authors": "Daniil Vlasenko, Vadim Ushakov, Alexey Zaikin, Denis Zakharov",
      "update_time": "2025-08-08",
      "abstract": "Understanding and classifying human cognitive brain states based on neuroimaging data remains one of the foremost and most challenging problems in neuroscience, owing to the high dimensionality and intrinsic noise of the signals. In this work, we propose an ensemble-based graph representation method of functional magnetic resonance imaging (fMRI) data for the task of binary brain-state classification. Our method builds the graph by leveraging multiple base machine-learning models: each edge weight reflects the difference in posterior probabilities between two cognitive states, yielding values in the range [-1, 1] that encode confidence in a given state. We applied this approach to seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject Release), including working memory, gambling, motor activity, language, social cognition, relational processing, and emotion processing. Using only the mean incident edge weights of the graphs as features, a simple logistic-regression classifier achieved average accuracies from 97.07% to 99.74%. We also compared our ensemble graphs with classical correlation-based graphs in a classification task with a graph neural network (GNN). In all experiments, the highest classification accuracy was obtained with ensemble graphs. These results demonstrate that ensemble graphs convey richer topological information and enhance brain-state discrimination. Our approach preserves edge-level interpretability of the fMRI graph representation, is adaptable to multiclass and regression tasks, and can be extended to other neuroimaging modalities and pathological-state classification.",
      "code_url": null
    },
    "2508.06589v1": {
      "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
      "url": "http://arxiv.org/abs/2508.06589v1",
      "authors": "Xinglin Zhao, Yanwen Wang, Xiaobo Liu, Yanrong Hao, Rui Cao, Xin Wen",
      "update_time": "2025-08-08",
      "abstract": "Computer-aided diagnosis (CAD) systems play a crucial role in analyzing neuroimaging data for neurological and psychiatric disorders. However, small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heterogeneity due to multiple disease subtypes being labeled under a single category. To address these challenges, we propose a novel federated learning framework tailored for neuroimaging CAD systems. Our approach includes a dynamic navigation module that routes samples to the most suitable local models based on latent subtype representations, and a meta-integration module that combines predictions from heterogeneous local models into a unified diagnostic output. We evaluated our framework using a comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100 healthy controls across multiple study cohorts. Experimental results demonstrate significant improvements in diagnostic accuracy and robustness compared to traditional methods. Specifically, our framework achieved an average accuracy of 74.06\\% across all tested sites, showcasing its effectiveness in handling subtype heterogeneity and enhancing model generalizability. Ablation studies further confirmed the importance of both the dynamic navigation and meta-integration modules in improving performance. By addressing data heterogeneity and subtype confounding, our framework advances reliable and reproducible neuroimaging CAD systems, offering significant potential for personalized medicine and clinical decision-making in neurology and psychiatry.",
      "code_url": null
    }
  },
  "MEG": {
    "2507.23525v1": {
      "title": "Wave Turbulence and Cortical Dynamics",
      "url": "http://arxiv.org/abs/2507.23525v1",
      "authors": "Gerald Kaushallye Cooray",
      "update_time": "2025-07-31",
      "abstract": "Cortical activity recorded through EEG and MEG reflects complex dynamics that span multiple temporal and spatial scales. Spectral analyses of these signals consistently reveal power-law behaviour, a hallmark of turbulent systems. In this paper, we derive a kinetic equation for neural field activity based on wave turbulence theory, highlighting how quantities such as energy and pseudo-particle density flow through wave-space (k-space) via direct and inverse cascades. We explore how different forms of nonlinearity, particularly 3-wave and 4-wave interactions, shape spectral features, including harmonic generation, spectral dispersion, and transient dynamics. While the observed power-law decays in empirical data are broadly consistent with turbulent cascades, variations across studies, such as the presence of dual decay rates or harmonic structures, point to a diversity of underlying mechanisms. We argue that although no single model fully explains all spectral observations, key constraints emerge: namely, that cortical dynamics exhibit features consistent with turbulent wave systems involving both single and dual cascades and a mixture of 3- and 4-wave interactions. This turbulence-based framework offers a principled and unifying approach to interpreting large-scale brain activity, including state transitions and seizure dynamics.",
      "code_url": null
    },
    "2507.21961v1": {
      "title": "Following the Committor Flow: A Data-Driven Discovery of Transition Pathways",
      "url": "http://arxiv.org/abs/2507.21961v1",
      "authors": "Cheng Giuseppe Chen, Chenyu Tang, Alberto Meg\u00edas, Radu A. Talmazan, Sergio Contreras Arredondo, Beno\u00eet Roux, Christophe Chipot",
      "update_time": "2025-07-29",
      "abstract": "The discovery of transition pathways to unravel distinct reaction mechanisms and, in general, rare events that occur in molecular systems is still a challenge. Recent advances have focused on analyzing the transition path ensemble using the committor probability, widely regarded as the most informative one-dimensional reaction coordinate. Consistency between transition pathways and the committor function is essential for accurate mechanistic insight. In this work, we propose an iterative framework to infer the committor and, subsequently, to identify the most relevant transition pathways. Starting from an initial guess for the transition path, we generate biased sampling from which we train a neural network to approximate the committor probability. From this learned committor, we extract dominant transition channels as discretized strings lying on isocommittor surfaces. These pathways are then used to enhance sampling and iteratively refine both the committor and the transition paths until convergence. The resulting committor enables accurate estimation of the reaction rate constant. We demonstrate the effectiveness of our approach on benchmark systems, including a two-dimensional model potential, peptide conformational transitions, and a Diels--Alder reaction.",
      "code_url": null
    },
    "2507.17700v1": {
      "title": "From Atoms to Dynamics: Learning the Committor Without Collective Variables",
      "url": "http://arxiv.org/abs/2507.17700v1",
      "authors": "Sergio Contreras Arredondo, Chenyu Tang, Radu A. Talmazan, Alberto Meg\u00edas, Cheng Giuseppe Chen, Christophe Chipot",
      "update_time": "2025-07-23",
      "abstract": "This Brief Communication introduces a graph-neural-network architecture built on geometric vector perceptrons to predict the committor function directly from atomic coordinates, bypassing the need for hand-crafted collective variables (CVs). The method offers atom-level interpretability, pinpointing the key atomic players in complex transitions without relying on prior assumptions. Applied across diverse molecular systems, the method accurately infers the committor function and highlights the importance of each heavy atom in the transition mechanism. It also yields precise estimates of the rate constants for the underlying processes. The proposed approach opens new avenues for understanding and modeling complex dynamics, by enabling CV-free learning and automated identification of physically meaningful reaction coordinates of complex molecular processes.",
      "code_url": null
    },
    "2507.14224v1": {
      "title": "Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG",
      "url": "http://arxiv.org/abs/2507.14224v1",
      "authors": "Beno\u00eet Brebion, Alban Gallard, Katrin Sippel, Amer Zaylaa, Hubert Preissl, Sahar Moghimi, Fabrice Wallois, Ya\u00ebl Fr\u00e9gier",
      "update_time": "2025-07-16",
      "abstract": "Background and objective: Brain activity in premature newborns has traditionally been studied using electroencephalography (EEG), leading to substantial advances in our understanding of early neural development. However, since brain development takes root at the fetal stage, a critical window of this process remains largely unknown. The only technique capable of recording neural activity in the intrauterine environment is fetal magnetoencephalography (fMEG), but this approach presents challenges in terms of data quality and scarcity. Using artificial intelligence, the present research aims to transfer the well-established knowledge from EEG studies to fMEG to improve understanding of prenatal brain development, laying the foundations for better detection and treatment of potential pathologies. Methods: We developed an unpaired diffusion translation method based on dual diffusion bridges, which notably includes numerical integration improvements to obtain more qualitative results at a lower computational cost. Models were trained on our unpaired dataset of bursts of spontaneous activity from 30 high-resolution premature newborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that our method achieves significant improvement upon previous results obtained with Generative Adversarial Networks (GANs), by almost 5% on the mean squared error in the time domain, and completely eliminating the mode collapse problem in the frequency domain, thus achieving near-perfect signal fidelity. Conclusion: We set a new state of the art in the EEG-fMEG unpaired translation problem, as our developed tool completely paves the way for early brain activity analysis. Overall, we also believe that our method could be reused for other unpaired signal translation applications.",
      "code_url": null
    },
    "2507.09747v1": {
      "title": "BrainFLORA: Uncovering Brain Concept Representation via Multimodal Neural Embeddings",
      "url": "http://arxiv.org/abs/2507.09747v1",
      "authors": "Dongyang Li, Haoyang Qin, Mingyang Wu, Chen Wei, Quanying Liu",
      "update_time": "2025-07-13",
      "abstract": "Understanding how the brain represents visual information is a fundamental challenge in neuroscience and artificial intelligence. While AI-driven decoding of neural data has provided insights into the human visual system, integrating multimodal neuroimaging signals, such as EEG, MEG, and fMRI, remains a critical hurdle due to their inherent spatiotemporal misalignment. Current approaches often analyze these modalities in isolation, limiting a holistic view of neural representation. In this study, we introduce BrainFLORA, a unified framework for integrating cross-modal neuroimaging data to construct a shared neural representation. Our approach leverages multimodal large language models (MLLMs) augmented with modality-specific adapters and task decoders, achieving state-of-the-art performance in joint-subject visual retrieval task and has the potential to extend multitasking. Combining neuroimaging analysis methods, we further reveal how visual concept representations align across neural modalities and with real world object perception. We demonstrate that the brain's structured visual concept representations exhibit an implicit mapping to physical-world stimuli, bridging neuroscience and machine learning from different modalities of neural imaging. Beyond methodological advancements, BrainFLORA offers novel implications for cognitive neuroscience and brain-computer interfaces (BCIs). Our code is available at https://github.com/ncclab-sustech/BrainFLORA.",
      "code_url": null
    },
    "2507.06610v1": {
      "title": "Resonant leptogenesis in inverse see-saw framework with modular $S_4$ symmetry",
      "url": "http://arxiv.org/abs/2507.06610v1",
      "authors": "Abhishek, V. Suryanarayana Mummidi",
      "update_time": "2025-07-09",
      "abstract": "This work introduces a model for lepton mass generation and flavor mixing, realized through a (2,3) inverse seesaw structure within a modular \\( S_4 \\) symmetry framework. The model employs modular forms to construct the lepton Yukawa couplings, thereby significantly simplifying the model by reducing its complexity. A detailed numerical analysis demonstrates consistency with current neutrino oscillation data, yielding constrained predictions for the mixing angles and CP-violating phases. The Dirac CP phase is sharply localized near \\( \\delta_{\\rm CP} \\sim 359^\\circ \\), and the model predicts an effective Majorana mass \\( |m_{ee}| \\sim \\mathcal{O}(10^{-3}) \\,\\text{eV} \\), Within the scope of upcoming experiments on neutrinoless double beta decay such as nEXO and AMoRE-II. The model also remains consistent with current bounds on charged lepton flavor violating processes from MEG and BaBar. We further explore resonant leptogenesis enabled by quasi-degenerate heavy neutrino states, and show that observed baryon asymmetry of the universe can be succesfully generated within this framework. The combined treatment of low-energy observables and high-scale baryogenesis demonstrates the predictivity and testability of the modular \\( S_4 \\)-based ISS(2,3) framework.",
      "code_url": null
    },
    "2506.20534v1": {
      "title": "Revisiting CHAMPAGNE: Sparse Bayesian Learning as Reweighted Sparse Coding",
      "url": "http://arxiv.org/abs/2506.20534v1",
      "authors": "Dylan Sechet, Matthieu Kowalski, Samy Mokhtari, Bruno Torr\u00e9sani",
      "update_time": "2025-06-25",
      "abstract": "This paper revisits the CHAMPAGNE algorithm within the Sparse Bayesian Learning (SBL) framework and establishes its connection to reweighted sparse coding. We demonstrate that the SBL objective can be reformulated as a reweighted $\\ell_{21}$-minimization problem, providing a more straightforward interpretation of the sparsity mechanism and enabling the design of an efficient iterative algorithm. Additionally, we analyze the behavior of this reformulation in the low signal-to-noise ratio (SNR) regime, showing that it simplifies to a weighted $\\ell_{21}$-regularized least squares problem. Numerical experiments validate the proposed approach, highlighting its improved computational efficiency and ability to produce exact sparse solutions, particularly in simulated MEG source localization tasks.",
      "code_url": null
    },
    "2506.12817v1": {
      "title": "Magnetoencephalography (MEG) Based Non-Invasive Chinese Speech Decoding",
      "url": "http://arxiv.org/abs/2506.12817v1",
      "authors": "Zhihong Jia, Hongbin Wang, Yuanzhong Shen, Feng Hu, Jiayu An, Kai Shu, Dongrui Wu",
      "update_time": "2025-06-15",
      "abstract": "As an emerging paradigm of brain-computer interfaces (BCIs), speech BCI has the potential to directly reflect auditory perception and thoughts, offering a promising communication alternative for patients with aphasia. Chinese is one of the most widely spoken languages in the world, whereas there is very limited research on speech BCIs for Chinese language. This paper reports a text-magnetoencephalography (MEG) dataset for non-invasive Chinese speech BCIs. It also proposes a multi-modality assisted speech decoding (MASD) algorithm to capture both text and acoustic information embedded in brain signals during speech activities. Experiment results demonstrated the effectiveness of both our text-MEG dataset and our proposed MASD algorithm. To our knowledge, this is the first study on modality-assisted decoding for non-invasive speech BCIs.",
      "code_url": null
    },
    "2506.10165v1": {
      "title": "The 2025 PNPL Competition: Speech Detection and Phoneme Classification in the LibriBrain Dataset",
      "url": "http://arxiv.org/abs/2506.10165v1",
      "authors": "Gilad Landau, Miran \u00d6zdogan, Gereon Elvers, Francesco Mantegna, Pratik Somaiya, Dulhan Jayalath, Luisa Kurth, Teyun Kwon, Brendan Shillingford, Greg Farquhar, Minqi Jiang, Karim Jerbi, Hamza Abdelhedi, Yorguin Mantilla Ramos, Caglar Gulcehre, Mark Woolrich, Natalie Voets, Oiwi Parker Jones",
      "update_time": "2025-06-11",
      "abstract": "The advance of speech decoding from non-invasive brain data holds the potential for profound societal impact. Among its most promising applications is the restoration of communication to paralysed individuals affected by speech deficits such as dysarthria, without the need for high-risk surgical interventions. The ultimate aim of the 2025 PNPL competition is to produce the conditions for an \"ImageNet moment\" or breakthrough in non-invasive neural decoding, by harnessing the collective power of the machine learning community.   To facilitate this vision we present the largest within-subject MEG dataset recorded to date (LibriBrain) together with a user-friendly Python library (pnpl) for easy data access and integration with deep learning frameworks. For the competition we define two foundational tasks (i.e. Speech Detection and Phoneme Classification from brain data), complete with standardised data splits and evaluation metrics, illustrative benchmark models, online tutorial code, a community discussion board, and public leaderboard for submissions. To promote accessibility and participation the competition features a Standard track that emphasises algorithmic innovation, as well as an Extended track that is expected to reward larger-scale computing, accelerating progress toward a non-invasive brain-computer interface for speech.",
      "code_url": null
    },
    "2506.08511v1": {
      "title": "The Predictive Brain: Neural Correlates of Word Expectancy Align with Large Language Model Prediction Probabilities",
      "url": "http://arxiv.org/abs/2506.08511v1",
      "authors": "Nikola K\u00f6lbl, Konstantin Tziridis, Andreas Maier, Thomas Kinfe, Ricardo Chavarriaga, Achim Schilling, Patrick Krauss",
      "update_time": "2025-06-10",
      "abstract": "Predictive coding theory suggests that the brain continuously anticipates upcoming words to optimize language processing, but the neural mechanisms remain unclear, particularly in naturalistic speech. Here, we simultaneously recorded EEG and MEG data from 29 participants while they listened to an audio book and assigned predictability scores to nouns using the BERT language model. Our results show that higher predictability is associated with reduced neural responses during word recognition, as reflected in lower N400 amplitudes, and with increased anticipatory activity before word onset. EEG data revealed increased pre-activation in left fronto-temporal regions, while MEG showed a tendency for greater sensorimotor engagement in response to low-predictability words, suggesting a possible motor-related component to linguistic anticipation. These findings provide new evidence that the brain dynamically integrates top-down predictions with bottom-up sensory input to facilitate language comprehension. To our knowledge, this is the first study to demonstrate these effects using naturalistic speech stimuli, bridging computational language models with neurophysiological data. Our findings provide novel insights for cognitive computational neuroscience, advancing the understanding of predictive processing in language and inspiring the development of neuroscience-inspired AI. Future research should explore the role of prediction and sensory precision in shaping neural responses and further refine models of language processing.",
      "code_url": null
    }
  },
  "neuroAI": {
    "2507.06645v1": {
      "title": "Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers",
      "url": "http://arxiv.org/abs/2507.06645v1",
      "authors": "Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding",
      "update_time": "2025-07-09",
      "abstract": "Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as e.g. accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.",
      "code_url": null
    },
    "2507.02103v1": {
      "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
      "url": "http://arxiv.org/abs/2507.02103v1",
      "authors": "Daniel Durstewitz, Bruno Averbeck, Georgia Koppe",
      "update_time": "2025-07-02",
      "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
      "code_url": null
    },
    "2506.04536v2": {
      "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models",
      "url": "http://arxiv.org/abs/2506.04536v2",
      "authors": "Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar",
      "update_time": "2025-06-12",
      "abstract": "Characterizing the diverse computational properties of human neurons via multimodal electrophysiological, transcriptomic, and morphological data provides the foundation for constructing and validating bio-realistic neuron models that can advance our understanding of fundamental mechanisms underlying brain function. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. To capture variability, ensembles of deterministic models are often used, but are difficult to scale as model generation requires repeating computationally expensive optimization for each neuron. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on data generated from biophysically realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE is the first scaled-up deep learning framework validated on real experimental data, enabling efficient generation of synthetic neurons that exhibit trial-to-trial variability and achieve a $4200\\times$ speedup over numerical solvers. To this end, NOBLE captures fundamental neural properties, opening the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.",
      "code_url": null
    },
    "2505.16080v1": {
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "url": "http://arxiv.org/abs/2505.16080v1",
      "authors": "Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang",
      "update_time": "2025-05-21",
      "abstract": "Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.",
      "code_url": null
    },
    "2503.06286v1": {
      "title": "A 7T fMRI dataset of synthetic images for out-of-distribution modeling of vision",
      "url": "http://arxiv.org/abs/2503.06286v1",
      "authors": "Alessandro T. Gifford, Radoslaw M. Cichy, Thomas Naselaris, Kendrick Kay",
      "update_time": "2025-03-08",
      "abstract": "Large-scale visual neural datasets such as the Natural Scenes Dataset (NSD) are boosting NeuroAI research by enabling computational models of the brain with performances beyond what was possible just a decade ago. However, these datasets lack out-of-distribution (OOD) components, which are crucial for the development of more robust models. Here, we address this limitation by releasing NSD-synthetic, a dataset consisting of 7T fMRI responses from the eight NSD subjects for 284 carefully controlled synthetic images. We show that NSD-synthetic's fMRI responses reliably encode stimulus-related information and are OOD with respect to NSD. Furthermore, OOD generalization tests on NSD-synthetic reveal differences between models of the brain that are not detected with NSD - specifically, self-supervised deep neural networks better explain neural responses than their task-supervised counterparts. These results showcase how NSD-synthetic enables OOD generalization tests that facilitate the development of more robust models of visual processing, and the formulation of more accurate theories of human vision.",
      "code_url": null
    },
    "2502.16238v1": {
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "url": "http://arxiv.org/abs/2502.16238v1",
      "authors": "Jenelle Feather, Meenakshi Khosla, N. Apurva Ratan Murty, Aran Nayebi",
      "update_time": "2025-02-22",
      "abstract": "What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \\emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development.",
      "code_url": null
    },
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": null
    },
    "2411.18526v2": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v2",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias, Anthony Zador",
      "update_time": "2025-04-03",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety.",
      "code_url": null
    },
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research.",
      "code_url": null
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.",
      "code_url": null
    }
  },
  "medical": {
    "2508.13072v1": {
      "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis",
      "url": "http://arxiv.org/abs/2508.13072v1",
      "authors": "Yuting Zhang, Tiantian Geng, Luoying Hao, Xinxing Cheng, Alexander Thorley, Xiaoxia Wang, Wenqi Lu, Sandeep S Hothi, Lei Wei, Zhaowen Qiu, Dipak Kotecha, Jinming Duan",
      "update_time": "2025-08-18",
      "abstract": "Contemporary cardiovascular management involves complex consideration and integration of multimodal cardiac datasets, where each modality provides distinct but complementary physiological characteristics. While the effective integration of multiple modalities could yield a holistic clinical profile that accurately models the true clinical situation with respect to data modalities and their relatives weightings, current methodologies remain limited by: 1) the scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated single-modality or rigid multimodal input combinations; 3) alignment strategies that prioritize cross-modal similarity over complementarity; and 4) a narrow single-task focus. In response to these limitations, a comprehensive multimodal dataset was curated for immediate application, integrating laboratory test results, electrocardiograms, and echocardiograms with clinical outcomes. Subsequently, a unified framework, Textual Guidance Multimodal fusion for Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key components: 1) a MedFlexFusion module designed to capture the unique and complementary characteristics of medical modalities and dynamically integrate data from diverse cardiac sources and their combinations; 2) a textual guidance module to derive task-relevant representations tailored to diverse clinical objectives, including heart disease diagnosis, risk stratification and information retrieval; and 3) a response module to produce final decisions for all these tasks. Furthermore, this study systematically explored key features across multiple modalities and elucidated their synergistic contributions in clinical decision-making. Extensive experiments showed that TGMM outperformed state-of-the-art methods across multiple clinical tasks, with additional validation confirming its robustness on another public dataset.",
      "code_url": null
    },
    "2508.13068v1": {
      "title": "Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation",
      "url": "http://arxiv.org/abs/2508.13068v1",
      "authors": "Tanjim Islam Riju, Shuchismita Anwar, Saman Sarker Joy, Farig Sadeque, Swakkhar Shatabda",
      "update_time": "2025-08-18",
      "abstract": "We propose a two-stage multimodal framework that enhances disease classification and region-aware radiology report generation from chest X-rays, leveraging the MIMIC-Eye dataset. In the first stage, we introduce a gaze-guided contrastive learning architecture for disease classification. It integrates visual features, clinical labels, bounding boxes, and radiologist eye-tracking signals and is equipped with a novel multi-term gaze-attention loss combining MSE, KL divergence, correlation, and center-of-mass alignment. Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC from 0.821 to 0.849 (+3.41%), while also improving precision and recall, highlighting the effectiveness of gaze-informed attention supervision. In the second stage, we present a modular report generation pipeline that extracts confidence-weighted diagnostic keywords, maps them to anatomical regions using a curated dictionary constructed from domain-specific priors, and generates region-aligned sentences via structured prompts. This pipeline improves report quality as measured by clinical keyword recall and ROUGE overlap. Our results demonstrate that integrating gaze data improves both classification performance and the interpretability of generated medical reports.",
      "code_url": null
    },
    "2508.12998v1": {
      "title": "Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health",
      "url": "http://arxiv.org/abs/2508.12998v1",
      "authors": "Sanja \u0160\u0107epanovi\u0107, Sagar Joglekar, Stephen Law, Daniele Quercia, Ke Zhou, Alice Battiston, Rossano Schifanella",
      "update_time": "2025-08-18",
      "abstract": "Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to {\\pounds}3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.",
      "code_url": null
    },
    "2508.12957v1": {
      "title": "Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination",
      "url": "http://arxiv.org/abs/2508.12957v1",
      "authors": "Yizhou Liu, Jingwei Wei, Zizhi Chen, Minghao Han, Xukun Zhang, Keliang Liu, Lihua Zhang",
      "update_time": "2025-08-18",
      "abstract": "Reinforcement learning (RL) with rule-based rewards has demonstrated strong potential in enhancing the reasoning and generalization capabilities of vision-language models (VLMs) and large language models (LLMs), while reducing computational overhead. However, its application in medical imaging remains underexplored. Existing reinforcement fine-tuning (RFT) approaches in this domain primarily target closed-ended visual question answering (VQA), limiting their applicability to real-world clinical reasoning. In contrast, open-ended medical VQA better reflects clinical practice but has received limited attention. While some efforts have sought to unify both formats via semantically guided RL, we observe that model-based semantic rewards often suffer from reward collapse, where responses with significant semantic differences receive similar scores. To address this, we propose ARMed (Adaptive Reinforcement for Medical Reasoning), a novel RL framework for open-ended medical VQA. ARMed first incorporates domain knowledge through supervised fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning with textual correctness and adaptive semantic rewards to enhance reasoning quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results show that ARMed consistently boosts both accuracy and generalization, achieving a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain benchmarks. These results highlight the critical role of reward discriminability in medical RL and the promise of semantically guided rewards for enabling robust and clinically meaningful multimodal reasoning.",
      "code_url": null
    },
    "2508.12927v1": {
      "title": "Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization",
      "url": "http://arxiv.org/abs/2508.12927v1",
      "authors": "Robin Trombetta, Carole Lartizien",
      "update_time": "2025-08-18",
      "abstract": "Unsupervised anomaly detection aims to detect defective parts of a sample by having access, during training, to a set of normal, i.e. defect-free, data. It has many applications in fields, such as industrial inspection or medical imaging, where acquiring labels is costly or when we want to avoid introducing biases in the type of anomalies that can be spotted. In this work, we propose a novel UAD method based on prototype learning and introduce a metric to compare a structured set of embeddings that balances a feature-based cost and a spatial-based cost. We leverage this metric to learn local and global prototypes with optimal transport from latent representations extracted with a pre-trained image encoder. We demonstrate that our approach can enforce a structural constraint when learning the prototypes, allowing to capture the underlying organization of the normal samples, thus improving the detection of incoherencies in images. Our model achieves performance that is on par with strong baselines on two reference benchmarks for anomaly detection on industrial images. The code is available at https://github.com/robintrmbtt/pradot.",
      "code_url": null
    },
    "2508.12827v1": {
      "title": "Towards a better understanding of abdominal wall biomechanics: in vivo relationship between dynamic intra-abdominal pressure and magnetic resonance imaging measurements",
      "url": "http://arxiv.org/abs/2508.12827v1",
      "authors": "Victoria Joppin, Arthur Jourdan, David Bendahan, Andr\u00e9a Soucasse, Maxime Guye, Catherine Masson, Thierry B\u00e8ge",
      "update_time": "2025-08-18",
      "abstract": "Background In vivo mechanical behaviour of the abdominal wall has been poorly characterised and important details are missing regarding the occurrence and post-operative recurrence rate of hernias which can be as high as 30 %. This study aimed to assess the correlation between abdominal wall displacement and intra-abdominal pressure, as well as abdominal compliance. Methods Eighteen healthy participants performed audio-guided passive (breathing) and active (coughing, Valsalva maneuver) exercises. Axial dynamic changes of abdominal muscles and visceral area were measured using MRI, and intra-abdominal pressure with ingested pressure sensor. Findings Correlations between abdominal wall displacement and intra-abdominal pressure were specific to participant, exercise, and varying between rectus abdominis and lateral muscles. Strong correlations were found between rectus abdominis displacement and intra-abdominal pressure during breathing (r = 0.92 $\\pm$ 0.06), as well as lateral muscles displacement with intra-abdominal pressure during coughing and Valsalva maneuver (r = --0.98 $\\pm$ 0.03 and -- 0.94 $\\pm$ 0.05 respectively). The abdominal pseudo-compliance varied greatly among participants during muscular contraction, the coefficient of variation reaching up to 70 %. Interpretation The combination of intra-abdominal pressure and dynamic MRI measurements enables the identification of participant-specific behaviour pattern. Intra-abdominal pressure and abdominal wall dynamic undergo consistent and predictable interactions. However, this relationship is subject-specific and may not be extrapolated to other individuals. Therefore, both intra-abdominal pressure and abdominal wall motion must be measured in the same participant in order to accurately characterise the abdominal wall behaviour. These results are of great importance for mesh design, surgical decision-making, and personalised healthcare.",
      "code_url": null
    },
    "2508.12815v1": {
      "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs",
      "url": "http://arxiv.org/abs/2508.12815v1",
      "authors": "Jayneel Parekh, Pegah Khayatan, Mustafa Shukor, Arnaud Dapogny, Alasdair Newson, Matthieu Cord",
      "update_time": "2025-08-18",
      "abstract": "Steering has emerged as a practical approach to enable post-hoc guidance of LLMs towards enforcing a specific behavior. However, it remains largely underexplored for multimodal LLMs (MLLMs); furthermore, existing steering techniques, such as mean steering, rely on a single steering vector, applied independently of the input query. This paradigm faces limitations when the desired behavior is dependent on the example at hand. For example, a safe answer may consist in abstaining from answering when asked for an illegal activity, or may point to external resources or consultation with an expert when asked about medical advice. In this paper, we investigate a fine-grained steering that uses an input-specific linear shift. This shift is computed using contrastive input-specific prompting. However, the input-specific prompts required for this approach are not known at test time. Therefore, we propose to train a small auxiliary module to predict the input-specific steering vector. Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces hallucinations and enforces safety in MLLMs, outperforming other static baselines.",
      "code_url": null
    },
    "2508.12778v1": {
      "title": "HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks",
      "url": "http://arxiv.org/abs/2508.12778v1",
      "authors": "Zhe Chen, Yusheng Liao, Shuyang Jiang, Zhiyuan Zhu, Haolin Li, Yanfeng Wang, Yu Wang",
      "update_time": "2025-08-18",
      "abstract": "Medical large vision-language Models (Med-LVLMs) have shown promise in clinical applications but suffer from factual inaccuracies and unreliable outputs, posing risks in real-world diagnostics. While retrieval-augmented generation has emerged as a potential solution, current medical multimodal RAG systems are unable to perform effective retrieval across heterogeneous sources. The irrelevance of retrieved reports affects the factuality of analysis, while insufficient knowledge affects the credibility of clinical decision-making. To bridge the gap, we construct MedAtlas, which includes extensive multimodal report repositories and diverse text corpora. Based on it, we present HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous knowledge sources. The framework introduces Modality-specific CLIPs for effective report retrieval and a Multi-corpora Query Generator for dynamically constructing queries for diverse corpora. Incorporating knowledge from such multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge Preference Tuning to achieve cross-modality and multi-source knowledge alignment. Extensive experiments across 12 datasets and 3 modalities demonstrate that the proposed HeteroRAG achieves state-of-the-art performance in most medical vision language benchmarks, significantly improving factual accuracy and reliability of Med-LVLMs.",
      "code_url": null
    },
    "2508.12741v1": {
      "title": "A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks",
      "url": "http://arxiv.org/abs/2508.12741v1",
      "authors": "Manuela Imbriani, Gina Belmonte, Mieke Massink, Alessandro Tofani, Vincenzo Ciancia",
      "update_time": "2025-08-18",
      "abstract": "This paper presents preliminary results in the definition of a comprehensive benchmark framework designed to systematically evaluate spatial reasoning capabilities in neural networks, with a particular focus on morphological properties such as connectivity and distance relationships. The framework is currently being used to study the capabilities of nnU-Net, exploiting the spatial model checker VoxLogicA to generate two distinct categories of synthetic datasets: maze connectivity problems for topological analysis and spatial distance computation tasks for geometric understanding. Each category is evaluated across multiple resolutions to assess scalability and generalization properties. The automated pipeline encompasses a complete machine learning workflow including: synthetic dataset generation, standardized training with cross-validation, inference execution, and comprehensive evaluation using Dice coefficient and IoU (Intersection over Union) metrics. Preliminary experimental results demonstrate significant challenges in neural network spatial reasoning capabilities, revealing systematic failures in basic geometric and topological understanding tasks. The framework provides a reproducible experimental protocol, enabling researchers to identify specific limitations. Such limitations could be addressed through hybrid approaches combining neural networks with symbolic reasoning methods for improved spatial understanding in clinical applications, establishing a foundation for ongoing research into neural network spatial reasoning limitations and potential solutions.",
      "code_url": null
    },
    "2508.12680v1": {
      "title": "Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation",
      "url": "http://arxiv.org/abs/2508.12680v1",
      "authors": "Yuheng Zha, Kun Zhou, Yujia Wu, Yushu Wang, Jie Feng, Zhi Xu, Shibo Hao, Zhengzhong Liu, Eric P. Xing, Zhiting Hu",
      "update_time": "2025-08-18",
      "abstract": "Despite their success, current training pipelines for reasoning VLMs focus on a limited range of tasks, such as mathematical and logical reasoning. As a result, these models face difficulties in generalizing their reasoning capabilities to a wide range of domains, primarily due to the scarcity of readily available and verifiable reward data beyond these narrowly defined areas. Moreover, integrating data from multiple domains is challenging, as the compatibility between domain-specific datasets remains uncertain. To address these limitations, we build a comprehensive RL-ready visual reasoning dataset from 46 data sources across 8 dimensions, covering a wide range of tasks such as infographic, mathematical, spatial, cross-image, graphic user interface, medical, common sense and general science. We propose an influence function based data selection and difficulty based filtering strategy to identify high-quality training samples from this dataset. Subsequently, we train the VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to iteratively improve its visual reasoning capabilities. Our model achieves state-of-the-art performance across various visual reasoning benchmarks, outperforming similar-sized VLMs and even proprietary models like GPT-4o and Gemini-1.5 Flash. The model, code and dataset are publicly available at https://github.com/yuh-zha/Vision-G1.",
      "code_url": null
    }
  }
}