{
  "Brain": {
    "2411.16582v1": {
      "title": "Dynamic Causal Models of Time-Varying Connectivity",
      "url": "http://arxiv.org/abs/2411.16582v1",
      "authors": "Johan Medrano, Karl J. Friston, Peter Zeidman",
      "update_time": "2024-11-25",
      "abstract": "This paper introduces a novel approach for modelling time-varying connectivity in neuroimaging data, focusing on the slow fluctuations in synaptic efficacy that mediate neuronal dynamics. Building on the framework of Dynamic Causal Modelling (DCM), we propose a method that incorporates temporal basis functions into neural models, allowing for the explicit representation of slow parameter changes. This approach balances expressivity and computational efficiency by modelling these fluctuations as a Gaussian process, offering a middle ground between existing methods that either strongly constrain or excessively relax parameter fluctuations. We validate the ensuing model through simulations and real data from an auditory roving oddball paradigm, demonstrating its potential to explain key aspects of brain dynamics. This work aims to equip researchers with a robust tool for investigating time-varying connectivity, particularly in the context of synaptic modulation and its role in both healthy and pathological brain function."
    },
    "2411.16558v1": {
      "title": "Stability of Brain Functional Network During Working Memory Using Structural Balance Theory",
      "url": "http://arxiv.org/abs/2411.16558v1",
      "authors": "Sepehr Gourabi, Masoud Lotfalipour, Reza Khosrowabadi, Reza Jafari",
      "update_time": "2024-11-25",
      "abstract": "Working memory plays a crucial role in various aspects of human life. Therefore, it has been an area of interest in different research studies, especially neuroscience. The neuroscientists investigating working memory have primarily emphasized the brain's functional modularity. At the same time, a holistic perspective is still required to investigate the brain as an integrated and unified system. We hypothesized that the brain should shift towards a more stable state during working memory than the resting state. Therefore, based on the Structural Balance Theory (SBT), we aimed to address this process. To achieve this, we examined triadic associations in signed fMRI networks in healthy individuals using the N-back as the working memory task. We demonstrated that the number of balanced triads increased during the working memory task compared to the resting state, while the opposite is true for imbalanced triads. The increase of balanced triads forced the network to a more stable state with a lower balance energy level. The increase of balanced triads was crucially related to changes in anti-synchrony to synchronous activities between the Temporal Cortex, the Prefrontal Cortex, and the Parietal Cortex, which are known to be involved in various aspects of working memory, during the working memory process. We hope these findings pave the way to a better understanding the working memory process."
    },
    "2411.16449v1": {
      "title": "Alpha-Delta Transitions in Cortical Rhythms as grazing bifurcations",
      "url": "http://arxiv.org/abs/2411.16449v1",
      "authors": "Huda Mahdi, Jan Sieber, Krasimira Tsaneva-Atanasova",
      "update_time": "2024-11-25",
      "abstract": "The Jansen-Rit model of a cortical column in the cerebral cortex is widely used to simulate spontaneous brain activity (EEG) and event-related potentials. It couples a pyramidal cell population with two interneuron populations, of which one is fast and excitatory and the other slow and inhibitory. Our paper studies the transition between alpha and delta oscillations produced by the model. Delta oscillations are slower than alpha oscillations and have a more complex relaxation-type time profile. In the context of neuronal population activation dynamics, a small threshold means that neurons begin to activate with small input or stimulus, indicating high sensitivity to incoming signals. A steep slope signifies that activation increases sharply as input crosses the threshold. Accordingly in the model the excitatory activation thresholds are small and the slopes are steep. Hence, a singular limit replacing the excitatory activation function with all-or-nothing switches, eg. a Heaviside function, is appropriate. In this limit we identify the transition between alpha and delta oscillations as a discontinuity-induced grazing bifurcation. At the grazing the minimum of the pyramidal-cell output equals the threshold for switching off the excitatory interneuron population, leading to a collapse in excitatory feedback."
    },
    "2411.16360v1": {
      "title": "Shapes of direct cortical responses vs. short-range axono-cortical evoked potentials: The effects of direct electrical stimulation applied to the human brain",
      "url": "http://arxiv.org/abs/2411.16360v1",
      "authors": "Clotilde Turpin, Olivier Rossel, F\u00e9lix Schlosser-Perrin, Sam Ng, Riki Matsumoto, Emmanuel Mandonnet, Hugues Duffau, Fran\u00e7ois Bonnetblanc",
      "update_time": "2024-11-25",
      "abstract": "Objective: Direct cortical responses (DCR) and axono-cortical evoked potentials (ACEP) are generated by electrically stimulating the cortex either directly or indirectly through white matter pathways, potentially leading to different electrogenic processes. For ACEP, the slow conduction velocity of axons (median around 4 m.s$^{-1}$) is anticipated to induce a delay. For DCR, direct electrical stimulation (DES) of the cortex is expected to elicit additional cortical activity involving smaller and slower non-myelinated axons. We tried to validate these hypotheses. Methods: DES was administered either directly on the cortex or to white matter fascicles within the resection cavity, while recording DCR or ACEP at the cortical level in nine patients. Results: Short but significant delays (around 2 ms) were measurable for ACEP immediately following the initial component (around 7 ms). Subsequent activities (around 40 ms) exhibited notable differences between DCR and ACEP, suggesting the presence of additional cortical activities for DCR. Conclusion: Distinctions between ACEPs and DCRs can be made based on a delay at the onset of early components and the dissimilarity in the shape of the later components >40 ms after the DES artifact). Significance: The comparison of different types of evoked potentials allows to better understand the effects of DES."
    },
    "2411.16349v1": {
      "title": "Machine learning for cerebral blood vessels' malformations",
      "url": "http://arxiv.org/abs/2411.16349v1",
      "authors": "Irem Topal, Alexander Cherevko, Yuri Bugay, Maxim Shishlenin, Jean Barbier, Deniz Eroglu, \u00c9dgar Rold\u00e1n, Roman Belousov",
      "update_time": "2024-11-25",
      "abstract": "Cerebral aneurysms and arteriovenous malformations are life-threatening hemodynamic pathologies of the brain. While surgical intervention is often essential to prevent fatal outcomes, it carries significant risks both during the procedure and in the postoperative period, making the management of these conditions highly challenging. Parameters of cerebral blood flow, routinely monitored during medical interventions, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis. To this end, we developed a linear oscillatory model of blood velocity and pressure for clinical data acquired from neurosurgical operations. Using the method of Sparse Identification of Nonlinear Dynamics (SINDy), the parameters of our model can be reconstructed online within milliseconds from a short time series of the hemodynamic variables. The identified parameter values enable automated classification of the blood-flow pathologies by means of logistic regression, achieving an accuracy of 73 %. Our results demonstrate the potential of this model for both diagnostic and prognostic applications, providing a robust and interpretable framework for assessing cerebral blood vessel conditions."
    },
    "2411.16326v1": {
      "title": "Brain-like emergent properties in deep networks: impact of network architecture, datasets and training",
      "url": "http://arxiv.org/abs/2411.16326v1",
      "authors": "Niranjan Rajesh, Georgin Jacob, SP Arun",
      "update_time": "2024-11-25",
      "abstract": "Despite the rapid pace at which deep networks are improving on standardized vision benchmarks, they are still outperformed by humans on real-world vision tasks. This paradoxical lack of generalization could be addressed by making deep networks more brain-like. Although several benchmarks have compared the ability of deep networks to predict brain responses to natural images, they do not capture subtle but important brain-like emergent properties. To resolve this issue, we report several well-known perceptual and neural emergent properties that can be tested on deep networks. To evaluate how various design factors impact brain-like properties, we systematically evaluated over 30 state-of-the-art networks with varying network architectures, training datasets and training regimes. Our main findings are as follows. First, network architecture had the strongest impact on brain-like properties compared to dataset and training regime variations. Second, networks varied widely in their alignment to the brain with no single network outperforming all others. Taken together, our results complement existing benchmarks by revealing brain-like properties that are either emergent or lacking in state-of-the-art deep networks."
    },
    "2411.16165v1": {
      "title": "Explainable MST-ECoGNet Decode Visual Information from ECoG Signal",
      "url": "http://arxiv.org/abs/2411.16165v1",
      "authors": "Changqing JI",
      "update_time": "2024-11-25",
      "abstract": "In the application of brain-computer interface (BCI), we not only need to accurately decode brain signals,but also need to consider the explainability of the decoding process, which is related to the reliability of the model. In the process of designing a decoder or processing brain signals, we need to explain the discovered phenomena in physical or physiological way. An explainable model not only makes the signal processing process clearer and improves reliability, but also allows us to better understand brain activities and facilitate further exploration of the brain. In this paper, we systematically analyze the multi-classification dataset of visual brain signals ECoG, using a simple and highly explainable method to explore the ways in which ECoG carry visual information, then based on these findings, we propose a model called MST-ECoGNet that combines traditional mathematics and deep learning. The main contributions of this paper are: 1) found that ECoG time-frequency domain information carries visual information, provides important features for visual classification tasks. The mathematical method of MST (Modified S Transform) can effectively extract temporal-frequency domain information; 2) The spatial domain of ECoG signals also carries visual information, the unique spatial features are also important features for classification tasks; 3) The real and imaginary information in the time-frequency domain are complementary. The effective combination of the two is more helpful for classification tasks than using amplitude information alone; 4) Finally, compared with previous work, our model is smaller and has higher performance: for the object MonJ, the model size is reduced to 10.82% of base model, the accuracy is improved by 6.63%; for the object MonC, the model size is reduced to 8.78%, the accuracy is improved by 16.63%."
    },
    "2411.16075v1": {
      "title": "The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum",
      "url": "http://arxiv.org/abs/2411.16075v1",
      "authors": "Shogo Ohmae, Keiko Ohmae",
      "update_time": "2024-11-25",
      "abstract": "AI's significant recent advances using general-purpose circuit computations offer a potential window into how the neocortex and cerebellum of the brain are able to achieve a diverse range of functions across sensory, cognitive, and motor domains, despite their uniform circuit structures. However, comparing the brain and AI is challenging unless clear similarities exist, and past reviews have been limited to comparison of brain-inspired vision AI and the visual neocortex. Here, to enable comparisons across diverse functional domains, we subdivide circuit computation into three elements -- circuit structure, input/outputs, and the learning algorithm -- and evaluate the similarities for each element. With this novel approach, we identify wide-ranging similarities and convergent evolution in the brain and AI, providing new insights into key concepts in neuroscience. Furthermore, inspired by processing mechanisms of AI, we propose a new theory that integrates established neuroscience theories, particularly the theories of internal models and the mirror neuron system. Both the neocortex and cerebellum predict future world events from past information and learn from prediction errors, thereby acquiring models of the world. These models enable three core processes: (1) Prediction -- generating future information, (2) Understanding -- interpreting the external world via compressed and abstracted sensory information, and (3) Generation -- repurposing the future-information generation mechanism to produce other types of outputs. The universal application of these processes underlies the ability of the neocortex and cerebellum to accomplish diverse functions with uniform circuits. Our systematic approach, insights, and theory promise groundbreaking advances in understanding the brain."
    },
    "2411.16061v1": {
      "title": "Scaling Spike-driven Transformer with Efficient Spike Firing Approximation Training",
      "url": "http://arxiv.org/abs/2411.16061v1",
      "authors": "Man Yao, Xuerui Qiu, Tianxiang Hu, Jiakui Hu, Yuhong Chou, Keyu Tian, Jianxing Liao, Luziwei Leng, Bo Xu, Guoqi Li",
      "update_time": "2024-11-25",
      "abstract": "The ambition of brain-inspired Spiking Neural Networks (SNNs) is to become a low-power alternative to traditional Artificial Neural Networks (ANNs). This work addresses two major challenges in realizing this vision: the performance gap between SNNs and ANNs, and the high training costs of SNNs. We identify intrinsic flaws in spiking neurons caused by binary firing mechanisms and propose a Spike Firing Approximation (SFA) method using integer training and spike-driven inference. This optimizes the spike firing pattern of spiking neurons, enhancing efficient training, reducing power consumption, improving performance, enabling easier scaling, and better utilizing neuromorphic chips. We also develop an efficient spike-driven Transformer architecture and a spike-masked autoencoder to prevent performance degradation during SNN scaling. On ImageNet-1k, we achieve state-of-the-art top-1 accuracy of 78.5\\%, 79.8\\%, 84.0\\%, and 86.2\\% with models containing 10M, 19M, 83M, and 173M parameters, respectively. For instance, the 10M model outperforms the best existing SNN by 7.2\\% on ImageNet, with training time acceleration and inference energy efficiency improved by 4.5$\\times$ and 3.9$\\times$, respectively. We validate the effectiveness and efficiency of the proposed method across various tasks, including object detection, semantic segmentation, and neuromorphic vision tasks. This work enables SNNs to match ANN performance while maintaining the low-power advantage, marking a significant step towards SNNs as a general visual backbone. Code is available at https://github.com/BICLab/Spike-Driven-Transformer-V3.",
      "code_url": "https://github.com/biclab/spike-driven-transformer-v3"
    },
    "2411.15872v1": {
      "title": "Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024 SSA and Pediatrics",
      "url": "http://arxiv.org/abs/2411.15872v1",
      "authors": "Sarim Hashmi, Juan Lugo, Abdelrahman Elsayed, Dinesh Saggurthi, Mohammed Elseiagy, Alikhan Nurkamal, Jaskaran Walia, Fadillah Adamsyah Maani, Mohammad Yaqub",
      "update_time": "2024-11-24",
      "abstract": "\\usepackage{url} Identifying key pathological features in brain MRIs is crucial for the long-term survival of glioma patients. However, manual segmentation is time-consuming, requiring expert intervention and is susceptible to human error. Therefore, significant research has been devoted to developing machine learning methods that can accurately segment tumors in 3D multimodal brain MRI scans. Despite their progress, state-of-the-art models are often limited by the data they are trained on, raising concerns about their reliability when applied to diverse populations that may introduce distribution shifts. Such shifts can stem from lower quality MRI technology (e.g., in sub-Saharan Africa) or variations in patient demographics (e.g., children). The BraTS-2024 challenge provides a platform to address these issues. This study presents our methodology for segmenting tumors in the BraTS-2024 SSA and Pediatric Tumors tasks using MedNeXt, comprehensive model ensembling, and thorough postprocessing. Our approach demonstrated strong performance on the unseen validation set, achieving an average Dice Similarity Coefficient (DSC) of 0.896 on the BraTS-2024 SSA dataset and an average DSC of 0.830 on the BraTS Pediatric Tumor dataset. Additionally, our method achieved an average Hausdorff Distance (HD95) of 14.682 on the BraTS-2024 SSA dataset and an average HD95 of 37.508 on the BraTS Pediatric dataset.Our GitHub repository can be accessed here: Project Repository: https://github.com/python-arch/BioMbz-Optimizing-Brain-Tumor-Segmentation-with-MedNeXt-BraTS-2024-SSA-and-Pediatrics"
    }
  },
  "EEG": {
    "2411.16449v1": {
      "title": "Alpha-Delta Transitions in Cortical Rhythms as grazing bifurcations",
      "url": "http://arxiv.org/abs/2411.16449v1",
      "authors": "Huda Mahdi, Jan Sieber, Krasimira Tsaneva-Atanasova",
      "update_time": "2024-11-25",
      "abstract": "The Jansen-Rit model of a cortical column in the cerebral cortex is widely used to simulate spontaneous brain activity (EEG) and event-related potentials. It couples a pyramidal cell population with two interneuron populations, of which one is fast and excitatory and the other slow and inhibitory. Our paper studies the transition between alpha and delta oscillations produced by the model. Delta oscillations are slower than alpha oscillations and have a more complex relaxation-type time profile. In the context of neuronal population activation dynamics, a small threshold means that neurons begin to activate with small input or stimulus, indicating high sensitivity to incoming signals. A steep slope signifies that activation increases sharply as input crosses the threshold. Accordingly in the model the excitatory activation thresholds are small and the slopes are steep. Hence, a singular limit replacing the excitatory activation function with all-or-nothing switches, eg. a Heaviside function, is appropriate. In this limit we identify the transition between alpha and delta oscillations as a discontinuity-induced grazing bifurcation. At the grazing the minimum of the pyramidal-cell output equals the threshold for switching off the excitatory interneuron population, leading to a collapse in excitatory feedback."
    },
    "2411.16155v1": {
      "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning",
      "url": "http://arxiv.org/abs/2411.16155v1",
      "authors": "Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori",
      "update_time": "2024-11-25",
      "abstract": "In diagnosing mental diseases from electroencephalography (EEG) data, neural network models such as Transformers have been employed to capture temporal dynamics. Additionally, it is crucial to learn the spatial relationships between EEG sensors, for which Graph Neural Networks (GNNs) are commonly used. However, fine-tuning large-scale complex neural network models simultaneously to capture both temporal and spatial features increases computational costs due to the more significant number of trainable parameters. It causes the limited availability of EEG datasets for downstream tasks, making it challenging to fine-tune large models effectively. We propose EEG-GraphAdapter (EGA), a parameter-efficient fine-tuning (PEFT) approach to address these challenges. EGA is integrated into pre-trained temporal backbone models as a GNN-based module and fine-tuned itself alone while keeping the backbone model parameters frozen. This enables the acquisition of spatial representations of EEG signals for downstream tasks, significantly reducing computational overhead and data requirements. Experimental evaluations on healthcare-related downstream tasks of Major Depressive Disorder and Abnormality Detection demonstrate that our EGA improves performance by up to 16.1% in the F1-score compared with the backbone BENDR model."
    },
    "2411.15395v1": {
      "title": "ChatBCI: A P300 Speller BCI Leveraging Large Language Models for Improved Sentence Composition in Realistic Scenarios",
      "url": "http://arxiv.org/abs/2411.15395v1",
      "authors": "Jiazhen Hong, Weinan Wang, Laleh Najafizadeh",
      "update_time": "2024-11-23",
      "abstract": "P300 speller BCIs allow users to compose sentences by selecting target keys on a GUI through the detection of P300 component in their EEG signals following visual stimuli. Most P300 speller BCIs require users to spell words letter by letter, or the first few initial letters, resulting in high keystroke demands that increase time, cognitive load, and fatigue. This highlights the need for more efficient, user-friendly methods for faster sentence composition. In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot learning capabilities of large language models (LLMs) to suggest words from user-spelled initial letters or predict the subsequent word(s), reducing keystrokes and accelerating sentence composition. ChatBCI retrieves word suggestions through remote queries to the GPT-3.5 API. A new GUI, displaying GPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300 classification. Seven subjects completed two online spelling tasks: 1) copy-spelling a self-composed sentence using ChatBCI, and 2) improvising a sentence using ChatBCI's word suggestions. Results demonstrate that in Task 1, on average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time and keystrokes by 62.14% and 53.22%, respectively, and increasing information transfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings and a record 8.53 characters/min for typing speed. Overall, ChatBCI, by employing remote LLM queries, enhances sentence composition in realistic scenarios, significantly outperforming traditional spellers without requiring local model training or storage. ChatBCI's (multi-) word predictions, combined with its new GUI, pave the way for developing next-generation speller BCIs that are efficient and effective for real-time communication, especially for users with communication and motor disabilities."
    },
    "2411.14666v1": {
      "title": "Brain-Computer Interfaces for Emotional Regulation in Patients with Various Disorders",
      "url": "http://arxiv.org/abs/2411.14666v1",
      "authors": "Vedant Mehta",
      "update_time": "2024-11-22",
      "abstract": "Neurological and Physiological Disorders that impact emotional regulation each have their own unique characteristics which are important to understand in order to create a generalized solution to all of them. The purpose of this experiment is to explore the potential applications of EEG-based Brain-Computer Interfaces (BCIs) in enhancing emotional regulation for individuals with neurological and physiological disorders. The research focuses on the development of a novel neural network algorithm for understanding EEG data, with a particular emphasis on recognizing and regulating emotional states. The procedure involves the collection of EEG-based emotion data from open-Neuro. Using novel data modification techniques, information from the dataset can be altered to create a dataset that has neural patterns of patients with disorders whilst showing emotional change. The data analysis reveals promising results, as the algorithm is able to successfully classify emotional states with a high degree of accuracy. This suggests that EEG-based BCIs have the potential to be a valuable tool in aiding individuals with a range of neurological and physiological disorders in recognizing and regulating their emotions. To improve upon this work, data collection on patients with neurological disorders should be done to improve overall sample diversity."
    },
    "2411.13931v1": {
      "title": "Implementation of tools for lessening the influence of artifacts in EEG signal analysis",
      "url": "http://arxiv.org/abs/2411.13931v1",
      "authors": "Mario Molina-Molina, Lorenzo J. Tardon, Ana M. Barbancho, Isabel Barbancho",
      "update_time": "2024-11-21",
      "abstract": "This manuscript describes and implementation of scripts of code aimed at reducing the influence of artifacts, specifically focused on ocular artifacts, in the measurement and processing of electroencephalogram (EEG) signals. This process is of importance because it benefits the analysis and study of long trial samples when the appearance of ocular artifacts cannot be avoided by simply discarding trials. The implementations provided to the reader illustrate, with slight modifications, previously proposed methods aimed at the partial or complete elimination of EEG channels or components are those that resemble the electro-oculogram (EOG) signals in which artifacts are detected. In addition to the description of each of the provided functions, examples of utilization and illustrative figures will be included to show the expected results and processing pipeline."
    },
    "2411.13288v1": {
      "title": "EEG Signal Denoising Using pix2pix GAN: Enhancing Neurological Data Analysis",
      "url": "http://arxiv.org/abs/2411.13288v1",
      "authors": "Haoyi Wang, Xufang Chen, Yue Yang, Kewei Zhou, Meining Lv, Dongrui Wang, Wenjie Zhang",
      "update_time": "2024-11-20",
      "abstract": "Electroencephalography (EEG) is essential in neuroscience and clinical practice, yet it suffers from physiological artifacts, particularly electromyography (EMG), which distort signals. We propose a deep learning model using pix2pixGAN to remove such noise and generate reliable EEG signals. Leveraging the EEGdenoiseNet dataset, we created synthetic datasets with controlled EMG noise levels for model training and testing across a signal-to-noise ratio (SNR) from -7 to 2. Our evaluation metrics included RRMSE and Pearson's CC, assessing both time and frequency domains, and compared our model with others. The pix2pixGAN model excelled, especially under high noise conditions, showing significant improvements in lower RRMSE and higher CC values. This demonstrates the model's superior accuracy and stability in purifying EEG signals, offering a robust solution for EEG analysis challenges and advancing clinical and neuroscience applications."
    },
    "2411.13217v1": {
      "title": "Energy-based features and bi-LSTM neural network for EEG-based music and voice classification",
      "url": "http://arxiv.org/abs/2411.13217v1",
      "authors": "Isaac Ariza, Ana M. Barbancho, Lorenzo J. Tardon, Isabel Barbancho",
      "update_time": "2024-11-20",
      "abstract": "The human brain receives stimuli in multiple ways; among them, audio constitutes an important source of relevant stimuli for the brain regarding communication, amusement, warning, etc. In this context, the aim of this manuscript is to advance in the classification of brain responses to music of diverse genres and to sounds of different nature: speech and music. For this purpose, two different experiments have been designed to acquiere EEG signals from subjects listening to songs of different musical genres and sentences in various languages. With this, a novel scheme is proposed to characterize brain signals for their classification; this scheme is based on the construction of a feature matrix built on relations between energy measured at the different EEG channels and the usage of a bi-LSTM neural network. With the data obtained, evaluations regarding EEG-based classification between speech and music, different musical genres, and whether the subject likes the song listened to or not are carried out. The experiments unveil satisfactory performance to the proposed scheme. The results obtained for binary audio type classification attain 98.66% of success. In multi-class classification between 4 musical genres, the accuracy attained is 61.59%, and results for binary classification of musical taste rise to 96.96%."
    },
    "2411.13172v1": {
      "title": "Enhanced average for event-related potential analysis using dynamic time warping",
      "url": "http://arxiv.org/abs/2411.13172v1",
      "authors": "Mario Molina, Lorenzo J. Tardon, Ana M. Barbancho, Irene De-Torres, Isabel Barbancho",
      "update_time": "2024-11-20",
      "abstract": "Electroencephalography (EEG) provides a way to understand, and evaluate neurotransmission. In this context, time-locked EEG activity or event-related potentials (ERPs) are often used to capture neural activity related to specific mental processes. Normally, they are considered on the basis of averages across a number of trials. However, there exist notable variability in latency jitter, jitter, and amplitude, across trials, and, also, across users; this causes the average ERP waveform to blur, and, furthermore, diminish the amplitude of underlying waves. For these reasons, a strategy is proposed for obtaining ERP waveforms based on dynamic time warping (DTW) to adapt, and adjust individual trials to the averaged ERP, previously calculated, to build an enhanced average by making use of these warped signals. At the sight of the experiments carried out on the behaviour of the proposed scheme using publicly available datasets, this strategy reduces the attenuation in amplitude of ERP components thanks to the reduction of the influence of variability of latency and jitter, and, thus, improves the averaged ERP waveforms."
    },
    "2411.12852v1": {
      "title": "Enhanced Cross-Dataset Electroencephalogram-based Emotion Recognition using Unsupervised Domain Adaptation",
      "url": "http://arxiv.org/abs/2411.12852v1",
      "authors": "Md Niaz Imtiaz, Naimul Khan",
      "update_time": "2024-11-19",
      "abstract": "Emotion recognition has significant potential in healthcare and affect-sensitive systems such as brain-computer interfaces (BCIs). However, challenges such as the high cost of labeled data and variability in electroencephalogram (EEG) signals across individuals limit the applicability of EEG-based emotion recognition models across domains. These challenges are exacerbated in cross-dataset scenarios due to differences in subject demographics, recording devices, and presented stimuli. To address these issues, we propose a novel approach to improve cross-domain EEG-based emotion classification. Our method, Gradual Proximity-guided Target Data Selection (GPTDS), incrementally selects reliable target domain samples for training. By evaluating their proximity to source clusters and the models confidence in predicting them, GPTDS minimizes negative transfer caused by noisy and diverse samples. Additionally, we introduce Prediction Confidence-aware Test-Time Augmentation (PC-TTA), a cost-effective augmentation technique. Unlike traditional TTA methods, which are computationally intensive, PC-TTA activates only when model confidence is low, improving inference performance while drastically reducing computational costs. Experiments on the DEAP and SEED datasets validate the effectiveness of our approach. When trained on DEAP and tested on SEED, our model achieves 67.44% accuracy, a 7.09% improvement over the baseline. Conversely, training on SEED and testing on DEAP yields 59.68% accuracy, a 6.07% improvement. Furthermore, PC-TTA reduces computational time by a factor of 15 compared to traditional TTA methods. Our method excels in detecting both positive and negative emotions, demonstrating its practical utility in healthcare applications. Code available at: https://github.com/RyersonMultimediaLab/EmotionRecognitionUDA",
      "code_url": "https://github.com/ryersonmultimedialab/emotionrecognitionuda"
    },
    "2411.12400v1": {
      "title": "Bi-LSTM neural network for EEG-based error detection in musicians' performance",
      "url": "http://arxiv.org/abs/2411.12400v1",
      "authors": "Isaac Ariza, Lorenzo J. Tardon, Ana M. Barbancho, Irene De-Torres, Isabel Barbancho",
      "update_time": "2024-11-19",
      "abstract": "Electroencephalography (EEG) is a tool that allows us to analyze brain activity with high temporal resolution. These measures, combined with deep learning and digital signal processing, are widely used in neurological disorder detection and emotion and mental activity recognition. In this paper, a new method for mental activity recognition is presented; instantaneous frequency, spectral entropy and Mel-frequency cepstral coefficients (MFCC) are used to classify EEG signals using bidirectional LSTM neural networks. It is shown that this method can be used for intra-subject or inter-subject analysis and has been applied to error detection in musician performance reaching compelling accuracy."
    }
  },
  "BCI": {
    "2411.16165v1": {
      "title": "Explainable MST-ECoGNet Decode Visual Information from ECoG Signal",
      "url": "http://arxiv.org/abs/2411.16165v1",
      "authors": "Changqing JI",
      "update_time": "2024-11-25",
      "abstract": "In the application of brain-computer interface (BCI), we not only need to accurately decode brain signals,but also need to consider the explainability of the decoding process, which is related to the reliability of the model. In the process of designing a decoder or processing brain signals, we need to explain the discovered phenomena in physical or physiological way. An explainable model not only makes the signal processing process clearer and improves reliability, but also allows us to better understand brain activities and facilitate further exploration of the brain. In this paper, we systematically analyze the multi-classification dataset of visual brain signals ECoG, using a simple and highly explainable method to explore the ways in which ECoG carry visual information, then based on these findings, we propose a model called MST-ECoGNet that combines traditional mathematics and deep learning. The main contributions of this paper are: 1) found that ECoG time-frequency domain information carries visual information, provides important features for visual classification tasks. The mathematical method of MST (Modified S Transform) can effectively extract temporal-frequency domain information; 2) The spatial domain of ECoG signals also carries visual information, the unique spatial features are also important features for classification tasks; 3) The real and imaginary information in the time-frequency domain are complementary. The effective combination of the two is more helpful for classification tasks than using amplitude information alone; 4) Finally, compared with previous work, our model is smaller and has higher performance: for the object MonJ, the model size is reduced to 10.82% of base model, the accuracy is improved by 6.63%; for the object MonC, the model size is reduced to 8.78%, the accuracy is improved by 16.63%."
    },
    "2411.15395v1": {
      "title": "ChatBCI: A P300 Speller BCI Leveraging Large Language Models for Improved Sentence Composition in Realistic Scenarios",
      "url": "http://arxiv.org/abs/2411.15395v1",
      "authors": "Jiazhen Hong, Weinan Wang, Laleh Najafizadeh",
      "update_time": "2024-11-23",
      "abstract": "P300 speller BCIs allow users to compose sentences by selecting target keys on a GUI through the detection of P300 component in their EEG signals following visual stimuli. Most P300 speller BCIs require users to spell words letter by letter, or the first few initial letters, resulting in high keystroke demands that increase time, cognitive load, and fatigue. This highlights the need for more efficient, user-friendly methods for faster sentence composition. In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot learning capabilities of large language models (LLMs) to suggest words from user-spelled initial letters or predict the subsequent word(s), reducing keystrokes and accelerating sentence composition. ChatBCI retrieves word suggestions through remote queries to the GPT-3.5 API. A new GUI, displaying GPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300 classification. Seven subjects completed two online spelling tasks: 1) copy-spelling a self-composed sentence using ChatBCI, and 2) improvising a sentence using ChatBCI's word suggestions. Results demonstrate that in Task 1, on average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time and keystrokes by 62.14% and 53.22%, respectively, and increasing information transfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings and a record 8.53 characters/min for typing speed. Overall, ChatBCI, by employing remote LLM queries, enhances sentence composition in realistic scenarios, significantly outperforming traditional spellers without requiring local model training or storage. ChatBCI's (multi-) word predictions, combined with its new GUI, pave the way for developing next-generation speller BCIs that are efficient and effective for real-time communication, especially for users with communication and motor disabilities."
    },
    "2411.14666v1": {
      "title": "Brain-Computer Interfaces for Emotional Regulation in Patients with Various Disorders",
      "url": "http://arxiv.org/abs/2411.14666v1",
      "authors": "Vedant Mehta",
      "update_time": "2024-11-22",
      "abstract": "Neurological and Physiological Disorders that impact emotional regulation each have their own unique characteristics which are important to understand in order to create a generalized solution to all of them. The purpose of this experiment is to explore the potential applications of EEG-based Brain-Computer Interfaces (BCIs) in enhancing emotional regulation for individuals with neurological and physiological disorders. The research focuses on the development of a novel neural network algorithm for understanding EEG data, with a particular emphasis on recognizing and regulating emotional states. The procedure involves the collection of EEG-based emotion data from open-Neuro. Using novel data modification techniques, information from the dataset can be altered to create a dataset that has neural patterns of patients with disorders whilst showing emotional change. The data analysis reveals promising results, as the algorithm is able to successfully classify emotional states with a high degree of accuracy. This suggests that EEG-based BCIs have the potential to be a valuable tool in aiding individuals with a range of neurological and physiological disorders in recognizing and regulating their emotions. To improve upon this work, data collection on patients with neurological disorders should be done to improve overall sample diversity."
    },
    "2411.12852v1": {
      "title": "Enhanced Cross-Dataset Electroencephalogram-based Emotion Recognition using Unsupervised Domain Adaptation",
      "url": "http://arxiv.org/abs/2411.12852v1",
      "authors": "Md Niaz Imtiaz, Naimul Khan",
      "update_time": "2024-11-19",
      "abstract": "Emotion recognition has significant potential in healthcare and affect-sensitive systems such as brain-computer interfaces (BCIs). However, challenges such as the high cost of labeled data and variability in electroencephalogram (EEG) signals across individuals limit the applicability of EEG-based emotion recognition models across domains. These challenges are exacerbated in cross-dataset scenarios due to differences in subject demographics, recording devices, and presented stimuli. To address these issues, we propose a novel approach to improve cross-domain EEG-based emotion classification. Our method, Gradual Proximity-guided Target Data Selection (GPTDS), incrementally selects reliable target domain samples for training. By evaluating their proximity to source clusters and the models confidence in predicting them, GPTDS minimizes negative transfer caused by noisy and diverse samples. Additionally, we introduce Prediction Confidence-aware Test-Time Augmentation (PC-TTA), a cost-effective augmentation technique. Unlike traditional TTA methods, which are computationally intensive, PC-TTA activates only when model confidence is low, improving inference performance while drastically reducing computational costs. Experiments on the DEAP and SEED datasets validate the effectiveness of our approach. When trained on DEAP and tested on SEED, our model achieves 67.44% accuracy, a 7.09% improvement over the baseline. Conversely, training on SEED and testing on DEAP yields 59.68% accuracy, a 6.07% improvement. Furthermore, PC-TTA reduces computational time by a factor of 15 compared to traditional TTA methods. Our method excels in detecting both positive and negative emotions, demonstrating its practical utility in healthcare applications. Code available at: https://github.com/RyersonMultimediaLab/EmotionRecognitionUDA",
      "code_url": "https://github.com/ryersonmultimedialab/emotionrecognitionuda"
    },
    "2411.11302v1": {
      "title": "Towards Personalized Brain-Computer Interface Application Based on Endogenous EEG Paradigms",
      "url": "http://arxiv.org/abs/2411.11302v1",
      "authors": "Heon-Gyu Kwak, Gi-Hwan Shin, Yeon-Woo Choi, Dong-Hoon Lee, Yoo-In Jeon, Jun-Su Kang, Seong-Whan Lee",
      "update_time": "2024-11-18",
      "abstract": "In this paper, we propose a conceptual framework for personalized brain-computer interface (BCI) applications, which can offer an enhanced user experience by customizing services to individual preferences and needs, based on endogenous electroencephalography (EEG) paradigms including motor imagery (MI), speech imagery (SI), and visual imagery. The framework includes two essential components: user identification and intention classification, which enable personalized services by identifying individual users and recognizing their intended actions through EEG signals. We validate the feasibility of our framework using a private EEG dataset collected from eight subjects, employing the ShallowConvNet architecture to decode EEG features. The experimental results demonstrate that user identification achieved an average classification accuracy of 0.995, while intention classification achieved 0.47 accuracy across all paradigms, with MI demonstrating the best performance. These findings indicate that EEG signals can effectively support personalized BCI applications, offering robust identification and reliable intention decoding, especially for MI and SI."
    },
    "2411.09400v1": {
      "title": "Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2411.09400v1",
      "authors": "Seo-Hyun Lee, Ji-Ha Park, Deok-Seon Kim",
      "update_time": "2024-11-14",
      "abstract": "Recent advancements in brain-computer interface (BCI) technology have emphasized the promise of imagined speech and visual imagery as effective paradigms for intuitive communication. This study investigates the classification performance and brain connectivity patterns associated with these paradigms, focusing on decoding accuracy across selected word classes. Sixteen participants engaged in tasks involving thirteen imagined speech and visual imagery classes, revealing above-chance classification accuracy for both paradigms. Variability in classification accuracy across individual classes highlights the influence of sensory and motor associations in imagined speech and vivid visual associations in visual imagery. Connectivity analysis further demonstrated increased functional connectivity in language-related and sensory regions for imagined speech, whereas visual imagery activated spatial and visual processing networks. These findings suggest the potential of imagined speech and visual imagery as an intuitive and scalable paradigm for BCI communication when selecting optimal word classes. Further exploration of the decoding outcomes for these two paradigms could provide insights for practical BCI communication."
    },
    "2411.07652v1": {
      "title": "On the BCI Problem",
      "url": "http://arxiv.org/abs/2411.07652v1",
      "authors": "Ted Dobson, Gregory Robson",
      "update_time": "2024-11-12",
      "abstract": "Let $G$ be a group. The BCI problem asks whether two Haar graphs of $G$ are isomorphic if and only if they are isomorphic by an element of an explicit list of isomorphisms. We first generalize this problem in a natural way and give a theoretical way to solve the isomorphism problem for the natural generalization. We then restrict our attention to abelian groups and, with an exception, reduce the problem to the isomorphism problem for a related quotient, component, or corresponding Cayley digraph. For Haar graphs of an abelian group of odd order with connection sets $S$ those of Cayley graphs (i.e. $S = -S$), the exception does not exist. For Haar graphs of cyclic groups of odd order with connection sets those of a Cayley graph, among others, we solve the isomorphism problem."
    },
    "2411.10469v1": {
      "title": "User-wise Perturbations for User Identity Protection in EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2411.10469v1",
      "authors": "Xiaoqing Chen, Siyang Li, Yunlu Tu, Ziwei Wang, Dongrui Wu",
      "update_time": "2024-11-04",
      "abstract": "Objective: An electroencephalogram (EEG)-based brain-computer interface (BCI) is a direct communication pathway between the human brain and a computer. Most research so far studied more accurate BCIs, but much less attention has been paid to the ethics of BCIs. Aside from task-specific information, EEG signals also contain rich private information, e.g., user identity, emotion, disorders, etc., which should be protected. Approach: We show for the first time that adding user-wise perturbations can make identity information in EEG unlearnable. We propose four types of user-wise privacy-preserving perturbations, i.e., random noise, synthetic noise, error minimization noise, and error maximization noise. After adding the proposed perturbations to EEG training data, the user identity information in the data becomes unlearnable, while the BCI task information remains unaffected. Main results: Experiments on six EEG datasets using three neural network classifiers and various traditional machine learning models demonstrated the robustness and practicability of the proposed perturbations. Significance: Our research shows the feasibility of hiding user identity information in EEG data without impacting the primary BCI task information."
    },
    "2411.02094v1": {
      "title": "Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2411.02094v1",
      "authors": "Xiaoqing Chen, Ziwei Wang, Dongrui Wu",
      "update_time": "2024-11-04",
      "abstract": "Machine learning has achieved great success in electroencephalogram (EEG) based brain-computer interfaces (BCIs). Most existing BCI studies focused on improving the decoding accuracy, with only a few considering the adversarial security. Although many adversarial defense approaches have been proposed in other application domains such as computer vision, previous research showed that their direct extensions to BCIs degrade the classification accuracy on benign samples. This phenomenon greatly affects the applicability of adversarial defense approaches to EEG-based BCIs. To mitigate this problem, we propose alignment-based adversarial training (ABAT), which performs EEG data alignment before adversarial training. Data alignment aligns EEG trials from different domains to reduce their distribution discrepancies, and adversarial training further robustifies the classification boundary. The integration of data alignment and adversarial training can make the trained EEG classifiers simultaneously more accurate and more robust. Experiments on five EEG datasets from two different BCI paradigms (motor imagery classification, and event related potential recognition), three convolutional neural network classifiers (EEGNet, ShallowCNN and DeepCNN) and three different experimental settings (offline within-subject cross-block/-session classification, online cross-session classification, and pre-trained classifiers) demonstrated its effectiveness. It is very intriguing that adversarial attacks, which are usually used to damage BCI systems, can be used in ABAT to simultaneously improve the model accuracy and robustness.",
      "code_url": "https://github.com/xqchen914/abat"
    },
    "2411.11874v1": {
      "title": "Personalized Continual EEG Decoding Framework for Knowledge Retention and Transfer",
      "url": "http://arxiv.org/abs/2411.11874v1",
      "authors": "Dan Li, Hye-Bin Shin, Kang Yin",
      "update_time": "2024-11-04",
      "abstract": "The significant inter-subject variability in electroencephalogram (EEG) signals often leads to knowledge being overwritten as new tasks are introduced in continual EEG decoding. While retraining on the entire dataset with each new input can prevent forgetting, this approach incurs high computational costs. An ideal brain-computer interface (BCI) model should continuously learn new information without retraining from scratch, thus reducing these costs. Most transfer learning models rely on large source-domain datasets for pre-training, yet data availability is frequently limited in real-world applications due to privacy concerns. Furthermore, such models are prone to catastrophic forgetting in continual EEG decoding tasks. To address these challenges, we propose a personalized subject-incremental learning (SIL) framework for continual EEG decoding that integrates Euclidean Alignment for fast domain adaptation, an exemplar replay mechanism to retain prior knowledge, and reservoir sampling-based memory management to handle memory constraints in long-term learning. Validated on the OpenBMI dataset with 54 subjects, our framework effectively balances knowledge retention with classification performance in continual MI-EEG tasks, offering a scalable solution for real-world BCI applications."
    }
  },
  "fMRI": {
    "2411.16558v1": {
      "title": "Stability of Brain Functional Network During Working Memory Using Structural Balance Theory",
      "url": "http://arxiv.org/abs/2411.16558v1",
      "authors": "Sepehr Gourabi, Masoud Lotfalipour, Reza Khosrowabadi, Reza Jafari",
      "update_time": "2024-11-25",
      "abstract": "Working memory plays a crucial role in various aspects of human life. Therefore, it has been an area of interest in different research studies, especially neuroscience. The neuroscientists investigating working memory have primarily emphasized the brain's functional modularity. At the same time, a holistic perspective is still required to investigate the brain as an integrated and unified system. We hypothesized that the brain should shift towards a more stable state during working memory than the resting state. Therefore, based on the Structural Balance Theory (SBT), we aimed to address this process. To achieve this, we examined triadic associations in signed fMRI networks in healthy individuals using the N-back as the working memory task. We demonstrated that the number of balanced triads increased during the working memory task compared to the resting state, while the opposite is true for imbalanced triads. The increase of balanced triads forced the network to a more stable state with a lower balance energy level. The increase of balanced triads was crucially related to changes in anti-synchrony to synchronous activities between the Temporal Cortex, the Prefrontal Cortex, and the Parietal Cortex, which are known to be involved in various aspects of working memory, during the working memory process. We hope these findings pave the way to a better understanding the working memory process."
    },
    "2411.15386v1": {
      "title": "Inducing Human-like Biases in Moral Reasoning Language Models",
      "url": "http://arxiv.org/abs/2411.15386v1",
      "authors": "Artem Karpov, Seong Hah Cho, Austin Meek, Raymond Koopmanschap, Lucy Farnik, Bogdan-Ionut Cirstea",
      "update_time": "2024-11-23",
      "abstract": "In this work, we study the alignment (BrainScore) of large language models (LLMs) fine-tuned for moral reasoning on behavioral data and/or brain data of humans performing the same task. We also explore if fine-tuning several LLMs on the fMRI data of humans performing moral reasoning can improve the BrainScore. We fine-tune several LLMs (BERT, RoBERTa, DeBERTa) on moral reasoning behavioral data from the ETHICS benchmark [Hendrycks et al., 2020], on the moral reasoning fMRI data from Koster-Hale et al. [2013], or on both. We study both the accuracy on the ETHICS benchmark and the BrainScores between model activations and fMRI data. While larger models generally performed better on both metrics, BrainScores did not significantly improve after fine-tuning."
    },
    "2411.13378v1": {
      "title": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding",
      "url": "http://arxiv.org/abs/2411.13378v1",
      "authors": "Hoang-Quan Nguyen, Xuan-Bac Nguyen, Hugh Churchill, Arabinda Kumar Choudhary, Pawan Sinha, Samee U. Khan, Khoa Luu",
      "update_time": "2024-11-20",
      "abstract": "Vision-brain understanding aims to extract semantic information about brain signals from human perceptions. Existing deep learning methods for vision-brain understanding are usually introduced in a traditional learning paradigm missing the ability to learn the connectivities between brain regions. Meanwhile, the quantum computing theory offers a new paradigm for designing deep learning models. Motivated by the connectivities in the brain signals and the entanglement properties in quantum computing, we propose a novel Quantum-Brain approach, a quantum-inspired neural network, to tackle the vision-brain understanding problem. To compute the connectivity between areas in brain signals, we introduce a new Quantum-Inspired Voxel-Controlling module to learn the impact of a brain voxel on others represented in the Hilbert space. To effectively learn connectivity, a novel Phase-Shifting module is presented to calibrate the value of the brain signals. Finally, we introduce a new Measurement-like Projection module to present the connectivity information from the Hilbert space into the feature space. The proposed approach can learn to find the connectivities between fMRI voxels and enhance the semantic information obtained from human perceptions. Our experimental results on the Natural Scene Dataset benchmarks illustrate the effectiveness of the proposed method with Top-1 accuracies of 95.1% and 95.6% on image and brain retrieval tasks and an Inception score of 95.3% on fMRI-to-image reconstruction task. Our proposed quantum-inspired network brings a potential paradigm to solving the vision-brain problems via the quantum computing theory."
    },
    "2411.12321v1": {
      "title": "Enhancing Blind Source Separation with Dissociative Principal Component Analysis",
      "url": "http://arxiv.org/abs/2411.12321v1",
      "authors": "Muhammad Usman Khalid",
      "update_time": "2024-11-19",
      "abstract": "Sparse principal component analysis (sPCA) enhances the interpretability of principal components (PCs) by imposing sparsity constraints on loading vectors (LVs). However, when used as a precursor to independent component analysis (ICA) for blind source separation (BSS), sPCA may underperform due to its focus on simplicity, potentially disregarding some statistical information essential for effective ICA. To overcome this limitation, a sophisticated approach is proposed that preserves the interpretability advantages of sPCA while significantly enhancing its source extraction capabilities. This consists of two tailored algorithms, dissociative PCA (DPCA1 and DPCA2), which employ adaptive and firm thresholding alongside gradient and coordinate descent approaches to optimize the proposed model dynamically. These algorithms integrate left and right singular vectors from singular value decomposition (SVD) through dissociation matrices (DMs) that replace traditional singular values, thus capturing latent interdependencies effectively to model complex source relationships. This leads to refined PCs and LVs that more accurately represent the underlying data structure. The proposed approach avoids focusing on individual eigenvectors, instead, it collaboratively combines multiple eigenvectors to disentangle interdependencies within each SVD variate. The superior performance of the proposed DPCA algorithms is demonstrated across four varied imaging applications including functional magnetic resonance imaging (fMRI) source retrieval, foreground-background separation, image reconstruction, and image inpainting. They outperformed traditional methods such as PCA+ICA, PPCA+ICA, SPCA+ICA, PMD, and GPower."
    },
    "2411.10872v1": {
      "title": "In silico discovery of representational relationships across visual cortex",
      "url": "http://arxiv.org/abs/2411.10872v1",
      "authors": "Alessandro T. Gifford, Maya A. Jastrz\u0119bowska, Johannes J. D. Singer, Radoslaw M. Cichy",
      "update_time": "2024-11-16",
      "abstract": "Human vision is mediated by a complex interconnected network of cortical brain areas jointly representing visual information. While these areas are increasingly understood in isolation, their representational relationships remain elusive. Here we developed relational neural control (RNC), and used it to investigate the representational relationships for univariate and multivariate fMRI responses of early- and mid-level visual areas. RNC generated and explored in silico fMRI responses for large amounts of images, discovering controlling images that align or disentangle responses across areas, thus indicating their shared or unique representational content. A large portion of representational content was shared across areas, unique representational content increased with cortical distance, and we isolated the visual features determining these effects. Closing the empirical cycle, we validated the in silico discoveries on in vivo fMRI responses from independent subjects. Together, this reveals how visual areas jointly represent the world as an interconnected network."
    },
    "2411.09723v1": {
      "title": "Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations for Decoding, Encoding, and Modality Conversion",
      "url": "http://arxiv.org/abs/2411.09723v1",
      "authors": "Matteo Ferrante, Tommaso Boccato, Grigorii Rashkov, Nicola Toschi",
      "update_time": "2024-11-14",
      "abstract": "This paper presents a novel approach towards creating a foundational model for aligning neural data and visual stimuli across multimodal representationsof brain activity by leveraging contrastive learning. We used electroencephalography (EEG), magnetoencephalography (MEG), and functional magnetic resonance imaging (fMRI) data. Our framework's capabilities are demonstrated through three key experiments: decoding visual information from neural data, encoding images into neural representations, and converting between neural modalities. The results highlight the model's ability to accurately capture semantic information across different brain imaging techniques, illustrating its potential in decoding, encoding, and modality conversion tasks."
    },
    "2411.09098v1": {
      "title": "Interdependent scaling exponents in the human brain",
      "url": "http://arxiv.org/abs/2411.09098v1",
      "authors": "Daniel M. Castro, Ernesto P. Raposo, Mauro Copelli, Fernando A. N. Santos",
      "update_time": "2024-11-14",
      "abstract": "We apply the phenomenological renormalization group to resting-state fMRI time series of brain activity in a large population. By recursively coarse-graining the data, we compute scaling exponents for the series variance, log probability of silence, and largest covariance eigenvalue. The exponents clearly exhibit linear interdependencies, which we derive analytically in a mean-field approach. We find a significant correlation of exponent values with the gray matter volume and cognitive performance. Akin to scaling relations near critical points in thermodynamics, our findings suggest scaling interdependencies are intrinsic to brain organization and may also exist in other complex systems."
    },
    "2411.08973v1": {
      "title": "Somatosensory and motor contributions to emotion representation",
      "url": "http://arxiv.org/abs/2411.08973v1",
      "authors": "Marianne C. Reddan, Luke Chang, Philip Kragel, Tor D. Wager",
      "update_time": "2024-11-13",
      "abstract": "Emotion is often described as something people 'feel' in their bodies. Embodied emotion theorists propose that this connection is not purely linguistic; perceiving an emotion may require somatosensory and motor re-experiencing. However, it remains unclear whether self-reports of emotion-related bodily sensations (i.e., 'lump in my throat') are related to neural simulations of bodily action and sensation or whether they can be explained by cognitive appraisals or the visual features of socioemotional signals. To investigate this, participants (N = 21) were shown arousing emotional images that varied in valence, complexity, and content while undergoing fMRI scans. Participants then rated the images on a set of emotion appraisal scales and indicated where, on a body map, they experienced sensation in response to the image. To derive normative models of responses on these scales, a separate larger online sample online (N = 56 - 128) also rated these images. Representational similarity analysis (RSA) was used to compare the emotional content in the body maps with appraisals and visual features. A pairwise distance matrix between the body maps generated for each stimulus was then used in a whole brain voxel-wise searchlight analysis to identify brain regions which reflect the representational geometry of embodied emotion. This analysis revealed a network including bilateral primary somatosensory and motor cortices, precuneus, insula, and medial prefrontal cortex. The results of this study suggest that the relationship between emotion and the body is not purely conceptual: It is supported by sensorimotor cortical activations."
    },
    "2411.08424v1": {
      "title": "A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis",
      "url": "http://arxiv.org/abs/2411.08424v1",
      "authors": "Feiyu Yin, Yu Lei, Siyuan Dai, Wenwen Zeng, Guoqing Wu, Liang Zhan, Jinhua Yu",
      "update_time": "2024-11-13",
      "abstract": "Brain connectivity alternations associated with brain disorders have been widely reported in resting-state functional imaging (rs-fMRI) and diffusion tensor imaging (DTI). While many dual-modal fusion methods based on graph neural networks (GNNs) have been proposed, they generally follow homogenous fusion ways ignoring rich heterogeneity of dual-modal information. To address this issue, we propose a novel method that integrates functional and structural connectivity based on heterogeneous graph neural networks (HGNNs) to better leverage the rich heterogeneity in dual-modal images. We firstly use blood oxygen level dependency and whiter matter structure information provided by rs-fMRI and DTI to establish homo-meta-path, capturing node relationships within the same modality. At the same time, we propose to establish hetero-meta-path based on structure-function coupling and brain community searching to capture relations among cross-modal nodes. Secondly, we further introduce a heterogeneous graph pooling strategy that automatically balances homo- and hetero-meta-path, effectively leveraging heterogeneous information and preventing feature confusion after pooling. Thirdly, based on the flexibility of heterogeneous graphs, we propose a heterogeneous graph data augmentation approach that can conveniently address the sample imbalance issue commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset for mild cognitive impairment (MCI) diagnosis. Experimental results indicate the proposed method is effective and superior to other algorithms, with a mean classification accuracy of 93.3%."
    },
    "2411.07506v1": {
      "title": "FM-TS: Flow Matching for Time Series Generation",
      "url": "http://arxiv.org/abs/2411.07506v1",
      "authors": "Yang Hu, Xiao Wang, Lirong Wu, Huatian Zhang, Stan Z. Li, Sheng Wang, Tianlong Chen",
      "update_time": "2024-11-12",
      "abstract": "Time series generation has emerged as an essential tool for analyzing temporal data across numerous fields. While diffusion models have recently gained significant attention in generating high-quality time series, they tend to be computationally demanding and reliant on complex stochastic processes. To address these limitations, we introduce FM-TS, a rectified Flow Matching-based framework for Time Series generation, which simplifies the time series generation process by directly optimizing continuous trajectories. This approach avoids the need for iterative sampling or complex noise schedules typically required in diffusion-based models. FM-TS is more efficient in terms of training and inference. Moreover, FM-TS is highly adaptive, supporting both conditional and unconditional time series generation. Notably, through our novel inference design, the model trained in an unconditional setting can seamlessly generalize to conditional tasks without the need for retraining. Extensive benchmarking across both settings demonstrates that FM-TS consistently delivers superior performance compared to existing approaches while being more efficient in terms of training and inference. For instance, in terms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005, 0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI unconditional time series datasets, respectively, significantly outperforming the second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and 0.167 on the same datasets. We have achieved superior performance in solar forecasting and MuJoCo imputation tasks, significantly enhanced by our innovative $t$ power sampling method. The code is available at https://github.com/UNITES-Lab/FMTS.",
      "code_url": "https://github.com/unites-lab/fmts"
    }
  },
  "MEG": {
    "2411.09723v1": {
      "title": "Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations for Decoding, Encoding, and Modality Conversion",
      "url": "http://arxiv.org/abs/2411.09723v1",
      "authors": "Matteo Ferrante, Tommaso Boccato, Grigorii Rashkov, Nicola Toschi",
      "update_time": "2024-11-14",
      "abstract": "This paper presents a novel approach towards creating a foundational model for aligning neural data and visual stimuli across multimodal representationsof brain activity by leveraging contrastive learning. We used electroencephalography (EEG), magnetoencephalography (MEG), and functional magnetic resonance imaging (fMRI) data. Our framework's capabilities are demonstrated through three key experiments: decoding visual information from neural data, encoding images into neural representations, and converting between neural modalities. The results highlight the model's ability to accurately capture semantic information across different brain imaging techniques, illustrating its potential in decoding, encoding, and modality conversion tasks."
    },
    "2411.07994v1": {
      "title": "Search for the X17 particle in $^{7}\\mathrm{Li}(\\mathrm{p},\\mathrm{e}^+ \\mathrm{e}^{-}) ^{8}\\mathrm{Be}$ processes with the MEG II detector",
      "url": "http://arxiv.org/abs/2411.07994v1",
      "authors": "The MEG II collaboration, K. Afanaciev, A. M. Baldini, S. Ban, H. Benmansour, G. Boca, P. W. Cattaneo, G. Cavoto, F. Cei, M. Chiappini, A. Corvaglia, G. Dal Maso, A. De Bari, M. De Gerone, L. Ferrari Barusso, M. Francesconi, L. Galli, G. Gallucci, F. Gatti, L. Gerritzen, F. Grancagnolo, E. G. Grandoni, M. Grassi, D. N. Grigoriev, M. Hildebrandt, F. Ignatov, F. Ikeda, T. Iwamoto, S. Karpov, P. -R. Kettle, N. Khomutov, A. Kolesnikov, N. Kravchuk, V. Krylov, N. Kuchinskiy, F. Leonetti, W. Li, V. Malyshev, A. Matsushita, M. Meucci, S. Mihara, W. Molzon, T. Mori, D. Nicol\u00f2, H. Nishiguchi, A. Ochi, W. Ootani, A. Oya, D. Palo, M. Panareo, A. Papa, V. Pettinacci, A. Popov, F. Renga, S. Ritt, M. Rossella, A. Rozhdestvensky. S. Scarpellini, P. Schwendimann, G. Signorelli, M. Takahashi, Y. Uchiyama, A. Venturini, B. Vitali, C. Voena, K. Yamamoto, R. Yokota, T. Yonemoto",
      "update_time": "2024-11-12",
      "abstract": "The observation of a resonance structure in the opening angle of the electron-positron pairs in the $^{7}$Li(p,\\ee) $^{8}$Be reaction was claimed and interpreted as the production and subsequent decay of a hypothetical particle (X17). Similar excesses, consistent with this particle, were later observed in processes involving $^{4}$He and $^{12}$C nuclei with the same experimental technique. The MEG II apparatus at PSI, designed to search for the $\\mu^+ \\rightarrow \\mathrm{e}^+ \\gamma$ decay, can be exploited to investigate the existence of this particle and study its nature. Protons from a Cockroft-Walton accelerator, with an energy up to 1.1 MeV, were delivered on a dedicated Li-based target. The $\\gamma$ and the e$^{+}$e$^{-}$ pair emerging from the $^8\\mathrm{Be}^*$ transitions were studied with calorimeters and a spectrometer, featuring a broader angular acceptance than previous experiments. We present in this paper the analysis of a four-week data-taking in 2023 with a beam energy of 1080 keV, resulting in the excitation of two different resonances with Q-value \\SI{17.6}{\\mega\\electronvolt} and \\SI{18.1}{\\mega\\electronvolt}. No significant signal was found, and limits at \\SI{90}{\\percent} C.L. on the branching ratios (relative to the $\\gamma$ emission) of the two resonances to X17 were set, $R_{17.6} < 1.8 \\times 10^{-6} $ and $R_{18.1} < 1.2 \\times 10^{-5} $."
    },
    "2411.03883v2": {
      "title": "MEG: Medical Knowledge-Augmented Large Language Models for Question Answering",
      "url": "http://arxiv.org/abs/2411.03883v2",
      "authors": "Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders S\u00f8gaard, Carlos Bobed",
      "update_time": "2024-11-07",
      "abstract": "Question answering is a natural language understanding task that involves reasoning over both explicit context and unstated, relevant domain knowledge. Large language models (LLMs), which underpin most contemporary question answering systems, struggle to induce how concepts relate in specialized domains such as medicine. Existing medical LLMs are also costly to train. In this work, we present MEG, a parameter-efficient approach for medical knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate graph embeddings into the LLM, enabling it to leverage external knowledge in a cost-effective way. We evaluate our method on four popular medical multiple-choice datasets and show that LLMs greatly benefit from the factual grounding provided by knowledge graph embeddings. MEG attains an average of +10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized models like BioMistral. We also show results based on Llama-3. Finally, we show that MEG's performance remains robust to the choice of graph encoder.",
      "code_url": "https://github.com/lautel/meg"
    },
    "2410.23386v1": {
      "title": "STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG",
      "url": "http://arxiv.org/abs/2410.23386v1",
      "authors": "Raquel Fern\u00e1ndez-Mart\u00edn, Alfonso Gij\u00f3n, Odile Feys, Elodie Juven\u00e9, Alec Aeby, Charline Urbain, Xavier De Ti\u00e8ge, Vincent Wens",
      "update_time": "2024-10-30",
      "abstract": "Magnetoencephalography (MEG) allows the non-invasive detection of interictal epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients traditionally relies on the visual identification of IEDs, which is time consuming and partially subjective. Automatic, data-driven detection methods exist but show limited performance. Still, the rise of deep learning (DL)-with its ability to reproduce human-like abilities-could revolutionize clinical MEG practice. Here, we developed and validated STIED, a simple yet powerful supervised DL algorithm combining two convolutional neural networks with temporal (1D time-course) and spatial (2D topography) features of MEG signals inspired from current clinical guidelines. Our DL model enabled both temporal and spatial localization of IEDs in patients suffering from focal epilepsy with frequent and high amplitude spikes (FE group), with high-performance metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning from spatiotemporal features of IEDs. This performance can be attributed to our handling of input data, which mimics established clinical MEG practice. Reverse engineering further revealed that STIED encodes fine spatiotemporal features of IEDs rather than their mere amplitude. The model trained on the FE group also showed promising results when applied to a separate group of presurgical patients with different types of refractory focal epilepsy, though further work is needed to distinguish IEDs from physiological transients. This study paves the way of incorporating STIED and DL algorithms into the routine clinical MEG evaluation of epilepsy."
    },
    "2410.20916v1": {
      "title": "NeuGPT: Unified multi-modal Neural GPT",
      "url": "http://arxiv.org/abs/2410.20916v1",
      "authors": "Yiqian Yang, Yiqun Duan, Hyejeong Jo, Qiang Zhang, Renjing Xu, Oiwi Parker Jones, Xuming Hu, Chin-teng Lin, Hui Xiong",
      "update_time": "2024-10-28",
      "abstract": "This paper introduces NeuGPT, a groundbreaking multi-modal language generation model designed to harmonize the fragmented landscape of neural recording research. Traditionally, studies in the field have been compartmentalized by signal type, with EEG, MEG, ECoG, SEEG, fMRI, and fNIRS data being analyzed in isolation. Recognizing the untapped potential for cross-pollination and the adaptability of neural signals across varying experimental conditions, we set out to develop a unified model capable of interfacing with multiple modalities. Drawing inspiration from the success of pre-trained large models in NLP, computer vision, and speech processing, NeuGPT is architected to process a diverse array of neural recordings and interact with speech and text data. Our model mainly focus on brain-to-text decoding, improving SOTA from 6.94 to 12.92 on BLEU-1 and 6.93 to 13.06 on ROUGE-1F. It can also simulate brain signals, thereby serving as a novel neural interface. Code is available at \\href{https://github.com/NeuSpeech/NeuGPT}{NeuSpeech/NeuGPT (https://github.com/NeuSpeech/NeuGPT) .}",
      "code_url": "https://github.com/neuspeech/neugpt"
    },
    "2410.19986v1": {
      "title": "Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings",
      "url": "http://arxiv.org/abs/2410.19986v1",
      "authors": "Jeremiah Ridge, Oiwi Parker Jones",
      "update_time": "2024-10-25",
      "abstract": "Machine learning techniques have enabled researchers to leverage neuroimaging data to decode speech from brain activity, with some amazing recent successes achieved by applications built using invasive devices. However, research requiring surgical implants has a number of practical limitations. Non-invasive neuroimaging techniques provide an alternative but come with their own set of challenges, the limited scale of individual studies being among them. Without the ability to pool the recordings from different non-invasive studies, data on the order of magnitude needed to leverage deep learning techniques to their full potential remains out of reach. In this work, we focus on non-invasive data collected using magnetoencephalography (MEG). We leverage two different, leading speech decoding models to investigate how an adversarial domain adaptation framework augments their ability to generalize across datasets. We successfully improve the performance of both models when training across multiple datasets. To the best of our knowledge, this study is the first ever application of feature-level, deep learning based harmonization for MEG neuroimaging data. Our analysis additionally offers further evidence of the impact of demographic features on neuroimaging data, demonstrating that participant age strongly affects how machine learning models solve speech decoding tasks using MEG data. Lastly, in the course of this study we produce a new open-source implementation of one of these models to the benefit of the broader scientific community."
    },
    "2410.19838v1": {
      "title": "Non-invasive Neural Decoding in Source Reconstructed Brain Space",
      "url": "http://arxiv.org/abs/2410.19838v1",
      "authors": "Yonatan Gideoni, Ryan Charles Timms, Oiwi Parker Jones",
      "update_time": "2024-10-20",
      "abstract": "Non-invasive brainwave decoding is usually done using Magneto/Electroencephalography (MEG/EEG) sensor measurements as inputs. This makes combining datasets and building models with inductive biases difficult as most datasets use different scanners and the sensor arrays have a nonintuitive spatial structure. In contrast, fMRI scans are acquired directly in brain space, a voxel grid with a typical structured input representation. By using established techniques to reconstruct the sensors' sources' neural activity it is possible to decode from voxels for MEG data as well. We show that this enables spatial inductive biases, spatial data augmentations, better interpretability, zero-shot generalisation between datasets, and data harmonisation."
    },
    "2410.14971v1": {
      "title": "BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation",
      "url": "http://arxiv.org/abs/2410.14971v1",
      "authors": "Jilong Li, Zhenxi Song, Jiaqi Wang, Min Zhang, Zhiguo Zhang",
      "update_time": "2024-10-19",
      "abstract": "Recent advances in decoding language from brain signals (EEG and MEG) have been significantly driven by pre-trained language models, leading to remarkable progress on publicly available non-invasive EEG/MEG datasets. However, previous works predominantly utilize teacher forcing during text generation, leading to significant performance drops without its use. A fundamental issue is the inability to establish a unified feature space correlating textual data with the corresponding evoked brain signals. Although some recent studies attempt to mitigate this gap using an audio-text pre-trained model, Whisper, which is favored for its signal input modality, they still largely overlook the inherent differences between audio signals and brain signals in directly applying Whisper to decode brain signals. To address these limitations, we propose a new multi-stage strategy for semantic brain signal decoding via vEctor-quantized speCtrogram reconstruction for WHisper-enhanced text generatiOn, termed BrainECHO. Specifically, BrainECHO successively conducts: 1) Discrete autoencoding of the audio spectrogram; 2) Brain-audio latent space alignment; and 3) Semantic text generation via Whisper finetuning. Through this autoencoding--alignment--finetuning process, BrainECHO outperforms state-of-the-art methods under the same data split settings on two widely accepted resources: the EEG dataset (Brennan) and the MEG dataset (GWilliams). The innovation of BrainECHO, coupled with its robustness and superiority at the sentence, session, and subject-independent levels across public datasets, underscores its significance for language-based brain-computer interfaces."
    },
    "2410.08718v1": {
      "title": "Determining sensor geometry and gain in a wearable MEG system",
      "url": "http://arxiv.org/abs/2410.08718v1",
      "authors": "Ryan M. Hill, Gonzalo Reina Rivero, Ashley J. Tyler, Holly Schofield, Cody Doyle, James Osborne, David Bobela, Lukas Rier, Joseph Gibson, Zoe Tanner, Elena Boto, Richard Bowtell, Matthew J. Brookes, Vishal Shah, Niall Holmes",
      "update_time": "2024-10-11",
      "abstract": "Optically pumped magnetometers (OPMs) are compact and lightweight sensors that can measure magnetic fields generated by current flow in neuronal assemblies in the brain. Such sensors enable construction of magnetoencephalography (MEG) instrumentation, with significant advantages over conventional MEG devices including adaptability to head size, enhanced movement tolerance, lower complexity and improved data quality. However, realising the potential of OPMs depends on our ability to perform system calibration, which means finding sensor locations, orientations, and the relationship between the sensor output and magnetic field (termed sensor gain). Such calibration is complex in OPMMEG since, for example, OPM placement can change from subject to subject (unlike in conventional MEG where sensor locations or orientations are fixed). Here, we present two methods for calibration, both based on generating well-characterised magnetic fields across a sensor array. Our first device (the HALO) is a head mounted system that generates dipole like fields from a set of coils. Our second (the matrix coil (MC)) generates fields using coils embedded in the walls of a magnetically shielded room. Our results show that both methods offer an accurate means to calibrate an OPM array (e.g. sensor locations within 2 mm of the ground truth) and that the calibrations produced by the two methods agree strongly with each other. When applied to data from human MEG experiments, both methods offer improved signal to noise ratio after beamforming suggesting that they give calibration parameters closer to the ground truth than factory settings and presumed physical sensor coordinates and orientations. Both techniques are practical and easy to integrate into real world MEG applications. This advances the field significantly closer to the routine use of OPMs for MEG recording."
    },
    "2410.03191v2": {
      "title": "Nested Deep Learning Model Towards A Foundation Model for Brain Signal Data",
      "url": "http://arxiv.org/abs/2410.03191v2",
      "authors": "Fangyi Wei, Jiajie Mo, Kai Zhang, Haipeng Shen, Srikantan Nagarajan, Fei Jiang",
      "update_time": "2024-10-09",
      "abstract": "Epilepsy affects over 50 million people globally, with EEG/MEG-based spike detection playing a crucial role in diagnosis and treatment. Manual spike identification is time-consuming and requires specialized training, limiting the number of professionals available to analyze EEG/MEG data. To address this, various algorithmic approaches have been developed. However, current methods face challenges in handling varying channel configurations and in identifying the specific channels where spikes originate. This paper introduces a novel Nested Deep Learning (NDL) framework designed to overcome these limitations. NDL applies a weighted combination of signals across all channels, ensuring adaptability to different channel setups, and allows clinicians to identify key channels more accurately. Through theoretical analysis and empirical validation on real EEG/MEG datasets, NDL demonstrates superior accuracy in spike detection and channel localization compared to traditional methods. The results show that NDL improves prediction accuracy, supports cross-modality data integration, and can be fine-tuned for various neurophysiological applications."
    }
  },
  "neuroAI": {
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research."
    },
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2302.07243v4": {
      "title": "A Deep Probabilistic Spatiotemporal Framework for Dynamic Graph Representation Learning with Application to Brain Disorder Identification",
      "url": "http://arxiv.org/abs/2302.07243v4",
      "authors": "Sin-Yee Yap, Junn Yong Loo, Chee-Ming Ting, Fuad Noman, Raphael C. -W. Phan, Adeel Razi, David L. Dowe",
      "update_time": "2024-11-09",
      "abstract": "Recent applications of pattern recognition techniques on brain connectome classification using functional connectivity (FC) are shifting towards acknowledging the non-Euclidean topology and dynamic aspects of brain connectivity across time. In this paper, a deep spatiotemporal variational Bayes (DSVB) framework is proposed to learn time-varying topological structures in dynamic FC networks for identifying autism spectrum disorder (ASD) in human participants. The framework incorporates a spatial-aware recurrent neural network with an attention-based message passing scheme to capture rich spatiotemporal patterns across dynamic FC networks. To overcome model overfitting on limited training datasets, an adversarial training strategy is introduced to learn graph embedding models that generalize well to unseen brain networks. Evaluation on the ABIDE resting-state functional magnetic resonance imaging dataset shows that our proposed framework substantially outperforms state-of-the-art methods in identifying patients with ASD. Dynamic FC analyses with DSVB-learned embeddings reveal apparent group differences between ASD and healthy controls in brain network connectivity patterns and switching dynamics of brain states. The code is available at https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes.",
      "code_url": "https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes"
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    }
  },
  "medical": {
    "2411.16637v1": {
      "title": "Automated Registration of 3D Neurovascular Territory Atlas to 2D DSA for Targeted Quantitative Angiography Analysis",
      "url": "http://arxiv.org/abs/2411.16637v1",
      "authors": "George Dimopoulos, Sabrina De Los Angeles Reverol Parra, Parmita Mondal, Michael Udin, Kyle Williams, Parisa Naghdi, Ahmad Rahmatpour, Swetadri Vasan Setlur Nagesh, Mohammad Mahdi Shiraz Bhurwani, Jason Davies, Ciprian N. Ionita",
      "update_time": "2024-11-25",
      "abstract": "Subarachnoid hemorrhage (SAH), typically due to intracranial aneurysms, demands precise imaging for effective treatment. Digital Subtraction Angiography (DSA), despite being the gold standard, broadly visualizes cerebral blood flow, potentially masking key details in areas. This study introduces an approach integrating a 3D vascular atlas with 2D DSA images to allow targeted quantitative analysis in these crucial regions, thus enhancing diagnostic accuracy during interventions. Initially, DSA data was examined to ascertain the injection site. Following this, the appropriate viewing angle was determined to align accurately with the 3D vascular atlas. Utilizing this atlas, regions corresponding to the areas indicated as perfused were selected. Concurrently, a mask representing the perfused areas was created from the DSA sequence. This mask facilitated the initial coarse alignment of the projected 3D atlas to the DSA perfused territory deformable registration techniques, ensuring a precise overlay with the DSAs perfused territories. The performance of each overlay was measured using the Structural Similarity Index Measure (SSIM). The coregistration process revealed that deformable registrations was essential to achieve precise overlays of the 3D atlas projections with the 2D DSA perfused areas. This approach enabled the extraction of targeted quantitative angiography parameters, essential for detailed vascular assessment in subarachnoid hemorrhage cases. The integration of 3D atlas registration with 2D DSA projections facilitates a more precise and targeted diagnostic process for SAH during critical interventions. This image processing strategy enhances the visualization of affected arterial territories, potentially improving the accuracy of diagnostics and supporting better informed clinical decisions at the time of intervention"
    },
    "2411.16568v1": {
      "title": "J-CaPA : Joint Channel and Pyramid Attention Improves Medical Image Segmentation",
      "url": "http://arxiv.org/abs/2411.16568v1",
      "authors": "Marzia Binta Nizam, Marian Zlateva, James Davis",
      "update_time": "2024-11-25",
      "abstract": "Medical image segmentation is crucial for diagnosis and treatment planning. Traditional CNN-based models, like U-Net, have shown promising results but struggle to capture long-range dependencies and global context. To address these limitations, we propose a transformer-based architecture that jointly applies Channel Attention and Pyramid Attention mechanisms to improve multi-scale feature extraction and enhance segmentation performance for medical images. Increasing model complexity requires more training data, and we further improve model generalization with CutMix data augmentation. Our approach is evaluated on the Synapse multi-organ segmentation dataset, achieving a 6.9% improvement in Mean Dice score and a 39.9% improvement in Hausdorff Distance (HD95) over an implementation without our enhancements. Our proposed model demonstrates improved segmentation accuracy for complex anatomical structures, outperforming existing state-of-the-art methods."
    },
    "2411.16551v1": {
      "title": "Coherence Based Sound Speed Aberration Correction -- with clinical validation in obstetric ultrasound",
      "url": "http://arxiv.org/abs/2411.16551v1",
      "authors": "Anders Emil Vr\u00e5lstad, Peter Fosodeder, Karin Ulrike Deibele, Ole Marius Hoel Rindal, Martin Mienkina, Svein-Erik M\u00e5s\u00f8y",
      "update_time": "2024-11-25",
      "abstract": "The purpose of this work is to demonstrate a robust and clinically validated method for correcting sound speed aberrations in medical ultrasound. We propose a correction method that calculates focusing delays directly from the observed two-way distributed average sound speed. The method beamforms multiple coherence images and selects the sound speed that maximizes the coherence for each image pixel. The main contribution of this work is the direct estimation of aberration, without the ill-posed inversion of a local sound speed map, and the proposed processing of coherence images which adapts to in vivo situations where low coherent regions and off-axis scattering represents a challenge. The method is validated in vitro and in silico showing high correlation with ground truth speed of sound maps. Further, the method is clinically validated by being applied to channel data recorded from 172 obstetric Bmode images, and 12 case examples are presented and discussed in detail. The data is recorded with a GE HealthCare Voluson Expert 22 system with an eM6c matrix array probe. The images are evaluated by three expert clinicians, and the results show that the corrected images are preferred or gave equivalent quality to no correction (1540m/s) for 72.5% of the 172 images. In addition, a sharpness metric from digital photography is used to quantify image quality improvement. The increase in sharpness and the change in average sound speed are shown to be linearly correlated with a Pearson Correlation Coefficient of 0.67."
    },
    "2411.16535v1": {
      "title": "ADOBI: Adaptive Diffusion Bridge For Blind Inverse Problems with Application to MRI Reconstruction",
      "url": "http://arxiv.org/abs/2411.16535v1",
      "authors": "Yuyang Hu, Albert Peng, Weijie Gan, Ulugbek S. Kamilov",
      "update_time": "2024-11-25",
      "abstract": "Diffusion bridges (DB) have emerged as a promising alternative to diffusion models for imaging inverse problems, achieving faster sampling by directly bridging low- and high-quality image distributions. While incorporating measurement consistency has been shown to improve performance, existing DB methods fail to maintain this consistency in blind inverse problems, where the forward model is unknown. To address this limitation, we introduce ADOBI (Adaptive Diffusion Bridge for Inverse Problems), a novel framework that adaptively calibrates the unknown forward model to enforce measurement consistency throughout sampling iterations. Our adaptation strategy allows ADOBI to achieve high-quality parallel magnetic resonance imaging (PMRI) reconstruction in only 5-10 steps. Our numerical results show that ADOBI consistently delivers state-of-the-art performance, and further advances the Pareto frontier for the perception-distortion trade-off."
    },
    "2411.16512v1": {
      "title": "Guarding the Gate: ConceptGuard Battles Concept-Level Backdoors in Concept Bottleneck Models",
      "url": "http://arxiv.org/abs/2411.16512v1",
      "authors": "Songning Lai, Yu Huang, Jiayu Yang, Gaoxiang Huang, Wenshuo Chen, Yutao Yue",
      "update_time": "2024-11-25",
      "abstract": "The increasing complexity of AI models, especially in deep learning, has raised concerns about transparency and accountability, particularly in high-stakes applications like medical diagnostics, where opaque models can undermine trust. Explainable Artificial Intelligence (XAI) aims to address these issues by providing clear, interpretable models. Among XAI techniques, Concept Bottleneck Models (CBMs) enhance transparency by using high-level semantic concepts. However, CBMs are vulnerable to concept-level backdoor attacks, which inject hidden triggers into these concepts, leading to undetectable anomalous behavior. To address this critical security gap, we introduce ConceptGuard, a novel defense framework specifically designed to protect CBMs from concept-level backdoor attacks. ConceptGuard employs a multi-stage approach, including concept clustering based on text distance measurements and a voting mechanism among classifiers trained on different concept subgroups, to isolate and mitigate potential triggers. Our contributions are threefold: (i) we present ConceptGuard as the first defense mechanism tailored for concept-level backdoor attacks in CBMs; (ii) we provide theoretical guarantees that ConceptGuard can effectively defend against such attacks within a certain trigger size threshold, ensuring robustness; and (iii) we demonstrate that ConceptGuard maintains the high performance and interpretability of CBMs, crucial for trustworthiness. Through comprehensive experiments and theoretical proofs, we show that ConceptGuard significantly enhances the security and trustworthiness of CBMs, paving the way for their secure deployment in critical applications."
    },
    "2411.16450v1": {
      "title": "Model-Based Perfusion Reconstruction with Time Separation Technique in Cone-Beam CT Dynamic Liver Perfusion Imaging",
      "url": "http://arxiv.org/abs/2411.16450v1",
      "authors": "Hana Haselji\u0107, Robert Frysch, Vojt\u011bch Kulvait, Thomas Werncke, Inga Brusch, Oliver Speck, Jessica Schulz, Michael Manhart, Georg Rose",
      "update_time": "2024-11-25",
      "abstract": "The success of embolisation, a minimally invasive treatment of liver cancer, could be evaluated in the operational room with cone-beam CT by acquiring a dynamic perfusion scan. The reconstruction algorithm must address the issues of low temporal sampling and higher noise levels inherent in cone-beam CT systems, compared to conventional CT. Therefore, a model-based perfusion reconstruction based on the time separation technique (TST) was applied. TST uses basis functions to model time attenuation curves. These functions are either analytical or based on prior knowledge, extracted using singular value decomposition from CT perfusion data. To explore how well the prior knowledge can model perfusion dynamics and what the potential limitations are, the dynamic CBCT perfusion scan was simulated under different noise levels. The TST method was compared to static reconstruction. It was demonstrated that a set consisting of only four basis functions results in perfusion maps that preserve relevant information, denoises the data, and outperforms static reconstruction under higher noise levels. TST with prior knowledge would not only outperform static reconstruction, but also the TST with analytical basis functions. Furthermore, it has been shown that only eight CBCT rotations, unlike previously assumed ten, are sufficient to obtain the perfusion maps comparable to the reference CT perfusion maps. This contributes to saving dose and reconstruction time. The real dynamic CBCT perfusion scan, reconstructed under the same conditions as the simulated scan, shows potential for maintaining the accuracy of the perfusion maps. By visual inspection, the embolised region was matching to that in corresponding CT perfusion maps. Further analysis of a larger cohort of patient data is needed to draw final conclusions regarding the expected advantages of the time separation technique."
    },
    "2411.16380v1": {
      "title": "Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence",
      "url": "http://arxiv.org/abs/2411.16380v1",
      "authors": "Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li",
      "update_time": "2024-11-25",
      "abstract": "Ultrasound imaging is widely used in clinical diagnosis due to its non-invasive nature and real-time capabilities. However, conventional ultrasound diagnostics face several limitations, including high dependence on physician expertise and suboptimal image quality, which complicates interpretation and increases the likelihood of diagnostic errors. Artificial intelligence (AI) has emerged as a promising solution to enhance clinical diagnosis, particularly in detecting abnormalities across various biomedical imaging modalities. Nonetheless, current AI models for ultrasound imaging face critical challenges. First, these models often require large volumes of labeled medical data, raising concerns over patient privacy breaches. Second, most existing models are task-specific, which restricts their broader clinical utility. To overcome these challenges, we present UltraFedFM, an innovative privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively pre-trained using federated learning across 16 distributed medical institutions in 9 countries, leveraging a dataset of over 1 million ultrasound images covering 19 organs and 10 ultrasound modalities. This extensive and diverse data, combined with a secure training framework, enables UltraFedFM to exhibit strong generalization and diagnostic capabilities. It achieves an average area under the receiver operating characteristic curve of 0.927 for disease diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation. Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level ultrasonographers and matches the performance of expert-level sonographers in the joint diagnosis of 8 common systemic diseases. These findings indicate that UltraFedFM can significantly enhance clinical diagnostics while safeguarding patient privacy, marking an advancement in AI-driven ultrasound imaging for future clinical applications."
    },
    "2411.16349v1": {
      "title": "Machine learning for cerebral blood vessels' malformations",
      "url": "http://arxiv.org/abs/2411.16349v1",
      "authors": "Irem Topal, Alexander Cherevko, Yuri Bugay, Maxim Shishlenin, Jean Barbier, Deniz Eroglu, \u00c9dgar Rold\u00e1n, Roman Belousov",
      "update_time": "2024-11-25",
      "abstract": "Cerebral aneurysms and arteriovenous malformations are life-threatening hemodynamic pathologies of the brain. While surgical intervention is often essential to prevent fatal outcomes, it carries significant risks both during the procedure and in the postoperative period, making the management of these conditions highly challenging. Parameters of cerebral blood flow, routinely monitored during medical interventions, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis. To this end, we developed a linear oscillatory model of blood velocity and pressure for clinical data acquired from neurosurgical operations. Using the method of Sparse Identification of Nonlinear Dynamics (SINDy), the parameters of our model can be reconstructed online within milliseconds from a short time series of the hemodynamic variables. The identified parameter values enable automated classification of the blood-flow pathologies by means of logistic regression, achieving an accuracy of 73 %. Our results demonstrate the potential of this model for both diagnostic and prognostic applications, providing a robust and interpretable framework for assessing cerebral blood vessel conditions."
    },
    "2411.16346v1": {
      "title": "Towards Foundation Models for Critical Care Time Series",
      "url": "http://arxiv.org/abs/2411.16346v1",
      "authors": "Manuel Burger, Fedor Sergeev, Malte Londschien, Daphn\u00e9 Chopard, Hugo Y\u00e8che, Eike Gerdes, Polina Leshetkina, Alexander Morgenroth, Zeynep Bab\u00fcr, Jasmina Bogojeska, Martin Faltys, Rita Kuznetsova, Gunnar R\u00e4tsch",
      "update_time": "2024-11-25",
      "abstract": "Notable progress has been made in generalist medical large language models across various healthcare areas. However, large-scale modeling of in-hospital time series data - such as vital signs, lab results, and treatments in critical care - remains underexplored. Existing datasets are relatively small, but combining them can enhance patient diversity and improve model robustness. To effectively utilize these combined datasets for large-scale modeling, it is essential to address the distribution shifts caused by varying treatment policies, necessitating the harmonization of treatment variables across the different datasets. This work aims to establish a foundation for training large-scale multi-variate time series models on critical care data and to provide a benchmark for machine learning models in transfer learning across hospitals to study and address distribution shift challenges. We introduce a harmonized dataset for sequence modeling and transfer learning research, representing the first large-scale collection to include core treatment variables. Future plans involve expanding this dataset to support further advancements in transfer learning and the development of scalable, generalizable models for critical healthcare applications."
    },
    "2411.16314v1": {
      "title": "Oriented histogram-based vector field embedding for characterizing 4D CT data sets in radiotherapy",
      "url": "http://arxiv.org/abs/2411.16314v1",
      "authors": "Frederic Madesta, Lukas Wimmert, Tobias Gauer, Ren\u00e9 Werner, Thilo Sentker",
      "update_time": "2024-11-25",
      "abstract": "In lung radiotherapy, the primary objective is to optimize treatment outcomes by minimizing exposure to healthy tissues while delivering the prescribed dose to the target volume. The challenge lies in accounting for lung tissue motion due to breathing, which impacts precise treatment alignment. To address this, the paper proposes a prospective approach that relies solely on pre-treatment information, such as planning CT scans and derived data like vector fields from deformable image registration. This data is compared to analogous patient data to tailor treatment strategies, i.e., to be able to review treatment parameters and success for similar patients. To allow for such a comparison, an embedding and clustering strategy of prospective patient data is needed. Therefore, the main focus of this study lies on reducing the dimensionality of deformable registration-based vector fields by employing a voxel-wise spherical coordinate transformation and a low-dimensional 2D oriented histogram representation. Afterwards, a fully unsupervised UMAP embedding of the encoded vector fields (i.e., patient-specific motion information) becomes applicable. The functionality of the proposed method is demonstrated with 71 in-house acquired 4D CT data sets and 33 external 4D CT data sets. A comprehensive analysis of the patient clusters is conducted, focusing on the similarity of breathing patterns of clustered patients. The proposed general approach of reducing the dimensionality of registration vector fields by encoding the inherent information into oriented histograms is, however, applicable to other tasks."
    }
  }
}