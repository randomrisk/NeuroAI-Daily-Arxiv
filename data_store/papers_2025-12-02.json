{
  "Brain": {
    "2511.23384v1": {
      "title": "Improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in the context of the 2024 Cybathlon",
      "url": "http://arxiv.org/abs/2511.23384v1",
      "authors": "Isabel Whiteley Tscherniak, Niels Christopher Thiemann, Ana McWhinney-Fern\u00e1ndez, Iustin Curcean, Leon Jokinen, Sadat Hodzic, Thomas E. Huber, Daniel Pavlov, Manuel Methasani, Pietro Marcolongo, Glenn Viktor Krafczyk, Oscar Osvaldo Soto Rivera, Thien Le, Flaminia Pallotti, Enrico A. Fazzi, neuroTUM e.",
      "update_time": "2025-11-28",
      "abstract": "Motivated by the Cybathlon 2024 competition, we developed a modular, online EEG-based brain-computer interface to address these challenges, increasing accessibility for individuals with severe mobility impairments. Our system uses three mental and motor imagery classes to control up to five control signals. The pipeline consists of four modules: data acquisition, preprocessing, classification, and the transfer function to map classification output to control dimensions. We use three diagonalized structured state-space sequence layers as a deep learning classifier. We developed a training game for our pilot where the mental tasks control the game during quick-time events. We implemented a mobile web application for live user feedback. The components were designed with a human-centred approach in collaboration with the tetraplegic user. We achieve up to 84% classification accuracy in offline analysis using an S4D-layer-based model. In a competition setting, our pilot successfully completed one task; we attribute the reduced performance in this context primarily to factors such as stress and the challenging competition environment. Following the Cybathlon, we further validated our pipeline with the original pilot and an additional participant, achieving a success rate of 73% in real-time gameplay. We also compare our model to the EEGEncoder, which is slower in training but has a higher performance. The S4D model outperforms the reference machine learning models. We provide insights into developing a framework for portable BCIs, bridging the gap between the laboratory and daily life. Specifically, our framework integrates modular design, real-time data processing, user-centred feedback, and low-cost hardware to deliver an accessible and adaptable BCI solution, addressing critical gaps in current BCI applications.",
      "code_url": null
    },
    "2511.23331v1": {
      "title": "Optimization and application of ultra-high field preclinical high-resolution and 3D 1H-MRSI using compressed sensing",
      "url": "http://arxiv.org/abs/2511.23331v1",
      "authors": "Brayan Alves, Thanh Phong L\u00ea, Gianna Nossa, Tan Toi Phan, Alessio Siviglia, Bernard Lanz, Wolfgang Bogner, Antoine Klauser, Bernhard Strasser, Cristina Cudalbu",
      "update_time": "2025-11-28",
      "abstract": "Proton magnetic resonance spectroscopic imaging (1H-MRSI) at ultra-high field has seen an increase in usage in the preclinical field. Challenges related to long acquisition time and low concentration of brain metabolites in the rodent brain have led to the development and application of acceleration schemes for 3D-1H-MRSI, such the undersampling technique Compressed Sensing (CS). This present study aims to explore the CS tool in the context of preclinical in vivo application in order to achieve high-resolution MRSI acquisition in both 2D with an in-plane increase and 3D/multi-slice acquisition with through-plane. The parameters are explored to achieve the highest acceleration possible as a way to make 3D as time efficient as possible. Results of the parameter study showed that an acceleration factor (AF) of 4 was possible with the right sampling size of the core at the center of the k-space. With this specific set, higher matrix size resulting in sub 1 \u03bcL nominal voxel size was explored with 2D-FID-MRSI and 9 supplementary phase-encoding/slices were added to achieve 3D-FID-MRSI. The spectral quality and the metabolic maps were accurate enough in the comparison with the non-accelerated 2D-FID-MRSI, within the slice of interest. Issues related with the point spread function (PSF) were noted throughout the different usage of CS. Our work presents a robust and effective protocol to achieve 3D-1H-MRSI using CS in order to reach an acquisition time below the 30 minutes bar, with minimal technical limitations and high-quality acquisition.",
      "code_url": null
    },
    "2511.23274v1": {
      "title": "Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI",
      "url": "http://arxiv.org/abs/2511.23274v1",
      "authors": "Georgia Kanli, Daniele Perlo, Selma Boudissa, Radovan Jirik, Olivier Keunen",
      "update_time": "2025-11-28",
      "abstract": "MR data are acquired in the frequency domain, known as k-space. Acquiring high-quality and high-resolution MR images can be time-consuming, posing a significant challenge when multiple sequences providing complementary contrast information are needed or when the patient is unable to remain in the scanner for an extended period of time. Reducing k-space measurements is a strategy to speed up acquisition, but often leads to reduced quality in reconstructed images. Additionally, in real-world MRI, both under-sampled and full-sampled images are prone to artefacts, and correcting these artefacts is crucial for maintaining diagnostic accuracy. Deep learning methods have been proposed to restore image quality from under-sampled data, while others focused on the correction of artefacts that result from the noise or motion. No approach has however been proposed so far that addresses both acceleration and artefacts correction, limiting the performance of these models when these degradation factors occur simultaneously. To address this gap, we present a method for recovering high-quality images from under-sampled data with simultaneously correction for noise and motion artefact called USArt (Under-Sampling and Artifact correction model). Customized for 2D brain anatomical images acquired with Cartesian sampling, USArt employs a dual sub-model approach. The results demonstrate remarkable increase of signal-to-noise ratio (SNR) and contrast in the images restored. Various under-sampling strategies and degradation levels were explored, with the gradient under-sampling strategy yielding the best outcomes. We achieved up to 5x acceleration and simultaneously artefacts correction without significant degradation, showcasing the model's robustness in real-world settings.",
      "code_url": null
    },
    "2511.23162v1": {
      "title": "Estimating the Event-Related Potential from Few EEG Trials",
      "url": "http://arxiv.org/abs/2511.23162v1",
      "authors": "Anders Vestergaard N\u00f8rskov, Kasper J\u00f8rgensen, Alexander Neergaard Zahid, Morten M\u00f8rup",
      "update_time": "2025-11-28",
      "abstract": "Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP",
      "code_url": null
    },
    "2511.23142v1": {
      "title": "Adapting Neural Audio Codecs to EEG",
      "url": "http://arxiv.org/abs/2511.23142v1",
      "authors": "Ard Kastrati, Luca Lanzend\u00f6rfer, Riccardo Rigoni, John Staib Matilla, Roger Wattenhofer",
      "update_time": "2025-11-28",
      "abstract": "EEG and audio are inherently distinct modalities, differing in sampling rate, channel structure, and scale. Yet, we show that pretrained neural audio codecs can serve as effective starting points for EEG compression, provided that the data are preprocessed to be suitable to the codec's input constraints. Using DAC, a state-of-the-art neural audio codec as our base, we demonstrate that raw EEG can be mapped into the codec's stride-based framing, enabling direct reuse of the audio-pretrained encoder-decoder. Even without modification, this setup yields stable EEG reconstructions, and fine-tuning on EEG data further improves fidelity and generalization compared to training from scratch. We systematically explore compression-quality trade-offs by varying residual codebook depth, codebook (vocabulary) size, and input sampling rate. To capture spatial dependencies across electrodes, we propose DAC-MC, a multi-channel extension with attention-based cross-channel aggregation and channel-specific decoding, while retaining the audio-pretrained initialization. Evaluations on the TUH Abnormal and Epilepsy datasets show that the adapted codecs preserve clinically relevant information, as reflected in spectrogram-based reconstruction loss and downstream classification accuracy.",
      "code_url": null
    },
    "2511.23135v1": {
      "title": "Strategies to Minimize Out-of-Distribution Effects in Data-Driven MRS Quantification",
      "url": "http://arxiv.org/abs/2511.23135v1",
      "authors": "Julian P. Merkofer, Antonia Kaiser, Anouk Schrantee, Oliver J. Gurney-Champion, Ruud J. G. van Sloun",
      "update_time": "2025-11-28",
      "abstract": "This study systematically compared data-driven and model-based strategies for metabolite quantification in magnetic resonance spectroscopy (MRS), focusing on resilience to out-of-distribution (OoD) effects and the balance between accuracy, robustness, and generalizability. A neural network designed for MRS quantification was trained using three distinct strategies: supervised regression, self-supervised learning, and test-time adaptation. These were compared against model-based fitting tools. Experiments combined large-scale simulated data, designed to probe metabolite concentration extrapolation and signal variability, with 1H single-voxel 7T in-vivo human brain spectra. In simulations, supervised learning achieved high accuracy for spectra similar to those in the training distribution, but showed marked degradation when extrapolated beyond the training distribution. Test-time adaptation proved more resilient to OoD effects, while self-supervised learning achieved intermediate performance. In-vivo experiments showed larger variance across the methods (data-driven and model-based) due to domain shift. Across all strategies, overlapping metabolites and baseline variability remained persistent challenges. While strong performance can be achieved by data-driven methods for MRS metabolite quantification, their reliability is contingent on careful consideration of the training distribution and potential OoD effects. When such conditions in the target distribution cannot be anticipated, test-time adaptation strategies ensure consistency between the quantification, the data, and the model, enabling reliable data-driven MRS pipelines.",
      "code_url": null
    },
    "2511.22889v1": {
      "title": "The Immutable Tensor Architecture: A Pure Dataflow Approach for Secure, Energy-Efficient AI Inference",
      "url": "http://arxiv.org/abs/2511.22889v1",
      "authors": "Fang Li",
      "update_time": "2025-11-28",
      "abstract": "The deployment of Large Language Models (LLMs) on consumer edge devices is throttled by the \"Memory Wall\" -- the prohibitive bandwidth and energy cost of fetching gigabytes of model weights from DRAM for every token generated. Current architectures (GPUs, NPUs) treat model weights as mutable software data, incurring massive energy penalties to maintain general-purpose programmability. We propose The Immutable Tensor Architecture (ITA), a paradigm shift that treats model weights not as data, but as physical circuit topology. By encoding parameters directly into the metal interconnects and logic of mature-node ASICs (28nm/40nm), ITA eliminates the memory hierarchy entirely. We present a \"Split-Brain\" system design where a host CPU manages dynamic KV-cache operations while the ITA ASIC acts as a stateless, ROM-embedded dataflow engine.",
      "code_url": null
    },
    "2511.22870v1": {
      "title": "Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis",
      "url": "http://arxiv.org/abs/2511.22870v1",
      "authors": "Jungwoo Seo, David Keetae Park, Shinjae Yoo, Jiook Cha",
      "update_time": "2025-11-28",
      "abstract": "Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models.",
      "code_url": null
    },
    "2511.22828v1": {
      "title": "Fast dynamical similarity analysis",
      "url": "http://arxiv.org/abs/2511.22828v1",
      "authors": "Arman Behrad, Mitchell Ostrow, Mohammad Taha Fakharian, Ila Fiete, Christian Beste, Shervin Safavi",
      "update_time": "2025-11-28",
      "abstract": "To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.",
      "code_url": null
    },
    "2511.22606v1": {
      "title": "Hard Spatial Gating for Precision-Driven Brain Metastasis Segmentation: Addressing the Over-Segmentation Paradox in Deep Attention Networks",
      "url": "http://arxiv.org/abs/2511.22606v1",
      "authors": "Rowzatul Zannath Prerona",
      "update_time": "2025-11-27",
      "abstract": "Brain metastasis segmentation in MRI remains a formidable challenge due to diminutive lesion sizes (5-15 mm) and extreme class imbalance (less than 2% tumor volume). While soft-attention CNNs are widely used, we identify a critical failure mode termed the \"over-segmentation paradox,\" where models achieve high sensitivity (recall > 0.88) but suffer from catastrophic precision collapse (precision < 0.23) and boundary errors exceeding 150 mm. This imprecision poses significant risks for stereotactic radiosurgery planning. To address this, we introduce the Spatial Gating Network (SG-Net), a precision-first architecture employing hard spatial gating mechanisms. Unlike traditional soft attention, SG-Net enforces strict feature selection to aggressively suppress background artifacts while preserving tumor features. Validated on the Brain-Mets-Lung-MRI dataset (n=92), SG-Net achieves a Dice Similarity Coefficient of 0.5578 +/- 0.0243 (95% CI: 0.45-0.67), statistically outperforming Attention U-Net (p < 0.001) and ResU-Net (p < 0.001). Most critically, SG-Net demonstrates a threefold improvement in boundary precision, achieving a 95% Hausdorff Distance of 56.13 mm compared to 157.52 mm for Attention U-Net, while maintaining robust recall (0.79) and superior precision (0.52 vs. 0.20). Furthermore, SG-Net requires only 0.67M parameters (8.8x fewer than Attention U-Net), facilitating deployment in resource-constrained environments. These findings establish hard spatial gating as a robust solution for precision-driven lesion detection, directly enhancing radiosurgery accuracy.",
      "code_url": null
    }
  },
  "EEG": {
    "2511.23384v1": {
      "title": "Improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in the context of the 2024 Cybathlon",
      "url": "http://arxiv.org/abs/2511.23384v1",
      "authors": "Isabel Whiteley Tscherniak, Niels Christopher Thiemann, Ana McWhinney-Fern\u00e1ndez, Iustin Curcean, Leon Jokinen, Sadat Hodzic, Thomas E. Huber, Daniel Pavlov, Manuel Methasani, Pietro Marcolongo, Glenn Viktor Krafczyk, Oscar Osvaldo Soto Rivera, Thien Le, Flaminia Pallotti, Enrico A. Fazzi, neuroTUM e.",
      "update_time": "2025-11-28",
      "abstract": "Motivated by the Cybathlon 2024 competition, we developed a modular, online EEG-based brain-computer interface to address these challenges, increasing accessibility for individuals with severe mobility impairments. Our system uses three mental and motor imagery classes to control up to five control signals. The pipeline consists of four modules: data acquisition, preprocessing, classification, and the transfer function to map classification output to control dimensions. We use three diagonalized structured state-space sequence layers as a deep learning classifier. We developed a training game for our pilot where the mental tasks control the game during quick-time events. We implemented a mobile web application for live user feedback. The components were designed with a human-centred approach in collaboration with the tetraplegic user. We achieve up to 84% classification accuracy in offline analysis using an S4D-layer-based model. In a competition setting, our pilot successfully completed one task; we attribute the reduced performance in this context primarily to factors such as stress and the challenging competition environment. Following the Cybathlon, we further validated our pipeline with the original pilot and an additional participant, achieving a success rate of 73% in real-time gameplay. We also compare our model to the EEGEncoder, which is slower in training but has a higher performance. The S4D model outperforms the reference machine learning models. We provide insights into developing a framework for portable BCIs, bridging the gap between the laboratory and daily life. Specifically, our framework integrates modular design, real-time data processing, user-centred feedback, and low-cost hardware to deliver an accessible and adaptable BCI solution, addressing critical gaps in current BCI applications.",
      "code_url": null
    },
    "2511.23162v1": {
      "title": "Estimating the Event-Related Potential from Few EEG Trials",
      "url": "http://arxiv.org/abs/2511.23162v1",
      "authors": "Anders Vestergaard N\u00f8rskov, Kasper J\u00f8rgensen, Alexander Neergaard Zahid, Morten M\u00f8rup",
      "update_time": "2025-11-28",
      "abstract": "Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP",
      "code_url": null
    },
    "2511.23142v1": {
      "title": "Adapting Neural Audio Codecs to EEG",
      "url": "http://arxiv.org/abs/2511.23142v1",
      "authors": "Ard Kastrati, Luca Lanzend\u00f6rfer, Riccardo Rigoni, John Staib Matilla, Roger Wattenhofer",
      "update_time": "2025-11-28",
      "abstract": "EEG and audio are inherently distinct modalities, differing in sampling rate, channel structure, and scale. Yet, we show that pretrained neural audio codecs can serve as effective starting points for EEG compression, provided that the data are preprocessed to be suitable to the codec's input constraints. Using DAC, a state-of-the-art neural audio codec as our base, we demonstrate that raw EEG can be mapped into the codec's stride-based framing, enabling direct reuse of the audio-pretrained encoder-decoder. Even without modification, this setup yields stable EEG reconstructions, and fine-tuning on EEG data further improves fidelity and generalization compared to training from scratch. We systematically explore compression-quality trade-offs by varying residual codebook depth, codebook (vocabulary) size, and input sampling rate. To capture spatial dependencies across electrodes, we propose DAC-MC, a multi-channel extension with attention-based cross-channel aggregation and channel-specific decoding, while retaining the audio-pretrained initialization. Evaluations on the TUH Abnormal and Epilepsy datasets show that the adapted codecs preserve clinically relevant information, as reflected in spectrogram-based reconstruction loss and downstream classification accuracy.",
      "code_url": null
    },
    "2511.22030v1": {
      "title": "Calibration-Free EEG-based Driver Drowsiness Detection with Online Test-Time Adaptation",
      "url": "http://arxiv.org/abs/2511.22030v1",
      "authors": "Geun-Deok Jang, Dong-Kyun Han, Seo-Hyeon Park, Seong-Whan Lee",
      "update_time": "2025-11-27",
      "abstract": "Drowsy driving is a growing cause of traffic accidents, prompting recent exploration of electroencephalography (EEG)-based drowsiness detection systems. However, the inherent variability of EEG signals due to psychological and physical factors necessitates a cumbersome calibration process. In particular, the inter-subject variability of EEG signals leads to a domain shift problem, which makes it challenging to generalize drowsiness detection models to unseen target subjects. To address these issues, we propose a novel driver drowsiness detection framework that leverages online test-time adaptation (TTA) methods to dynamically adjust to target subject distributions. Our proposed method updates the learnable parameters in batch normalization (BN) layers, while preserving pretrained normalization statistics, resulting in a modified configuration that ensures effective adaptation during test time. We incorporate a memory bank that dynamically manages streaming EEG segments, selecting samples based on their reliability determined by negative energy scores and persistence time. In addition, we introduce prototype learning to ensure robust predictions against distribution shifts over time. We validated our method on the sustained-attention driving dataset collected in a simulated environment, where drowsiness was estimated from delayed reaction times during monotonous lane-keeping tasks. Our experiments show that our method outperforms all baselines, achieving an average F1-score of 81.73\\%, an improvement of 11.73\\% over the best TTA baseline. This demonstrates that our proposed method significantly enhances the adaptability of EEG-based drowsiness detection systems in non-i.i.d. scenarios.",
      "code_url": null
    },
    "2511.21940v1": {
      "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection",
      "url": "http://arxiv.org/abs/2511.21940v1",
      "authors": "Kiran Nair, Hubert Cecotti",
      "update_time": "2025-11-26",
      "abstract": "Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.",
      "code_url": null
    },
    "2511.20990v1": {
      "title": "Meditative absorption shifts brain dynamics toward criticality",
      "url": "http://arxiv.org/abs/2511.20990v1",
      "authors": "Jonas Mago, Joshua Brahinsky, Mark Miller, Charlotte Maschke, Heleen A. Slagter, Shaila Catherine, Ruben E. Laukkonen, B. Rael Cahn, Matthew D. Sacchet, Wangmo Dixey, Richard Dixey, Soham Rej, Michael Lifshitz",
      "update_time": "2025-11-26",
      "abstract": "Criticality describes a regime between order and chaos that supports flexible yet stable information processing. Here we examine whether neural dynamics can be volitionally shifted toward criticality through the self-regulation of attention. We examined ten experienced practitioners of meditation during a 10-day retreat, comparing refined states of meditative absorption, called the jhanas, to regular mindfulness of breathing. We collected electroencephalography (EEG) and physiological data during these practices and quantified the signal's dynamical properties using Lempel-Ziv complexity, signal entropy, chaoticity and long-range temporal correlations. In addition, we estimated perturbational sensitivity using a global auditory oddball mismatch negativity (MMN) during meditation. Relative to mindfulness, jhana was associated with pronounced self-reported sensory fading, slower respiration, higher neural signal diversity across multiple measures, reduced chaoticity, and enhanced MMN amplitude over frontocentral sites. Spectral analyses showed a flatter aperiodic one over f component and a frequency-specific reorganization of long-range temporal correlations. Together, increased diversity with reduced chaoticity and heightened deviance detection indicate a shift toward a metastable, near-critical regime during jhana. We propose an overlap of the phenomenology of jhana with minimal phenomenal experiences in terms of progressive attenuation of sensory content with preserved tonic alertness. Accordingly, our findings suggest that criticality is a candidate neurophysiological marker of the absorptive, minimal-content dimension of the minimal phenomenal experience.",
      "code_url": null
    },
    "2511.20950v1": {
      "title": "Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures",
      "url": "http://arxiv.org/abs/2511.20950v1",
      "authors": "Yaoyue Wang, Arian Ashourvan, Guilherme Ramos, Paul Bogdan, Emily Pereira",
      "update_time": "2025-11-26",
      "abstract": "Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.",
      "code_url": null
    },
    "2511.20848v1": {
      "title": "NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities",
      "url": "http://arxiv.org/abs/2511.20848v1",
      "authors": "Tasha Kim, Yingke Wang, Hanvit Cho, Alex Hodges",
      "update_time": "2025-11-25",
      "abstract": "Neural Signal Operated Intelligent Robots (NOIR) system is a versatile brain-robot interface that allows humans to control robots for daily tasks using their brain signals. This interface utilizes electroencephalography (EEG) to translate human intentions regarding specific objects and desired actions directly into commands that robots can execute. We present NOIR 2.0, an enhanced version of NOIR. NOIR 2.0 includes faster and more accurate brain decoding algorithms, which reduce task completion time by 46%. NOIR 2.0 uses few-shot robot learning algorithms to adapt to individual users and predict their intentions. The new learning algorithms leverage foundation models for more sample-efficient learning and adaptation (15 demos vs. a single demo), significantly reducing overall human time by 65%.",
      "code_url": null
    },
    "2511.20835v1": {
      "title": "Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2511.20835v1",
      "authors": "Gao Wang, Yingying Huang, Lars Muckli, Daniele Faccio",
      "update_time": "2025-11-25",
      "abstract": "Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.",
      "code_url": null
    },
    "2511.20570v1": {
      "title": "Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics",
      "url": "http://arxiv.org/abs/2511.20570v1",
      "authors": "Tasha Kim, Oiwi Parker Jones",
      "update_time": "2025-11-25",
      "abstract": "Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.",
      "code_url": null
    }
  },
  "BCI": {
    "2511.23384v1": {
      "title": "Improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in the context of the 2024 Cybathlon",
      "url": "http://arxiv.org/abs/2511.23384v1",
      "authors": "Isabel Whiteley Tscherniak, Niels Christopher Thiemann, Ana McWhinney-Fern\u00e1ndez, Iustin Curcean, Leon Jokinen, Sadat Hodzic, Thomas E. Huber, Daniel Pavlov, Manuel Methasani, Pietro Marcolongo, Glenn Viktor Krafczyk, Oscar Osvaldo Soto Rivera, Thien Le, Flaminia Pallotti, Enrico A. Fazzi, neuroTUM e.",
      "update_time": "2025-11-28",
      "abstract": "Motivated by the Cybathlon 2024 competition, we developed a modular, online EEG-based brain-computer interface to address these challenges, increasing accessibility for individuals with severe mobility impairments. Our system uses three mental and motor imagery classes to control up to five control signals. The pipeline consists of four modules: data acquisition, preprocessing, classification, and the transfer function to map classification output to control dimensions. We use three diagonalized structured state-space sequence layers as a deep learning classifier. We developed a training game for our pilot where the mental tasks control the game during quick-time events. We implemented a mobile web application for live user feedback. The components were designed with a human-centred approach in collaboration with the tetraplegic user. We achieve up to 84% classification accuracy in offline analysis using an S4D-layer-based model. In a competition setting, our pilot successfully completed one task; we attribute the reduced performance in this context primarily to factors such as stress and the challenging competition environment. Following the Cybathlon, we further validated our pipeline with the original pilot and an additional participant, achieving a success rate of 73% in real-time gameplay. We also compare our model to the EEGEncoder, which is slower in training but has a higher performance. The S4D model outperforms the reference machine learning models. We provide insights into developing a framework for portable BCIs, bridging the gap between the laboratory and daily life. Specifically, our framework integrates modular design, real-time data processing, user-centred feedback, and low-cost hardware to deliver an accessible and adaptable BCI solution, addressing critical gaps in current BCI applications.",
      "code_url": null
    },
    "2511.23162v1": {
      "title": "Estimating the Event-Related Potential from Few EEG Trials",
      "url": "http://arxiv.org/abs/2511.23162v1",
      "authors": "Anders Vestergaard N\u00f8rskov, Kasper J\u00f8rgensen, Alexander Neergaard Zahid, Morten M\u00f8rup",
      "update_time": "2025-11-28",
      "abstract": "Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP",
      "code_url": null
    },
    "2511.21940v1": {
      "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection",
      "url": "http://arxiv.org/abs/2511.21940v1",
      "authors": "Kiran Nair, Hubert Cecotti",
      "update_time": "2025-11-26",
      "abstract": "Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.",
      "code_url": null
    },
    "2511.20835v1": {
      "title": "Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2511.20835v1",
      "authors": "Gao Wang, Yingying Huang, Lars Muckli, Daniele Faccio",
      "update_time": "2025-11-25",
      "abstract": "Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.",
      "code_url": null
    },
    "2511.19312v1": {
      "title": "Human-AI Teaming Under Deception: An Implicit BCI Safeguards Drone Team Performance in Virtual Reality",
      "url": "http://arxiv.org/abs/2511.19312v1",
      "authors": "Christopher Baker, Stephen Hinton, Akashdeep Nijjar, Riccardo Poli, Caterina Cinel, Tom Reed, Stephen Fairclough",
      "update_time": "2025-11-24",
      "abstract": "Human-AI teams can be vulnerable to catastrophic failure when feedback from the AI is incorrect, especially under high cognitive workload. Traditional team aggregation methods, such as voting, are susceptible to these AI errors, which can actively bias the behaviour of each individual and inflate the likelihood of an erroneous group decision. We hypothesised that a collaborative Brain-Computer Interface (cBCI) using neural activity collected before a behavioural decision is made can provide a source of information that is decoupled from this biased behaviour, thereby protecting the team from the deleterious influence of AI error. We tested this in a VR drone surveillance task where teams of operators faced high workload and systematically misleading AI cues, comparing traditional behaviour-based team strategies against a purely Neuro-Decoupled Team (NDT) that used only BCI confidence scores derived from pre-response EEG. Under AI deception, behaviour-based teams catastrophically failed, with Majority Vote accuracy collapsing to 44%. The NDT, however, maintained 98% accuracy, a statistically significant synergistic gain over even the team's best individual performer (p < .001). This was explained by a neuro-behavioural decoupling, where the BCI's predictions remained highly accurate while the operator's subjective confidence became an unreliable signal. We conclude that an implicit BCI provides resilience by learning to adapt its neural strategy, shifting from relying on signals of efficient, autopilot processing in simple conditions to interpreting signatures of effortful deliberation when confronted with cognitive conflict. This demonstrates a system that leverages the context of the neural signal to defend against AI-induced error in high-stakes environments.",
      "code_url": null
    },
    "2511.18940v1": {
      "title": "Geometry-Aware Deep Congruence Networks for Manifold Learning in Cross-Subject Motor Imagery",
      "url": "http://arxiv.org/abs/2511.18940v1",
      "authors": "Sanjeev Manivannan, Chandrashekar Lakshminarayan",
      "update_time": "2025-11-24",
      "abstract": "Cross-subject motor-imagery decoding remains a major challenge in EEG-based brain-computer interfaces due to strong subject variability and the curved geometry of covariance matrices on the symmetric positive definite (SPD) manifold. We address the zero-shot cross-subject setting, where no target-subject labels or adaptation are allowed, by introducing novel geometry-aware preprocessing modules and deep congruence networks that operate directly on SPD covariance matrices. Our preprocessing modules, DCR and RiFU, extend Riemannian Alignment by improving action separation while reducing subject-specific distortions. We further propose two manifold classifiers, SPD-DCNet and RiFUNet, which use hierarchical congruence transforms to learn discriminative, subject-invariant covariance representations. On the BCI-IV 2a benchmark, our framework improves cross-subject accuracy by 3-4% over the strongest classical baselines, demonstrating the value of geometry-aware transformations for robust EEG decoding.",
      "code_url": null
    },
    "2511.20696v1": {
      "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding",
      "url": "http://arxiv.org/abs/2511.20696v1",
      "authors": "Dan Li, Hye-Bin Shin, Yeon-Woo Choi",
      "update_time": "2025-11-24",
      "abstract": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.",
      "code_url": null
    },
    "2511.18294v1": {
      "title": "MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding",
      "url": "http://arxiv.org/abs/2511.18294v1",
      "authors": "Mengchun Zhang, Kateryna Shapovalenko, Yucheng Shao, Eddie Guo, Parusha Pradhan",
      "update_time": "2025-11-23",
      "abstract": "Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \\textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.",
      "code_url": null
    },
    "2511.21740v1": {
      "title": "Decoding inner speech with an end-to-end brain-to-text neural interface",
      "url": "http://arxiv.org/abs/2511.21740v1",
      "authors": "Yizi Zhang, Linyang He, Chaofei Fan, Tingkai Liu, Han Yu, Trung Le, Jingyuan Li, Scott Linderman, Lea Duncker, Francis R Willett, Nima Mesgarani, Liam Paninski",
      "update_time": "2025-11-21",
      "abstract": "Speech brain-computer interfaces (BCIs) aim to restore communication for people with paralysis by translating neural activity into text. Most systems use cascaded frameworks that decode phonemes before assembling sentences with an n-gram language model (LM), preventing joint optimization of all stages simultaneously. Here, we introduce an end-to-end Brain-to-Text (BIT) framework that translates neural activity into coherent sentences using a single differentiable neural network. Central to our approach is a cross-task, cross-species pretrained neural encoder, whose representations transfer to both attempted and imagined speech. In a cascaded setting with an n-gram LM, the pretrained encoder establishes a new state-of-the-art (SOTA) on the Brain-to-Text '24 and '25 benchmarks. Integrated end-to-end with audio large language models (LLMs) and trained with contrastive learning for cross-modal alignment, BIT reduces the word error rate (WER) of the prior end-to-end method from 24.69% to 10.22%. Notably, we find that small-scale audio LLMs markedly improve end-to-end decoding. Beyond record-setting performance, BIT aligns attempted and imagined speech embeddings to enable cross-task generalization. Altogether, our approach advances the integration of large, diverse neural datasets, paving the way for an end-to-end decoding framework that supports seamless, differentiable optimization.",
      "code_url": null
    },
    "2511.17401v1": {
      "title": "Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment",
      "url": "http://arxiv.org/abs/2511.17401v1",
      "authors": "Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat",
      "update_time": "2025-11-21",
      "abstract": "Non-invasive electroencephalography (EEG)-based brain-computer interfaces (BCIs) offer an intuitive means for individuals with severe motor impairments to independently operate assistive robotic wheelchairs and navigate built environments. Despite considerable progress in BCI research, most current motion control systems are limited to discrete commands, rather than supporting continuous pursuit, where users can freely adjust speed and direction in real time. Such natural mobility control is, however, essential for wheelchair users to navigate complex public spaces, such as transit stations, airports, hospitals, and indoor corridors, to interact socially with the dynamic populations with agility, and to move flexibly and comfortably as autonomous driving is refined to allow movement at will. In this study, we address the gap of continuous pursuit motion control in BCIs by proposing and validating a brain-inspired Bayesian inference framework, where embodied dynamics in acceleration-based motor representations are decoded. This approach contrasts with conventional kinematics-level decoding and deep learning-based methods. Using a public dataset with sixteen hours of EEG from four subjects performing motor imagery-based target-following, we demonstrate that our method, utilizing Automatic Relevance Determination for feature selection and continual online learning, reduces the normalized mean squared error between predicted and true velocities by 72% compared to autoregressive and EEGNet-based methods in a session-accumulative transfer learning setting. Theoretically, these findings empirically support embodied cognition theory and reveal the brain's intrinsic motor control dynamics in an embodied and predictive nature. Practically, grounding EEG decoding in the same dynamical principles that govern biological motion offers a promising path toward more stable and intuitive BCI control.",
      "code_url": null
    }
  },
  "fMRI": {
    "2511.22870v1": {
      "title": "Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis",
      "url": "http://arxiv.org/abs/2511.22870v1",
      "authors": "Jungwoo Seo, David Keetae Park, Shinjae Yoo, Jiook Cha",
      "update_time": "2025-11-28",
      "abstract": "Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models.",
      "code_url": null
    },
    "2511.22178v1": {
      "title": "Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph Attention for Autism Spectrum Disorder Classification",
      "url": "http://arxiv.org/abs/2511.22178v1",
      "authors": "Adnan Ferdous Ashrafi, Hasanul Kabir",
      "update_time": "2025-11-27",
      "abstract": "ASD is a complicated neurodevelopmental disorder marked by variation in symptom presentation and neurological underpinnings, making early and objective diagnosis extremely problematic. This paper presents a Graph Convolutional Network (GCN) model, incorporating Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), to increase the classification accuracy of ASD utilizing multimodal neuroimaging and phenotypic data. Leveraging the ABIDE I dataset, which contains resting-state functional MRI (rs-fMRI), structural MRI (sMRI), and phenotypic variables from 870 patients, the model leverages a multi-branch architecture that processes each modality individually before merging them via concatenation. Graph structure is encoded using site-based similarity to generate a population graph, which helps in understanding relationship connections across individuals. Chebyshev polynomial filters provide localized spectral learning with lower computational complexity, whereas GAT layers increase node representations by attention-weighted aggregation of surrounding information. The proposed model is trained using stratified five-fold cross-validation with a total input dimension of 5,206 features per individual. Extensive trials demonstrate the enhanced model's superiority, achieving a test accuracy of 74.82\\% and an AUC of 0.82 on the entire dataset, surpassing multiple state-of-the-art baselines, including conventional GCNs, autoencoder-based deep neural networks, and multimodal CNNs.",
      "code_url": null
    },
    "2511.21605v1": {
      "title": "Detecting absence: A dedicated prediction-error signal emerging in the auditory thalamus",
      "url": "http://arxiv.org/abs/2511.21605v1",
      "authors": "Alejandro Tabas, Heike S\u00f6nnichsen, Sandeep Kaur, Marco Meixner, Katharina von Kriegstein",
      "update_time": "2025-11-26",
      "abstract": "How does the brain know what is out there and what is not? Living organisms cannot rely solely on sensory signals for perception because they are noisy and ambiguous. To transform sensory signals into stable percepts, the brain uses its prior knowledge or beliefs. Current theories describe perceptual beliefs as probability distributions over the features of the stimuli, summarised by their mean and variance. Beliefs are updated by feature prediction errors: the mismatch between expected and observed feature values. This framework explains how the brain encodes unexpected changes in stimulus features (e.g., higher or lower pitch, stronger or weaker motion). How the brain updates beliefs about a stimulus' presence or absence is, however, unclear.   We propose that the detection of absence relies on a distinct form of prediction error dedicated to reducing the beliefs on stimulus occurrence. We call this signal absence prediction error. Using the human auditory system as a model for sensory processing, we developed a paradigm designed to test this hypothesis. fMRI results showed that absence prediction error is encoded in the auditory thalamus and cortex, indicating that absence is explicitly represented in subcortical sensory pathways. Moreover, while feature prediction error is already encoded in the auditory midbrain, absence prediction error was not, implying that absence-related error signals are supported by a different circuit.   These results identify a neural mechanism for the detection of sensory absence. Such mechanisms may be disrupted in conditions such as psychosis, where predictions about absence and presence are impaired.",
      "code_url": null
    },
    "2511.21760v1": {
      "title": "fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding",
      "url": "http://arxiv.org/abs/2511.21760v1",
      "authors": "Yuxiang Wei, Yanteng Zhang, Xi Xiao, Chengxuan Qian, Tianyang Wang, Vince D. Calhoun",
      "update_time": "2025-11-24",
      "abstract": "Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored. Bridging this gap is essential to link neural activity with semantic cognition and to develop cross-modal brain representations. To this end, we present fMRI-LM, a foundational model that bridges functional MRI (fMRI) and language through a three-stage framework. In Stage 1, we learn a neural tokenizer that maps fMRI into discrete tokens embedded in a language-consistent space. In Stage 2, a pretrained LLM is adapted to jointly model fMRI tokens and text, treating brain activity as a sequence that can be temporally predicted and linguistically described. To overcome the lack of natural fMRI-text pairs, we construct a large descriptive corpus that translates diverse imaging-based features into structured textual descriptors, capturing the low-level organization of fMRI signals. In Stage 3, we perform multi-task, multi-paradigm instruction tuning to endow fMRI-LM with high-level semantic understanding, supporting diverse downstream applications. Across various benchmarks, fMRI-LM achieves strong zero-shot and few-shot performance, and adapts efficiently with parameter-efficient tuning (LoRA), establishing a scalable pathway toward a language-aligned, universal model for structural and semantic understanding of fMRI.",
      "code_url": null
    },
    "2511.18781v1": {
      "title": "A Novel Dual-Stream Framework for dMRI Tractography Streamline Classification with Joint dMRI and fMRI Data",
      "url": "http://arxiv.org/abs/2511.18781v1",
      "authors": "Haotian Yan, Bocheng Guo, Jianzhong He, Nir A. Sochen, Ofer Pasternak, Lauren J O'Donnell, Fan Zhang",
      "update_time": "2025-11-24",
      "abstract": "Streamline classification is essential to identify anatomically meaningful white matter tracts from diffusion MRI (dMRI) tractography. However, current streamline classification methods rely primarily on the geometric features of the streamline trajectory, failing to distinguish between functionally distinct fiber tracts with similar pathways. To address this, we introduce a novel dual-stream streamline classification framework that jointly analyzes dMRI and functional MRI (fMRI) data to enhance the functional coherence of tract parcellation. We design a novel network that performs streamline classification using a pretrained backbone model for full streamline trajectories, while augmenting with an auxiliary network that processes fMRI signals from fiber endpoint regions. We demonstrate our method by parcellating the corticospinal tract (CST) into its four somatotopic subdivisions. Experimental results from ablation studies and comparisons with state-of-the-art methods demonstrate our approach's superior performance.",
      "code_url": null
    },
    "2511.18325v1": {
      "title": "Brain-MGF: Multimodal Graph Fusion Network for EEG-fMRI Brain Connectivity Analysis Under Psilocybin",
      "url": "http://arxiv.org/abs/2511.18325v1",
      "authors": "Sin-Yee Yap, Fuad Noman, Junn Yong Loo, Devon Stoliker, Moein Khajehnejad, Rapha\u00ebl C. -W. Phan, David L. Dowe, Adeel Razi, Chee-Ming Ting",
      "update_time": "2025-11-23",
      "abstract": "Psychedelics, such as psilocybin, reorganise large-scale brain connectivity, yet how these changes are reflected across electrophysiological (electroencephalogram, EEG) and haemodynamic (functional magnetic resonance imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal graph fusion network for joint EEG-fMRI connectivity analysis. For each modality, we construct graphs with partial-correlation edges and Pearson-profile node features, and learn subject-level embeddings via graph convolution. An adaptive softmax gate then fuses modalities with sample-specific weights to capture context-dependent contributions. Using the world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF distinguishes psilocybin from no-psilocybin conditions in meditation and rest. Fusion improves over unimodal and non-adaptive variants, achieving 74.0% accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8% ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused embeddings. These results indicate that adaptive graph fusion effectively integrates complementary EEG-fMRI information, providing an interpretable framework for characterising psilocybin-induced alterations in large-scale neural organisation.",
      "code_url": null
    },
    "2511.20692v1": {
      "title": "The Human Brain as a Combinatorial Complex",
      "url": "http://arxiv.org/abs/2511.20692v1",
      "authors": "Valentina S\u00e1nchez, \u00c7i\u00e7ek G\u00fcven, Koen Haak, Theodore Papamarkou, Gonzalo N\u00e1poles, Marie \u0160af\u00e1\u0159 Postma",
      "update_time": "2025-11-22",
      "abstract": "We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.",
      "code_url": null
    },
    "2511.16849v1": {
      "title": "Better audio representations are more brain-like: linking model-brain alignment with performance in downstream auditory tasks",
      "url": "http://arxiv.org/abs/2511.16849v1",
      "authors": "Leonardo Pepino, Pablo Riera, Juan Kamienkowski, Luciana Ferrer",
      "update_time": "2025-11-20",
      "abstract": "Artificial neural networks (ANNs) are increasingly powerful models of brain computation, yet it remains unclear whether improving their task performance also makes their internal representations more similar to brain signals. To address this question in the auditory domain, we quantified the alignment between the internal representations of 36 different audio models and brain activity from two independent fMRI datasets. Using voxel-wise and component-wise regression, and representation similarity analysis (RSA), we found that recent self-supervised audio models with strong performance in diverse downstream tasks are better predictors of auditory cortex activity than older and more specialized models. To assess the quality of the audio representations, we evaluated these models in 6 auditory tasks from the HEAREval benchmark, spanning music, speech, and environmental sounds. This revealed strong positive Pearson correlations ($r>0.7$) between a model's overall task performance and its alignment with brain representations. Finally, we analyzed the evolution of the similarity between audio and brain representations during the pretraining of EnCodecMAE. We discovered that brain similarity increases progressively and emerges early during pretraining, despite the model not being explicitly optimized for this objective. This suggests that brain-like representations can be an emergent byproduct of learning to reconstruct missing information from naturalistic audio data.",
      "code_url": null
    },
    "2511.14453v1": {
      "title": "Multi-network Topology Underlying Individual Language Learning Success",
      "url": "http://arxiv.org/abs/2511.14453v1",
      "authors": "Peilun Song, Shuguang Yang, Xiujuan Geng, Zhenzhong Gan, Suiping Wang, Gangyi Feng",
      "update_time": "2025-11-18",
      "abstract": "Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education.",
      "code_url": null
    },
    "2511.14196v1": {
      "title": "MindCross: Fast New Subject Adaptation with Limited Data for Cross-subject Video Reconstruction from Brain Signals",
      "url": "http://arxiv.org/abs/2511.14196v1",
      "authors": "Xuan-Hao Liu, Yan-Kai Liu, Tianyi Zhou, Bao-Liang Lu, Wei-Long Zheng",
      "update_time": "2025-11-18",
      "abstract": "Reconstructing video from brain signals is an important brain decoding task. Existing brain decoding frameworks are primarily built on a subject-dependent paradigm, which requires large amounts of brain data for each subject. However, the expensive cost of collecting brain-video data causes severe data scarcity. Although some cross-subject methods being introduced, they often overfocus with subject-invariant information while neglecting subject-specific information, resulting in slow fine-tune-based adaptation strategy. To achieve fast and data-efficient new subject adaptation, we propose MindCross, a novel cross-subject framework. MindCross's N specific encoders and one shared encoder are designed to extract subject-specific and subject-invariant information, respectively. Additionally, a Top-K collaboration module is adopted to enhance new subject decoding with the knowledge learned from previous subjects' encoders. Extensive experiments on fMRI/EEG-to-video benchmarks demonstrate MindCross's efficacy and efficiency of cross-subject decoding and new subject adaptation using only one model.",
      "code_url": null
    }
  },
  "MEG": {
    "2511.23162v1": {
      "title": "Estimating the Event-Related Potential from Few EEG Trials",
      "url": "http://arxiv.org/abs/2511.23162v1",
      "authors": "Anders Vestergaard N\u00f8rskov, Kasper J\u00f8rgensen, Alexander Neergaard Zahid, Morten M\u00f8rup",
      "update_time": "2025-11-28",
      "abstract": "Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP",
      "code_url": null
    },
    "2511.08679v1": {
      "title": "Hunting for Neutrino Texture Zeros with Muon and Tau Flavor Violation",
      "url": "http://arxiv.org/abs/2511.08679v1",
      "authors": "Lorenzo Calibbi, Xiyuan Gao, Man Yuan",
      "update_time": "2025-11-11",
      "abstract": "We revisit the minimal type II seesaw mechanism generating the Majorana neutrino mass matrix $M^\u03bd$, under the assumption that two entries of $M^\u03bd$ vanish. Such flavor structures are known as two-zero textures. Processes with charged lepton flavor violation (CLFV), absent in the Standard Model (SM), can have sizable rates in this framework and are directly linked to the flavor structure of $M^\u03bd$. For each allowed two-zero texture, we quantify the predicted correlations among various CLFV observables using current neutrino oscillation data and show that they lead to distinctive patterns of CLFV processes that could be discriminated between at running and upcoming experiments. In addition, together with information from colliders, the sensitivity of these correlations to renormalization group (RG) effects could shed light on the potentially ultra-high scale where new dynamics (e.g. some underlying flavor symmetry) give rise to the two-zero texture. Furthermore, we find that certain zero textures, although not third-generation specific, can suppress $\u03bc\\to e$ transitions while allowing the rate of the process $\u03c4\\to \\bar\u03bcee$ to be within the future experimental sensitivity, even when the RG evolution is taken into account. The lowest possible cut-off scale of the effective theory, constructed by treating the two-zero flavor structure of $M^\u03bd$ as a CLFV spurion, can therefore reach $5-6$ TeV. Our results provide further motivation for searches for $\u03c4$ CLFV at Belle II, as probes of new physics complementary to MEG II and the upcoming Mu3e, COMET, and Mu2e experiments, as well as for collider searches for doubly charged scalar bosons.",
      "code_url": null
    },
    "2511.07082v1": {
      "title": "The Use of O2 in Gas Mixtures for Drift Chambers",
      "url": "http://arxiv.org/abs/2511.07082v1",
      "authors": "A. M. Baldini, L. Bianco, H. Benmansour, G. Cavoto, F. Cei, M. Chiappini, A. Corvaglia, M. Francesconi, E. Gabbrielli, L. Galli, G. Gallucci, F. Grancagnolo, E. G. Grandoni, M. Grassi, F. Leonetti, D. Nicolo', M. Panareo, D. Pasciuto, A. Papa, F. Renga, S. Scarpellini, A. Venturini, C. Voena",
      "update_time": "2025-11-10",
      "abstract": "The use of Oxygen in gas mixtures for drift chambers is highly discouraged because Oxygen, being strongly electronegative, is generally believed to lead, even in very small quantities, to extremely reduced drift electron attachment values, thus preventing the detector's operation.The drift chamber of the MEG II experiment at PSI has been operating for several years with a gas mixture that mainly contains He:Isobutane in relative proportions of 90:10% by molar concentration, in addition to 1.5% Isopropanol and 0.5% Oxygen. Oxygen and Isopropanol are essential for the proper functioning of the chamber. The electron attachment in the mixture used has proven negligible for the proper operation of the chamber and agrees well with the Garfield++ simulation after correctly accounting for the three-body attachment simulation.",
      "code_url": null
    },
    "2511.04078v1": {
      "title": "Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment",
      "url": "http://arxiv.org/abs/2511.04078v1",
      "authors": "Zehui Feng, Chenqi Zhang, Mingru Wang, Minuo Wei, Shiwei Cheng, Cuntai Guan, Ting Han",
      "update_time": "2025-11-06",
      "abstract": "Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI remains a fundamental challenge due to subject variability and the entangled nature of visual features. Existing approaches primarily align neural activity directly with visual embeddings, but visual-only representations often fail to capture latent semantic dimensions, limiting interpretability and deep robustness. To address these limitations, we propose Bratrix, the first end-to-end framework to achieve multimodal Language-Anchored Vision-Brain alignment. Bratrix decouples visual stimuli into hierarchical visual and linguistic semantic components, and projects both visual and brain representations into a shared latent space, enabling the formation of aligned visual-language and brain-language embeddings. To emulate human-like perceptual reliability and handle noisy neural signals, Bratrix incorporates a novel uncertainty perception module that applies uncertainty-aware weighting during alignment. By leveraging learnable language-anchored semantic matrices to enhance cross-modal correlations and employing a two-stage training strategy of single-modality pretraining followed by multimodal fine-tuning, Bratrix-M improves alignment precision. Extensive experiments on EEG, MEG, and fMRI benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and captioning performance compared to state-of-the-art methods, specifically surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.",
      "code_url": null
    },
    "2511.01784v1": {
      "title": "Variational Representational Similarity Analysis (vRSA) for M/EEG",
      "url": "http://arxiv.org/abs/2511.01784v1",
      "authors": "Alex Lepauvre, Lucia Melloni, Karl Friston, Peter Zeidman",
      "update_time": "2025-11-03",
      "abstract": "This paper introduces variational representational similarity analysis RSA (vRSA) for electromagnetic recordings of neural responses (e.g., EEG, MEG, ECoG or LFP). Variational RSA is a Bayesian approach for testing whether the similarity of stimuli or experimental conditions is expressed in univariate or multivariate neural recordings. Extending an approach previously introduced in the context of functional MRI, vRSA decomposes the condition-by-condition data covariance matrix into hypothesised effects and observation noise, thereby casting RSA as a covariance component estimation problem. In this context, peristimulus time may be treated as an experimental factor, enabling one to test for the probability that different experimental effects are expressed in data at different times. Variational Bayesian methods are used for model estimation and model comparison, which confer a number of advantages over classical approaches, including statistically efficient hypothesis testing, quantification of uncertainty using Bayesian credible intervals and computational efficiency. After introducing the theory, we provide a worked example using openly available EEG data. Software functions implementing vRSA for the SPM software package accompany this paper, together with exemplar analysis scripts.",
      "code_url": null
    },
    "2511.00697v1": {
      "title": "Smooth Models of Fibered Partially Hyperbolic Systems",
      "url": "http://arxiv.org/abs/2511.00697v1",
      "authors": "Jonathan DeWitt, Meg Doucette, Oliver Wang",
      "update_time": "2025-11-01",
      "abstract": "We study fibered partially hyperbolic diffeomorphisms. We show that as long as certain topological obstructions vanish and as long as homological minimum expansion dominates the distortion on the fibers that a fibered partially hyperbolic system can be homotoped to a fibered partially hyperbolic system with a $C^{\\infty}$-center fibering. In addition, we study obstructions to the existence of smooth lifts of Anosov diffeomorphisms to bundles. In particular, we give an example of smooth topologically trivial bundle over a torus, where an Anosov diffeomorphism can lift continuously but not smoothly to the bundle.",
      "code_url": null
    },
    "2510.25913v1": {
      "title": "Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields",
      "url": "http://arxiv.org/abs/2510.25913v1",
      "authors": "Gilbert Bahati, Ryan M. Bena, Meg Wilkinson, Pol Mestres, Ryan K. Cosner, Aaron D. Ames",
      "update_time": "2025-10-29",
      "abstract": "Robotic systems navigating in real-world settings require a semantic understanding of their environment to properly determine safe actions. This work aims to develop the mathematical underpinnings of such a representation -- specifically, the goal is to develop safety filters that are risk-aware. To this end, we take a two step approach: encoding an understanding of the environment via Poisson's equation, and associated risk via Laplace guidance fields. That is, we first solve a Dirichlet problem for Poisson's equation to generate a safety function that encodes system safety as its 0-superlevel set. We then separately solve a Dirichlet problem for Laplace's equation to synthesize a safe \\textit{guidance field} that encodes variable levels of caution around obstacles -- by enforcing a tunable flux boundary condition. The safety function and guidance fields are then combined to define a safety constraint and used to synthesize a risk-aware safety filter which, given a semantic understanding of an environment with associated risk levels of environmental features, guarantees safety while prioritizing avoidance of higher risk obstacles. We demonstrate this method in simulation and discuss how \\textit{a priori} understandings of obstacle risk can be directly incorporated into the safety filter to generate safe behaviors that are risk-aware.",
      "code_url": null
    },
    "2510.23742v1": {
      "title": "Molecular Gas in Major Mergers Hosting Dual and Single AGN at <10 kpc Nuclear Separations",
      "url": "http://arxiv.org/abs/2510.23742v1",
      "authors": "Makoto A. Johnstone, Ezequiel Treister, Franz E. Bauer, Chin-Shin Chang, Claudia Cicone, Michael J. Koss, Ignacio del Moral-Castro, Francisco Muller-Sanchez, George C. Privon, Claudio Ricci, Nick Scoville, Giacomo Venturi, Loreto Barcos-Mu\u00f1oz, Lee Armus, Laura Blecha, Caitlin Casey, Julia Comerford, Aaron Evans, Taiki Kawamuro, Anne M. Medling, Hugo Messias, Neil Nagar, Alejandra Rojas, David Sanders, Benny Trakhtenbrot, Vivian U, Meg Urry",
      "update_time": "2025-10-27",
      "abstract": "We present high-resolution ($\\sim$50$-$100 pc) Atacama Large Millimeter Array (ALMA) observations of $^{12}$CO(2-1) or $^{12}$CO(1-0) emission in seven local ($z$ $\\lesssim$ 0.05) major mergers -- five of which are dual active galactic nuclei (AGN) systems, and two of which are single AGN systems. We model the molecular gas kinematics through rotating disk profiles using a Bayesian Markov chain Monte Carlo approach. The residuals were then used to isolate non-rotating components of the molecular gas -- the most likely contributor to future SMBH growth. We find that more massive SMBHs have higher surface densities of non-rotating molecular gas within their sphere of influence. This potential molecular gas supply, however, does not correlate with the current accretion efficiency of the SMBHs, suggesting that only a fraction of the observed non-rotating gas is currently reaching the SMBH. Finally, we tentatively find no significant differences in the nuclear molecular gas masses of single AGN and dual AGN hosts, both within the SMBH sphere of influence and within the central kiloparsec. Our results indicate that the probability of occurrence of the dual AGN phenomenon is likely dependent on AGN variability and/or obscuration rather than the availability of molecular gas in the nuclear regions.",
      "code_url": null
    },
    "2510.21596v1": {
      "title": "Automated interictal epileptic spike detection from simple and noisy annotations in MEG data",
      "url": "http://arxiv.org/abs/2510.21596v1",
      "authors": "Pauline Mouches, Julien Jung, Armand Demasson, Agn\u00e8s Guinard, Romain Bouet, Rosalie Marchal, Romain Quentin",
      "update_time": "2025-10-24",
      "abstract": "In drug-resistant epilepsy, presurgical evaluation of epilepsy can be considered. Magnetoencephalography (MEG) has been shown to be an effective exam to inform the localization of the epileptogenic zone through the localization of interictal epileptic spikes. Manual detection of these pathological biomarkers remains a fastidious and error-prone task due to the high dimensionality of MEG recordings, and interrater agreement has been reported to be only moderate. Current automated methods are unsuitable for clinical practice, either requiring extensively annotated data or lacking robustness on non-typical data. In this work, we demonstrate that deep learning models can be used for detecting interictal spikes in MEG recordings, even when only temporal and single-expert annotations are available, which represents real-world clinical practice. We propose two model architectures: a feature-based artificial neural network (ANN) and a convolutional neural network (CNN), trained on a database of 59 patients, and evaluated against a state-of-the-art model to classify short time windows of signal. In addition, we employ an interactive machine learning strategy to iteratively improve our data annotation quality using intermediary model outputs. Both proposed models outperform the state-of-the-art model (F1-scores: CNN=0.46, ANN=0.44) when tested on 10 holdout test patients. The interactive machine learning strategy demonstrates that our models are robust to noisy annotations. Overall, results highlight the robustness of models with simple architectures when analyzing complex and imperfectly annotated data. Our method of interactive machine learning offers great potential for faster data annotation, while our models represent useful and efficient tools for automated interictal spikes detection.",
      "code_url": null
    },
    "2510.19702v1": {
      "title": "Dictionary learning methods for brain activity mapping with MEG data",
      "url": "http://arxiv.org/abs/2510.19702v1",
      "authors": "Daniela Calvetti, Erkki Somersalo",
      "update_time": "2025-10-22",
      "abstract": "A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.",
      "code_url": null
    }
  },
  "neuroAI": {
    "2511.19548v1": {
      "title": "When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics",
      "url": "http://arxiv.org/abs/2511.19548v1",
      "authors": "Yiven, Zhu",
      "update_time": "2025-11-24",
      "abstract": "Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, \"brain-based\" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies \"true\" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.",
      "code_url": null
    },
    "2510.22178v1": {
      "title": "Dopamine-driven synaptic credit assignment in neural networks",
      "url": "http://arxiv.org/abs/2510.22178v1",
      "authors": "Saranraj Nambusubramaniyan, Shervin Safavi, Raja Guru, Andreas Knoblauch",
      "update_time": "2025-10-25",
      "abstract": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in both biological and artificial neural systems. Finding an optimal solution for synaptic CAP means setting the synaptic weights that assign credit to each neuron for influencing the final output and behavior of neural networks or animals. Gradient-based methods solve this problem in artificial neural networks using back-propagation, however, not in the most efficient way. For instance, back-propagation requires a chain of top-down gradient computations. This leads to an expensive optimization process in terms of computing power and memory linked with well-known weight transport and update locking problems. To address these shortcomings, we take a NeuroAI approach and draw inspiration from neural Reinforcement Learning to develop a derivative-free optimizer for training neural networks, Dopamine. Dopamine is developed for Weight Perturbation (WP) learning that exploits stochastic updating of weights towards optima. It achieves this by minimizing the regret, a form of Reward Prediction Error (RPE) between the expected outcome from the perturbed model and the actual outcome from the unperturbed model. We use this RPE to adjust the learning rate in the network (i.e., creating an adaptive learning rate strategy, similar to the role of dopamine in the brain). We tested the Dopamine optimizer for training multi-layered perceptrons for XOR tasks, and recurrent neural networks for chaotic time series forecasting. Dopamine-trained models demonstrate accelerated convergence and outperform standard WP, and give comparable performance to gradient-based algorithms, while consuming significantly less computation and memory. Overall, the Dopamine optimizer not only finds robust solutions and comparable performance to the state-of-the-art Machine Learning optimizers but is also neurobiologically more plausible.",
      "code_url": null
    },
    "2509.23896v2": {
      "title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence",
      "url": "http://arxiv.org/abs/2509.23896v2",
      "authors": "Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang",
      "update_time": "2025-10-09",
      "abstract": "NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",
      "code_url": null
    },
    "2507.06645v2": {
      "title": "Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers",
      "url": "http://arxiv.org/abs/2507.06645v2",
      "authors": "Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding",
      "update_time": "2025-11-07",
      "abstract": "Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.",
      "code_url": null
    },
    "2507.02103v1": {
      "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
      "url": "http://arxiv.org/abs/2507.02103v1",
      "authors": "Daniel Durstewitz, Bruno Averbeck, Georgia Koppe",
      "update_time": "2025-07-02",
      "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
      "code_url": null
    },
    "2506.04536v3": {
      "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models",
      "url": "http://arxiv.org/abs/2506.04536v3",
      "authors": "Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar",
      "update_time": "2025-10-27",
      "abstract": "Characterizing the cellular properties of neurons is fundamental to understanding their function in the brain. In this quest, the generation of bio-realistic models is central towards integrating multimodal cellular data sets and establishing causal relationships. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. The deterministic formalism of bio-realistic models currently precludes accounting for the natural variability observed experimentally. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on synthetic data generated from bio-realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE enables the efficient generation of synthetic neurons that closely resemble experimental data and exhibit trial-to-trial variability, offering a $4200\\times$ speedup over the numerical solver. NOBLE is the first scaled-up deep learning framework that validates its generalization with real experimental data. To this end, NOBLE captures fundamental neural properties in a unique and emergent manner that opens the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.",
      "code_url": null
    },
    "2505.16080v1": {
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "url": "http://arxiv.org/abs/2505.16080v1",
      "authors": "Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang",
      "update_time": "2025-05-21",
      "abstract": "Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.",
      "code_url": null
    },
    "2502.16238v1": {
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "url": "http://arxiv.org/abs/2502.16238v1",
      "authors": "Jenelle Feather, Meenakshi Khosla, N. Apurva Ratan Murty, Aran Nayebi",
      "update_time": "2025-02-22",
      "abstract": "What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \\emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development.",
      "code_url": null
    },
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": null
    },
    "2411.18526v2": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v2",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias, Anthony Zador",
      "update_time": "2025-04-03",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety.",
      "code_url": null
    }
  },
  "medical": {
    "2511.23372v1": {
      "title": "Design, modelling and experimental validation of bipenniform shape memory alloy-based linear actuator integrable with hydraulic stroke amplification mechanism",
      "url": "http://arxiv.org/abs/2511.23372v1",
      "authors": "Kanhaiya Lal Chaurasiya, Ruchira Kumar Pradhan, Yashaswi Sinha, Shivam Gupta, Ujjain Kumar Bidila, Digambar Killedar, Kapil Das Sahu, Bishakh Bhattacharya",
      "update_time": "2025-11-28",
      "abstract": "The increasing industrial demand for alternative actuators over conventional electromagnetism-based systems having limited efficiency, bulky size, complex design due to in-built gear-train mechanisms, and high production and amortization costs necessitates the innovation in new actuator development. Integrating bio-inspired design principles into linear actuators could bring forth the next generation of adaptive and energy efficient smart material-based actuation systems. The present study amalgamates the advantages of bipenniform architecture, which generates high force in the given physiological region and a high power-to-weight ratio of shape memory alloy (SMA), into a novel bio-inspired SMA-based linear actuator. A mathematical model of a multi-layered bipenniform configuration-based SMA actuator was developed and validated experimentally. The current research also caters to the incorporation of failure mitigation strategies using design failure mode and effects analysis along with the experimental assessment of the performance of the developed actuator. The system has been benchmarked against an industry-developed stepper motor-driven actuator. It has shown promising results generating an actuation force of 257 N with 15 V input voltage, meeting the acceptable range for actuation operation. It further exhibits about 67% reduction in the weight of the drive mechanism, with 80% lesser component, 32% cost reduction, and 19% energy savings and similar envelope dimensions for assembly compatibility with dampers and louvers for easy onsite deployment. The study introduces SMA coil-based actuator as an advanced design that can be deployed for high force-high stroke applications. The bio-inspired SMA-based linear actuator has applications ranging from building automation controls to lightweight actuation systems for space robotics and medical prosthesis.",
      "code_url": null
    },
    "2511.23331v1": {
      "title": "Optimization and application of ultra-high field preclinical high-resolution and 3D 1H-MRSI using compressed sensing",
      "url": "http://arxiv.org/abs/2511.23331v1",
      "authors": "Brayan Alves, Thanh Phong L\u00ea, Gianna Nossa, Tan Toi Phan, Alessio Siviglia, Bernard Lanz, Wolfgang Bogner, Antoine Klauser, Bernhard Strasser, Cristina Cudalbu",
      "update_time": "2025-11-28",
      "abstract": "Proton magnetic resonance spectroscopic imaging (1H-MRSI) at ultra-high field has seen an increase in usage in the preclinical field. Challenges related to long acquisition time and low concentration of brain metabolites in the rodent brain have led to the development and application of acceleration schemes for 3D-1H-MRSI, such the undersampling technique Compressed Sensing (CS). This present study aims to explore the CS tool in the context of preclinical in vivo application in order to achieve high-resolution MRSI acquisition in both 2D with an in-plane increase and 3D/multi-slice acquisition with through-plane. The parameters are explored to achieve the highest acceleration possible as a way to make 3D as time efficient as possible. Results of the parameter study showed that an acceleration factor (AF) of 4 was possible with the right sampling size of the core at the center of the k-space. With this specific set, higher matrix size resulting in sub 1 \u03bcL nominal voxel size was explored with 2D-FID-MRSI and 9 supplementary phase-encoding/slices were added to achieve 3D-FID-MRSI. The spectral quality and the metabolic maps were accurate enough in the comparison with the non-accelerated 2D-FID-MRSI, within the slice of interest. Issues related with the point spread function (PSF) were noted throughout the different usage of CS. Our work presents a robust and effective protocol to achieve 3D-1H-MRSI using CS in order to reach an acquisition time below the 30 minutes bar, with minimal technical limitations and high-quality acquisition.",
      "code_url": null
    },
    "2511.23274v1": {
      "title": "Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI",
      "url": "http://arxiv.org/abs/2511.23274v1",
      "authors": "Georgia Kanli, Daniele Perlo, Selma Boudissa, Radovan Jirik, Olivier Keunen",
      "update_time": "2025-11-28",
      "abstract": "MR data are acquired in the frequency domain, known as k-space. Acquiring high-quality and high-resolution MR images can be time-consuming, posing a significant challenge when multiple sequences providing complementary contrast information are needed or when the patient is unable to remain in the scanner for an extended period of time. Reducing k-space measurements is a strategy to speed up acquisition, but often leads to reduced quality in reconstructed images. Additionally, in real-world MRI, both under-sampled and full-sampled images are prone to artefacts, and correcting these artefacts is crucial for maintaining diagnostic accuracy. Deep learning methods have been proposed to restore image quality from under-sampled data, while others focused on the correction of artefacts that result from the noise or motion. No approach has however been proposed so far that addresses both acceleration and artefacts correction, limiting the performance of these models when these degradation factors occur simultaneously. To address this gap, we present a method for recovering high-quality images from under-sampled data with simultaneously correction for noise and motion artefact called USArt (Under-Sampling and Artifact correction model). Customized for 2D brain anatomical images acquired with Cartesian sampling, USArt employs a dual sub-model approach. The results demonstrate remarkable increase of signal-to-noise ratio (SNR) and contrast in the images restored. Various under-sampling strategies and degradation levels were explored, with the gradient under-sampling strategy yielding the best outcomes. We achieved up to 5x acceleration and simultaneously artefacts correction without significant degradation, showcasing the model's robustness in real-world settings.",
      "code_url": null
    },
    "2511.23269v1": {
      "title": "OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning",
      "url": "http://arxiv.org/abs/2511.23269v1",
      "authors": "Timothy Ossowski, Sheng Zhang, Qianchu Liu, Guanghui Qin, Reuben Tan, Tristan Naumann, Junjie Hu, Hoifung Poon",
      "update_time": "2025-11-28",
      "abstract": "High-quality and carefully curated data is a cornerstone of training medical large language models, as it directly impacts both generalization and robustness to unseen clinical tasks. We investigate strategies for training and data curation to develop a robust multimodal reasoning model in the medical domain. Our work focuses on supervised fine-tuning (SFT) and explores data recipes that leverage structured reasoning traces. Using our proposed data recipe, we scale experiments to a dataset of over 8 million examples and 6.8 billion response tokens, achieving state-of-the-art performance among open-source models across diverse out-of-distribution medical benchmark tasks. Our results further indicate that curating a high-quality, diverse training dataset with varying structured reasoning trace lengths enables the fine-tuned model to self-calibrate its reasoning trajectory lengths based on the downstream task, without explicit supervision. We present key insights, describe the data curation strategy, and outline next steps toward developing robust medical vision-language reasoning system.",
      "code_url": null
    },
    "2511.23135v1": {
      "title": "Strategies to Minimize Out-of-Distribution Effects in Data-Driven MRS Quantification",
      "url": "http://arxiv.org/abs/2511.23135v1",
      "authors": "Julian P. Merkofer, Antonia Kaiser, Anouk Schrantee, Oliver J. Gurney-Champion, Ruud J. G. van Sloun",
      "update_time": "2025-11-28",
      "abstract": "This study systematically compared data-driven and model-based strategies for metabolite quantification in magnetic resonance spectroscopy (MRS), focusing on resilience to out-of-distribution (OoD) effects and the balance between accuracy, robustness, and generalizability. A neural network designed for MRS quantification was trained using three distinct strategies: supervised regression, self-supervised learning, and test-time adaptation. These were compared against model-based fitting tools. Experiments combined large-scale simulated data, designed to probe metabolite concentration extrapolation and signal variability, with 1H single-voxel 7T in-vivo human brain spectra. In simulations, supervised learning achieved high accuracy for spectra similar to those in the training distribution, but showed marked degradation when extrapolated beyond the training distribution. Test-time adaptation proved more resilient to OoD effects, while self-supervised learning achieved intermediate performance. In-vivo experiments showed larger variance across the methods (data-driven and model-based) due to domain shift. Across all strategies, overlapping metabolites and baseline variability remained persistent challenges. While strong performance can be achieved by data-driven methods for MRS metabolite quantification, their reliability is contingent on careful consideration of the training distribution and potential OoD effects. When such conditions in the target distribution cannot be anticipated, test-time adaptation strategies ensure consistency between the quantification, the data, and the model, enabling reliable data-driven MRS pipelines.",
      "code_url": null
    },
    "2511.23124v1": {
      "title": "DNA-Prior: Unsupervised Denoise Anything via Dual-Domain Prior",
      "url": "http://arxiv.org/abs/2511.23124v1",
      "authors": "Yanqi Cheng, Chun-Wun Cheng, Jim Denholm, Thiago Lima, Javier A. Montoya-Zegarra, Richard Goodwin, Carola-Bibiane Sch\u00f6nlieb, Angelica I Aviles-Rivero",
      "update_time": "2025-11-28",
      "abstract": "Medical imaging pipelines critically rely on robust denoising to stabilise downstream tasks such as segmentation and reconstruction. However, many existing denoisers depend on large annotated datasets or supervised learning, which restricts their usability in clinical environments with heterogeneous modalities and limited ground-truth data. To address this limitation, we introduce DNA-Prior, a universal unsupervised denoising framework that reconstructs clean images directly from corrupted observations through a mathematically principled hybrid prior. DNA-Prior integrates (i) an implicit architectural prior, enforced through a deep network parameterisation, with (ii) an explicit spectral-spatial prior composed of a frequency-domain fidelity term and a spatial regularisation functional. This dual-domain formulation yields a well-structured optimisation problem that jointly preserves global frequency characteristics and local anatomical structure, without requiring any external training data or modality-specific tuning. Experiments across multiple modalities show that DNA achieves consistent noise suppression and structural preservation under diverse noise conditions.",
      "code_url": null
    },
    "2511.23082v1": {
      "title": "Implementation of a Skin Lesion Detection System for Managing Children with Atopic Dermatitis Based on Ensemble Learning",
      "url": "http://arxiv.org/abs/2511.23082v1",
      "authors": "Soobin Jeon, Sujong Kim, Dongmahn Seo",
      "update_time": "2025-11-28",
      "abstract": "The amendments made to the Data 3 Act and impact of COVID-19 have fostered the growth of digital healthcare market and promoted the use of medical data in artificial intelligence in South Korea. Atopic dermatitis, a chronic inflammatory skin disease, is diagnosed via subjective evaluations without using objective diagnostic methods, thereby increasing the risk of misdiagnosis. It is also similar to psoriasis in appearance, further complicating its accurate diagnosis. Existing studies on skin diseases have used high-quality dermoscopic image datasets, but such high-quality images cannot be obtained in actual clinical settings. Moreover, existing systems must ensure accuracy and fast response times. To this end, an ensemble learning-based skin lesion detection system (ENSEL) was proposed herein. ENSEL enhanced diagnostic accuracy by integrating various deep learning models via an ensemble approach. Its performance was verified by conducting skin lesion detection experiments using images of skin lesions taken by actual users. Its accuracy and response time were measured using randomly sampled skin disease images. Results revealed that ENSEL achieved high recall in most images and less than 1s s processing speed. This study contributes to the objective diagnosis of skin lesions and promotes the advancement of digital healthcare.",
      "code_url": null
    },
    "2511.23066v1": {
      "title": "Evaluating the Clinical Impact of Generative Inpainting on Bone Age Estimation",
      "url": "http://arxiv.org/abs/2511.23066v1",
      "authors": "Felipe Akio Matsuoka, Eduardo Moreno J. M. Farina, Augusto Sarquis Serpa, Soraya Monteiro, Rodrigo Ragazzini, Nitamar Abdala, Marcelo Straus Takahashi, Felipe Campos Kitamura",
      "update_time": "2025-11-28",
      "abstract": "Generative foundation models can remove visual artifacts through realistic image inpainting, but their impact on medical AI performance remains uncertain. Pediatric hand radiographs often contain non-anatomical markers, and it is unclear whether inpainting these regions preserves features needed for bone age and gender prediction. To evaluate the clinical reliability of generative model-based inpainting for artifact removal, we used the RSNA Bone Age Challenge dataset, selecting 200 original radiographs and generating 600 inpainted versions with gpt-image-1 using natural language prompts to target non-anatomical artifacts. Downstream performance was assessed with deep learning ensembles for bone age estimation and gender classification, using mean absolute error (MAE) and area under the ROC curve (AUC) as metrics, and pixel intensity distributions to detect structural alterations. Inpainting markedly degraded model performance: bone age MAE increased from 6.26 to 30.11 months, and gender classification AUC decreased from 0.955 to 0.704. Inpainted images displayed pixel-intensity shifts and inconsistencies, indicating structural modifications not corrected by simple calibration. These findings show that, although visually realistic, foundation model-based inpainting can obscure subtle but clinically relevant features and introduce latent bias even when edits are confined to non-diagnostic regions, underscoring the need for rigorous, task-specific validation before integrating such generative tools into clinical AI workflows.",
      "code_url": null
    },
    "2511.23059v1": {
      "title": "Conveying Imagistic Thinking in TCM Translation: A Prompt Engineering and LLM-Based Evaluation Framework",
      "url": "http://arxiv.org/abs/2511.23059v1",
      "authors": "Jiatong Han",
      "update_time": "2025-11-28",
      "abstract": "Traditional Chinese Medicine theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis. Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient and replicable HITL methodological pathway for translation of ancient, concept-dense texts like TCM.",
      "code_url": null
    },
    "2511.22990v1": {
      "title": "MIMM-X: Disentangling Spurious Correlations for Medical Image Analysis",
      "url": "http://arxiv.org/abs/2511.22990v1",
      "authors": "Louisa Fay, Hajer Reguigui, Bin Yang, Sergios Gatidis, Thomas K\u00fcstner",
      "update_time": "2025-11-28",
      "abstract": "Deep learning models can excel on medical tasks, yet often experience spurious correlations, known as shortcut learning, leading to poor generalization in new environments. Particularly in medical imaging, where multiple spurious correlations can coexist, misclassifications can have severe consequences. We propose MIMM-X, a framework that disentangles causal features from multiple spurious correlations by minimizing their mutual information. It enables predictions based on true underlying causal relationships rather than dataset-specific shortcuts. We evaluate MIMM-X on three datasets (UK Biobank, NAKO, CheXpert) across two imaging modalities (MRI and X-ray). Results demonstrate that MIMM-X effectively mitigates shortcut learning of multiple spurious correlations.",
      "code_url": null
    }
  }
}