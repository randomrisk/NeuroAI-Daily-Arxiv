{
  "Brain": {
    "2411.04986v1": {
      "title": "The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities",
      "url": "http://arxiv.org/abs/2411.04986v1",
      "authors": "Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, Jiasen Lu, Yoon Kim",
      "update_time": "2024-11-07",
      "abstract": "Modern language models can process inputs across diverse languages and modalities. We hypothesize that models acquire this capability through learning a shared representation space across heterogeneous data types (e.g., different languages and modalities), which places semantically similar inputs near one another, even if they are from different modalities/languages. We term this the semantic hub hypothesis, following the hub-and-spoke model from neuroscience (Patterson et al., 2007) which posits that semantic knowledge in the human brain is organized through a transmodal semantic \"hub\" which integrates information from various modality-specific \"spokes\" regions. We first show that model representations for semantically equivalent inputs in different languages are similar in the intermediate layers, and that this space can be interpreted using the model's dominant pretraining language via the logit lens. This tendency extends to other data types, including arithmetic expressions, code, and visual/audio inputs. Interventions in the shared representation space in one data type also predictably affect model outputs in other data types, suggesting that this shared representations space is not simply a vestigial byproduct of large-scale training on broad data, but something that is actively utilized by the model during input processing.",
      "code_url": "https://github.com/ZhaofengWu/semantic-hub"
    },
    "2411.04832v1": {
      "title": "Plasticity Loss in Deep Reinforcement Learning: A Survey",
      "url": "http://arxiv.org/abs/2411.04832v1",
      "authors": "Timo Klein, Lukas Miklautz, Kevin Sidak, Claudia Plant, Sebastian Tschiatschek",
      "update_time": "2024-11-07",
      "abstract": "Akin to neuroplasticity in human brains, the plasticity of deep neural networks enables their quick adaption to new data. This makes plasticity particularly crucial for deep Reinforcement Learning (RL) agents: Once plasticity is lost, an agent's performance will inevitably plateau because it cannot improve its policy to account for changes in the data distribution, which are a necessary consequence of its learning process. Thus, developing well-performing and sample-efficient agents hinges on their ability to remain plastic during training. Furthermore, the loss of plasticity can be connected to many other issues plaguing deep RL, such as training instabilities, scaling failures, overestimation bias, and insufficient exploration. With this survey, we aim to provide an overview of the emerging research on plasticity loss for academics and practitioners of deep reinforcement learning. First, we propose a unified definition of plasticity loss based on recent works, relate it to definitions from the literature, and discuss metrics for measuring plasticity loss. Then, we categorize and discuss numerous possible causes of plasticity loss before reviewing currently employed mitigation strategies. Our taxonomy is the first systematic overview of the current state of the field. Lastly, we discuss prevalent issues within the literature, such as a necessity for broader evaluation, and provide recommendations for future research, like gaining a better understanding of an agent's neural activity and behavior."
    },
    "2411.04715v1": {
      "title": "NeuroFly: A framework for whole-brain single neuron reconstruction",
      "url": "http://arxiv.org/abs/2411.04715v1",
      "authors": "Rubin Zhao, Yang Liu, Shiqi Zhang, Zijian Yi, Yanyang Xiao, Fang Xu, Yi Yang, Pencheng Zhou",
      "update_time": "2024-11-07",
      "abstract": "Neurons, with their elongated, tree-like dendritic and axonal structures, enable efficient signal integration and long-range communication across brain regions. By reconstructing individual neurons' morphology, we can gain valuable insights into brain connectivity, revealing the structure basis of cognition, movement, and perception. Despite the accumulation of extensive 3D microscopic imaging data, progress has been considerably hindered by the absence of automated tools to streamline this process. Here we introduce NeuroFly, a validated framework for large-scale automatic single neuron reconstruction. This framework breaks down the process into three distinct stages: segmentation, connection, and proofreading. In the segmentation stage, we perform automatic segmentation followed by skeletonization to generate over-segmented neuronal fragments without branches. During the connection stage, we use a 3D image-based path following approach to extend each fragment and connect it with other fragments of the same neuron. Finally, human annotators are required only to proofread the few unresolved positions. The first two stages of our process are clearly defined computer vision problems, and we have trained robust baseline models to solve them. We validated NeuroFly's efficiency using in-house datasets that include a variety of challenging scenarios, such as dense arborizations, weak axons, images with contamination. We will release the datasets along with a suite of visualization and annotation tools for better reproducibility. Our goal is to foster collaboration among researchers to address the neuron reconstruction challenge, ultimately accelerating advancements in neuroscience research. The dataset and code are available at https://github.com/beanli161514/neurofly",
      "code_url": "https://github.com/beanli161514/neurofly"
    },
    "2411.04665v1": {
      "title": "PZT Optical Memristors",
      "url": "http://arxiv.org/abs/2411.04665v1",
      "authors": "Chenlei Li, Hongyan Yu, Tao Shu, Yueyang Zhang, Chengfeng Wen, Hengzhen Cao, Jin Xie, Hanwen Li, Zixu Xu, Gong Zhang, Zejie Yu, Huan Li, Liu Liu, Yaocheng Shi, Feng Qiu, Daoxin Dai",
      "update_time": "2024-11-07",
      "abstract": "Optical memristors represent a monumental leap in the fusion of photonics and electronics, heralding a new era of new applications from neuromorphic computing to artificial intelligence. However, current technologies are hindered by complex fabrication, limited endurance, high optical loss or low modulation efficiency. For the first time, we unprecedentedly reveal optical non-volatility in thin-film Lead Zirconate Titanate (PZT) by electrically manipulating the ferroelectric domains to control the refractive index, providing a brand-new routine for optical memristors. The developed PZT optical memristors offer unprecedented advantages more than exceptional performance metrics like low loss, high precision, high-efficiency modulation, high stability quasi-continuity and reconfigurability. The wafer-scale sol-gel fabrication process also ensures compatible with standardized mass fabrication processes and high scalability for photonic integration. Specially, these devices also demonstrate unique functional duality: setting above a threshold voltage enables non-volatile behaviors, below this threshold allows volatile high-speed optical switching. This marks the first-ever optical memristor capable of performing high-speed signal processing and non-volatile retention on a single platform, and is also the inaugural demonstration of scalable functional systems. The PZT optical memristors developed here facilitate the realization of novel paradigms for high-speed and energy-efficient optical interconnects, programmable PICs, quantum computing, neural networks, in-memory computing and brain-like architecture."
    },
    "2411.04657v1": {
      "title": "EarCapAuth: Biometric Method for Earables Using Capacitive Sensing Eartips",
      "url": "http://arxiv.org/abs/2411.04657v1",
      "authors": "Richard Hanser, Tobias R\u00f6ddiger, Till Riedel, Michael Beigl",
      "update_time": "2024-11-07",
      "abstract": "Earphones can give access to sensitive information via voice assistants which demands security methods that prevent unauthorized use. Therefore, we developed EarCapAuth, an authentication mechanism using 48 capacitive electrodes embedded into the soft silicone eartips of two earables. For evaluation, we gathered capactive ear canal measurements from 20 participants in 20 wearing sessions (12 at rest, 8 while walking). A per user classifier trained for authentication achieves an EER of 7.62% and can be tuned to a FAR (False Acceptance Rate) of 1% at FRR (False Rejection Rate) of 16.14%. For identification, EarCapAuth achieves 89.95%. This outperforms some earable biometric principles from related work. Performance under motion slightly decreased to 9.76% EER for authentication and 86.40% accuracy for identification. Enrollment can be performed rapidly with multiple short earpiece insertions and a biometric decision is made every 0.33s. In the future, EarCapAuth could be integrated into high-resolution brain sensing electrode tips."
    },
    "2411.04632v1": {
      "title": "Improved Multi-Task Brain Tumour Segmentation with Synthetic Data Augmentation",
      "url": "http://arxiv.org/abs/2411.04632v1",
      "authors": "Andr\u00e9 Ferreira, Tiago Jesus, Behrus Puladi, Jens Kleesiek, Victor Alves, Jan Egger",
      "update_time": "2024-11-07",
      "abstract": "This paper presents the winning solution of task 1 and the third-placed solution of task 3 of the BraTS challenge. The use of automated tools in clinical practice has increased due to the development of more and more sophisticated and reliable algorithms. However, achieving clinical standards and developing tools for real-life scenarios is a major challenge. To this end, BraTS has organised tasks to find the most advanced solutions for specific purposes. In this paper, we propose the use of synthetic data to train state-of-the-art frameworks in order to improve the segmentation of adult gliomas in a post-treatment scenario, and the segmentation of meningioma for radiotherapy planning. Our results suggest that the use of synthetic data leads to more robust algorithms, although the synthetic data generation pipeline is not directly suited to the meningioma task. The code for these tasks is available at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.",
      "code_url": "https://github.com/shadowtwin41/brats_2023_2024_solutions"
    },
    "2411.04630v1": {
      "title": "Brain Tumour Removing and Missing Modality Generation using 3D WDM",
      "url": "http://arxiv.org/abs/2411.04630v1",
      "authors": "Andr\u00e9 Ferreira, Gijs Luijten, Behrus Puladi, Jens Kleesiek, Victor Alves, Jan Egger",
      "update_time": "2024-11-07",
      "abstract": "This paper presents the second-placed solution for task 8 and the participation solution for task 7 of BraTS 2024. The adoption of automated brain analysis algorithms to support clinical practice is increasing. However, many of these algorithms struggle with the presence of brain lesions or the absence of certain MRI modalities. The alterations in the brain's morphology leads to high variability and thus poor performance of predictive models that were trained only on healthy brains. The lack of information that is usually provided by some of the missing MRI modalities also reduces the reliability of the prediction models trained with all modalities. In order to improve the performance of these models, we propose the use of conditional 3D wavelet diffusion models. The wavelet transform enabled full-resolution image training and prediction on a GPU with 48 GB VRAM, without patching or downsampling, preserving all information for prediction. For the inpainting task of BraTS 2024, the use of a large and variable number of healthy masks and the stability and efficiency of the 3D wavelet diffusion model resulted in 0.007, 22.61 and 0.842 in the validation set and 0.07 , 22.8 and 0.91 in the testing set (MSE, PSNR and SSIM respectively). The code for these tasks is available at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.",
      "code_url": "https://github.com/shadowtwin41/brats_2023_2024_solutions"
    },
    "2411.04568v1": {
      "title": "Dynamic-Attention-based EEG State Transition Modeling for Emotion Recognition",
      "url": "http://arxiv.org/abs/2411.04568v1",
      "authors": "Xinke Shen, Runmin Gan, Kaixuan Wang, Shuyi Yang, Qingzhu Zhang, Quanying Liu, Dan Zhang, Sen Song",
      "update_time": "2024-11-07",
      "abstract": "Electroencephalogram (EEG)-based emotion decoding can objectively quantify people's emotional state and has broad application prospects in human-computer interaction and early detection of emotional disorders. Recently emerging deep learning architectures have significantly improved the performance of EEG emotion decoding. However, existing methods still fall short of fully capturing the complex spatiotemporal dynamics of neural signals, which are crucial for representing emotion processing. This study proposes a Dynamic-Attention-based EEG State Transition (DAEST) modeling method to characterize EEG spatiotemporal dynamics. The model extracts spatiotemporal components of EEG that represent multiple parallel neural processes and estimates dynamic attention weights on these components to capture transitions in brain states. The model is optimized within a contrastive learning framework for cross-subject emotion recognition. The proposed method achieved state-of-the-art performance on three publicly available datasets: FACED, SEED, and SEED-V. It achieved 75.4% accuracy in the binary classification of positive and negative emotions and 59.3% in nine-class discrete emotion classification on the FACED dataset, 88.1% in the three-class classification of positive, negative, and neutral emotions on the SEED dataset, and 73.6% in five-class discrete emotion classification on the SEED-V dataset. The learned EEG spatiotemporal patterns and dynamic transition properties offer valuable insights into neural dynamics underlying emotion processing."
    },
    "2411.04508v1": {
      "title": "A Comprehensive Review of Multimodal XR Applications, Risks, and Ethical Challenges in the Metaverse",
      "url": "http://arxiv.org/abs/2411.04508v1",
      "authors": "Panagiotis Kourtesis",
      "update_time": "2024-11-07",
      "abstract": "This scoping review examines the broad applications, risks, and ethical challenges associated with Extended Reality (XR) technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), within the context of Metaverse. XR is revolutionizing fields such as immersive learning in education, medical and professional training, neuropsychological assessment, therapeutic interventions, arts, entertainment, retail, e-commerce, remote work, sports, architecture, urban planning, and cultural heritage preservation. The integration of multimodal technologies such as haptics, eye-tracking, face- and body-tracking, and brain-computer interfaces, enhances user engagement and interactivity, playing a key role in shaping the immersive experiences in the Metaverse. However, XR's expansion raises serious concerns, including data privacy risks, cybersecurity vulnerabilities, cybersickness, addiction, dissociation, harassment, bullying, and misinformation. These psychological, social, and security challenges are further complicated by intense advertising, manipulation of public opinion, and social inequality, which could disproportionately affect vulnerable individuals and social groups. This review emphasizes the urgent need for robust ethical frameworks and regulatory guidelines to address these risks while promoting equitable access, privacy, autonomy, and mental well-being. As XR technologies increasingly integrate with artificial intelligence, responsible governance is essential to ensure the safe and beneficial development of the Metaverse and the broader application of XR in enhancing human development."
    },
    "2411.04229v1": {
      "title": "Detecting State Changes in Functional Neuronal Connectivity using Factorial Switching Linear Dynamical Systems",
      "url": "http://arxiv.org/abs/2411.04229v1",
      "authors": "Yiwei Gong, Susanna B. Mierau, Sinead A. Williamson",
      "update_time": "2024-11-06",
      "abstract": "A key question in brain sciences is how to identify time-evolving functional connectivity, such as that obtained from recordings of neuronal activity over time. We wish to explain the observed phenomena in terms of latent states which, in the case of neuronal activity, might correspond to subnetworks of neurons within a brain or organoid. Many existing approaches assume that only one latent state can be active at a time, in contrast to our domain knowledge. We propose a switching dynamical system based on the factorial hidden Markov model. Unlike existing approaches, our model acknowledges that neuronal activity can be caused by multiple subnetworks, which may be activated either jointly or independently. A change in one part of the network does not mean that the entire connectivity pattern will change. We pair our model with scalable variational inference algorithm, using a concrete relaxation of the underlying factorial hidden Markov model, to effectively infer the latent states and model parameters. We show that our algorithm can recover ground-truth structure and yield insights about the maturation of neuronal activity in microelectrode array recordings from in vitro neuronal cultures."
    }
  },
  "EEG": {
    "2411.04568v1": {
      "title": "Dynamic-Attention-based EEG State Transition Modeling for Emotion Recognition",
      "url": "http://arxiv.org/abs/2411.04568v1",
      "authors": "Xinke Shen, Runmin Gan, Kaixuan Wang, Shuyi Yang, Qingzhu Zhang, Quanying Liu, Dan Zhang, Sen Song",
      "update_time": "2024-11-07",
      "abstract": "Electroencephalogram (EEG)-based emotion decoding can objectively quantify people's emotional state and has broad application prospects in human-computer interaction and early detection of emotional disorders. Recently emerging deep learning architectures have significantly improved the performance of EEG emotion decoding. However, existing methods still fall short of fully capturing the complex spatiotemporal dynamics of neural signals, which are crucial for representing emotion processing. This study proposes a Dynamic-Attention-based EEG State Transition (DAEST) modeling method to characterize EEG spatiotemporal dynamics. The model extracts spatiotemporal components of EEG that represent multiple parallel neural processes and estimates dynamic attention weights on these components to capture transitions in brain states. The model is optimized within a contrastive learning framework for cross-subject emotion recognition. The proposed method achieved state-of-the-art performance on three publicly available datasets: FACED, SEED, and SEED-V. It achieved 75.4% accuracy in the binary classification of positive and negative emotions and 59.3% in nine-class discrete emotion classification on the FACED dataset, 88.1% in the three-class classification of positive, negative, and neutral emotions on the SEED dataset, and 73.6% in five-class discrete emotion classification on the SEED-V dataset. The learned EEG spatiotemporal patterns and dynamic transition properties offer valuable insights into neural dynamics underlying emotion processing."
    },
    "2411.02726v1": {
      "title": "Elliptical Wishart distributions: information geometry, maximum likelihood estimator, performance analysis and statistical learning",
      "url": "http://arxiv.org/abs/2411.02726v1",
      "authors": "Imen Ayadi, Florent Bouchard, Fr\u00e9d\u00e9ric Pascal",
      "update_time": "2024-11-05",
      "abstract": "This paper deals with Elliptical Wishart distributions - which generalize the Wishart distribution - in the context of signal processing and machine learning. Two algorithms to compute the maximum likelihood estimator (MLE) are proposed: a fixed point algorithm and a Riemannian optimization method based on the derived information geometry of Elliptical Wishart distributions. The existence and uniqueness of the MLE are characterized as well as the convergence of both estimation algorithms. Statistical properties of the MLE are also investigated such as consistency, asymptotic normality and an intrinsic version of Fisher efficiency. On the statistical learning side, novel classification and clustering methods are designed. For the $t$-Wishart distribution, the performance of the MLE and statistical learning algorithms are evaluated on both simulated and real EEG and hyperspectral data, showcasing the interest of our proposed methods."
    },
    "2411.02286v1": {
      "title": "Federated GNNs for EEG-Based Stroke Assessment",
      "url": "http://arxiv.org/abs/2411.02286v1",
      "authors": "Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio",
      "update_time": "2024-11-04",
      "abstract": "Machine learning (ML) has the potential to become an essential tool in supporting clinical decision-making processes, offering enhanced diagnostic capabilities and personalized treatment plans. However, outsourcing medical records to train ML models using patient data raises legal, privacy, and security concerns. Federated learning has emerged as a promising paradigm for collaborative ML, meeting healthcare institutions' requirements for robust models without sharing sensitive data and compromising patient privacy. This study proposes a novel method that combines federated learning (FL) and Graph Neural Networks (GNNs) to predict stroke severity using electroencephalography (EEG) signals across multiple medical institutions. Our approach enables multiple hospitals to jointly train a shared GNN model on their local EEG data without exchanging patient information. Specifically, we address a regression problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a key indicator of stroke severity. The proposed model leverages a masked self-attention mechanism to capture salient brain connectivity patterns and employs EdgeSHAP to provide post-hoc explanations of the neurological states after a stroke. We evaluated our method on EEG recordings from four institutions, achieving a mean absolute error (MAE) of 3.23 in predicting NIHSS, close to the average error made by human experts (MAE $\\approx$ 3.0). This demonstrates the method's effectiveness in providing accurate and explainable predictions while maintaining data privacy."
    },
    "2411.02094v1": {
      "title": "Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2411.02094v1",
      "authors": "Xiaoqing Chen, Ziwei Wang, Dongrui Wu",
      "update_time": "2024-11-04",
      "abstract": "Machine learning has achieved great success in electroencephalogram (EEG) based brain-computer interfaces (BCIs). Most existing BCI studies focused on improving the decoding accuracy, with only a few considering the adversarial security. Although many adversarial defense approaches have been proposed in other application domains such as computer vision, previous research showed that their direct extensions to BCIs degrade the classification accuracy on benign samples. This phenomenon greatly affects the applicability of adversarial defense approaches to EEG-based BCIs. To mitigate this problem, we propose alignment-based adversarial training (ABAT), which performs EEG data alignment before adversarial training. Data alignment aligns EEG trials from different domains to reduce their distribution discrepancies, and adversarial training further robustifies the classification boundary. The integration of data alignment and adversarial training can make the trained EEG classifiers simultaneously more accurate and more robust. Experiments on five EEG datasets from two different BCI paradigms (motor imagery classification, and event related potential recognition), three convolutional neural network classifiers (EEGNet, ShallowCNN and DeepCNN) and three different experimental settings (offline within-subject cross-block/-session classification, online cross-session classification, and pre-trained classifiers) demonstrated its effectiveness. It is very intriguing that adversarial attacks, which are usually used to damage BCI systems, can be used in ABAT to simultaneously improve the model accuracy and robustness.",
      "code_url": "https://github.com/xqchen914/abat"
    },
    "2411.01589v1": {
      "title": "BiT-MamSleep: Bidirectional Temporal Mamba for EEG Sleep Staging",
      "url": "http://arxiv.org/abs/2411.01589v1",
      "authors": "Xinliang Zhou, Yuzhe Han, Chenyu Liu, Yi Ding, Ziyu Jia, Yang Liu",
      "update_time": "2024-11-03",
      "abstract": "In this paper, we address the challenges in automatic sleep stage classification, particularly the high computational cost, inadequate modeling of bidirectional temporal dependencies, and class imbalance issues faced by Transformer-based models. To address these limitations, we propose BiT-MamSleep, a novel architecture that integrates the Triple-Resolution CNN (TRCNN) for efficient multi-scale feature extraction with the Bidirectional Mamba (BiMamba) mechanism, which models both short- and long-term temporal dependencies through bidirectional processing of EEG data. Additionally, BiT-MamSleep incorporates an Adaptive Feature Recalibration (AFR) module and a temporal enhancement block to dynamically refine feature importance, optimizing classification accuracy without increasing computational complexity. To further improve robustness, we apply optimization techniques such as Focal Loss and SMOTE to mitigate class imbalance. Extensive experiments on four public datasets demonstrate that BiT-MamSleep significantly outperforms state-of-the-art methods, particularly in handling long EEG sequences and addressing class imbalance, leading to more accurate and scalable sleep stage classification."
    },
    "2411.01522v1": {
      "title": "Are EEG functional networks really describing the brain? A comparison with other information-processing complex systems",
      "url": "http://arxiv.org/abs/2411.01522v1",
      "authors": "Sofia Gil-Rodrigo, Ra\u00fal L\u00f3pez-Mart\u00edn, G\u00f6rsev Yener, Jan R. Wiersema, Bahar G\u00fcntekin, Massimiliano Zanin",
      "update_time": "2024-11-03",
      "abstract": "Functional networks representing human brain dynamics have become a standard tool in neuroscience, providing an accessible way of depicting the computation performed by the brain in healthy and pathological conditions. Yet, these networks share multiple characteristics with those representing other natural and man-made complex systems, leading to the question of whether they are actually capturing the uniqueness of the human brain. By resorting to a large set of data representing multiple financial, technological, social, and natural complex systems, and by relying on Deep Learning classification models, we show how they are highly similar. We specifically reach the conclusion that, under some general reconstruction methodological choices, it is as difficult to understand whether a network represents a human brain or a financial market, as to diagnose a major pathology. This suggests that functional networks are describing information processing mechanisms that are common across complex systems; but that are not currently defining the uniqueness of the human mind. We discuss the consequence of these findings for neuroscience and complexity science in general, and suggest future avenues for exploring this interesting topic."
    },
    "2411.01220v2": {
      "title": "Enhancing Neural Network Interpretability with Feature-Aligned Sparse Autoencoders",
      "url": "http://arxiv.org/abs/2411.01220v2",
      "authors": "Luke Marks, Alasdair Paren, David Krueger, Fazl Barez",
      "update_time": "2024-11-06",
      "abstract": "Sparse Autoencoders (SAEs) have shown promise in improving the interpretability of neural network activations, but can learn features that are not features of the input, limiting their effectiveness. We propose \\textsc{Mutual Feature Regularization} \\textbf{(MFR)}, a regularization technique for improving feature learning by encouraging SAEs trained in parallel to learn similar features. We motivate \\textsc{MFR} by showing that features learned by multiple SAEs are more likely to correlate with features of the input. By training on synthetic data with known features of the input, we show that \\textsc{MFR} can help SAEs learn those features, as we can directly compare the features learned by the SAE with the input features for the synthetic data. We then scale \\textsc{MFR} to SAEs that are trained to denoise electroencephalography (EEG) data and SAEs that are trained to reconstruct GPT-2 Small activations. We show that \\textsc{MFR} can improve the reconstruction loss of SAEs by up to 21.21\\% on GPT-2 Small, and 6.67\\% on EEG data. Our results suggest that the similarity between features learned by different SAEs can be leveraged to improve SAE training, thereby enhancing performance and the usefulness of SAEs for model interpretability.",
      "code_url": "https://github.com/luke-marks0/mutual-feature-regularization"
    },
    "2411.00718v1": {
      "title": "PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals",
      "url": "http://arxiv.org/abs/2411.00718v1",
      "authors": "Saurav R. Pandey, Aaqib Saeed, Harlin Lee",
      "update_time": "2024-11-01",
      "abstract": "Pediatric sleep is an important but often overlooked area in health informatics. We present PedSleepMAE, a generative model that fully leverages multimodal pediatric sleep signals including multichannel EEGs, respiratory signals, EOGs and EMG. This masked autoencoder-based model performs comparably to supervised learning models in sleep scoring and in the detection of apnea, hypopnea, EEG arousal and oxygen desaturation. Its embeddings are also shown to capture subtle differences in sleep signals coming from a rare genetic disorder. Furthermore, PedSleepMAE generates realistic signals that can be used for sleep segment retrieval, outlier detection, and missing channel imputation. This is the first general-purpose generative model trained on multiple types of pediatric sleep signals."
    },
    "2411.00143v1": {
      "title": "Enhancing Brain Source Reconstruction through Physics-Informed 3D Neural Networks",
      "url": "http://arxiv.org/abs/2411.00143v1",
      "authors": "Marco Morik, Ali Hashemi, Klaus-Robert M\u00fcller, Stefan Haufe, Shinichi Nakajima",
      "update_time": "2024-10-31",
      "abstract": "Reconstructing brain sources is a fundamental challenge in neuroscience, crucial for understanding brain function and dysfunction. Electroencephalography (EEG) signals have a high temporal resolution. However, identifying the correct spatial location of brain sources from these signals remains difficult due to the ill-posed structure of the problem. Traditional methods predominantly rely on manually crafted priors, missing the flexibility of data-driven learning, while recent deep learning approaches focus on end-to-end learning, typically using the physical information of the forward model only for generating training data. We propose the novel hybrid method 3D-PIUNet for EEG source localization that effectively integrates the strengths of traditional and deep learning techniques. 3D-PIUNet starts from an initial physics-informed estimate by using the pseudo inverse to map from measurements to source space. Secondly, by viewing the brain as a 3D volume, we use a 3D convolutional U-Net to capture spatial dependencies and refine the solution according to the learned data prior. Training the model relies on simulated pseudo-realistic brain source data, covering different source distributions. Trained on this data, our model significantly improves spatial accuracy, demonstrating superior performance over both traditional and end-to-end data-driven methods. Additionally, we validate our findings with real EEG data from a visual task, where 3D-PIUNet successfully identifies the visual cortex and reconstructs the expected temporal behavior, thereby showcasing its practical applicability."
    },
    "2410.23812v1": {
      "title": "Graph Neural Networks Uncover Geometric Neural Representations in Reinforcement-Based Motor Learning",
      "url": "http://arxiv.org/abs/2410.23812v1",
      "authors": "Federico Nardi, Jinpei Han, Shlomi Haar, A. Aldo Faisal",
      "update_time": "2024-10-31",
      "abstract": "Graph Neural Networks (GNN) can capture the geometric properties of neural representations in EEG data. Here we utilise those to study how reinforcement-based motor learning affects neural activity patterns during motor planning, leveraging the inherent graph structure of EEG channels to capture the spatial relationships in brain activity. By exploiting task-specific symmetries, we define different pretraining strategies that not only improve model performance across all participant groups but also validate the robustness of the geometric representations. Explainability analysis based on the graph structures reveals consistent group-specific neural signatures that persist across pretraining conditions, suggesting stable geometric structures in the neural representations associated with motor learning and feedback processing. These geometric patterns exhibit partial invariance to certain task space transformations, indicating symmetries that enable generalisation across conditions while maintaining specificity to individual learning strategies. This work demonstrates how GNNs can uncover the effects of previous outcomes on motor planning, in a complex real-world task, providing insights into the geometric principles governing neural representations. Our experimental design bridges the gap between controlled experiments and ecologically valid scenarios, offering new insights into the organisation of neural representations during naturalistic motor learning, which may open avenues for exploring fundamental principles governing brain activity in complex tasks."
    }
  },
  "BCI": {
    "2411.02094v1": {
      "title": "Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs",
      "url": "http://arxiv.org/abs/2411.02094v1",
      "authors": "Xiaoqing Chen, Ziwei Wang, Dongrui Wu",
      "update_time": "2024-11-04",
      "abstract": "Machine learning has achieved great success in electroencephalogram (EEG) based brain-computer interfaces (BCIs). Most existing BCI studies focused on improving the decoding accuracy, with only a few considering the adversarial security. Although many adversarial defense approaches have been proposed in other application domains such as computer vision, previous research showed that their direct extensions to BCIs degrade the classification accuracy on benign samples. This phenomenon greatly affects the applicability of adversarial defense approaches to EEG-based BCIs. To mitigate this problem, we propose alignment-based adversarial training (ABAT), which performs EEG data alignment before adversarial training. Data alignment aligns EEG trials from different domains to reduce their distribution discrepancies, and adversarial training further robustifies the classification boundary. The integration of data alignment and adversarial training can make the trained EEG classifiers simultaneously more accurate and more robust. Experiments on five EEG datasets from two different BCI paradigms (motor imagery classification, and event related potential recognition), three convolutional neural network classifiers (EEGNet, ShallowCNN and DeepCNN) and three different experimental settings (offline within-subject cross-block/-session classification, online cross-session classification, and pre-trained classifiers) demonstrated its effectiveness. It is very intriguing that adversarial attacks, which are usually used to damage BCI systems, can be used in ABAT to simultaneously improve the model accuracy and robustness.",
      "code_url": "https://github.com/xqchen914/abat"
    },
    "2410.23639v1": {
      "title": "Biologically-Inspired Technologies: Integrating Brain-Computer Interface and Neuromorphic Computing for Human Digital Twins",
      "url": "http://arxiv.org/abs/2410.23639v1",
      "authors": "Chen Shang, Jiadong Yu, Dinh Thai Hoang",
      "update_time": "2024-10-31",
      "abstract": "The integration of the Metaverse into a human-centric ecosystem has intensified the need for sophisticated Human Digital Twins (HDTs) that are driven by the multifaceted human data. However, the effective construction of HDTs faces significant challenges due to the heterogeneity of data collection devices, the high energy demands associated with processing intricate data, and concerns over the privacy of sensitive information. This work introduces a novel biologically-inspired (bio-inspired) HDT framework that leverages Brain-Computer Interface (BCI) sensor technology to capture brain signals as the data source for constructing HDT. By collecting and analyzing these signals, the framework not only minimizes device heterogeneity and enhances data collection efficiency, but also provides richer and more nuanced physiological and psychological data for constructing personalized HDTs. To this end, we further propose a bio-inspired neuromorphic computing learning model based on the Spiking Neural Network (SNN). This model utilizes discrete neural spikes to emulate the way of human brain processes information, thereby enhancing the system's ability to process data effectively while reducing energy consumption. Additionally, we integrate a Federated Learning (FL) strategy within the model to strengthen data privacy. We then conduct a case study to demonstrate the performance of our proposed twofold bio-inspired scheme. Finally, we present several challenges and promising directions for future research of HDTs driven by bio-inspired technologies."
    },
    "2410.22008v1": {
      "title": "Neurofeedback-Driven 6-DOF Robotic Arm: Integration of Brain-Computer Interface with Arduino for Advanced Control",
      "url": "http://arxiv.org/abs/2410.22008v1",
      "authors": "Ihab A. Satam, R\u00f3bert Szabolcsi",
      "update_time": "2024-10-29",
      "abstract": "Brain computer interface (BCI) applications in robotics are becoming more famous and famous. People with disabilities are facing a real-time problem of doing simple activities such as grasping, handshaking etc. in order to aid with this problem, the use of brain signals to control actuators is showing a great importance. The Emotive Insight, a Brain-Computer Interface (BCI) device, is utilized in this project to collect brain signals and transform them into commands for controlling a robotic arm using an Arduino controller. The Emotive Insight captures brain signals, which are subsequently analyzed using Emotive software and connected with Arduino code. The HITI Brain software integrates these devices, allowing for smooth communication between brain activity and the robotic arm. This system demonstrates how brain impulses may be utilized to control external devices directly. The results showed that the system is applicable efficiently to robotic arms and also for prosthetic arms with Multi Degree of Freedom. In addition to that, the system can be used for other actuators such as bikes, mobile robots, wheelchairs etc."
    },
    "2410.15161v1": {
      "title": "Evaluation Of P300 Speller Performance Using Large Language Models Along With Cross-Subject Training",
      "url": "http://arxiv.org/abs/2410.15161v1",
      "authors": "Nithin Parthasarathy, James Soetedjo, Saarang Panchavati, Nitya Parthasarathy, Corey Arnold, Nader Pouratian, William Speier",
      "update_time": "2024-10-19",
      "abstract": "Amyotrophic lateral sclerosis (ALS), a progressive neuromuscular degenerative disease, severely restricts patient communication capacity within a few years of onset, resulting in a significant deterioration of quality of life. The P300 speller brain computer interface (BCI) offers an alternative communication medium by leveraging a subject's EEG response to characters traditionally highlighted on a character grid on a graphical user interface (GUI). A recurring theme in P300-based research is enhancing performance to enable faster subject interaction. This study builds on that theme by addressing key limitations, particularly in the training of multi-subject classifiers, and by integrating advanced language models to optimize stimuli presentation and word prediction, thereby improving communication efficiency. Furthermore, various advanced large language models such as Generative Pre-Trained Transformer (GPT2), BERT, and BART, alongside Dijkstra's algorithm, are utilized to optimize stimuli and provide word completion choices based on the spelling history. In addition, a multi-layered smoothing approach is applied to allow for out-of-vocabulary (OOV) words. By conducting extensive simulations based on randomly sampled EEG data from subjects, we show substantial speed improvements in typing passages that include rare and out-of-vocabulary (OOV) words, with the extent of improvement varying depending on the language model utilized. The gains through such character-level interface optimizations are approximately 10%, and GPT2 for multi-word prediction provides gains of around 40%. In particular, some large language models achieve performance levels within 10% of the theoretical performance limits established in this study. In addition, both within and across subjects, training techniques are explored, and speed improvements are shown to hold in both cases.",
      "code_url": "https://github.com/nithinparthasarthy/P300Speller"
    },
    "2410.12267v1": {
      "title": "iFuzzyTL: Interpretable Fuzzy Transfer Learning for SSVEP BCI System",
      "url": "http://arxiv.org/abs/2410.12267v1",
      "authors": "Xiaowei Jiang, Beining Cao, Liang Ou, Yu-Cheng Chang, Thomas Do, Chin-Teng Lin",
      "update_time": "2024-10-16",
      "abstract": "The rapid evolution of Brain-Computer Interfaces (BCIs) has significantly influenced the domain of human-computer interaction, with Steady-State Visual Evoked Potentials (SSVEP) emerging as a notably robust paradigm. This study explores advanced classification techniques leveraging interpretable fuzzy transfer learning (iFuzzyTL) to enhance the adaptability and performance of SSVEP-based systems. Recent efforts have strengthened to reduce calibration requirements through innovative transfer learning approaches, which refine cross-subject generalizability and minimize calibration through strategic application of domain adaptation and few-shot learning strategies. Pioneering developments in deep learning also offer promising enhancements, facilitating robust domain adaptation and significantly improving system responsiveness and accuracy in SSVEP classification. However, these methods often require complex tuning and extensive data, limiting immediate applicability. iFuzzyTL introduces an adaptive framework that combines fuzzy logic principles with neural network architectures, focusing on efficient knowledge transfer and domain adaptation. iFuzzyTL refines input signal processing and classification in a human-interpretable format by integrating fuzzy inference systems and attention mechanisms. This approach bolsters the model's precision and aligns with real-world operational demands by effectively managing the inherent variability and uncertainty of EEG data. The model's efficacy is demonstrated across three datasets: 12JFPM (89.70% accuracy for 1s with an information transfer rate (ITR) of 149.58), Benchmark (85.81% accuracy for 1s with an ITR of 213.99), and eldBETA (76.50% accuracy for 1s with an ITR of 94.63), achieving state-of-the-art results and setting new benchmarks for SSVEP BCI performance."
    },
    "2410.11339v1": {
      "title": "EEG-based 90-Degree Turn Intention Detection for Brain-Computer Interface",
      "url": "http://arxiv.org/abs/2410.11339v1",
      "authors": "Pradyot Anand, Anant Jain, Suriya Prakash Muthukrishnan, Shubhendu Bhasin, Sitikantha Roy, Mohanavelu Kalathe, Lalan Kumar",
      "update_time": "2024-10-15",
      "abstract": "Electroencephalography (EEG)--based turn intention prediction for lower limb movement is important to build an efficient brain-computer interface (BCI) system. This study investigates the feasibility of intention detection of left-turn, right-turn, and straight walk by utilizing EEG signals obtained before the event occurrence. Synchronous data was collected using 31-channel EEG and IMU-based motion capture systems for nine healthy participants while performing left-turn, right-turn, and straight walk movements. EEG data was preprocessed with steps including Artifact Subspace Reconstruction (ASR), re-referencing, and Independent Component Analysis (ICA) to remove data noise. Feature extraction from the preprocessed EEG data involved computing various statistical measures (mean, median, standard deviation, skew, and kurtosis), and Hjorth parameters (activity, mobility, and complexity). Further, the feature selection was performed using the Random forest algorithm for the dimensionality reduction. The feature set obtained was utilized for 3-class classification using XG boost, gradient boosting, and support vector machine (SVM) with RBF kernel classifiers in a five-fold cross-validation scheme. Using the proposed intention detection methodology, the SVM classifier using an EEG window of 1.5 s and 0 s time-lag has the best decoding performance with mean accuracy, precision, and recall of 81.23%, 85.35%, and 83.92%, respectively, across the nine participants. The decoding analysis shows the feasibility of turn intention prediction for lower limb movement using the EEG signal before the event onset."
    },
    "2410.12866v1": {
      "title": "Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings",
      "url": "http://arxiv.org/abs/2410.12866v1",
      "authors": "Di Wu, Siyuan Li, Chen Feng, Lu Cao, Yue Zhang, Jie Yang, Mohamad Sawan",
      "update_time": "2024-10-13",
      "abstract": "Recent advancements in brain-computer interfaces (BCIs) have enabled the decoding of lexical tones from intracranial recordings, offering the potential to restore the communication abilities of speech-impaired tonal language speakers. However, data heterogeneity induced by both physiological and instrumental factors poses a significant challenge for unified invasive brain tone decoding. Traditional subject-specific models, which operate under a heterogeneous decoding paradigm, fail to capture generalized neural representations and cannot effectively leverage data across subjects. To address these limitations, we introduce Homogeneity-Heterogeneity Disentangled Learning for neural Representations (H2DiLR), a novel framework that disentangles and learns both the homogeneity and heterogeneity from intracranial recordings across multiple subjects. To evaluate H2DiLR, we collected stereoelectroencephalography (sEEG) data from multiple participants reading Mandarin materials comprising 407 syllables, representing nearly all Mandarin characters. Extensive experiments demonstrate that H2DiLR, as a unified decoding paradigm, significantly outperforms the conventional heterogeneous decoding approach. Furthermore, we empirically confirm that H2DiLR effectively captures both homogeneity and heterogeneity during neural representation learning."
    },
    "2410.09763v1": {
      "title": "EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing Wheelchair System Using Machine Learning Mechanism with Right and Left Voluntary Hand Movement",
      "url": "http://arxiv.org/abs/2410.09763v1",
      "authors": "Biplov Paneru, Bishwash Paneru, Khem Narayan Poudyal",
      "update_time": "2024-10-13",
      "abstract": "This paper presents an Artificial Intelligence (AI) integrated novel approach to Brain-Computer Interface (BCI)-based wheelchair development, utilizing a voluntary Right Left Hand Movement mechanism for control. The system is designed to simulate wheelchair navigation based on voluntary right and left-hand movements using electroencephalogram (EEG) data. A pre-filtered dataset, obtained from an open-source EEG repository, was segmented into arrays of 19x200 to capture the onset of hand movements. The data was acquired at a sampling frequency 200Hz in the laboratory experiment. The system integrates a Tkinter-based interface for simulating wheelchair movements, offering users a functional and intuitive control system. Various machine learning models, including Support Vector Machines (SVM), XGBoost, random forest, and a Bi-directional Long Short-Term Memory (Bi-LSTM) attention-based model, were developed. The random forest model obtained 79% accuracy. Great performance was seen on the Logistic Regression model which outperforms other models with 92% accuracy and 91% accuracy on the Multi-Layer Perceptron (MLP) model. The Bi-LSTM attention-based model achieved a mean accuracy of 86% through cross-validation, showcasing the potential of attention mechanisms in BCI applications."
    },
    "2410.08561v1": {
      "title": "Towards Effective Deep Neural Network Approach for Multi-Trial P300-based Character Recognition in Brain-Computer Interfaces",
      "url": "http://arxiv.org/abs/2410.08561v1",
      "authors": "Praveen Kumar Shukla, Hubert Cecotti, Yogesh Kumar Meena",
      "update_time": "2024-10-11",
      "abstract": "Brain-computer interfaces (BCIs) enable direct interaction between users and computers by decoding brain signals. This study addresses the challenges of detecting P300 event-related potentials in electroencephalograms (EEGs) and integrating these P300 responses for character spelling, particularly within oddball paradigms characterized by uneven P300 distribution, low target probability, and poor signal-to-noise ratio (SNR). This work proposes a weighted ensemble spatio-sequential convolutional neural network (WE-SPSQ-CNN) to improve classification accuracy and SNR by mitigating signal variability for character identification. We evaluated the proposed WE-SPSQ-CNN on dataset II from the BCI Competition III, achieving P300 classification accuracies of 69.7\\% for subject A and 79.9\\% for subject B across fifteen epochs. For character recognition, the model achieved average accuracies of 76.5\\%, 87.5\\%, and 94.5\\% with five, ten, and fifteen repetitions, respectively. Our proposed model outperformed state-of-the-art models in the five-repetition and delivered comparable performance in the ten and fifteen repetitions."
    },
    "2410.07920v1": {
      "title": "Post-Training Quantization in Brain-Computer Interfaces based on Event-Related Potential Detection",
      "url": "http://arxiv.org/abs/2410.07920v1",
      "authors": "Hubert Cecotti, Dalvir Dhaliwal, Hardip Singh, Yogesh Kumar Meena",
      "update_time": "2024-10-10",
      "abstract": "Post-training quantization (PTQ) is a technique used to optimize and reduce the memory footprint and computational requirements of machine learning models. It has been used primarily for neural networks. For Brain-Computer Interfaces (BCI) that are fully portable and usable in various situations, it is necessary to provide approaches that are lightweight for storage and computation. In this paper, we propose the evaluation of post-training quantization on state-of-the-art approaches in brain-computer interfaces and assess their impact on accuracy. We evaluate the performance of the single-trial detection of event-related potentials representing one major BCI paradigm. The area under the receiver operating characteristic curve drops from 0.861 to 0.825 with PTQ when applied on both spatial filters and the classifier, while reducing the size of the model by about $\\times$ 15. The results support the conclusion that PTQ can substantially reduce the memory footprint of the models while keeping roughly the same level of accuracy."
    }
  },
  "fMRI": {
    "2411.02949v1": {
      "title": "A scalable generative model for dynamical system reconstruction from neuroimaging data",
      "url": "http://arxiv.org/abs/2411.02949v1",
      "authors": "Eric Volkmann, Alena Br\u00e4ndle, Daniel Durstewitz, Georgia Koppe",
      "update_time": "2024-11-05",
      "abstract": "Data-driven inference of the generative dynamics underlying a set of observed time series is of growing interest in machine learning and the natural sciences. In neuroscience, such methods promise to alleviate the need to handcraft models based on biophysical principles and allow to automatize the inference of inter-individual differences in brain dynamics. Recent breakthroughs in training techniques for state space models (SSMs) specifically geared toward dynamical systems (DS) reconstruction (DSR) enable to recover the underlying system including its geometrical (attractor) and long-term statistical invariants from even short time series. These techniques are based on control-theoretic ideas, like modern variants of teacher forcing (TF), to ensure stable loss gradient propagation while training. However, as it currently stands, these techniques are not directly applicable to data modalities where current observations depend on an entire history of previous states due to a signal's filtering properties, as common in neuroscience (and physiology more generally). Prominent examples are the blood oxygenation level dependent (BOLD) signal in functional magnetic resonance imaging (fMRI) or Ca$^{2+}$ imaging data. Such types of signals render the SSM's decoder model non-invertible, a requirement for previous TF-based methods. Here, exploiting the recent success of control techniques for training SSMs, we propose a novel algorithm that solves this problem and scales exceptionally well with model dimensionality and filter length. We demonstrate its efficiency in reconstructing dynamical systems, including their state space geometry and long-term temporal properties, from just short BOLD time series."
    },
    "2411.01859v1": {
      "title": "A Novel Deep Learning Tractography Fiber Clustering Framework for Functionally Consistent White Matter Parcellation Using Multimodal Diffusion MRI and Functional MRI",
      "url": "http://arxiv.org/abs/2411.01859v1",
      "authors": "Jin Wang, Bocheng Guo, Yijie Li, Junyi Wang, Yuqian Chen, Jarrett Rushmore, Nikos Makris, Yogesh Rathi, Lauren J O'Donnell, Fan Zhang",
      "update_time": "2024-11-04",
      "abstract": "Tractography fiber clustering using diffusion MRI (dMRI) is a crucial strategy for white matter (WM) parcellation. Current methods primarily use the geometric information of fibers (i.e., the spatial trajectories) to group similar fibers into clusters, overlooking the important functional signals present along the fiber tracts. There is increasing evidence that neural activity in the WM can be measured using functional MRI (fMRI), offering potentially valuable multimodal information for fiber clustering. In this paper, we develop a novel deep learning fiber clustering framework, namely Deep Multi-view Fiber Clustering (DMVFC), that uses joint dMRI and fMRI data to enable functionally consistent WM parcellation. DMVFC can effectively integrate the geometric characteristics of the WM fibers with the fMRI BOLD signals along the fiber tracts. It includes two major components: 1) a multi-view pretraining module to compute embedding features from fiber geometric information and functional signals separately, and 2) a collaborative fine-tuning module to simultaneously refine the two kinds of embeddings. In the experiments, we compare DMVFC with two state-of-the-art fiber clustering methods and demonstrate superior performance in achieving functionally meaningful and consistent WM parcellation results."
    },
    "2411.01092v1": {
      "title": "Cost efficiency of fMRI studies using resting-state vs task-based functional connectivity",
      "url": "http://arxiv.org/abs/2411.01092v1",
      "authors": "Xinzhi Zhang, Leslie A Hulvershorn, Todd Constable, Yize Zhao, Selena Wang",
      "update_time": "2024-11-02",
      "abstract": "We investigate whether and how we can improve the cost efficiency of neuroimaging studies with well-tailored fMRI tasks. The comparative study is conducted using a novel network science-driven Bayesian connectome-based predictive method, which incorporates network theories in model building and substantially improves precision and robustness in imaging biomarker detection. The robustness of the method lays the foundation for identifying predictive power differential across fMRI task conditions if such difference exists. When applied to a clinically heterogeneous transdiagnostic cohort, we found shared and distinct functional fingerprints of neuropsychological outcomes across seven fMRI conditions. For example, emotional N-back memory task was found to be less optimal for negative emotion outcomes, and gradual-onset continuous performance task was found to have stronger links with sensitivity and sociability outcomes than with cognitive control outcomes. Together, our results show that there are unique optimal pairings of task-based fMRI conditions and neuropsychological outcomes that should not be ignored when designing well-powered neuroimaging studies."
    },
    "2411.00992v2": {
      "title": "Correlation of Correlation Networks: High-Order Interactions in the Topology of Brain Networks",
      "url": "http://arxiv.org/abs/2411.00992v2",
      "authors": "Qiang Li, Jingyu Liu, Vince D. Calhoun",
      "update_time": "2024-11-05",
      "abstract": "To understand collective network behavior in the complex human brain, pairwise correlation networks alone are insufficient for capturing the high-order interactions that extend beyond pairwise interactions and play a crucial role in brain network dynamics. These interactions often reveal intricate relationships among multiple brain networks, significantly influencing cognitive processes. In this study, we explored the correlation of correlation networks and topological network analysis with resting-state fMRI to gain deeper insights into these higher-order interactions and their impact on the topology of brain networks, ultimately enhancing our understanding of brain function. We observed that the correlation of correlation networks highlighted network connections while preserving the topological structure of correlation networks. Our findings suggested that the correlation of correlation networks surpassed traditional correlation networks, showcasing considerable potential for applications in various areas of network science. Moreover, after applying topological network analysis to the correlation of correlation networks, we observed that some high-order interaction hubs predominantly occurred in primary and high-level cognitive areas, such as the visual and fronto-parietal regions. These high-order hubs played a crucial role in information integration within the human brain."
    },
    "2411.00982v2": {
      "title": "The Dynamics of Triple Interactions in Resting fMRI: Insights into Psychotic Disorders",
      "url": "http://arxiv.org/abs/2411.00982v2",
      "authors": "Qiang Li, Vince D. Calhoun, Armin Iraji",
      "update_time": "2024-11-05",
      "abstract": "The human brain dynamically integrated and configured information to adapt to the environment. To capture these changes over time, dynamic second-order functional connectivity was typically used to capture transient brain patterns. However, dynamic second-order functional connectivity typically ignored interactions beyond pairwise relationships. To address this limitation, we utilized dynamic triple interactions to investigate multiscale network interactions in the brain. In this study, we evaluated a resting-state fMRI dataset that included individuals with psychotic disorders (PD). We first estimated dynamic triple interactions using resting-state fMRI. After clustering, we estimated cohort-specific and cohort-common states for controls (CN), schizophrenia (SZ), and schizoaffective disorder (SAD). From the cohort-specific states, we observed significant triple interactions, particularly among visual, subcortical, and somatomotor networks, as well as temporal and higher cognitive networks in SZ. In SAD, key interactions involved temporal networks in the initial state and somatomotor networks in subsequent states. From the cohort-common states, we observed that high-cognitive networks were primarily involved in SZ and SAD compared to CN. Furthermore, the most significant differences between SZ and SAD also existed in high-cognitive networks. In summary, we studied PD using dynamic triple interaction, the first time such an approach has been used to study PD. Our findings highlighted the significant potential of dynamic high-order functional connectivity, paving the way for new avenues in the study of the healthy and disordered human brain."
    },
    "2411.00888v1": {
      "title": "Topology-Aware Graph Augmentation for Predicting Clinical Trajectories in Neurocognitive Disorders",
      "url": "http://arxiv.org/abs/2411.00888v1",
      "authors": "Qianqian Wang, Wei Wang, Yuqi Fang, Hong-Jun Li, Andrea Bozoki, Mingxia Liu",
      "update_time": "2024-10-31",
      "abstract": "Brain networks/graphs derived from resting-state functional MRI (fMRI) help study underlying pathophysiology of neurocognitive disorders by measuring neuronal activities in the brain. Some studies utilize learning-based methods for brain network analysis, but typically suffer from low model generalizability caused by scarce labeled fMRI data. As a notable self-supervised strategy, graph contrastive learning helps leverage auxiliary unlabeled data. But existing methods generally arbitrarily perturb graph nodes/edges to generate augmented graphs, without considering essential topology information of brain networks. To this end, we propose a topology-aware graph augmentation (TGA) framework, comprising a pretext model to train a generalizable encoder on large-scale unlabeled fMRI cohorts and a task-specific model to perform downstream tasks on a small target dataset. In the pretext model, we design two novel topology-aware graph augmentation strategies: (1) hub-preserving node dropping that prioritizes preserving brain hub regions according to node importance, and (2) weight-dependent edge removing that focuses on keeping important functional connectivities based on edge weights. Experiments on 1, 688 fMRI scans suggest that TGA outperforms several state-of-the-art methods."
    },
    "2411.00066v1": {
      "title": "Interpretable Language Modeling via Induction-head Ngram Models",
      "url": "http://arxiv.org/abs/2411.00066v1",
      "authors": "Eunji Kim, Sriya Mantena, Weiwei Yang, Chandan Singh, Sungroh Yoon, Jianfeng Gao",
      "update_time": "2024-10-31",
      "abstract": "Recent large language models (LLMs) have excelled across a wide range of tasks, but their use in high-stakes and compute-limited settings has intensified the demand for interpretability and efficiency. We address this need by proposing Induction-head ngram models (Induction-Gram), a method that builds an efficient, interpretable LM by bolstering modern ngram models with a hand-engineered \"induction head\". This induction head uses a custom neural similarity metric to efficiently search the model's input context for potential next-word completions. This process enables Induction-Gram to provide ngram-level grounding for each generated token. Moreover, experiments show that this simple method significantly improves next-word prediction over baseline interpretable models (up to 26%p) and can be used to speed up LLM inference for large models through speculative decoding. We further study Induction-Gram in a natural-language neuroscience setting, where the goal is to predict the next fMRI response in a sequence. It again provides a significant improvement over interpretable models (20% relative increase in the correlation of predicted fMRI responses), potentially enabling deeper scientific investigation of language selectivity in the brain. The code is available at https://github.com/ejkim47/induction-gram.",
      "code_url": "https://github.com/ejkim47/induction-gram"
    },
    "2410.23754v1": {
      "title": "RealMind: Zero-Shot EEG-Based Visual Decoding and Captioning Using Multi-Modal Models",
      "url": "http://arxiv.org/abs/2410.23754v1",
      "authors": "Dongyang Li, Haoyang Qin, Mingyang Wu, Yuang Cao, Chen Wei, Quanying Liu",
      "update_time": "2024-10-31",
      "abstract": "Despite significant progress in visual decoding with fMRI data, its high cost and low temporal resolution limit widespread applicability. To address these challenges, we introduce RealMind, a novel EEG-based visual decoding framework that leverages multi-modal models to efficiently interpret semantic information. By integrating semantic and geometric consistency learning, RealMind enhances feature alignment, leading to improved decoding performance. Our framework achieves a 56.73\\% Top-5 accuracy in a 200-way retrieval task and a 26.59\\% BLEU-1 score in a 200-way visual captioning task, representing the first successful attempt at zero-shot visual captioning using EEG data. RealMind provides a robust, adaptable, and cost-effective alternative to fMRI-based methods, offering scalable solutions for EEG-based visual decoding in practical applications."
    },
    "2410.23515v1": {
      "title": "Generative forecasting of brain activity enhances Alzheimer's classification and interpretation",
      "url": "http://arxiv.org/abs/2410.23515v1",
      "authors": "Yutong Gao, Vince D. Calhoun, Robyn L. Miller",
      "update_time": "2024-10-30",
      "abstract": "Understanding the relationship between cognition and intrinsic brain activity through purely data-driven approaches remains a significant challenge in neuroscience. Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive method to monitor regional neural activity, providing a rich and complex spatiotemporal data structure. Deep learning has shown promise in capturing these intricate representations. However, the limited availability of large datasets, especially for disease-specific groups such as Alzheimer's Disease (AD), constrains the generalizability of deep learning models. In this study, we focus on multivariate time series forecasting of independent component networks derived from rs-fMRI as a form of data augmentation, using both a conventional LSTM-based model and the novel Transformer-based BrainLM model. We assess their utility in AD classification, demonstrating how generative forecasting enhances classification performance. Post-hoc interpretation of BrainLM reveals class-specific brain network sensitivities associated with AD."
    },
    "2410.22681v1": {
      "title": "Persistent Homology for MCI Classification: A Comparative Analysis between Graph and Vietoris-Rips Filtrations",
      "url": "http://arxiv.org/abs/2410.22681v1",
      "authors": "Debanjali Bhattacharya, Rajneet Kaur, Ninad Aithal, Neelam Sinha, Thomas Gregor Issac",
      "update_time": "2024-10-30",
      "abstract": "Mild cognitive impairment (MCI), often linked to early neurodegeneration, is characterized by subtle cognitive declines and disruptions in brain connectivity. The present study offers a detailed analysis of topological changes associated with MCI, focusing on two subtypes: Early MCI and Late MCI. This analysis utilizes fMRI time series data from two distinct populations: the publicly available ADNI dataset (Western cohort) and the in-house TLSA dataset (Indian Urban cohort). Persistent Homology, a topological data analysis method, is employed with two distinct filtration techniques - Vietoris-Rips and graph filtration-for classifying MCI subtypes. For Vietoris-Rips filtration, inter-ROI Wasserstein distance matrices between persistent diagrams are used for classification, while graph filtration relies on the top ten most persistent homology features. Comparative analysis shows that the Vietoris-Rips filtration significantly outperforms graph filtration, capturing subtle variations in brain connectivity with greater accuracy. The Vietoris-Rips filtration method achieved the highest classification accuracy of 85.7\\% for distinguishing between age and gender matched healthy controls and MCI, whereas graph filtration reached a maximum accuracy of 71.4\\% for the same task. This superior performance highlights the sensitivity of Vietoris-Rips filtration in detecting intricate topological features associated with neurodegeneration. The findings underscore the potential of persistent homology, particularly when combined with the Wasserstein distance, as a powerful tool for early diagnosis and precise classification of cognitive impairments, offering valuable insights into brain connectivity changes in MCI."
    }
  },
  "MEG": {
    "2411.03883v2": {
      "title": "MEG: Medical Knowledge-Augmented Large Language Models for Question Answering",
      "url": "http://arxiv.org/abs/2411.03883v2",
      "authors": "Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders S\u00f8gaard, Carlos Bobed",
      "update_time": "2024-11-07",
      "abstract": "Question answering is a natural language understanding task that involves reasoning over both explicit context and unstated, relevant domain knowledge. Large language models (LLMs), which underpin most contemporary question answering systems, struggle to induce how concepts relate in specialized domains such as medicine. Existing medical LLMs are also costly to train. In this work, we present MEG, a parameter-efficient approach for medical knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate graph embeddings into the LLM, enabling it to leverage external knowledge in a cost-effective way. We evaluate our method on four popular medical multiple-choice datasets and show that LLMs greatly benefit from the factual grounding provided by knowledge graph embeddings. MEG attains an average of +10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized models like BioMistral. We also show results based on Llama-3. Finally, we show that MEG's performance remains robust to the choice of graph encoder.",
      "code_url": "https://github.com/lautel/meg"
    },
    "2410.23386v1": {
      "title": "STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG",
      "url": "http://arxiv.org/abs/2410.23386v1",
      "authors": "Raquel Fern\u00e1ndez-Mart\u00edn, Alfonso Gij\u00f3n, Odile Feys, Elodie Juven\u00e9, Alec Aeby, Charline Urbain, Xavier De Ti\u00e8ge, Vincent Wens",
      "update_time": "2024-10-30",
      "abstract": "Magnetoencephalography (MEG) allows the non-invasive detection of interictal epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients traditionally relies on the visual identification of IEDs, which is time consuming and partially subjective. Automatic, data-driven detection methods exist but show limited performance. Still, the rise of deep learning (DL)-with its ability to reproduce human-like abilities-could revolutionize clinical MEG practice. Here, we developed and validated STIED, a simple yet powerful supervised DL algorithm combining two convolutional neural networks with temporal (1D time-course) and spatial (2D topography) features of MEG signals inspired from current clinical guidelines. Our DL model enabled both temporal and spatial localization of IEDs in patients suffering from focal epilepsy with frequent and high amplitude spikes (FE group), with high-performance metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning from spatiotemporal features of IEDs. This performance can be attributed to our handling of input data, which mimics established clinical MEG practice. Reverse engineering further revealed that STIED encodes fine spatiotemporal features of IEDs rather than their mere amplitude. The model trained on the FE group also showed promising results when applied to a separate group of presurgical patients with different types of refractory focal epilepsy, though further work is needed to distinguish IEDs from physiological transients. This study paves the way of incorporating STIED and DL algorithms into the routine clinical MEG evaluation of epilepsy."
    },
    "2410.20916v1": {
      "title": "NeuGPT: Unified multi-modal Neural GPT",
      "url": "http://arxiv.org/abs/2410.20916v1",
      "authors": "Yiqian Yang, Yiqun Duan, Hyejeong Jo, Qiang Zhang, Renjing Xu, Oiwi Parker Jones, Xuming Hu, Chin-teng Lin, Hui Xiong",
      "update_time": "2024-10-28",
      "abstract": "This paper introduces NeuGPT, a groundbreaking multi-modal language generation model designed to harmonize the fragmented landscape of neural recording research. Traditionally, studies in the field have been compartmentalized by signal type, with EEG, MEG, ECoG, SEEG, fMRI, and fNIRS data being analyzed in isolation. Recognizing the untapped potential for cross-pollination and the adaptability of neural signals across varying experimental conditions, we set out to develop a unified model capable of interfacing with multiple modalities. Drawing inspiration from the success of pre-trained large models in NLP, computer vision, and speech processing, NeuGPT is architected to process a diverse array of neural recordings and interact with speech and text data. Our model mainly focus on brain-to-text decoding, improving SOTA from 6.94 to 12.92 on BLEU-1 and 6.93 to 13.06 on ROUGE-1F. It can also simulate brain signals, thereby serving as a novel neural interface. Code is available at \\href{https://github.com/NeuSpeech/NeuGPT}{NeuSpeech/NeuGPT (https://github.com/NeuSpeech/NeuGPT) .}",
      "code_url": "https://github.com/neuspeech/neugpt"
    },
    "2410.19986v1": {
      "title": "Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings",
      "url": "http://arxiv.org/abs/2410.19986v1",
      "authors": "Jeremiah Ridge, Oiwi Parker Jones",
      "update_time": "2024-10-25",
      "abstract": "Machine learning techniques have enabled researchers to leverage neuroimaging data to decode speech from brain activity, with some amazing recent successes achieved by applications built using invasive devices. However, research requiring surgical implants has a number of practical limitations. Non-invasive neuroimaging techniques provide an alternative but come with their own set of challenges, the limited scale of individual studies being among them. Without the ability to pool the recordings from different non-invasive studies, data on the order of magnitude needed to leverage deep learning techniques to their full potential remains out of reach. In this work, we focus on non-invasive data collected using magnetoencephalography (MEG). We leverage two different, leading speech decoding models to investigate how an adversarial domain adaptation framework augments their ability to generalize across datasets. We successfully improve the performance of both models when training across multiple datasets. To the best of our knowledge, this study is the first ever application of feature-level, deep learning based harmonization for MEG neuroimaging data. Our analysis additionally offers further evidence of the impact of demographic features on neuroimaging data, demonstrating that participant age strongly affects how machine learning models solve speech decoding tasks using MEG data. Lastly, in the course of this study we produce a new open-source implementation of one of these models to the benefit of the broader scientific community."
    },
    "2410.19838v1": {
      "title": "Non-invasive Neural Decoding in Source Reconstructed Brain Space",
      "url": "http://arxiv.org/abs/2410.19838v1",
      "authors": "Yonatan Gideoni, Ryan Charles Timms, Oiwi Parker Jones",
      "update_time": "2024-10-20",
      "abstract": "Non-invasive brainwave decoding is usually done using Magneto/Electroencephalography (MEG/EEG) sensor measurements as inputs. This makes combining datasets and building models with inductive biases difficult as most datasets use different scanners and the sensor arrays have a nonintuitive spatial structure. In contrast, fMRI scans are acquired directly in brain space, a voxel grid with a typical structured input representation. By using established techniques to reconstruct the sensors' sources' neural activity it is possible to decode from voxels for MEG data as well. We show that this enables spatial inductive biases, spatial data augmentations, better interpretability, zero-shot generalisation between datasets, and data harmonisation."
    },
    "2410.14971v1": {
      "title": "BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation",
      "url": "http://arxiv.org/abs/2410.14971v1",
      "authors": "Jilong Li, Zhenxi Song, Jiaqi Wang, Min Zhang, Zhiguo Zhang",
      "update_time": "2024-10-19",
      "abstract": "Recent advances in decoding language from brain signals (EEG and MEG) have been significantly driven by pre-trained language models, leading to remarkable progress on publicly available non-invasive EEG/MEG datasets. However, previous works predominantly utilize teacher forcing during text generation, leading to significant performance drops without its use. A fundamental issue is the inability to establish a unified feature space correlating textual data with the corresponding evoked brain signals. Although some recent studies attempt to mitigate this gap using an audio-text pre-trained model, Whisper, which is favored for its signal input modality, they still largely overlook the inherent differences between audio signals and brain signals in directly applying Whisper to decode brain signals. To address these limitations, we propose a new multi-stage strategy for semantic brain signal decoding via vEctor-quantized speCtrogram reconstruction for WHisper-enhanced text generatiOn, termed BrainECHO. Specifically, BrainECHO successively conducts: 1) Discrete autoencoding of the audio spectrogram; 2) Brain-audio latent space alignment; and 3) Semantic text generation via Whisper finetuning. Through this autoencoding--alignment--finetuning process, BrainECHO outperforms state-of-the-art methods under the same data split settings on two widely accepted resources: the EEG dataset (Brennan) and the MEG dataset (GWilliams). The innovation of BrainECHO, coupled with its robustness and superiority at the sentence, session, and subject-independent levels across public datasets, underscores its significance for language-based brain-computer interfaces."
    },
    "2410.08718v1": {
      "title": "Determining sensor geometry and gain in a wearable MEG system",
      "url": "http://arxiv.org/abs/2410.08718v1",
      "authors": "Ryan M. Hill, Gonzalo Reina Rivero, Ashley J. Tyler, Holly Schofield, Cody Doyle, James Osborne, David Bobela, Lukas Rier, Joseph Gibson, Zoe Tanner, Elena Boto, Richard Bowtell, Matthew J. Brookes, Vishal Shah, Niall Holmes",
      "update_time": "2024-10-11",
      "abstract": "Optically pumped magnetometers (OPMs) are compact and lightweight sensors that can measure magnetic fields generated by current flow in neuronal assemblies in the brain. Such sensors enable construction of magnetoencephalography (MEG) instrumentation, with significant advantages over conventional MEG devices including adaptability to head size, enhanced movement tolerance, lower complexity and improved data quality. However, realising the potential of OPMs depends on our ability to perform system calibration, which means finding sensor locations, orientations, and the relationship between the sensor output and magnetic field (termed sensor gain). Such calibration is complex in OPMMEG since, for example, OPM placement can change from subject to subject (unlike in conventional MEG where sensor locations or orientations are fixed). Here, we present two methods for calibration, both based on generating well-characterised magnetic fields across a sensor array. Our first device (the HALO) is a head mounted system that generates dipole like fields from a set of coils. Our second (the matrix coil (MC)) generates fields using coils embedded in the walls of a magnetically shielded room. Our results show that both methods offer an accurate means to calibrate an OPM array (e.g. sensor locations within 2 mm of the ground truth) and that the calibrations produced by the two methods agree strongly with each other. When applied to data from human MEG experiments, both methods offer improved signal to noise ratio after beamforming suggesting that they give calibration parameters closer to the ground truth than factory settings and presumed physical sensor coordinates and orientations. Both techniques are practical and easy to integrate into real world MEG applications. This advances the field significantly closer to the routine use of OPMs for MEG recording."
    },
    "2410.03191v2": {
      "title": "Nested Deep Learning Model Towards A Foundation Model for Brain Signal Data",
      "url": "http://arxiv.org/abs/2410.03191v2",
      "authors": "Fangyi Wei, Jiajie Mo, Kai Zhang, Haipeng Shen, Srikantan Nagarajan, Fei Jiang",
      "update_time": "2024-10-09",
      "abstract": "Epilepsy affects over 50 million people globally, with EEG/MEG-based spike detection playing a crucial role in diagnosis and treatment. Manual spike identification is time-consuming and requires specialized training, limiting the number of professionals available to analyze EEG/MEG data. To address this, various algorithmic approaches have been developed. However, current methods face challenges in handling varying channel configurations and in identifying the specific channels where spikes originate. This paper introduces a novel Nested Deep Learning (NDL) framework designed to overcome these limitations. NDL applies a weighted combination of signals across all channels, ensuring adaptability to different channel setups, and allows clinicians to identify key channels more accurately. Through theoretical analysis and empirical validation on real EEG/MEG datasets, NDL demonstrates superior accuracy in spike detection and channel localization compared to traditional methods. The results show that NDL improves prediction accuracy, supports cross-modality data integration, and can be fine-tuned for various neurophysiological applications."
    },
    "2410.07189v1": {
      "title": "Dual Stream Graph Transformer Fusion Networks for Enhanced Brain Decoding",
      "url": "http://arxiv.org/abs/2410.07189v1",
      "authors": "Lucas Goene, Siamak Mehrkanoon",
      "update_time": "2024-09-23",
      "abstract": "This paper presents the novel Dual Stream Graph-Transformer Fusion (DS-GTF) architecture designed specifically for classifying task-based Magnetoencephalography (MEG) data. In the spatial stream, inputs are initially represented as graphs, which are then passed through graph attention networks (GAT) to extract spatial patterns. Two methods, TopK and Thresholded Adjacency are introduced for initializing the adjacency matrix used in the GAT. In the temporal stream, the Transformer Encoder receives concatenated windowed input MEG data and learns new temporal representations. The learned temporal and spatial representations from both streams are fused before reaching the output layer. Experimental results demonstrate an enhancement in classification performance and a reduction in standard deviation across multiple test subjects compared to other examined models."
    },
    "2409.10346v1": {
      "title": "MEGS: Morphological Evaluation of Galactic Structure",
      "url": "http://arxiv.org/abs/2409.10346v1",
      "authors": "Ufuk \u00c7ak\u0131r, Tobias Buck",
      "update_time": "2024-09-16",
      "abstract": "Understanding the morphology of galaxies is a critical aspect of astrophysics research, providing insight into the formation, evolution, and physical properties of these vast cosmic structures. Various observational and computational methods have been developed to quantify galaxy morphology, and with the advent of large galaxy simulations, the need for automated and effective classification methods has become increasingly important. This paper investigates the use of Principal Component Analysis (PCA) as an interpretable dimensionality reduction algorithm for galaxy morphology using the IllustrisTNG cosmological simulation dataset with the aim of developing a generative model for galaxies. We first generate a dataset of 2D images and 3D cubes of galaxies from the IllustrisTNG simulation, focusing on the mass, metallicity, and stellar age distribution of each galaxy. PCA is then applied to this data, transforming it into a lower-dimensional image space, where closeness of data points corresponds to morphological similarity. We find that PCA can effectively capture the key morphological features of galaxies, with a significant proportion of the variance in the data being explained by a small number of components. With our method we achieve a dimensionality reduction by a factor of $\\sim200$ for 2D images and $\\sim3650$ for 3D cubes at a reconstruction accuracy below five percent. Our results illustrate the potential of PCA in compressing large cosmological simulations into an interpretable generative model for galaxies that can easily be used in various downstream tasks such as galaxy classification and analysis.",
      "code_url": "https://github.com/ufuk-cakir/MEGS"
    }
  },
  "neuroAI": {
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    },
    "2112.15459v3": {
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "authors": "Samuele Bolotta, Guillaume Dumas",
      "update_time": "2022-04-11",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied."
    },
    "2011.07464v2": {
      "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
      "url": "http://arxiv.org/abs/2011.07464v2",
      "authors": "Joseph Marino",
      "update_time": "2021-10-23",
      "abstract": "This paper reviews predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (non-linear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field."
    }
  },
  "medical": {
    "2411.04797v1": {
      "title": "Development of a Service Robot for Hospital Environments in Rehabilitation Medicine with LiDAR Based Simultaneous Localization and Mapping",
      "url": "http://arxiv.org/abs/2411.04797v1",
      "authors": "Sayat Ibrayev, Arman Ibrayeva, Bekzat Amanov, Serik Tolenov",
      "update_time": "2024-11-07",
      "abstract": "This paper presents the development and evaluation of a medical service robot equipped with 3D LiDAR and advanced localization capabilities for use in hospital environments. The robot employs LiDAR-based Simultaneous Localization and Mapping SLAM to navigate autonomously and interact effectively within complex and dynamic healthcare settings. A comparative analysis with established 3D SLAM technology in Autoware version 1.14.0, under a Linux ROS framework, provided a benchmark for evaluating our system performance. The adaptation of Normal Distribution Transform NDT Matching to indoor navigation allowed for precise real-time mapping and enhanced obstacle avoidance capabilities. Empirical validation was conducted through manual maneuvers in various environments, supplemented by ROS simulations to test the system response to simulated challenges. The findings demonstrate that the robot integration of 3D LiDAR and NDT Matching significantly improves navigation accuracy and operational reliability in a healthcare context. This study highlights the robot ability to perform essential tasks with high efficiency and identifies potential areas for further improvement, particularly in sensor performance under diverse environmental conditions. The successful deployment of this technology in a hospital setting illustrates its potential to support medical staff and contribute to patient care, suggesting a promising direction for future research and development in healthcare robotics."
    },
    "2411.04740v1": {
      "title": "Quantum Neural Network Classifier for Cancer Registry System Testing: A Feasibility Study",
      "url": "http://arxiv.org/abs/2411.04740v1",
      "authors": "Xinyi Wang, Shaukat Ali, Paolo Arcaini, Narasimha Raghavan Veeraragavan, Jan F. Nyg\u00e5rd",
      "update_time": "2024-11-07",
      "abstract": "The Cancer Registry of Norway (CRN) is a part of the Norwegian Institute of Public Health (NIPH) and is tasked with producing statistics on cancer among the Norwegian population. For this task, CRN develops, tests, and evolves a software system called Cancer Registration Support System (CaReSS). It is a complex socio-technical software system that interacts with many entities (e.g., hospitals, medical laboratories, and other patient registries) to achieve its task. For cost-effective testing of CaReSS, CRN has employed EvoMaster, an AI-based REST API testing tool combined with an integrated classical machine learning model. Within this context, we propose Qlinical to investigate the feasibility of using, inside EvoMaster, a Quantum Neural Network (QNN) classifier, i.e., a quantum machine learning model, instead of the existing classical machine learning model. Results indicate that Qlinical can achieve performance comparable to that of EvoClass. We further explore the effects of various QNN configurations on performance and offer recommendations for optimal QNN settings for future QNN developers."
    },
    "2411.04698v1": {
      "title": "Robust multimode interference and conversion in topological unidirectional surface magnetoplasmons",
      "url": "http://arxiv.org/abs/2411.04698v1",
      "authors": "Chao Liu, Ziyang Zhao, Tianjing Guo, Jie Xu, Xiaohua Deng, Kai Yuan, Rongxin Tang, Kosmas L. Tsakmakidis, Lujun Hong",
      "update_time": "2024-11-07",
      "abstract": "We have theoretically investigated surface magnetoplasmons (SMPs) in a yttrium-iron-garnet (YIG) sandwiched waveguide. The dispersion demonstated that this waveguide can support topological unidirectional SMPs. Based on unidirectional SMPs, magnetically controllable multimode interference (MMI) is verified in both symmetric and asymmetric waveguides. Due to the coupling between the modes along two YIG-air interfaces, the asymmetric waveguide supports a unidirectional even mode within a single-mode frequency range. Moreover, these modes are topological protected when disorder is introduced. Utilizing robust unidirectional SMPs MMI (USMMI), tunable splitters have been achieved. It has been demonstrated that mode conversion between different modes can be realized. These results provide many degrees of freedom to manipulate topological waves."
    },
    "2411.04656v1": {
      "title": "ICH-SCNet: Intracerebral Hemorrhage Segmentation and Prognosis Classification Network Using CLIP-guided SAM mechanism",
      "url": "http://arxiv.org/abs/2411.04656v1",
      "authors": "Xinlei Yu, Ahmed Elazab, Ruiquan Ge, Hui Jin, Xinchen Jiang, Gangyong Jia, Qing Wu, Qinglei Shi, Changmiao Wang",
      "update_time": "2024-11-07",
      "abstract": "Intracerebral hemorrhage (ICH) is the most fatal subtype of stroke and is characterized by a high incidence of disability. Accurate segmentation of the ICH region and prognosis prediction are critically important for developing and refining treatment plans for post-ICH patients. However, existing approaches address these two tasks independently and predominantly focus on imaging data alone, thereby neglecting the intrinsic correlation between the tasks and modalities. This paper introduces a multi-task network, ICH-SCNet, designed for both ICH segmentation and prognosis classification. Specifically, we integrate a SAM-CLIP cross-modal interaction mechanism that combines medical text and segmentation auxiliary information with neuroimaging data to enhance cross-modal feature recognition. Additionally, we develop an effective feature fusion module and a multi-task loss function to improve performance further. Extensive experiments on an ICH dataset reveal that our approach surpasses other state-of-the-art methods. It excels in the overall performance of classification tasks and outperforms competing models in all segmentation task metrics."
    },
    "2411.04634v1": {
      "title": "More variable circadian rhythms in epilepsy: a retrospective cross-sectional study using long-term heart rate recordings from wearable sensors",
      "url": "http://arxiv.org/abs/2411.04634v1",
      "authors": "Billy C. Smith, Christopher Thornton, Rachel E. Stirling, Guillermo M. Besne, Nathan Evans, Peter N. Taylor, Philippa J. Karoly, Yujiang Wang",
      "update_time": "2024-11-07",
      "abstract": "Background: The circadian rhythm aligns physiology and behaviour with the 24-hour light-dark cycle, and its disruption is linked to neurological disorders such as epilepsy. However, how to best quantify circadian disruption remains unclear, as it can manifest across various properties and timescales. A promising but under-explored approach is to assess the intra-individual variability in circadian rhythms over timescales of weeks to years. This is yet to be studied in epilepsy.   Methods: We retrospectively used wearable smartwatch data (Fitbit) from 143 people with epilepsy (PWE) and 31 controls. For each participant, we extracted the circadian oscillation underlying their heart rate time series and analysed the intra-individual variability of three circadian properties: period, acrophase, and amplitude.   Findings: We found increased intra-individual variability in period (77 min vs. 62 min, z=3.32, p<0.001) and acrophase (68 min vs. 54 min, z=2.97, p=0.003) for PWE compared to controls, but not in amplitude (1.98 bpm vs. 2.05 bpm, z=-0.66, p=0.51). For PWE, we did not find any correlations between seizure frequency and intra-individual variability in circadian properties, or any difference between weeks with and without seizures.   Interpretation: This finding indicates that the circadian rhythm of heart rate is more variable for people with epilepsy and that this can be detected using a wearable device. However, we were unable to find any associations with seizure frequency or occurrence, suggesting intra-individual variability could be another manifestation of epilepsy aetiology. Future work should investigate the combined role of anti-seizure medications, demographics, co-morbidities, and health behaviours in driving the increased intra-individual variability of circadian properties in epilepsy."
    },
    "2411.04607v1": {
      "title": "Cross- and Intra-image Prototypical Learning for Multi-label Disease Diagnosis and Interpretation",
      "url": "http://arxiv.org/abs/2411.04607v1",
      "authors": "Chong Wang, Fengbei Liu, Yuanhong Chen, Helen Frazer, Gustavo Carneiro",
      "update_time": "2024-11-07",
      "abstract": "Recent advances in prototypical learning have shown remarkable potential to provide useful decision interpretations associating activation maps and predictions with class-specific training prototypes. Such prototypical learning has been well-studied for various single-label diseases, but for quite relevant and more challenging multi-label diagnosis, where multiple diseases are often concurrent within an image, existing prototypical learning models struggle to obtain meaningful activation maps and effective class prototypes due to the entanglement of the multiple diseases. In this paper, we present a novel Cross- and Intra-image Prototypical Learning (CIPL) framework, for accurate multi-label disease diagnosis and interpretation from medical images. CIPL takes advantage of common cross-image semantics to disentangle the multiple diseases when learning the prototypes, allowing a comprehensive understanding of complicated pathological lesions. Furthermore, we propose a new two-level alignment-based regularisation strategy that effectively leverages consistent intra-image information to enhance interpretation robustness and predictive performance. Extensive experiments show that our CIPL attains the state-of-the-art (SOTA) classification accuracy in two public multi-label benchmarks of disease diagnosis: thoracic radiography and fundus images. Quantitative interpretability results show that CIPL also has superiority in weakly-supervised thoracic disease localisation over other leading saliency- and prototype-based explanation methods."
    },
    "2411.04595v1": {
      "title": "TexLiverNet: Leveraging Medical Knowledge and Spatial-Frequency Perception for Enhanced Liver Tumor Segmentation",
      "url": "http://arxiv.org/abs/2411.04595v1",
      "authors": "Xiaoyan Jiang, Zhi Zhou, Hailing Wang, Guozhong Wang, Zhijun Fang",
      "update_time": "2024-11-07",
      "abstract": "Integrating textual data with imaging in liver tumor segmentation is essential for enhancing diagnostic accuracy. However, current multi-modal medical datasets offer only general text annotations, lacking lesion-specific details critical for extracting nuanced features, especially for fine-grained segmentation of tumor boundaries and small lesions. To address these limitations, we developed datasets with lesion-specific text annotations for liver tumors and introduced the TexLiverNet model. TexLiverNet employs an agent-based cross-attention module that integrates text features efficiently with visual features, significantly reducing computational costs. Additionally, enhanced spatial and adaptive frequency domain perception is proposed to precisely delineate lesion boundaries, reduce background interference, and recover fine details in small lesions. Comprehensive evaluations on public and private datasets demonstrate that TexLiverNet achieves superior performance compared to current state-of-the-art methods.",
      "code_url": "https://github.com/sky-visionX/TexLiverNet"
    },
    "2411.04584v1": {
      "title": "PASSION for Dermatology: Bridging the Diversity Gap with Pigmented Skin Images from Sub-Saharan Africa",
      "url": "http://arxiv.org/abs/2411.04584v1",
      "authors": "Philippe Gottfrois, Fabian Gr\u00f6ger, Faly Herizo Andriambololoniaina, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Christophe Hsu, Agnes Kessy, Simone Lionetti, Daudi Mavura, Wingston Ng'ambi, Dingase Faith Ngongonda, Marc Pouly, Mendrika Fifaliana Rakotoarisaona, Fahafahantsoa Rapelanoro Rabenja, Ibrahima Traor\u00e9, Alexander A. Navarini",
      "update_time": "2024-11-07",
      "abstract": "Africa faces a huge shortage of dermatologists, with less than one per million people. This is in stark contrast to the high demand for dermatologic care, with 80% of the paediatric population suffering from largely untreated skin conditions. The integration of AI into healthcare sparks significant hope for treatment accessibility, especially through the development of AI-supported teledermatology. Current AI models are predominantly trained on white-skinned patients and do not generalize well enough to pigmented patients. The PASSION project aims to address this issue by collecting images of skin diseases in Sub-Saharan countries with the aim of open-sourcing this data. This dataset is the first of its kind, consisting of 1,653 patients for a total of 4,901 images. The images are representative of telemedicine settings and encompass the most common paediatric conditions: eczema, fungals, scabies, and impetigo. We also provide a baseline machine learning model trained on the dataset and a detailed performance analysis for the subpopulations represented in the dataset. The project website can be found at https://passionderm.github.io/."
    },
    "2411.04577v1": {
      "title": "Laser initiated p-11B fusion reactions in petawatt high-repetition-rates laser facilities",
      "url": "http://arxiv.org/abs/2411.04577v1",
      "authors": "M. Scisci\u00f2, G. Petringa, Z. Zhu, M. R. D. Rodrigues, M. Alonzo, P. L. Andreoli, F. Filippi, Fe. Consoli, M. Huault, D. Raffestin, D. Molloy, H. Larreur, D. Singappuli, T. Carriere, C. Verona, P. Nicolai, A. McNamee, M. Ehret, E. Filippov, R. Lera, J. A. P\u00e9rez-Hern\u00e1ndez, S. Agarwal, M. Krupka, S. Singh, V. Istokskaia, D. Lattuada, M. La Cognata, G. L. Guardo, S. Palmerini, G. Rapisarda, K. Batani, M. Cipriani, G. Cristofari, E. Di Ferdinando, G. Di Giorgio, R. De Angelis, D. Giulietti, J. Xu, L. Volpe, M. D. Rodr\u00edguez-Fr\u00edas, L. Giuffrida, D. Margarone, D. Batani, G. A. P. Cirrone, A. Bonasera, Fa. Consoli",
      "update_time": "2024-11-07",
      "abstract": "Driving the nuclear fusion reaction p+11B -> 3 alpha + 8.7 MeV in laboratory conditions, by interaction between high-power laser pulses and matter, has become a popular field of research, due to numerous applications that it can potentially allow: an alternative to deuterium-tritium (DT) for fusion energy production, astrophysics studies and alpha-particle generation for medical treatments. A possible scheme for laser-driven p-11B reactions is to direct a beam of laser-accelerated protons onto a boron sample (the so-called 'pitcher-catcher' scheme). This technique was successfully implemented on large, energetic lasers, yielding hundreds of joules per shot at low repetition. We present here a complementary approach, exploiting the high-repetition rate of the VEGA III petawatt laser at CLPU (Spain), aiming at accumulating results from many interactions at much lower energy, for better controlling the parameters and the statistics of the measurements. Despite a moderate energy per pulse, our experiment allowed exploring the laser-driven fusion process with tens (up to hundreds) of laser shots. The experiment provided a clear signature of the produced reactions and of the fusion products, accumulated over many shots, leading to an improved optimization of the diagnostic for these experimental campaigns In this paper we discuss the effectiveness of the laser-driven p-11B fusion in the pitcher-catcher scheme, at high-repetition rate, addressing the challenges of this experimental scheme and highlighting its critical aspects. Our proposed methodologies allow evaluating the performance of this scheme for laser-driven alpha particle production and can be adapted to high-repetition rate laser facilities with higher energy and intensity."
    },
    "2411.04515v1": {
      "title": "Effect of the geometry of butt-joint implant-supported restorations on the fatigue life of prosthetic screws",
      "url": "http://arxiv.org/abs/2411.04515v1",
      "authors": "Mikel Armentia, Mikel Abasolo, Ibai Coria, Nicolas Saintier",
      "update_time": "2024-11-07",
      "abstract": "Statement of problem. Dental implant geometry affects the mechanical performance and fatigue behavior of butt-joint implant-supported restorations. However, failure of the implant component has been generally studied by ignoring the prosthetic screw, which is frequently the critical restoration component Purpose. Evaluate the effect of 3 main implant geometric parameters: the implant body diameter, the platform diameter, and the implant-abutment connection type (external versus internal butt-joint) on the fatigue life of the prosthetic screw. The experimental values were further compared with the theoretical ones obtained by using a previously published methodology M&M. 4 different designs of direct-to-implant dental restorations from the manufacturer BTI were tested. Forty-eight fatigue tests were performed in an axial fatigue testing machine according to ISO 14801. Linear regression models, 95% interval confidence bands for the linear regression, and 95% prediction intervals of the fatigue load-life results were obtained and compared through an analysis of covariance to determine the influence of the 3 parameters under study on the fatigue behavior Results. Linear regression models showed a statistical difference when the implant body diameter was increased by 1 mm; an average 3.5-fold increase in fatigue life was observed. Increasing the implant abutment connection diameter by 1.4 mm also showed a significant difference, leading to 7-fold longer fatigue life on average. No significant statistical evidence was found to demonstrate a difference in fatigue life between internal and external connections Conclusions. Increasing the implant platform and body diameter significantly improved the fatigue life of the screw, whereas external and internal connections provided similar results. In addition, experimental results proved the accuracy of the fatigue life prediction methodology"
    }
  }
}