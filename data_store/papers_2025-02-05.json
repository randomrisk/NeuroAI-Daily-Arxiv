{
  "Brain": {
    "2501.19359v1": {
      "title": "Mechanical Properties of the Meninges: Large Language Model Assisted Systematic Review of over 25,000 Studies",
      "url": "http://arxiv.org/abs/2501.19359v1",
      "authors": "Brandon P. Chelstrom, Maciej P. Polak, Dane Morgan, Corinne R. Henak",
      "update_time": "2025-01-31",
      "abstract": "Accurate constitutive models and corresponding mechanical property values for the meninges are important for predicting mechanical damage to brain tissue due to traumatic brain injury. The meninges are often oversimplified in current finite element (FE) head models due to their complex anatomy and spatially-variant mechanical behavior. This study performed a systematic review (SR) on the mechanical properties of each individual layer of the meninges to obtain benchmark data for FE modeling and to identify gaps in the current literature. Relevant studies were filtered through three stages: a broad initial search filter, a large language model classifier, and manual verification by a human reviewer. Out of over 25,000 studies initially considered, this review ultimately included 47 studies on the dura mater, 8 on the arachnoid mater, and 7 on the pia mater, representing the largest and most comprehensive SR on the mechanical properties of the meninges. Each layer was found to exhibit nonlinear rate dependence that varies with species, age, location, and orientation. This study revealed that the elastic modulus of pia mater most often used in simplified linear elastic FE models is likely underestimated by an order of magnitude and fails to consider directional dependence. Future studies investigating the mechanical properties of the meninges should focus on a wider range of loading rates as well as age effects for the arachnoid mater and pia mater, as these features are relatively understudied and expected to affect the fidelity of FE predictions."
    },
    "2501.19304v1": {
      "title": "Solid-state Synapse Based on Magnetoelectrically Coupled Memristor",
      "url": "http://arxiv.org/abs/2501.19304v1",
      "authors": "Weichuan Huang, Yue-Wen Fang, Yuewei Yin, Bobo Tian, Wenbo Zhao, Chuangming Hou, Chao Ma, Qi Li, Evgeny Y. Tsymbal, Chun-Gang Duan, Xiaoguang Li",
      "update_time": "2025-01-31",
      "abstract": "Brain-inspired computing architectures attempt to emulate the computations performed in the neurons and the synapses in human brain. Memristors with continuously tunable resistances are ideal building blocks for artificial synapses. Through investigating the memristor behaviors in a La0.7Sr0.3MnO3/BaTiO3/La0.7Sr0.3MnO3 multiferroic tunnel junction, it was found that the ferroelectric domain dynamics characteristics are influenced by the relative magnetization alignment of the electrodes, and the interfacial spin polarization is manipulated continuously by ferroelectric domain reversal, enriching our understanding of the magnetoelectric coupling fundamentally. This creates a functionality that not only the resistance of the memristor but also the synaptic plasticity form can be further manipulated, as demonstrated by the spike-timing-dependent plasticity investigations. Density functional theory calculations are carried out to describe the obtained magnetoelectric coupling, which is probably related to the Mn-Ti intermixing at the interfaces. The multiple and controllable plasticity characteristic in a single artificial synapse, to resemble the synaptic morphological alteration property in a biological synapse, will be conducive to the development of artificial intelligence."
    },
    "2501.19217v1": {
      "title": "Exploring Flow in Real-World Knowledge Work Using Discreet cEEGrid Sensors",
      "url": "http://arxiv.org/abs/2501.19217v1",
      "authors": "Michael T. Knierim, Fabio Stano, Fabio Kurz, Antonius Heusch, Max L. Wilson",
      "update_time": "2025-01-31",
      "abstract": "Flow, a state of deep task engagement, is associated with optimal experience and well-being, making its detection a prolific HCI research focus. While physiological sensors show promise for flow detection, most studies are lab-based. Furthermore, brain sensing during natural work remains unexplored due to the intrusive nature of traditional EEG setups. This study addresses this gap by using wearable, around-the-ear EEG sensors to observe flow during natural knowledge work, measuring EEG throughout an entire day. In a semi-controlled field experiment, participants engaged in academic writing or programming, with their natural flow experiences compared to those from a classic lab paradigm. Our results show that natural work tasks elicit more intense flow than artificial tasks, albeit with smaller experience contrasts. EEG results show a well-known quadratic relationship between theta power and flow across tasks, and a novel quadratic relationship between beta asymmetry and flow during complex, real-world tasks."
    },
    "2501.19107v1": {
      "title": "Brain-inspired sparse training enables Transformers and LLMs to perform as fully connected",
      "url": "http://arxiv.org/abs/2501.19107v1",
      "authors": "Yingtao Zhang, Jialin Zhao, Wenjing Wu, Ziheng Liao, Umberto Michieli, Carlo Vittorio Cannistraci",
      "update_time": "2025-01-31",
      "abstract": "This study aims to enlarge our current knowledge on application of brain-inspired network science principles for training artificial neural networks (ANNs) with sparse connectivity. Dynamic sparse training (DST) can reduce the computational demands in ANNs, but faces difficulties to keep peak performance at high sparsity levels. The Cannistraci-Hebb training (CHT) is a brain-inspired method for growing connectivity in DST. CHT leverages a gradient-free, topology-driven link regrowth, which has shown ultra-sparse (1% connectivity or lower) advantage across various tasks compared to fully connected networks. Yet, CHT suffers two main drawbacks: (i) its time complexity is O(Nd^3) - N node network size, d node degree - hence it can apply only to ultra-sparse networks. (ii) it selects top link prediction scores, which is inappropriate for the early training epochs, when the network presents unreliable connections. We propose a GPU-friendly approximation of the CH link predictor, which reduces the computational complexity to O(N^3), enabling a fast implementation of CHT in large-scale models. We introduce the Cannistraci-Hebb training soft rule (CHTs), which adopts a strategy for sampling connections in both link removal and regrowth, balancing the exploration and exploitation of network topology. To improve performance, we integrate CHTs with a sigmoid gradual density decay (CHTss). Empirical results show that, using 1% of connections, CHTs outperforms fully connected networks in MLP on visual classification tasks, compressing some networks to < 30% nodes. Using 5% of the connections, CHTss outperforms fully connected networks in two Transformer-based machine translation tasks. Using 30% of the connections, CHTss achieves superior performance compared to other dynamic sparse training methods in language modeling, and it surpasses the fully connected counterpart in zero-shot evaluations."
    },
    "2501.19106v1": {
      "title": "Stiff-sloppy analysis of brain networks to reveal individual differences in task performance",
      "url": "http://arxiv.org/abs/2501.19106v1",
      "authors": "Sida Chen, Qianyuan Tang, Taro Toyoizumi, Werner Sommer, Lianchun Yu, Changsong Zhou",
      "update_time": "2025-01-31",
      "abstract": "Understanding how brain networks recruit resources during cognitive tasks is key to explaining individual differences in task performance. Brain network parameters-including activity levels of regions and their connectivity-reflect the integration and segregation of functional subnetworks underlying task processing. However, the complexity and high dimensionality of these parameters pose a significant barrier to identifying functionally relevant individual differences. Here, we introduce stiff-sloppy analysis as a framework for uncovering the stiff parameter combinations that critically influence task-state brain dynamics, exemplified by working memory. Using the pairwise maximum entropy model (PMEM) calibrated to fMRI data and Fisher Information Matrix (FIM) analysis, we reveal that the stiff dimensions of the model parameters capture the most relevant integration and segregation processes of the default mode network and the working memory network. Individual differences along these stiff neural dimensions consistently correlate with working memory performance. Notably, stiff parameters robustly predicted working memory performance, even when the less sensitive (\"sloppy\") parameters were excluded. This study establishes stiff-sloppy analysis as a powerful approach to identify cognition-related brain networks, bridging neural dynamics and behavior and offering new avenues for personalized neuroscience including therapeutic innovation."
    },
    "2501.19059v1": {
      "title": "Controllable Neural Architectures for Multi-Task Control",
      "url": "http://arxiv.org/abs/2501.19059v1",
      "authors": "Umberto Casti, Giacomo Baggio, Sandro Zampieri, Fabio Pasqualetti",
      "update_time": "2025-01-31",
      "abstract": "This paper studies a multi-task control problem where multiple linear systems are to be regulated by a single non-linear controller. In particular, motivated by recent advances in multi-task learning and the design of brain-inspired architectures, we consider a neural controller with (smooth) ReLU activation function. The parameters of the controller are a connectivity matrix and a bias vector: although both parameters can be designed, the connectivity matrix is constant while the bias vector can be varied and is used to adapt the controller across different control tasks. The bias vector determines the equilibrium of the neural controller and, consequently, of its linearized dynamics. Our multi-task control strategy consists of designing the connectivity matrix and a set of bias vectors in a way that the linearized dynamics of the neural controller for the different bias vectors provide a good approximation of a set of desired controllers. We show that, by properly choosing the bias vector, the linearized dynamics of the neural controller can replicate the dynamics of any single, linear controller. Further, we design gradient-based algorithms to train the parameters of the neural controller, and we provide upper and lower bounds for the performance of our neural controller. Finally, we validate our results using different numerical examples."
    },
    "2501.19024v1": {
      "title": "Multilayer Networks in Neuroimaging",
      "url": "http://arxiv.org/abs/2501.19024v1",
      "authors": "Vesna Vuksanovic",
      "update_time": "2025-01-31",
      "abstract": "Recent advances in network science, applied to \\textit{in vivo} brain recordings, have paved the way for better understanding of the structure and function of the brain. However, despite its obvious usefulness in neuroscience, traditional network science lacks tools for -- so important -- simultaneous investigation of the inter-relationship between the two domains. In this chapter, I explore the increasing role of multilayer networks in building brain generative models and abilities of such models to uncover the full information about the brain complex spatiotemporal interactions that span across multiple scales and modalities. First, I begin with the theoretical foundation of brain networks accompanied by a brief overview of traditional networks and their role in constructing multilayer network models. Then, I delve into the applications of multilayer networks in neuroscience, particularly in deciphering structure-function relationship, modelling diseases, and integrating multi-scale and multi-modal data. Finally, I demonstrate how incorporating the multilayer framework into network neuroscience has brought to light previously hidden features of brain networks and, how multilayer networks can provide new insights and a description of the structure and function of the brain."
    },
    "2501.19005v1": {
      "title": "Assessing Sensitivity of Brain-to-Scalp Blood Flows in Laser Speckle Imaging by Occluding the Superficial Temporal Artery",
      "url": "http://arxiv.org/abs/2501.19005v1",
      "authors": "Yu Xi Huang, Simon Mahler, Maya Dickson, Aidin Abedi, Yu Tung Lo, Patrick D. Lyden, Jonathan Russin, Charles Liu, Changhuei Yang",
      "update_time": "2025-01-31",
      "abstract": "Cerebral blood flow is a critical metric for cerebrovascular monitoring, with applications in stroke detection, brain injury evaluation, aging, and neurological disorders. Non-invasively measuring cerebral blood dynamics is challenging due to the scalp and skull, which obstruct direct brain access and contain their own blood dynamics that must be isolated. We developed an aggregated seven-channel speckle contrast optical spectroscopy system to measure blood flow and blood volume non-invasively. Each channel, with distinct source-to-detector distance, targeted different depths to detect scalp and brain blood dynamics separately. By briefly occluding the superficial temporal artery, which supplies blood only to the scalp, we isolated surface blood dynamics from brain signals. Results on 20 subjects show that scalp-sensitive channels experienced significant reductions in blood dynamics during occlusion, while brain-sensitive channels experienced minimal changes. This provides experimental evidence of brain-to-scalp sensitivity in optical measurements, highlighting optimal configuration for preferentially probing brain signals non-invasively."
    },
    "2501.18894v1": {
      "title": "Nonlinear Inference Capacity of Fiber-Optical Extreme Learning Machines",
      "url": "http://arxiv.org/abs/2501.18894v1",
      "authors": "Sobhi Saeed, Mehmet M\u00fcft\u00fcoglu, Glitta R. Cheeran, Thomas Bocklitz, Bennet Fischer, Mario Chemnitz",
      "update_time": "2025-01-31",
      "abstract": "The intrinsic complexity of nonlinear optical phenomena offers a fundamentally new resource to analog brain-inspired computing, with the potential to address the pressing energy requirements of artificial intelligence. We introduce and investigate the concept of nonlinear inference capacity in optical neuromorphic computing in highly nonlinear fiber-based optical Extreme Learning Machines. We demonstrate that this capacity scales with nonlinearity to the point where it surpasses the performance of a deep neural network model with five hidden layers on a scalable nonlinear classification benchmark. By comparing normal and anomalous dispersion fibers under various operating conditions and against digital classifiers, we observe a direct correlation between the system's nonlinear dynamics and its classification performance. Our findings suggest that image recognition tasks, such as MNIST, are incomplete in showcasing deep computing capabilities in analog hardware. Our approach provides a framework for evaluating and comparing computational capabilities, particularly their ability to emulate deep networks, across different physical and digital platforms, paving the way for a more generalized set of benchmarks for unconventional, physics-inspired computing architectures."
    },
    "2501.18859v1": {
      "title": "A Deep Spatio-Temporal Architecture for Dynamic Effective Connectivity Network Analysis Based on Dynamic Causal Discovery",
      "url": "http://arxiv.org/abs/2501.18859v1",
      "authors": "Faming Xu, Yiding Wang, Chen Qiao, Gang Qu, Vince D. Calhoun, Julia M. Stephen, Tony W. Wilson, Yu-Ping Wang",
      "update_time": "2025-01-31",
      "abstract": "Dynamic effective connectivity networks (dECNs) reveal the changing directed brain activity and the dynamic causal influences among brain regions, which facilitate the identification of individual differences and enhance the understanding of human brain. Although the existing causal discovery methods have shown promising results in effective connectivity network analysis, they often overlook the dynamics of causality, in addition to the incorporation of spatio-temporal information in brain activity data. To address these issues, we propose a deep spatio-temporal fusion architecture, which employs a dynamic causal deep encoder to incorporate spatio-temporal information into dynamic causality modeling, and a dynamic causal deep decoder to verify the discovered causality. The effectiveness of the proposed method is first illustrated with simulated data. Then, experimental results from Philadelphia Neurodevelopmental Cohort (PNC) demonstrate the superiority of the proposed method in inferring dECNs, which reveal the dynamic evolution of directed flow between brain regions. The analysis shows the difference of dECNs between young adults and children. Specifically, the directed brain functional networks transit from fluctuating undifferentiated systems to more stable specialized networks as one grows. This observation provides further evidence on the modularization and adaptation of brain networks during development, leading to higher cognitive abilities observed in young adults."
    }
  },
  "EEG": {
    "2501.19217v1": {
      "title": "Exploring Flow in Real-World Knowledge Work Using Discreet cEEGrid Sensors",
      "url": "http://arxiv.org/abs/2501.19217v1",
      "authors": "Michael T. Knierim, Fabio Stano, Fabio Kurz, Antonius Heusch, Max L. Wilson",
      "update_time": "2025-01-31",
      "abstract": "Flow, a state of deep task engagement, is associated with optimal experience and well-being, making its detection a prolific HCI research focus. While physiological sensors show promise for flow detection, most studies are lab-based. Furthermore, brain sensing during natural work remains unexplored due to the intrusive nature of traditional EEG setups. This study addresses this gap by using wearable, around-the-ear EEG sensors to observe flow during natural knowledge work, measuring EEG throughout an entire day. In a semi-controlled field experiment, participants engaged in academic writing or programming, with their natural flow experiences compared to those from a classic lab paradigm. Our results show that natural work tasks elicit more intense flow than artificial tasks, albeit with smaller experience contrasts. EEG results show a well-known quadratic relationship between theta power and flow across tasks, and a novel quadratic relationship between beta asymmetry and flow during complex, real-world tasks."
    },
    "2501.18192v1": {
      "title": "Machine Learning Fairness for Depression Detection using EEG Data",
      "url": "http://arxiv.org/abs/2501.18192v1",
      "authors": "Angus Man Ho Kwok, Jiaee Cheong, Sinan Kalkan, Hatice Gunes",
      "update_time": "2025-01-30",
      "abstract": "This paper presents the very first attempt to evaluate machine learning fairness for depression detection using electroencephalogram (EEG) data. We conduct experiments using different deep learning architectures such as Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Unit (GRU) networks across three EEG datasets: Mumtaz, MODMA and Rest. We employ five different bias mitigation strategies at the pre-, in- and post-processing stages and evaluate their effectiveness. Our experimental results show that bias exists in existing EEG datasets and algorithms for depression detection, and different bias mitigation methods address bias at different levels across different fairness measures."
    },
    "2501.18089v1": {
      "title": "ISAM-MTL: Cross-subject multi-task learning model with identifiable spikes and associative memory networks",
      "url": "http://arxiv.org/abs/2501.18089v1",
      "authors": "Junyan Li, Bin Hu, Zhi-Hong Guan",
      "update_time": "2025-01-30",
      "abstract": "Cross-subject variability in EEG degrades performance of current deep learning models, limiting the development of brain-computer interface (BCI). This paper proposes ISAM-MTL, which is a multi-task learning (MTL) EEG classification model based on identifiable spiking (IS) representations and associative memory (AM) networks. The proposed model treats EEG classification of each subject as an independent task and leverages cross-subject data training to facilitate feature sharing across subjects. ISAM-MTL consists of a spiking feature extractor that captures shared features across subjects and a subject-specific bidirectional associative memory network that is trained by Hebbian learning for efficient and fast within-subject EEG classification. ISAM-MTL integrates learned spiking neural representations with bidirectional associative memory for cross-subject EEG classification. The model employs label-guided variational inference to construct identifiable spike representations, enhancing classification accuracy. Experimental results on two BCI Competition datasets demonstrate that ISAM-MTL improves the average accuracy of cross-subject EEG classification while reducing performance variability among subjects. The model further exhibits the characteristics of few-shot learning and identifiable neural activity beneath EEG, enabling rapid and interpretable calibration for BCI systems."
    },
    "2501.17489v1": {
      "title": "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding",
      "url": "http://arxiv.org/abs/2501.17489v1",
      "authors": "Xiaowei Jiang, Charles Zhou, Yiqun Duan, Ziyi Zhao, Thomas Do, Chin-Teng Lin",
      "update_time": "2025-01-29",
      "abstract": "Brain-computer interfaces (BCIs) present a promising avenue by translating neural activity directly into text, eliminating the need for physical actions. However, existing non-invasive BCI systems have not successfully covered the entire alphabet, limiting their practicality. In this paper, we propose a novel non-invasive EEG-based BCI system with Curriculum-based Neural Spelling Framework, which recognizes all 26 alphabet letters by decoding neural signals associated with handwriting first, and then apply a Generative AI (GenAI) to enhance spell-based neural language decoding tasks. Our approach combines the ease of handwriting with the accessibility of EEG technology, utilizing advanced neural decoding algorithms and pre-trained large language models (LLMs) to translate EEG patterns into text with high accuracy. This system show how GenAI can improve the performance of typical spelling-based neural language decoding task, and addresses the limitations of previous methods, offering a scalable and user-friendly solution for individuals with communication impairments, thereby enhancing inclusive communication options."
    },
    "2501.17475v1": {
      "title": "EMD-Fuzzy: An Empirical Mode Decomposition Based Fuzzy Model for Cross-Stimulus Transfer Learning of SSVEP",
      "url": "http://arxiv.org/abs/2501.17475v1",
      "authors": "Beining Cao, Xiaowei Jiang, Daniel Leong, Charlie Li-Ting Tsai, Yu-Cheng Chang, Thomas Do, Chin-Teng",
      "update_time": "2025-01-29",
      "abstract": "The Brain-Computer Interface (BCI) enables direct brain-to-device communication, with the Steady-State Visual Evoked Potential (SSVEP) paradigm favored for its stability and high accuracy across various fields. In SSVEP BCI systems, supervised learning models significantly enhance performance over unsupervised models, achieving higher accuracy in less time. However, prolonged data collection can cause user fatigue and even trigger photosensitive epilepsy, creating a negative user experience. Thus, reducing calibration time is crucial. To address this, Cross-Stimulus transfer learning (CSTL) can shorten calibration by utilizing only partial frequencies. Traditional CSTL methods, affected by time-domain impulse response variations, are suitable only for adjacent frequency transfers, limiting their general applicability. We introduce an Empirical Mode Decomposition (EMD) Based Fuzzy Model (EMD-Fuzzy), which employs EMD to extract crucial frequency information and achieves stimulus transfer in the frequency domain through Fast Fourier Transform (FFT) to mitigate time-domain differences. Combined with a Fuzzy Decoder that uses fuzzy logic for representation learning, our approach delivers promising preliminary results in offline tests and state-of-the-art performance. With only 4 frequencies, our method achieved an accuracy of 82.75% (16.30%) and an information transfer rate (ITR) of 186.56 (52.09) bits/min on the 40-target Benchmark dataset. In online tests, our method demonstrates robust efficacy, achieving an averaged accuracy of 86.30% (6.18%) across 7 subjects. This performance underscores the effectiveness of integrating EMD and fuzzy logic into EEG decoding for CSTL and highlights our method's potential in real-time applications where consistent and reliable decoding is crucial."
    },
    "2501.16762v1": {
      "title": "Rate-Distortion under Neural Tracking of Speech: A Directed Redundancy Approach",
      "url": "http://arxiv.org/abs/2501.16762v1",
      "authors": "Jan \u00d8stergaard, Sangeeth Geetha Jayaprakash, Rodrigo Ordo\u00f1ez",
      "update_time": "2025-01-28",
      "abstract": "The data acquired at different scalp EEG electrodes when human subjects are exposed to speech stimuli are highly redundant. The redundancy is partly due to volume conduction effects and partly due to localized regions of the brain synchronizing their activity in response to the stimuli. In a competing talker scenario, we use a recent measure of directed redundancy to assess the amount of redundant information that is causally conveyed from the attended stimuli to the left temporal region of the brain. We observe that for the attended stimuli, the transfer entropy as well as the directed redundancy is proportional to the correlation between the speech stimuli and the reconstructed signal from the EEG signals.   This demonstrates that both the rate as well as the rate-redundancy are inversely proportional to the distortion in neural speech tracking. Thus, a greater rate indicates a greater redundancy between the electrode signals, and a greater correlation between the reconstructed signal and the attended stimuli. A similar relationship is not observed for the distracting stimuli."
    },
    "2501.16329v1": {
      "title": "sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic Sleep Staging",
      "url": "http://arxiv.org/abs/2501.16329v1",
      "authors": "Jingyuan Chen, Yuan Yao, Mie Anderson, Natalie Hauglund, Celia Kjaerby, Verena Untiet, Maiken Nedergaard, Jiebo Luo",
      "update_time": "2025-01-27",
      "abstract": "Automatic sleep staging based on electroencephalography (EEG) and electromyography (EMG) signals is an important aspect of sleep-related research. Current sleep staging methods suffer from two major drawbacks. First, there are limited information interactions between modalities in the existing methods. Second, current methods do not develop unified models that can handle different sources of input. To address these issues, we propose a novel sleep stage scoring model sDREAMER, which emphasizes cross-modality interaction and per-channel performance. Specifically, we develop a mixture-of-modality-expert (MoME) model with three pathways for EEG, EMG, and mixed signals with partially shared weights. We further propose a self-distillation training scheme for further information interaction across modalities. Our model is trained with multi-channel inputs and can make classifications on either single-channel or multi-channel inputs. Experiments demonstrate that our model outperforms the existing transformer-based sleep scoring methods for multi-channel inference. For single-channel inference, our model also outperforms the transformer-based models trained with single-channel signals."
    },
    "2501.16230v1": {
      "title": "MIND-EEG: Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition",
      "url": "http://arxiv.org/abs/2501.16230v1",
      "authors": "Yuzhe Zhang, Chengxi Xie, Huan Liu, Yuhan Shi, Dalin Zhang",
      "update_time": "2025-01-27",
      "abstract": "Emotion recognition using electroencephalogram (EEG) signals has broad potential across various domains. EEG signals have ability to capture rich spatial information related to brain activity, yet effectively modeling and utilizing these spatial relationships remains a challenge. Existing methods struggle with simplistic spatial structure modeling, failing to capture complex node interactions, and lack generalizable spatial connection representations, failing to balance the dynamic nature of brain networks with the need for discriminative and generalizable features. To address these challenges, we propose the Multi-granularity Integration Network with Discrete Codebook for EEG-based Emotion Recognition (MIND-EEG). The framework employs a multi-granularity approach, integrating global and regional spatial information through a Global State Encoder, an Intra-Regional Functionality Encoder, and an Inter-Regional Interaction Encoder to comprehensively model brain activity. Additionally, we introduce a discrete codebook mechanism for constructing network structures via vector quantization, ensuring compact and meaningful brain network representations while mitigating over-smoothing and enhancing model generalization. The proposed framework effectively captures the dynamic and diverse nature of EEG signals, enabling robust emotion recognition. Extensive comparisons and analyses demonstrate the effectiveness of MIND-EEG, and the source code is publicly available at https://anonymous.4open.science/r/MIND_EEG."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.15062v1": {
      "title": "Exact Fit Attention in Node-Holistic Graph Convolutional Network for Improved EEG-Based Driver Fatigue Detection",
      "url": "http://arxiv.org/abs/2501.15062v1",
      "authors": "Meiyan Xu, Qingqing Chen, Duo Chen, Yi Ding, Jingyuan Wang, Peipei Gu, Yijie Pan, Deshuang Huang, Xun Zhang, Jiayang Guo",
      "update_time": "2025-01-25",
      "abstract": "EEG-based fatigue monitoring can effectively reduce the incidence of related traffic accidents. In the past decade, with the advancement of deep learning, convolutional neural networks (CNN) have been increasingly used for EEG signal processing. However, due to the data's non-Euclidean characteristics, existing CNNs may lose important spatial information from EEG, specifically channel correlation. Thus, we propose the node-holistic graph convolutional network (NHGNet), a model that uses graphic convolution to dynamically learn each channel's features. With exact fit attention optimization, the network captures inter-channel correlations through a trainable adjacency matrix. The interpretability is enhanced by revealing critical areas of brain activity and their interrelations in various mental states. In validations on two public datasets, NHGNet outperforms the SOTAs. Specifically, in the intra-subject, NHGNet improved detection accuracy by at least 2.34% and 3.42%, and in the inter-subjects, it improved by at least 2.09% and 15.06%. Visualization research on the model revealed that the central parietal area plays an important role in detecting fatigue levels, whereas the frontal and temporal lobes are essential for maintaining vigilance."
    }
  },
  "BCI": {
    "2501.18089v1": {
      "title": "ISAM-MTL: Cross-subject multi-task learning model with identifiable spikes and associative memory networks",
      "url": "http://arxiv.org/abs/2501.18089v1",
      "authors": "Junyan Li, Bin Hu, Zhi-Hong Guan",
      "update_time": "2025-01-30",
      "abstract": "Cross-subject variability in EEG degrades performance of current deep learning models, limiting the development of brain-computer interface (BCI). This paper proposes ISAM-MTL, which is a multi-task learning (MTL) EEG classification model based on identifiable spiking (IS) representations and associative memory (AM) networks. The proposed model treats EEG classification of each subject as an independent task and leverages cross-subject data training to facilitate feature sharing across subjects. ISAM-MTL consists of a spiking feature extractor that captures shared features across subjects and a subject-specific bidirectional associative memory network that is trained by Hebbian learning for efficient and fast within-subject EEG classification. ISAM-MTL integrates learned spiking neural representations with bidirectional associative memory for cross-subject EEG classification. The model employs label-guided variational inference to construct identifiable spike representations, enhancing classification accuracy. Experimental results on two BCI Competition datasets demonstrate that ISAM-MTL improves the average accuracy of cross-subject EEG classification while reducing performance variability among subjects. The model further exhibits the characteristics of few-shot learning and identifiable neural activity beneath EEG, enabling rapid and interpretable calibration for BCI systems."
    },
    "2501.17489v1": {
      "title": "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding",
      "url": "http://arxiv.org/abs/2501.17489v1",
      "authors": "Xiaowei Jiang, Charles Zhou, Yiqun Duan, Ziyi Zhao, Thomas Do, Chin-Teng Lin",
      "update_time": "2025-01-29",
      "abstract": "Brain-computer interfaces (BCIs) present a promising avenue by translating neural activity directly into text, eliminating the need for physical actions. However, existing non-invasive BCI systems have not successfully covered the entire alphabet, limiting their practicality. In this paper, we propose a novel non-invasive EEG-based BCI system with Curriculum-based Neural Spelling Framework, which recognizes all 26 alphabet letters by decoding neural signals associated with handwriting first, and then apply a Generative AI (GenAI) to enhance spell-based neural language decoding tasks. Our approach combines the ease of handwriting with the accessibility of EEG technology, utilizing advanced neural decoding algorithms and pre-trained large language models (LLMs) to translate EEG patterns into text with high accuracy. This system show how GenAI can improve the performance of typical spelling-based neural language decoding task, and addresses the limitations of previous methods, offering a scalable and user-friendly solution for individuals with communication impairments, thereby enhancing inclusive communication options."
    },
    "2501.17475v1": {
      "title": "EMD-Fuzzy: An Empirical Mode Decomposition Based Fuzzy Model for Cross-Stimulus Transfer Learning of SSVEP",
      "url": "http://arxiv.org/abs/2501.17475v1",
      "authors": "Beining Cao, Xiaowei Jiang, Daniel Leong, Charlie Li-Ting Tsai, Yu-Cheng Chang, Thomas Do, Chin-Teng",
      "update_time": "2025-01-29",
      "abstract": "The Brain-Computer Interface (BCI) enables direct brain-to-device communication, with the Steady-State Visual Evoked Potential (SSVEP) paradigm favored for its stability and high accuracy across various fields. In SSVEP BCI systems, supervised learning models significantly enhance performance over unsupervised models, achieving higher accuracy in less time. However, prolonged data collection can cause user fatigue and even trigger photosensitive epilepsy, creating a negative user experience. Thus, reducing calibration time is crucial. To address this, Cross-Stimulus transfer learning (CSTL) can shorten calibration by utilizing only partial frequencies. Traditional CSTL methods, affected by time-domain impulse response variations, are suitable only for adjacent frequency transfers, limiting their general applicability. We introduce an Empirical Mode Decomposition (EMD) Based Fuzzy Model (EMD-Fuzzy), which employs EMD to extract crucial frequency information and achieves stimulus transfer in the frequency domain through Fast Fourier Transform (FFT) to mitigate time-domain differences. Combined with a Fuzzy Decoder that uses fuzzy logic for representation learning, our approach delivers promising preliminary results in offline tests and state-of-the-art performance. With only 4 frequencies, our method achieved an accuracy of 82.75% (16.30%) and an information transfer rate (ITR) of 186.56 (52.09) bits/min on the 40-target Benchmark dataset. In online tests, our method demonstrates robust efficacy, achieving an averaged accuracy of 86.30% (6.18%) across 7 subjects. This performance underscores the effectiveness of integrating EMD and fuzzy logic into EEG decoding for CSTL and highlights our method's potential in real-time applications where consistent and reliable decoding is crucial."
    },
    "2501.16471v1": {
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "url": "http://arxiv.org/abs/2501.16471v1",
      "authors": "Simon Dahan, Gabriel B\u00e9n\u00e9dict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson",
      "update_time": "2025-01-27",
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at https://github.com/metrics-lab/sim, processed data for training will be available upon request at https://gin.g-node.org/Sdahan30/sim.",
      "code_url": "https://github.com/metrics-lab/sim"
    },
    "2501.09700v1": {
      "title": "Cueless EEG imagined speech for subject identification: dataset and benchmarks",
      "url": "http://arxiv.org/abs/2501.09700v1",
      "authors": "Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee",
      "update_time": "2025-01-16",
      "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for biometric identification. While previous studies have explored the use of imagined speech with semantically meaningful words for subject identification, most have relied on additional visual or auditory cues. In this study, we introduce a cueless EEG-based imagined speech paradigm, where subjects imagine the pronunciation of semantically meaningful words without any external cues. This innovative approach addresses the limitations of prior methods by requiring subjects to select and imagine words from a predefined list naturally. The dataset comprises over 4,350 trials from 11 subjects across five sessions. We assess a variety of classification methods, including traditional machine learning techniques such as Support Vector Machines (SVM) and XGBoost, as well as time-series foundation models and deep learning architectures specifically designed for EEG classification, such as EEG Conformer and Shallow ConvNet. A session-based hold-out validation strategy was employed to ensure reliable evaluation and prevent data leakage. Our results demonstrate outstanding classification accuracy, reaching 97.93%. These findings highlight the potential of cueless EEG paradigms for secure and reliable subject identification in real-world applications, such as brain-computer interfaces (BCIs).",
      "code_url": "https://github.com/alidr79/cueless_eeg_subject_identification"
    },
    "2501.09459v1": {
      "title": "Teaching Wav2Vec2 the Language of the Brain",
      "url": "http://arxiv.org/abs/2501.09459v1",
      "authors": "Tobias Fiedler, Leon Hermann, Florian M\u00fcller, Sarel Cohen, Peter Chin, Tobias Friedrich, Eilon Vaadia",
      "update_time": "2025-01-16",
      "abstract": "The decoding of continuously spoken speech from neuronal activity has the potential to become an important clinical solution for paralyzed patients. Deep Learning Brain Computer Interfaces (BCIs) have recently successfully mapped neuronal activity to text contents in subjects who attempted to formulate speech. However, only small BCI datasets are available. In contrast, labeled data and pre-trained models for the closely related task of speech recognition from audio are widely available. One such model is Wav2Vec2 which has been trained in a self-supervised fashion to create meaningful representations of speech audio data. In this study, we show that patterns learned by Wav2Vec2 are transferable to brain data. Specifically, we replace its audio feature extractor with an untrained Brain Feature Extractor (BFE) model. We then execute full fine-tuning with pre-trained weights for Wav2Vec2, training ''from scratch'' without pre-trained weights as well as freezing a pre-trained Wav2Vec2 and training only the BFE each for 45 different BFE architectures. Across these experiments, the best run is from full fine-tuning with pre-trained weights, achieving a Character Error Rate (CER) of 18.54\\%, outperforming the best training from scratch run by 20.46\\% and that of frozen Wav2Vec2 training by 15.92\\% percentage points. These results indicate that knowledge transfer from audio speech recognition to brain decoding is possible and significantly improves brain decoding performance for the same architectures. Related source code is available at https://github.com/tfiedlerdev/Wav2Vec2ForBrain.",
      "code_url": "https://github.com/tfiedlerdev/wav2vec2forbrain"
    },
    "2501.08518v1": {
      "title": "Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface",
      "url": "http://arxiv.org/abs/2501.08518v1",
      "authors": "Xiaoyu Bao, Kailin Xu, Jiawei Zhu, Haiyun Huang, Kangning Li, Qiyun Huang, Yuanqing Li",
      "update_time": "2025-01-15",
      "abstract": "Seasickness is a prevalent issue that adversely impacts both passenger experiences and the operational efficiency of maritime crews. While techniques that redirect attention have proven effective in alleviating motion sickness symptoms in terrestrial environments, applying similar strategies to manage seasickness poses unique challenges due to the prolonged and intense motion environment associated with maritime travel. In this study, we propose a mindfulness brain-computer interface (BCI), specifically designed to redirect attention with the aim of mitigating seasickness symptoms in real-world settings. Our system utilizes a single-channel headband to capture prefrontal EEG signals, which are then wirelessly transmitted to computing devices for the assessment of mindfulness states. The results are transferred into real-time feedback as mindfulness scores and audiovisual stimuli, facilitating a shift in attentional focus from physiological discomfort to mindfulness practices. A total of 43 individuals participated in a real-world maritime experiment consisted of three sessions: a real-feedback mindfulness session, a resting session, and a pseudofeedback mindfulness session. Notably, 81.39% of participants reported that the mindfulness BCI intervention was effective, and there was a significant reduction in the severity of seasickness, as measured by the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in the theta/beta ratio, corresponding with the alleviation of seasickness symptoms. A decrease in overall EEG band power during the real-feedback mindfulness session suggests that the mindfulness BCI fosters a more tranquil and downregulated state of brain activity. Together, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, with the potential to enhance the cruising experience for both passengers and crews."
    },
    "2501.06326v2": {
      "title": "On Creating A Brain-To-Text Decoder",
      "url": "http://arxiv.org/abs/2501.06326v2",
      "authors": "Zenon Lamprou, Yashar Moshfeghi",
      "update_time": "2025-02-02",
      "abstract": "Brain decoding has emerged as a rapidly advancing and extensively utilized technique within neuroscience. This paper centers on the application of raw electroencephalogram (EEG) signals for decoding human brain activity, offering a more expedited and efficient methodology for enhancing our understanding of the human brain. The investigation specifically scrutinizes the efficacy of brain-computer interfaces (BCI) in deciphering neural signals associated with speech production, with particular emphasis on the impact of vocabulary size, electrode density, and training data on the framework's performance. The study reveals the competitive word error rates (WERs) achievable on the Librispeech benchmark through pre-training on unlabelled data for speech processing. Furthermore, the study evaluates the efficacy of voice recognition under configurations with limited labeled data, surpassing previous state-of-the-art techniques while utilizing significantly fewer labels. Additionally, the research provides a comprehensive analysis of error patterns in voice recognition and the influence of model size and unlabelled training data. It underscores the significance of factors such as vocabulary size and electrode density in enhancing BCI performance, advocating for an increase in microelectrodes and refinement of language models."
    },
    "2501.05610v1": {
      "title": "Towards Probabilistic Inference of Human Motor Intentions by Assistive Mobile Robots Controlled via a Brain-Computer Interface",
      "url": "http://arxiv.org/abs/2501.05610v1",
      "authors": "Xiaoshan Zhou, Carol M. Menassa, Vineet R. Kamat",
      "update_time": "2025-01-09",
      "abstract": "Assistive mobile robots are a transformative technology that helps persons with disabilities regain the ability to move freely. Although autonomous wheelchairs significantly reduce user effort, they still require human input to allow users to maintain control and adapt to changing environments. Brain Computer Interface (BCI) stands out as a highly user-friendly option that does not require physical movement. Current BCI systems can understand whether users want to accelerate or decelerate, but they implement these changes in discrete speed steps rather than allowing for smooth, continuous velocity adjustments. This limitation prevents the systems from mimicking the natural, fluid speed changes seen in human self-paced motion. The authors aim to address this limitation by redesigning the perception-action cycle in a BCI controlled robotic system: improving how the robotic agent interprets the user's motion intentions (world state) and implementing these actions in a way that better reflects natural physical properties of motion, such as inertia and damping. The scope of this paper focuses on the perception aspect. We asked and answered a normative question \"what computation should the robotic agent carry out to optimally perceive incomplete or noisy sensory observations?\" Empirical EEG data were collected, and probabilistic representation that served as world state distributions were learned and evaluated in a Generative Adversarial Network framework. The ROS framework was established that connected with a Gazebo environment containing a digital twin of an indoor space and a virtual model of a robotic wheelchair. Signal processing and statistical analyses were implemented to identity the most discriminative features in the spatial-spectral-temporal dimensions, which are then used to construct the world model for the robotic agent to interpret user motion intentions as a Bayesian observer."
    },
    "2501.05589v1": {
      "title": "LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric Learning",
      "url": "http://arxiv.org/abs/2501.05589v1",
      "authors": "Jianchao Lu, Yuzhe Tian, Yang Zhang, Quan Z. Sheng, Xi Zheng",
      "update_time": "2025-01-09",
      "abstract": "Brain--computer interfaces are groundbreaking technology whereby brain signals are used to control external devices. Despite some advances in recent years, electroencephalogram (EEG)-based motor-imagery tasks face challenges, such as amplitude and phase variability and complex spatial correlations, with a need for smaller models and faster inference. In this study, we develop a prototype, called the Lightweight Geometric Learning Brain--Computer Interface (LGL-BCI), which uses our customized geometric deep learning architecture for swift model inference without sacrificing accuracy. LGL-BCI contains an EEG channel selection module via a feature decomposition algorithm to reduce the dimensionality of a symmetric positive definite matrix, providing adaptiveness among the continuously changing EEG signal. Meanwhile, a built-in lossless transformation helps boost the inference speed. The performance of our solution was evaluated using two real-world EEG devices and two public EEG datasets. LGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54% compared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses fewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency. These findings underscore both the superior accuracy and computational efficiency of LGL-BCI, demonstrating the feasibility and robustness of geometric deep learning in motor-imagery brain--computer interface applications."
    }
  },
  "fMRI": {
    "2501.19106v1": {
      "title": "Stiff-sloppy analysis of brain networks to reveal individual differences in task performance",
      "url": "http://arxiv.org/abs/2501.19106v1",
      "authors": "Sida Chen, Qianyuan Tang, Taro Toyoizumi, Werner Sommer, Lianchun Yu, Changsong Zhou",
      "update_time": "2025-01-31",
      "abstract": "Understanding how brain networks recruit resources during cognitive tasks is key to explaining individual differences in task performance. Brain network parameters-including activity levels of regions and their connectivity-reflect the integration and segregation of functional subnetworks underlying task processing. However, the complexity and high dimensionality of these parameters pose a significant barrier to identifying functionally relevant individual differences. Here, we introduce stiff-sloppy analysis as a framework for uncovering the stiff parameter combinations that critically influence task-state brain dynamics, exemplified by working memory. Using the pairwise maximum entropy model (PMEM) calibrated to fMRI data and Fisher Information Matrix (FIM) analysis, we reveal that the stiff dimensions of the model parameters capture the most relevant integration and segregation processes of the default mode network and the working memory network. Individual differences along these stiff neural dimensions consistently correlate with working memory performance. Notably, stiff parameters robustly predicted working memory performance, even when the less sensitive (\"sloppy\") parameters were excluded. This study establishes stiff-sloppy analysis as a powerful approach to identify cognition-related brain networks, bridging neural dynamics and behavior and offering new avenues for personalized neuroscience including therapeutic innovation."
    },
    "2501.16471v1": {
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "url": "http://arxiv.org/abs/2501.16471v1",
      "authors": "Simon Dahan, Gabriel B\u00e9n\u00e9dict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson",
      "update_time": "2025-01-27",
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at https://github.com/metrics-lab/sim, processed data for training will be available upon request at https://gin.g-node.org/Sdahan30/sim.",
      "code_url": "https://github.com/metrics-lab/sim"
    },
    "2501.16409v1": {
      "title": "Classification of Mild Cognitive Impairment Based on Dynamic Functional Connectivity Using Spatio-Temporal Transformer",
      "url": "http://arxiv.org/abs/2501.16409v1",
      "authors": "Jing Zhang, Yanjun Lyu, Xiaowei Yu, Lu Zhang, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Tianming Liu, Dajiang Zhu",
      "update_time": "2025-01-27",
      "abstract": "Dynamic functional connectivity (dFC) using resting-state functional magnetic resonance imaging (rs-fMRI) is an advanced technique for capturing the dynamic changes of neural activities, and can be very useful in the studies of brain diseases such as Alzheimer's disease (AD). Yet, existing studies have not fully leveraged the sequential information embedded within dFC that can potentially provide valuable information when identifying brain conditions. In this paper, we propose a novel framework that jointly learns the embedding of both spatial and temporal information within dFC based on the transformer architecture. Specifically, we first construct dFC networks from rs-fMRI data through a sliding window strategy. Then, we simultaneously employ a temporal block and a spatial block to capture higher-order representations of dynamic spatio-temporal dependencies, via mapping them into an efficient fused feature representation. To further enhance the robustness of these feature representations by reducing the dependency on labeled data, we also introduce a contrastive learning strategy to manipulate different brain states. Experimental results on 345 subjects with 570 scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) demonstrate the superiority of our proposed method for MCI (Mild Cognitive Impairment, the prodromal stage of AD) prediction, highlighting its potential for early identification of AD."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.14854v1": {
      "title": "BOLDreams: Dreaming with pruned in-silico fMRI Encoding Models of the Visual Cortex",
      "url": "http://arxiv.org/abs/2501.14854v1",
      "authors": "Uzair Hussain, Kamil Uludag",
      "update_time": "2025-01-24",
      "abstract": "In this article we use the Natural Scenes Dataset (NSD) to train a family of feature-weighted receptive field neural encoding models. These models use a pre-trained vision or text backbone and map extracted features to the voxel space via receptive field readouts. We comprehensively assess such models, quantifying performance changes based on using different modalities like text or images, toggling finetuning, using different pre-trained backbones, and changing the width of the readout. We also dissect each model using explainable AI (XAI) techniques, such as feature visualization via input optimization, also referred to as ``dreaming'' in the AI literature, and the integrated gradients approach to calculate implicit attention maps to illustrate which features drive the predicted signal in different brain areas. These XAI tools illustrate biologically plausible features that drive the predicted signal. Traversing the model hyperparameter space reveals the existence of a maximally minimal model, balancing simplicity while maintaining performance."
    },
    "2501.14309v1": {
      "title": "BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from Brain Activities",
      "url": "http://arxiv.org/abs/2501.14309v1",
      "authors": "Zhibo Tian, Ruijie Quan, Fan Ma, Kun Zhan, Yi Yang",
      "update_time": "2025-01-24",
      "abstract": "Reconstructing perceived images from human brain activity forms a crucial link between human and machine learning through Brain-Computer Interfaces. Early methods primarily focused on training separate models for each individual to account for individual variability in brain activity, overlooking valuable cross-subject commonalities. Recent advancements have explored multisubject methods, but these approaches face significant challenges, particularly in data privacy and effectively managing individual variability. To overcome these challenges, we introduce BrainGuard, a privacy-preserving collaborative training framework designed to enhance image reconstruction from multisubject fMRI data while safeguarding individual privacy. BrainGuard employs a collaborative global-local architecture where individual models are trained on each subject's local data and operate in conjunction with a shared global model that captures and leverages cross-subject patterns. This architecture eliminates the need to aggregate fMRI data across subjects, thereby ensuring privacy preservation. To tackle the complexity of fMRI data, BrainGuard integrates a hybrid synchronization strategy, enabling individual models to dynamically incorporate parameters from the global model. By establishing a secure and collaborative training environment, BrainGuard not only protects sensitive brain data but also improves the image reconstructions accuracy. Extensive experiments demonstrate that BrainGuard sets a new benchmark in both high-level and low-level metrics, advancing the state-of-the-art in brain decoding through its innovative design.",
      "code_url": "https://github.com/kunzhan/brainguard"
    },
    "2501.13239v1": {
      "title": "Peak Inference for Gaussian Random Fields on a Lattice",
      "url": "http://arxiv.org/abs/2501.13239v1",
      "authors": "Tuo Lin, Armin Schwartzman, Samuel Davenport",
      "update_time": "2025-01-22",
      "abstract": "In this work we develop a Monte Carlo method to compute the height distribution of local maxima of a stationary Gaussian or Gaussian-related random field that is observed on a regular lattice. We show that our method can be used to provide valid peak based inference in datasets with low levels of smoothness, where existing formulae derived for continuous domains are not accurate. We also extend the methods in Worsley (2005) and Taylor et al. (2007) to compute the peak height distribution and compare them with our approach. Lastly, we apply our method to a task fMRI dataset to show how it can be used in practice.",
      "code_url": "https://github.com/tuolin123/dlm-code"
    },
    "2501.12111v1": {
      "title": "Using Space-Filling Curves and Fractals to Reveal Spatial and Temporal Patterns in Neuroimaging Data",
      "url": "http://arxiv.org/abs/2501.12111v1",
      "authors": "Jacek Grela, Zbigniew Drogosz, Jakub Janarek, Jeremi K. Ochab, Ignacio Cifre, Ewa Gudowska-Nowak, Maciej A. Nowak, Pawe\u0142 O\u015bwi\u0119cimka, Dante R. Chialvo",
      "update_time": "2025-01-21",
      "abstract": "We present a novel method, Fractal Space-Curve Analysis (FSCA), which combines Space-Filling Curve (SFC) mapping for dimensionality reduction with fractal Detrended Fluctuation Analysis (DFA). The method is suitable for multidimensional geometrically embedded data, especially for neuroimaging data which is highly correlated temporally and spatially. We conduct extensive feasibility studies on diverse, artificially generated data with known fractal characteristics: the fractional Brownian motion, Cantor sets, and Gaussian processes. We compare the suitability of dimensionality reduction via Hilbert SFC and a data-driven alternative. FSCA is then successfully applied to real-world magnetic resonance imaging (MRI) and functional MRI (fMRI) scans.   The method utilizing Hilbert curves is optimized for computational efficiency, proven robust against boundary effects typical in experimental data analysis, and resistant to data sub-sampling. It is able to correctly quantify and discern correlations in both stationary and dynamic two-dimensional images. In MRI Alzheimer's dataset, patients reveal a progression of the disease associated with a systematic decrease of the Hurst exponent. In fMRI recording of breath-holding task, the change in the exponent allows distinguishing different experimental phases.   This study introduces a robust method for fractal characterization of spatial and temporal correlations in many types of multidimensional neuroimaging data. Very few assumptions allow it to be generalized to more dimensions than typical for neuroimaging and utilized in other scientific fields. The method can be particularly useful in analyzing fMRI experiments to compute markers of pathological conditions resulting from neurodegeneration. We also showcase its potential for providing insights into brain dynamics in task-related experiments.",
      "code_url": "https://github.com/mark-kac-center/fsca"
    },
    "2501.16346v1": {
      "title": "Self-supervised Graph Transformer with Contrastive Learning for Brain Connectivity Analysis towards Improving Autism Detection",
      "url": "http://arxiv.org/abs/2501.16346v1",
      "authors": "Yicheng Leng, Syed Muhammad Anwar, Islem Rekik, Sen He, Eung-Joo Lee",
      "update_time": "2025-01-18",
      "abstract": "Functional Magnetic Resonance Imaging (fMRI) provides useful insights into the brain function both during task or rest. Representing fMRI data using correlation matrices is found to be a reliable method of analyzing the inherent connectivity of the brain in the resting and active states. Graph Neural Networks (GNNs) have been widely used for brain network analysis due to their inherent explainability capability. In this work, we introduce a novel framework using contrastive self-supervised learning graph transformers, incorporating a brain network transformer encoder with random graph alterations. The proposed network leverages both contrastive learning and graph alterations to effectively train the graph transformer for autism detection. Our approach, tested on Autism Brain Imaging Data Exchange (ABIDE) data, demonstrates superior autism detection, achieving an AUROC of 82.6 and an accuracy of 74%, surpassing current state-of-the-art methods."
    },
    "2501.16345v1": {
      "title": "Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity",
      "url": "http://arxiv.org/abs/2501.16345v1",
      "authors": "Bishal Thapaliya, Esra Akbas, Ram Sapkota, Bhaskar Ray, Vince Calhoun, Jingyu Liu",
      "update_time": "2025-01-17",
      "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers valuable insights into the human brain's functional organization and is a powerful tool for investigating the relationship between brain function and cognitive processes, as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this study, we introduce a novel attention mechanism for graphs with subnetworks, named Self-Clustering Graph Transformer (SCGT), designed to handle the issue of uniform node updates in graph transformers. By using static functional connectivity (FC) correlation features as input to the transformer model, SCGT effectively captures the sub-network structure of the brain by performing cluster-specific updates to the nodes, unlike uniform node updates in vanilla graph transformers, further allowing us to learn and interpret the subclusters. We validate our approach on the Adolescent Brain Cognitive Development (ABCD) dataset, comprising 7,957 participants, for the prediction of total cognitive score and gender classification. Our results demonstrate that SCGT outperforms the vanilla graph transformer method and other recent models, offering a promising tool for modeling brain functional connectivity and interpreting the underlying subnetwork structures."
    }
  },
  "MEG": {
    "2501.18837v1": {
      "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming",
      "url": "http://arxiv.org/abs/2501.18837v1",
      "authors": "Mrinank Sharma, Meg Tong, Jesse Mu, Jerry Wei, Jorrit Kruthoff, Scott Goodfriend, Euan Ong, Alwin Peng, Raj Agarwal, Cem Anil, Amanda Askell, Nathan Bailey, Joe Benton, Emma Bluemke, Samuel R. Bowman, Eric Christiansen, Hoagy Cunningham, Andy Dau, Anjali Gopal, Rob Gilson, Logan Graham, Logan Howard, Nimit Kalra, Taesung Lee, Kevin Lin, Peter Lofgren, Francesco Mosconi, Clare O'Hara, Catherine Olsson, Linda Petrini, Samir Rajani, Nikhil Saxena, Alex Silverstein, Tanya Singh, Theodore Sumers, Leonard Tang, Kevin K. Troy, Constantin Weisser, Ruiqi Zhong, Giulio Zhou, Jan Leike, Jared Kaplan, Ethan Perez",
      "update_time": "2025-01-31",
      "abstract": "Large language models (LLMs) are vulnerable to universal jailbreaks-prompting strategies that systematically bypass model safeguards and enable users to carry out harmful processes that require many model interactions, like manufacturing illegal substances at scale. To defend against these attacks, we introduce Constitutional Classifiers: safeguards trained on synthetic data, generated by prompting LLMs with natural language rules (i.e., a constitution) specifying permitted and restricted content. In over 3,000 estimated hours of red teaming, no red teamer found a universal jailbreak that could extract information from an early classifier-guarded LLM at a similar level of detail to an unguarded model across most target queries. On automated evaluations, enhanced classifiers demonstrated robust defense against held-out domain-specific jailbreaks. These classifiers also maintain deployment viability, with an absolute 0.38% increase in production-traffic refusals and a 23.7% inference overhead. Our work demonstrates that defending against universal jailbreaks while maintaining practical deployment viability is tractable."
    },
    "2501.17299v1": {
      "title": "\"Ownership, Not Just Happy Talk\": Co-Designing a Participatory Large Language Model for Journalism",
      "url": "http://arxiv.org/abs/2501.17299v1",
      "authors": "Emily Tseng, Meg Young, Marianne Aubin Le Qu\u00e9r\u00e9, Aimee Rinehart, Harini Suresh",
      "update_time": "2025-01-28",
      "abstract": "Journalism has emerged as an essential domain for understanding the uses, limitations, and impacts of large language models (LLMs) in the workplace. News organizations face divergent financial incentives: LLMs already permeate newswork processes within financially constrained organizations, even as ongoing legal challenges assert that AI companies violate their copyright. At stake are key questions about what LLMs are created to do, and by whom: How might a journalist-led LLM work, and what can participatory design illuminate about the present-day challenges about adapting ``one-size-fits-all'' foundation models to a given context of use? In this paper, we undertake a co-design exploration to understand how a participatory approach to LLMs might address opportunities and challenges around AI in journalism. Our 20 interviews with reporters, data journalists, editors, labor organizers, product leads, and executives highlight macro, meso, and micro tensions that designing for this opportunity space must address. From these desiderata, we describe the result of our co-design work: organizational structures and functionality for a journalist-controlled LLM. In closing, we discuss the limitations of commercial foundation models for workplace use, and the methodological implications of applying participatory methods to LLM co-design."
    },
    "2501.15664v1": {
      "title": "The Advanced Muon Facility: a proposed multi-purpose muon facility at Fermilab",
      "url": "http://arxiv.org/abs/2501.15664v1",
      "authors": "Sophie Middleton",
      "update_time": "2025-01-26",
      "abstract": "Charged lepton flavor violation (CLFV) is expected in a diverse set of new physics scenarios. The current generation of experiments probe CLFV in the muon sector in three complementary channels: $\\mu^-N \\rightarrow e^- N$ (Mu2e, COMET), $\\mu^+ \\rightarrow e^+ \\gamma$ (MEG-II), and $\\mu^+ \\rightarrow e^+e^+e^-$s (Mu3e). These experiments aim to enhance existing limits by several orders-of-magnitude in the coming decade and offer discovery potential to many new physics models. The proposed Advanced Muon Facility (AMF) would be a multi-purpose muon facility based at Fermilab and introduces an innovative approach based on a muon storage ring to enable a full suite of muon CLFV experiments. AMF would host CLFV experiments with sensitivities orders-of-magnitude beyond the present era. In the event of a signal in these currently planned experiments, AMF would enable additional measurements to elucidate the nature of the new physics observed. The design and R$\\&$D for AMF is in its infancy. This article outlines the motivations for AMF, detailing on-going R$\\&$D efforts, and highlighting potential synergies with the proposed muon collider."
    },
    "2501.15322v2": {
      "title": "Scaling laws for decoding images from brain activity",
      "url": "http://arxiv.org/abs/2501.15322v2",
      "authors": "Hubert Banville, Yohann Benchetrit, St\u00e9phane d'Ascoli, J\u00e9r\u00e9my Rapin, Jean-R\u00e9mi King",
      "update_time": "2025-01-28",
      "abstract": "Generative AI has recently propelled the decoding of images from brain activity. How do these approaches scale with the amount and type of neural recordings? Here, we systematically compare image decoding from four types of non-invasive devices: electroencephalography (EEG), magnetoencephalography (MEG), high-field functional Magnetic Resonance Imaging (3T fMRI) and ultra-high field (7T) fMRI. For this, we evaluate decoding models on the largest benchmark to date, encompassing 8 public datasets, 84 volunteers, 498 hours of brain recording and 2.3 million brain responses to natural images. Unlike previous work, we focus on single-trial decoding performance to simulate real-time settings. This systematic comparison reveals three main findings. First, the most precise neuroimaging devices tend to yield the best decoding performances, when the size of the training sets are similar. However, the gain enabled by deep learning - in comparison to linear models - is obtained with the noisiest devices. Second, we do not observe any plateau of decoding performance as the amount of training data increases. Rather, decoding performance scales log-linearly with the amount of brain recording. Third, this scaling law primarily depends on the amount of data per subject. However, little decoding gain is observed by increasing the number of subjects. Overall, these findings delineate the path most suitable to scale the decoding of images from non-invasive brain recordings."
    },
    "2501.12184v1": {
      "title": "Probing Type II Seesaw Leptogenesis Through Lepton Flavor Violation",
      "url": "http://arxiv.org/abs/2501.12184v1",
      "authors": "Chengcheng Han, Yijun Han, Sihui Huang, Zhanhong Lei",
      "update_time": "2025-01-21",
      "abstract": "Lepton flavor violation (LFV) offers a powerful probe of physics beyond the Standard Model, particularly in models addressing neutrino masses and the baryon asymmetry of the universe. In this study, we investigate LFV processes within the framework of type II seesaw leptogenesis, where the Standard Model is extended by an $SU(2)_L$ triplet Higgs field. We focus on key LFV processes including $\\mu^+\\to e^+\\gamma$, $\\mu^+ \\to e^+e^-e^+$, and $\\mu \\rightarrow e$ conversion in nuclei, deriving stringent constraints on the parameter space from current experimental data. We scan the 3$\\sigma$ range of neutrino oscillation parameters and identify the most conservative bounds consistent with existing measurements. Our results reveal that the MEG experiment currently provides the strongest constraints in the normal ordering (NO) scenario, while the SINDRUM experiment offers comparable sensitivity in the inverted ordering (IO) case. Future experiments, such as MEG II, Mu3e, Mu2e, and COMET, are predicted to significantly improve the sensitivity, testing larger regions of the parameter space. This work underscores the crucial role of LFV experiments in probing type II seesaw leptogenesis, providing an avenue to explore the connections between neutrino mass generation, baryogenesis, and inflation at experimentally accessible energy scales."
    },
    "2501.11566v1": {
      "title": "Artificial Neural Networks for Magnetoencephalography: A review of an emerging field",
      "url": "http://arxiv.org/abs/2501.11566v1",
      "authors": "Arthur Dehgan, Hamza Abdelhedi, Vanessa Hadid, Irina Rish, Karim Jerbi",
      "update_time": "2025-01-20",
      "abstract": "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that measures the intricate brain dynamics underlying cognitive processes with an unparalleled combination of high temporal and spatial precision. MEG data analytics has always relied on advanced signal processing and mathematical and statistical tools for various tasks ranging from data cleaning to probing the signals' rich dynamics and estimating the neural sources underlying the surface-level recordings. Like in most domains, the surge in Artificial Intelligence (AI) has led to the increased use of Machine Learning (ML) methods for MEG data classification. More recently, an emerging trend in this field is using Artificial Neural Networks (ANNs) to address many MEG-related tasks. This review provides a comprehensive overview of how ANNs are being used with MEG data from three vantage points: First, we review work that employs ANNs for MEG signal classification, i.e., for brain decoding. Second, we report on work that has used ANNs as putative models of information processing in the human brain. Finally, we examine studies that use ANNs as techniques to tackle methodological questions in MEG, including artifact correction and source estimation. Furthermore, we assess the current strengths and limitations of using ANNs with MEG and discuss future challenges and opportunities in this field. Finally, by establishing a detailed portrait of the field and providing practical recommendations for the future, this review seeks to provide a helpful reference for both seasoned MEG researchers and newcomers to the field who are interested in using ANNs to enhance the exploration of the complex dynamics of the human brain with MEG."
    },
    "2501.07426v1": {
      "title": "MVICAD2: Multi-View Independent Component Analysis with Delays and Dilations",
      "url": "http://arxiv.org/abs/2501.07426v1",
      "authors": "Ambroise Heurtebise, Omar Chehab, Pierre Ablin, Alexandre Gramfort",
      "update_time": "2025-01-13",
      "abstract": "Machine learning techniques in multi-view settings face significant challenges, particularly when integrating heterogeneous data, aligning feature spaces, and managing view-specific biases. These issues are prominent in neuroscience, where data from multiple subjects exposed to the same stimuli are analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG), where signals are captured at the scalp level, estimating the brain's underlying sources is crucial, especially in group studies where sources are assumed to be similar for all subjects. Common methods, such as Multi-View Independent Component Analysis (MVICA), assume identical sources across subjects, but this assumption is often too restrictive due to individual variability and age-related changes. Multi-View Independent Component Analysis with Delays (MVICAD) addresses this by allowing sources to differ up to a temporal delay. However, temporal dilation effects, particularly in auditory stimuli, are common in brain dynamics, making the estimation of time delays alone insufficient. To address this, we propose Multi-View Independent Component Analysis with Delays and Dilations (MVICAD2), which allows sources to differ across subjects in both temporal delays and dilations. We present a model with identifiable sources, derive an approximation of its likelihood in closed form, and use regularization and optimization techniques to enhance performance. Through simulations, we demonstrate that MVICAD2 outperforms existing multi-view ICA methods. We further validate its effectiveness using the Cam-CAN dataset, and showing how delays and dilations are related to aging.",
      "code_url": "https://github.com/ambroiseheurtebise/mvicad"
    },
    "2501.07394v2": {
      "title": "Exploring the distribution of connectivity weights in resting-state EEG networks",
      "url": "http://arxiv.org/abs/2501.07394v2",
      "authors": "Shiang Hu, Xiao Gong, Xiaolong Huang, Jie Ruan, Pedro Antonio Valdes-Sosa",
      "update_time": "2025-01-18",
      "abstract": "The resting-state brain networks (RSNs) reflects the functional connectivity patterns between brain modules, providing essential foundations for decoding intrinsic neural information within the brain. It serves as one of the primary tools for describing the spatial dynamics of the brain using various neuroimaging techniques, such as electroencephalography (EEG) and magnetoencephalography (MEG). However, the distribution rules or potential modes of functional connectivity weights in the resting state remain unclear. In this context, we first start from simulation, using forward solving model to generate scalp EEG with four channel densities (19, 32, 64, 128). Subsequently, we construct scalp brain networks using five coupling measures, aiming to explore whether different channel density or coupling measures affect the distribution pattern of functional connectivity weights. Next, we quantify the distribution pattern by calculating the skewness, kurtosis, and Shannon entropy of the functional connectivity network weights. Finally, the results of the simulation were validated in a normative database. We observed that: 1) The functional connection weights exhibit a right-skewed distribution, and are not influenced by channel density or coupling measures; 2) The functional connection weights exhibit a relatively uniform distribution, with the potential for volume conduction to affect the degree of uniformity in the distribution; 3) Networks constructed using coupling measures influenced by volume conduction exhibit significant correlations between the average connection weight and measures of skewness, kurtosis, and Shannon entropy. This study contributes to a deeper understanding of RSNs, providing valuable insights for research in the field of neuroscience, and holds promise for being associated with brain cognition and disease diagnosis."
    },
    "2501.05507v1": {
      "title": "On the Atomki nuclear anomaly after the MEG-II result",
      "url": "http://arxiv.org/abs/2501.05507v1",
      "authors": "Daniele Barducci, Davide Germani, Marco Nardecchia, Stefano Scacco, Claudio Toni",
      "update_time": "2025-01-09",
      "abstract": "Recent experimental results from the Atomki collaboration have reported the observation of anomalous effects in Beryllium, Helium and Carbon nuclear transitions that could hint at physics beyond the Standard Model. However, the MEG-II experiment has recently found no significant anomalous signal in the Beryllium transition ${^8}\\text{Be}^\\star\\to{^8}\\text{Be}+e^+e^-$. In view of this result, we critically re-examine the possible theoretical interpretations of the anomalies observed by the Atomki experiment in terms of a new boson $X$ with mass around $17\\;$MeV. The present work aims to study the phenomenology of a spin-2 state and revisit the possibility of a pure CP-even scalar, which was initially dismissed due to its inability to explain the Beryllium anomalous signal. Our analysis shows that a spin-2 state is highly disfavoured by the SINDRUM constraint while a scalar boson could explain the Helium and Carbon anomalies while being compatible with other experimental constraints."
    },
    "2501.05128v2": {
      "title": "Development of the high-rate capable DLC-RPC based on the current evacuation pattern",
      "url": "http://arxiv.org/abs/2501.05128v2",
      "authors": "Masato Takahashi, Sei Ban, Weiyuan Li, Atsuhiko Ochi, Wataru Ootani, Atsushi Oya, Hiromu Suzuki, Kensuke Yamamoto",
      "update_time": "2025-01-10",
      "abstract": "The Resistive Plate Chamber using Diamond-Like Carbon electrodes (DLC-RPC) has been developed as a background tagging detector in the MEG$~$II experiment. The DLC-RPC is planned to be installed in a high-intensity and low-momentum muon beam. This detector is required to have a detection efficiency of above 90 % with four active gaps in the muon beam due to the limitation of the material budget. In such an environment, the high current flowing through the resistive electrodes causes a voltage drop, which reduces the performance of the DLC-RPC. This voltage drop can be suppressed by implementing a current evacuation pattern, though discharges are more likely to occur near the pattern. Therefore the pattern must be covered by a protection cover made of an insulator. In this study, electrode samples with the current evacuation pattern and different widths of protection cover (0.2 mm and 0.8 mm) have been produced, and their performance and stability were measured. The detection efficiency of the single-gap for $\\beta$-ray from a $^{90}$Sr source was measured to be up to approximately 60 % in both electrode samples. The target efficiency can be achieved even with a drop of 100 $-$ 150 V. On the other hand, after more than a dozen hours of operation, discharges suddenly occurred and the detector was prevented from further operation. These discharges created current paths on the spacing pillars. This serious problem must be investigated and solved in the future."
    }
  },
  "neuroAI": {
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": "https://github.com/henri-edinb/async_learning"
    },
    "2411.18526v1": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v1",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias",
      "update_time": "2024-11-27",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety."
    },
    "2411.14633v1": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v1",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2024-11-21",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research."
    },
    "2410.19315v1": {
      "title": "A prescriptive theory for brain-like inference",
      "url": "http://arxiv.org/abs/2410.19315v1",
      "authors": "Hadi Vafaii, Dekel Galor, Jacob L. Yates",
      "update_time": "2024-10-25",
      "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI."
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."
    },
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2302.07243v4": {
      "title": "A Deep Probabilistic Spatiotemporal Framework for Dynamic Graph Representation Learning with Application to Brain Disorder Identification",
      "url": "http://arxiv.org/abs/2302.07243v4",
      "authors": "Sin-Yee Yap, Junn Yong Loo, Chee-Ming Ting, Fuad Noman, Raphael C. -W. Phan, Adeel Razi, David L. Dowe",
      "update_time": "2024-11-09",
      "abstract": "Recent applications of pattern recognition techniques on brain connectome classification using functional connectivity (FC) are shifting towards acknowledging the non-Euclidean topology and dynamic aspects of brain connectivity across time. In this paper, a deep spatiotemporal variational Bayes (DSVB) framework is proposed to learn time-varying topological structures in dynamic FC networks for identifying autism spectrum disorder (ASD) in human participants. The framework incorporates a spatial-aware recurrent neural network with an attention-based message passing scheme to capture rich spatiotemporal patterns across dynamic FC networks. To overcome model overfitting on limited training datasets, an adversarial training strategy is introduced to learn graph embedding models that generalize well to unseen brain networks. Evaluation on the ABIDE resting-state functional magnetic resonance imaging dataset shows that our proposed framework substantially outperforms state-of-the-art methods in identifying patients with ASD. Dynamic FC analyses with DSVB-learned embeddings reveal apparent group differences between ASD and healthy controls in brain network connectivity patterns and switching dynamics of brain states. The code is available at https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes.",
      "code_url": "https://github.com/Monash-NeuroAI/Deep-Spatiotemporal-Variational-Bayes"
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    }
  },
  "medical": {
    "2501.19381v1": {
      "title": "Using gradient of Lagrangian function to compute efficient channels for the ideal observer",
      "url": "http://arxiv.org/abs/2501.19381v1",
      "authors": "Weimin Zhou",
      "update_time": "2025-01-31",
      "abstract": "It is widely accepted that the Bayesian ideal observer (IO) should be used to guide the objective assessment and optimization of medical imaging systems. The IO employs complete task-specific information to compute test statistics for making inference decisions and performs optimally in signal detection tasks. However, the IO test statistic typically depends non-linearly on the image data and cannot be analytically determined. The ideal linear observer, known as the Hotelling observer (HO), can sometimes be used as a surrogate for the IO. However, when image data are high dimensional, HO computation can be difficult. Efficient channels that can extract task-relevant features have been investigated to reduce the dimensionality of image data to approximate IO and HO performance. This work proposes a novel method for generating efficient channels by use of the gradient of a Lagrangian-based loss function that was designed to learn the HO. The generated channels are referred to as the Lagrangian-gradient (L-grad) channels. Numerical studies are conducted that consider binary signal detection tasks involving various backgrounds and signals. It is demonstrated that channelized HO (CHO) using L-grad channels can produce significantly better signal detection performance compared to the CHO using PLS channels. Moreover, it is shown that the proposed L-grad method can achieve significantly lower computation time compared to the PLS method."
    },
    "2501.19359v1": {
      "title": "Mechanical Properties of the Meninges: Large Language Model Assisted Systematic Review of over 25,000 Studies",
      "url": "http://arxiv.org/abs/2501.19359v1",
      "authors": "Brandon P. Chelstrom, Maciej P. Polak, Dane Morgan, Corinne R. Henak",
      "update_time": "2025-01-31",
      "abstract": "Accurate constitutive models and corresponding mechanical property values for the meninges are important for predicting mechanical damage to brain tissue due to traumatic brain injury. The meninges are often oversimplified in current finite element (FE) head models due to their complex anatomy and spatially-variant mechanical behavior. This study performed a systematic review (SR) on the mechanical properties of each individual layer of the meninges to obtain benchmark data for FE modeling and to identify gaps in the current literature. Relevant studies were filtered through three stages: a broad initial search filter, a large language model classifier, and manual verification by a human reviewer. Out of over 25,000 studies initially considered, this review ultimately included 47 studies on the dura mater, 8 on the arachnoid mater, and 7 on the pia mater, representing the largest and most comprehensive SR on the mechanical properties of the meninges. Each layer was found to exhibit nonlinear rate dependence that varies with species, age, location, and orientation. This study revealed that the elastic modulus of pia mater most often used in simplified linear elastic FE models is likely underestimated by an order of magnitude and fails to consider directional dependence. Future studies investigating the mechanical properties of the meninges should focus on a wider range of loading rates as well as age effects for the arachnoid mater and pia mater, as these features are relatively understudied and expected to affect the fidelity of FE predictions."
    },
    "2501.19343v1": {
      "title": "Effect of a new type of healthy and live food supplement on osteoporosis blood parameters and induced rheumatoid arthritis in Wistar rats",
      "url": "http://arxiv.org/abs/2501.19343v1",
      "authors": "Azam Bayat, Aref Khalkhali, Ali Reza Mahjoub",
      "update_time": "2025-01-31",
      "abstract": "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in bone strength and puts the individual at risk for fracture. On the other hand, rheumatoid arthritis is a systemic disease of unknown etiology that causes inflammation of the joints of the organs. Purpose Due to the destructive effects of these diseases and its increasing prevalence and lack of appropriate medication for treatment, the present study aimed to evaluate the therapeutic effect of a new type of healthy and live food supplement on rheumatoid arthritis and induced osteoporosis in rats. Methods In this research, healthy and live food powder were synthesized by a new and green route. This organic biomaterial was named NBS. The NBS food supplement had various vitamins, macro and micro molecules, and ingredients. The new healthy and nutritious diet showed that the use of this supplement led to the return of the parameters to normal levels. Results The concentration of 12.5 mg/ kg showed the least therapeutic effect and 50 mg/ kg had the highest therapeutic effect for osteoporosis. The results of blood parameters involved in inflammation in both healthy and patient groups showed that the use of complete adjuvant induction causes joint inflammation. In the study of the interaction of the concentrations, it was observed that the concentration of 50 mg/ kg had the highest therapeutic effect against the disease in the studied mice. Conclusion The results showed that the new healthy and viable supplement restores the blood osteoporotic and rheumatoid factors of the mice to normal."
    },
    "2501.19265v1": {
      "title": "Medical Semantic Segmentation with Diffusion Pretrain",
      "url": "http://arxiv.org/abs/2501.19265v1",
      "authors": "David Li, Anvar Kurmukov, Mikhail Goncharov, Roman Sokolov, Mikhail Belyaev",
      "update_time": "2025-01-31",
      "abstract": "Recent advances in deep learning have shown that learning robust feature representations is critical for the success of many computer vision tasks, including medical image segmentation. In particular, both transformer and convolutional-based architectures have benefit from leveraging pretext tasks for pretraining. However, the adoption of pretext tasks in 3D medical imaging has been less explored and remains a challenge, especially in the context of learning generalizable feature representations.   We propose a novel pretraining strategy using diffusion models with anatomical guidance, tailored to the intricacies of 3D medical image data. We introduce an auxiliary diffusion process to pretrain a model that produce generalizable feature representations, useful for a variety of downstream segmentation tasks. We employ an additional model that predicts 3D universal body-part coordinates, providing guidance during the diffusion process and improving spatial awareness in generated representations. This approach not only aids in resolving localization inaccuracies but also enriches the model's ability to understand complex anatomical structures.   Empirical validation on a 13-class organ segmentation task demonstrate the effectiveness of our pretraining technique. It surpasses existing restorative pretraining methods in 3D medical image segmentation by $7.5\\%$, and is competitive with the state-of-the-art contrastive pretraining approach, achieving an average Dice coefficient of 67.8 in a non-linear evaluation scenario."
    },
    "2501.19246v1": {
      "title": "Computational Assessment of Hemodynamics in Asymmetric-type Lesion of Idealized Coronary Stenoses",
      "url": "http://arxiv.org/abs/2501.19246v1",
      "authors": "Ayodele Oyejide, Oluwatosin Abodunrin, Ebenezer Ige, Adetokunbo Awonusi",
      "update_time": "2025-01-31",
      "abstract": "Coronary artery stenosis, characterized by the narrowing of the lumen, significantly affects blood flow and contributes to the progression of cardiovascular diseases. This study investigates the hemodynamics of coronary artery models with varying stenosis configurations, all maintaining an 80% lumen reduction, to determine how differences in morphology influence flow behavior and mechanical stresses. We employed computational fluid dynamics to analyze five idealized geometries with (10% & 70%), (20% & 60%), (30% & 50%), (40% & 40%), and (0% & 80%) stenosis configurations. Through physiological pulsatile flow conditions, we evaluated key hemodynamic pattern including velocity profiles, wall shear stress, and pressure distribution. Our results reveal that despite the same degree of lumen reduction, each stenosis configuration produced distinct flow patterns and hemodynamic profiles. Asymmetric configurations, such as 10% & 70% and 20% & 60%, exhibited pronounced flow disruptions and higher wall shear stress at the stenosis throats, while symmetric configurations, such as 40% & 40%, demonstrated more uniform flow and reduced vortex. Our findings challenge the practice of generalizing results across stenosis configurations without accounting for morphological variations, which is prevalent in many CFD studies using idealized models. This study emphasizes the importance of considering stenosis-specific morphology in CFD analyses and clinical interpretations to enhance the accuracy of diagnostic tools, improve personalized treatment planning, and guide the design of medical devices such as stents."
    },
    "2501.19097v1": {
      "title": "Analysis of the sensitivity of tumor control probability in molecular radiotherapy to uncertainties in the dose rate curves",
      "url": "http://arxiv.org/abs/2501.19097v1",
      "authors": "Pedro Otero-Casal, Ald\u00e1n Bali\u00f1o, Sara Neira, Faustino G\u00f3mez, Juan Pardo-Montero",
      "update_time": "2025-01-31",
      "abstract": "In this work, we have investigated the sensitivity of the effectiveness (TCP) of molecular radiotherapy (MRT) treatment to uncertainties of the dose rate curves that may appear when reconstructing those curves.   We generated different dose rate curves from experimental data, imposing the constraint of equal dose for each of them. Then, we computed TCPs and looked for correlations between metrics measuring the differences between the dose rate curves and differences in TCP. Finally, according to these results, we estimated the range of tolerable uncertainties in the dose rate curves. The study was performed for different radiopharmaceuticals and different radiosensitive parameters that can affect the dose rate response ($\\alpha/\\beta$, sub-lethal repair rate).   The best correlation between differences in the dose rate curves and TCP was found for a metric that computes averaged linear differences between the curves. With this metric, we quantified differences in dose rate curves that would lead to differences in TCP of 0.02, a parameter denoted $m_{1,\\: 0.02}$ that is a surrogate of the dependence of the TCP on the dose rate profile. The results showed that the sensitivity of the TCP to dose rate variations decreases (i.e. larger values of $m_{1,\\: 0.02}$) with increasing $\\alpha/\\beta$ and sub-lethal damage repair rate of the tumor cells, and increasing biological half-life of the dose rate curves.   The radiobiological effect of a MRT treatment on a tumor depends on the absorbed dose and the dose rate profile. Ideally, both magnitudes should be measured with accuracy in order to progress towards the optimization of individualized MRT treatments. Our study suggests that this would be more important for tumors with low $\\alpha/\\beta$ and moderately slow sub-lethal damage repair treated with fast-decaying radiopharmaceuticals."
    },
    "2501.19094v1": {
      "title": "Ambient Denoising Diffusion Generative Adversarial Networks for Establishing Stochastic Object Models from Noisy Image Data",
      "url": "http://arxiv.org/abs/2501.19094v1",
      "authors": "Xichen Xu, Wentao Chen, Weimin Zhou",
      "update_time": "2025-01-31",
      "abstract": "It is widely accepted that medical imaging systems should be objectively assessed via task-based image quality (IQ) measures that ideally account for all sources of randomness in the measured image data, including the variation in the ensemble of objects to be imaged. Stochastic object models (SOMs) that can randomly draw samples from the object distribution can be employed to characterize object variability. To establish realistic SOMs for task-based IQ analysis, it is desirable to employ experimental image data. However, experimental image data acquired from medical imaging systems are subject to measurement noise. Previous work investigated the ability of deep generative models (DGMs) that employ an augmented generative adversarial network (GAN), AmbientGAN, for establishing SOMs from noisy measured image data. Recently, denoising diffusion models (DDMs) have emerged as a leading DGM for image synthesis and can produce superior image quality than GANs. However, original DDMs possess a slow image-generation process because of the Gaussian assumption in the denoising steps. More recently, denoising diffusion GAN (DDGAN) was proposed to permit fast image generation while maintain high generated image quality that is comparable to the original DDMs. In this work, we propose an augmented DDGAN architecture, Ambient DDGAN (ADDGAN), for learning SOMs from noisy image data. Numerical studies that consider clinical computed tomography (CT) images and digital breast tomosynthesis (DBT) images are conducted. The ability of the proposed ADDGAN to learn realistic SOMs from noisy image data is demonstrated. It has been shown that the ADDGAN significantly outperforms the advanced AmbientGAN models for synthesizing high resolution medical images with complex textures."
    },
    "2501.19086v1": {
      "title": "Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification",
      "url": "http://arxiv.org/abs/2501.19086v1",
      "authors": "Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang",
      "update_time": "2025-01-31",
      "abstract": "X-ray imaging is pivotal in medical diagnostics, offering non-invasive insights into a range of health conditions. Recently, vision-language models, such as the Contrastive Language-Image Pretraining (CLIP) model, have demonstrated potential in improving diagnostic accuracy by leveraging large-scale image-text datasets. However, since CLIP was not initially designed for medical images, several CLIP-like models trained specifically on medical images have been developed. Despite their enhanced performance, issues of fairness - particularly regarding demographic attributes - remain largely unaddressed. In this study, we perform a comprehensive fairness analysis of CLIP-like models applied to X-ray image classification. We assess their performance and fairness across diverse patient demographics and disease categories using zero-shot inference and various fine-tuning techniques, including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation (LoRA), and full fine-tuning. Our results indicate that while fine-tuning improves model accuracy, fairness concerns persist, highlighting the need for further fairness interventions in these foundational models."
    },
    "2501.19005v1": {
      "title": "Assessing Sensitivity of Brain-to-Scalp Blood Flows in Laser Speckle Imaging by Occluding the Superficial Temporal Artery",
      "url": "http://arxiv.org/abs/2501.19005v1",
      "authors": "Yu Xi Huang, Simon Mahler, Maya Dickson, Aidin Abedi, Yu Tung Lo, Patrick D. Lyden, Jonathan Russin, Charles Liu, Changhuei Yang",
      "update_time": "2025-01-31",
      "abstract": "Cerebral blood flow is a critical metric for cerebrovascular monitoring, with applications in stroke detection, brain injury evaluation, aging, and neurological disorders. Non-invasively measuring cerebral blood dynamics is challenging due to the scalp and skull, which obstruct direct brain access and contain their own blood dynamics that must be isolated. We developed an aggregated seven-channel speckle contrast optical spectroscopy system to measure blood flow and blood volume non-invasively. Each channel, with distinct source-to-detector distance, targeted different depths to detect scalp and brain blood dynamics separately. By briefly occluding the superficial temporal artery, which supplies blood only to the scalp, we isolated surface blood dynamics from brain signals. Results on 20 subjects show that scalp-sensitive channels experienced significant reductions in blood dynamics during occlusion, while brain-sensitive channels experienced minimal changes. This provides experimental evidence of brain-to-scalp sensitivity in optical measurements, highlighting optimal configuration for preferentially probing brain signals non-invasively."
    },
    "2501.18929v1": {
      "title": "Training-free Quantum-Inspired Image Edge Extraction Method",
      "url": "http://arxiv.org/abs/2501.18929v1",
      "authors": "Arti Jain, Pradeep Singh",
      "update_time": "2025-01-31",
      "abstract": "Edge detection is a cornerstone of image processing, yet existing methods often face critical limitations. Traditional deep learning edge detection methods require extensive training datasets and fine-tuning, while classical techniques often fail in complex or noisy scenarios, limiting their real-world applicability. To address these limitations, we propose a training-free, quantum-inspired edge detection model. Our approach integrates classical Sobel edge detection, the Schr\\\"odinger wave equation refinement, and a hybrid framework combining Canny and Laplacian operators. By eliminating the need for training, the model is lightweight and adaptable to diverse applications. The Schr\\\"odinger wave equation refines gradient-based edge maps through iterative diffusion, significantly enhancing edge precision. The hybrid framework further strengthens the model by synergistically combining local and global features, ensuring robustness even under challenging conditions. Extensive evaluations on datasets like BIPED, Multicue, and NYUD demonstrate superior performance of the proposed model, achieving state-of-the-art metrics, including ODS, OIS, AP, and F-measure. Noise robustness experiments highlight its reliability, showcasing its practicality for real-world scenarios. Due to its versatile and adaptable nature, our model is well-suited for applications such as medical imaging, autonomous systems, and environmental monitoring, setting a new benchmark for edge detection."
    }
  }
}