{
  "Brain": {
    "2510.11221v1": {
      "title": "WebRouter: Query-specific Router via Variational Information Bottleneck for Cost-sensitive Web Agent",
      "url": "http://arxiv.org/abs/2510.11221v1",
      "authors": "Tao Li, Jinlong Hu, Yang Wang, Junfeng Liu, Xuejun Liu",
      "update_time": "2025-10-13",
      "abstract": "LLM-brained web agents offer powerful capabilities for web automation but face a critical cost-performance trade-off. The challenge is amplified by web agents' inherently complex prompts that include goals, action histories, and environmental states, leading to degraded LLM ensemble performance. To address this, we introduce WebRouter, a novel query-specific router trained from an information-theoretic perspective. Our core contribution is a cost-aware Variational Information Bottleneck (ca-VIB) objective, which learns a compressed representation of the input prompt while explicitly penalizing the expected operational cost. Experiments on five real-world websites from the WebVoyager benchmark show that WebRouter reduces operational costs by a striking 87.8\\% compared to a GPT-4o baseline, while incurring only a 3.8\\% accuracy drop.",
      "code_url": null
    },
    "2510.10872v1": {
      "title": "FeNOMS: Enhancing Open Modification Spectral Library Search with In-Storage Processing on Ferroelectric NAND (FeNAND) Flash",
      "url": "http://arxiv.org/abs/2510.10872v1",
      "authors": "Sumukh Pinge, Ashkan Moradifirouzabadi, Keming Fan, Prasanna Venkatesan Ravindran, Tanvir H. Pantha, Po-Kai Hsu, Zheyu Li, Weihong Xu, Zihan Xia, Flavio Ponzina, Winston Chern, Taeyoung Song, Priyankka Ravikumar, Mengkun Tian, Lance Fernandes, Huy Tran, Hari Jayasankar, Hang Chen, Chinsung Park, Amrit Garlapati, Kijoon Kim, Jongho Woo, Suhwan Lim, Kwangsoo Kim, Wanki Kim, Daewon Ha, Duygu Kuzum, Shimeng Yu, Sourav Dutta, Asif Khan, Tajana Rosing, Mingu Kang",
      "update_time": "2025-10-13",
      "abstract": "The rapid expansion of mass spectrometry (MS) data, now exceeding hundreds of terabytes, poses significant challenges for efficient, large-scale library search - a critical component for drug discovery. Traditional processors struggle to handle this data volume efficiently, making in-storage computing (ISP) a promising alternative. This work introduces an ISP architecture leveraging a 3D Ferroelectric NAND (FeNAND) structure, providing significantly higher density, faster speeds, and lower voltage requirements compared to traditional NAND flash. Despite its superior density, the NAND structure has not been widely utilized in ISP applications due to limited throughput associated with row-by-row reads from serially connected cells. To overcome these limitations, we integrate hyperdimensional computing (HDC), a brain-inspired paradigm that enables highly parallel processing with simple operations and strong error tolerance. By combining HDC with the proposed dual-bound approximate matching (D-BAM) distance metric, tailored to the FeNAND structure, we parallelize vector computations to enable efficient MS spectral library search, achieving 43x speedup and 21x higher energy efficiency over state-of-the-art 3D NAND methods, while maintaining comparable accuracy.",
      "code_url": null
    },
    "2510.10791v1": {
      "title": "A compressed code for memory discrimination",
      "url": "http://arxiv.org/abs/2510.10791v1",
      "authors": "Dale Zhou, Sharon Mina Noh, Nora C Harhen, Nidhi V Banavar, C. Brock Kirwan, Michael A Yassa, Aaron M Bornstein",
      "update_time": "2025-10-12",
      "abstract": "The ability to discriminate similar visual stimuli is an important index of memory function. This ability is widely thought to be supported by expanding the dimensionality of relevant neural codes, such that neural representations for similar stimuli are maximally distinct, or ``separated.'' An alternative hypothesis is that discrimination is supported by lossy compression of visual inputs, efficiently coding sensory information by discarding seemingly irrelevant details. A benefit of compression, relative to expansion, is that it allows individuals to retain fewer essential dimensions underlying stimulus variation -- a process linked to higher-order visual processing -- without hindering discrimination. Under this hypothesis, pattern separation is facilitated when more information from similar stimuli can be discarded, rather than preserved. We test the compression versus expansion hypotheses by predicting performance on the canonical mnemonic similarity task. We train neural networks to compress perceptual and semantic factors of stimuli, measuring lossiness using the mathematical framework underlying compression. Consistent with the compression hypothesis, and not the expansion hypothesis, greater lossiness predicts the ease and performance of lure discrimination, especially in deeper convolutional network layers that predict higher-order visual brain activity. We then confirm these predictions across two image sets, four behavioral datasets, and alternative lossiness metrics. Finally, using task fMRI, we identify signatures of lossy compression -- neural dimensionality reduction and information loss -- in higher-order visual regions V4 and IT and hippocampal DG/CA3 and CA1 linked to lure discrimination. These results suggest lossy compression supports mnemonic discrimination by discarding redundant and overlapping information.",
      "code_url": null
    },
    "2510.10777v1": {
      "title": "Preconditioned Norms: A Unified Framework for Steepest Descent, Quasi-Newton and Adaptive Methods",
      "url": "http://arxiv.org/abs/2510.10777v1",
      "authors": "Andrey Veprikov, Arman Bolatov, Samuel Horv\u00e1th, Aleksandr Beznosikov, Martin Tak\u00e1\u010d, Slavomir Hanzely",
      "update_time": "2025-10-12",
      "abstract": "Optimization lies at the core of modern deep learning, yet existing methods often face a fundamental trade-off between adapting to problem geometry and leveraging curvature utilization. Steepest descent algorithms adapt to different geometries through norm choices but remain strictly first-order, whereas quasi-Newton and adaptive optimizers incorporate curvature information but are restricted to Frobenius geometry, limiting their applicability across diverse architectures. In this work, we propose a unified framework generalizing steepest descent, quasi-Newton methods, and adaptive methods through the novel notion of preconditioned matrix norms. This abstraction reveals that widely used optimizers such as SGD and Adam, as well as more advanced approaches like Muon and KL-Shampoo, and recent hybrids including SOAP and SPlus, all emerge as special cases of the same principle. Within this framework, we provide the first systematic treatment of affine and scale invariance in the matrix-parameterized setting, establishing necessary and sufficient conditions under generalized norms. Building on this foundation, we introduce two new methods, $\\texttt{MuAdam}$ and $\\texttt{MuAdam-SANIA}$, which combine the spectral geometry of Muon with Adam-style preconditioning. Our experiments demonstrate that these optimizers are competitive with, and in some cases outperform, existing state-of-the-art methods. Our code is available at https://github.com/brain-lab-research/LIB/tree/quasi_descent",
      "code_url": null
    },
    "2510.10770v1": {
      "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source Localization and BCI Accuracy",
      "url": "http://arxiv.org/abs/2510.10770v1",
      "authors": "Eva Guttmann-Flury, Yanyan Wei, Shan Zhao, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.",
      "code_url": null
    },
    "2510.10733v1": {
      "title": "Does Re-referencing Matter? Large Laplacian Filter Optimizes Single-Trial P300 BCI Performance",
      "url": "http://arxiv.org/abs/2510.10733v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation.",
      "code_url": null
    },
    "2510.10679v1": {
      "title": "MSM-Seg: A Modality-and-Slice Memory Framework with Category-Agnostic Prompting for Multi-Modal Brain Tumor Segmentation",
      "url": "http://arxiv.org/abs/2510.10679v1",
      "authors": "Yuxiang Luo, Qing Xu, Hai Huang, Yuqi Ouyang, Zhen Chen, Wenting Duan",
      "update_time": "2025-10-12",
      "abstract": "Multi-modal brain tumor segmentation is critical for clinical diagnosis, and it requires accurate identification of distinct internal anatomical subregions. While the recent prompt-based segmentation paradigms enable interactive experiences for clinicians, existing methods ignore cross-modal correlations and rely on labor-intensive category-specific prompts, limiting their applicability in real-world scenarios. To address these issues, we propose a MSM-Seg framework for multi-modal brain tumor segmentation. The MSM-Seg introduces a novel dual-memory segmentation paradigm that synergistically integrates multi-modal and inter-slice information with the efficient category-agnostic prompt for brain tumor understanding. To this end, we first devise a modality-and-slice memory attention (MSMA) to exploit the cross-modal and inter-slice relationships among the input scans. Then, we propose a multi-scale category-agnostic prompt encoder (MCP-Encoder) to provide tumor region guidance for decoding. Moreover, we devise a modality-adaptive fusion decoder (MF-Decoder) that leverages the complementary decoding information across different modalities to improve segmentation accuracy. Extensive experiments on different MRI datasets demonstrate that our MSM-Seg framework outperforms state-of-the-art methods in multi-modal metastases and glioma tumor segmentation. The code is available at https://github.com/xq141839/MSM-Seg.",
      "code_url": null
    },
    "2510.10604v1": {
      "title": "FusionGen: Feature Fusion-Based Few-Shot EEG Data Generation",
      "url": "http://arxiv.org/abs/2510.10604v1",
      "authors": "Yuheng Chen, Dingkun Liu, Xinyao Yang, Xinping Xu, Baicheng Chen, Dongrui Wu",
      "update_time": "2025-10-12",
      "abstract": "Brain-computer interfaces (BCIs) provide potential for applications ranging from medical rehabilitation to cognitive state assessment by establishing direct communication pathways between the brain and external devices via electroencephalography (EEG). However, EEG-based BCIs are severely constrained by data scarcity and significant inter-subject variability, which hinder the generalization and applicability of EEG decoding models in practical settings. To address these challenges, we propose FusionGen, a novel EEG data generation framework based on disentangled representation learning and feature fusion. By integrating features across trials through a feature matching fusion module and combining them with a lightweight feature extraction and reconstruction pipeline, FusionGen ensures both data diversity and trainability under limited data constraints. Extensive experiments on multiple publicly available EEG datasets demonstrate that FusionGen significantly outperforms existing augmentation techniques, yielding notable improvements in classification accuracy.",
      "code_url": null
    },
    "2510.10521v1": {
      "title": "A ferroelectric junction transistor memory made from switchable van der Waals p-n heterojunctions",
      "url": "http://arxiv.org/abs/2510.10521v1",
      "authors": "Baoyu Wang, Lingrui Zou, Tao Wang, Lijun Xu, Zexin Dong, Xin He, Shangui Lan, Yinchang Ma, Meng Tang, Maolin Chen, Chen Liu, Zhengdong Luo, Lijie Zhang, Zhenhua Wu, Yan Liu, Genquan Han, Bin Yu, Xixiang Zhang, Fei Xue, Kai Chang",
      "update_time": "2025-10-12",
      "abstract": "Van der Waals (vdW) p-n heterojunctions are important building blocks for advanced electronics and optoelectronics, in which high-quality heterojunctions essentially determine device performances or functionalities. Creating tunable depletion regions with substantially suppressed leakage currents presents huge challenges, but is crucial for heterojunction applications. Here, by using band-aligned p-type SnSe and n-type ferroelectric {\\alpha}-In2Se3 as a model, we report near-ideal multifunctional vdW p-n heterojunctions with small reverse leakage currents (0.1 pA) and a desired diode ideality factor (1.95). As-fabricated junction transistors exhibit superior performance, such as a high on/off ratio of over 105. Importantly, we realize ferroelectric-tuned band alignment with a giant barrier modulation of 900 meV. Based on such tunable heterojunctions, we propose and demonstrate a fundamental different device termed ferroelectric junction field-effect transistor memory, which shows large memory windows (1.8 V), ultrafast speed (100 ns), high operation temperature (393 K), and low cycle-to-cycle variation (2 %). Additionally, the reliable synaptic characteristics of these memory devices promise low-power neuromorphic computing. Our work provides a new device platform with switchable memory heterojunctions, applicable to high performance brain-inspired electronics and optoelectronics.",
      "code_url": null
    },
    "2510.10308v1": {
      "title": "Artificial intelligence as a surrogate brain: Bridging neural dynamical models and data",
      "url": "http://arxiv.org/abs/2510.10308v1",
      "authors": "Yinuo Zhang, Demao Liu, Zhichao Liang, Jiani Cheng, Kexin Lou, Jinqiao Duan, Ting Gao, Bin Hu, Quanying Liu",
      "update_time": "2025-10-11",
      "abstract": "Recent breakthroughs in artificial intelligence (AI) are reshaping the way we construct computational counterparts of the brain, giving rise to a new class of ``surrogate brains''. In contrast to conventional hypothesis-driven biophysical models, the AI-based surrogate brain encompasses a broad spectrum of data-driven approaches to solve the inverse problem, with the primary objective of accurately predicting future whole-brain dynamics with historical data. Here, we introduce a unified framework of constructing an AI-based surrogate brain that integrates forward modeling, inverse problem solving, and model evaluation. Leveraging the expressive power of AI models and large-scale brain data, surrogate brains open a new window for decoding neural systems and forecasting complex dynamics with high dimensionality, nonlinearity, and adaptability. We highlight that the learned surrogate brain serves as a simulation platform for dynamical systems analysis, virtual perturbation, and model-guided neurostimulation. We envision that the AI-based surrogate brain will provide a functional bridge between theoretical neuroscience and translational neuroengineering.",
      "code_url": null
    }
  },
  "EEG": {
    "2510.10770v1": {
      "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source Localization and BCI Accuracy",
      "url": "http://arxiv.org/abs/2510.10770v1",
      "authors": "Eva Guttmann-Flury, Yanyan Wei, Shan Zhao, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.",
      "code_url": null
    },
    "2510.10733v1": {
      "title": "Does Re-referencing Matter? Large Laplacian Filter Optimizes Single-Trial P300 BCI Performance",
      "url": "http://arxiv.org/abs/2510.10733v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation.",
      "code_url": null
    },
    "2510.10604v1": {
      "title": "FusionGen: Feature Fusion-Based Few-Shot EEG Data Generation",
      "url": "http://arxiv.org/abs/2510.10604v1",
      "authors": "Yuheng Chen, Dingkun Liu, Xinyao Yang, Xinping Xu, Baicheng Chen, Dongrui Wu",
      "update_time": "2025-10-12",
      "abstract": "Brain-computer interfaces (BCIs) provide potential for applications ranging from medical rehabilitation to cognitive state assessment by establishing direct communication pathways between the brain and external devices via electroencephalography (EEG). However, EEG-based BCIs are severely constrained by data scarcity and significant inter-subject variability, which hinder the generalization and applicability of EEG decoding models in practical settings. To address these challenges, we propose FusionGen, a novel EEG data generation framework based on disentangled representation learning and feature fusion. By integrating features across trials through a feature matching fusion module and combining them with a lightweight feature extraction and reconstruction pipeline, FusionGen ensures both data diversity and trainability under limited data constraints. Extensive experiments on multiple publicly available EEG datasets demonstrate that FusionGen significantly outperforms existing augmentation techniques, yielding notable improvements in classification accuracy.",
      "code_url": null
    },
    "2510.10004v1": {
      "title": "Bidirectional Time-Frequency Pyramid Network for Enhanced Robust EEG Classification",
      "url": "http://arxiv.org/abs/2510.10004v1",
      "authors": "Jiahui Hong, Siqing Li, Muqing Jian, Luming Yang",
      "update_time": "2025-10-11",
      "abstract": "Existing EEG recognition models suffer from poor cross-paradigm generalization due to dataset-specific constraints and individual variability. To overcome these limitations, we propose BITE (Bidirectional Time-Freq Pyramid Network), an end-to-end unified architecture featuring robust multistream synergy, pyramid time-frequency attention (PTFA), and bidirectional adaptive convolutions. The framework uniquely integrates: 1) Aligned time-frequency streams maintaining temporal synchronization with STFT for bidirectional modeling, 2) PTFA-based multi-scale feature enhancement amplifying critical neural patterns, 3) BiTCN with learnable fusion capturing forward/backward neural dynamics. Demonstrating enhanced robustness, BITE achieves state-of-the-art performance across four divergent paradigms (BCICIV-2A/2B, HGD, SD-SSVEP), excelling in both within-subject accuracy and cross-subject generalization. As a unified architecture, it combines robust performance across both MI and SSVEP tasks with exceptional computational efficiency. Our work validates that paradigm-aligned spectral-temporal processing is essential for reliable BCI systems. Just as its name suggests, BITE \"takes a bite out of EEG.\" The source code is available at https://github.com/cindy-hong/BiteEEG.",
      "code_url": null
    },
    "2510.09477v1": {
      "title": "Efficient Autoregressive Inference for Transformer Probabilistic Models",
      "url": "http://arxiv.org/abs/2510.09477v1",
      "authors": "Conor Hassan, Nasrulloh Loka, Cen-You Li, Daolang Huang, Paul E. Chang, Yang Yang, Francesco Silvestrin, Samuel Kaski, Luigi Acerbi",
      "update_time": "2025-10-10",
      "abstract": "Transformer-based models for amortized probabilistic inference, such as neural processes, prior-fitted networks, and tabular foundation models, excel at single-pass marginal prediction. However, many real-world applications, from signal interpolation to multi-column tabular predictions, require coherent joint distributions that capture dependencies between predictions. While purely autoregressive architectures efficiently generate such distributions, they sacrifice the flexible set-conditioning that makes these models powerful for meta-learning. Conversely, the standard approach to obtain joint distributions from set-based models requires expensive re-encoding of the entire augmented conditioning set at each autoregressive step. We introduce a causal autoregressive buffer that preserves the advantages of both paradigms. Our approach decouples context encoding from updating the conditioning set. The model processes the context once and caches it. A dynamic buffer then captures target dependencies: as targets are incorporated, they enter the buffer and attend to both the cached context and previously buffered targets. This enables efficient batched autoregressive generation and one-pass joint log-likelihood evaluation. A unified training strategy allows seamless integration of set-based and autoregressive modes at minimal additional cost. Across synthetic functions, EEG signals, cognitive models, and tabular data, our method matches predictive accuracy of strong baselines while delivering up to 20 times faster joint sampling. Our approach combines the efficiency of autoregressive generative models with the representational power of set-based conditioning, making joint prediction practical for transformer-based probabilistic models.",
      "code_url": null
    },
    "2510.09242v1": {
      "title": "Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models",
      "url": "http://arxiv.org/abs/2510.09242v1",
      "authors": "Marco Siino, Giuseppe Bonomo, Rosario Sorbello, Ilenia Tinnirello",
      "update_time": "2025-10-10",
      "abstract": "The present study investigates the impact of the Rational Discrete Wavelet Transform (RDWT), used as a plug-in preprocessing step for motor imagery electroencephalographic (EEG) decoding prior to applying deep learning classifiers. A systematic paired evaluation (with/without RDWT) is conducted on four state-of-the-art deep learning architectures: EEGNet, ShallowConvNet, MBEEG\\_SENet, and EEGTCNet. This evaluation was carried out across three benchmark datasets: High Gamma, BCI-IV-2a, and BCI-IV-2b. The performance of the RDWT is reported with subject-wise averages using accuracy and Cohen's kappa, complemented by subject-level analyses to identify when RDWT is beneficial. On BCI-IV-2a, RDWT yields clear average gains for EEGTCNet (+4.44 percentage points, pp; kappa +0.059) and MBEEG\\_SENet (+2.23 pp; +0.030), with smaller improvements for EEGNet (+2.08 pp; +0.027) and ShallowConvNet (+0.58 pp; +0.008). On BCI-IV-2b, the enhancements observed are modest yet consistent for EEGNet (+0.21 pp; +0.044) and EEGTCNet (+0.28 pp; +0.077). On HGD, average effects are modest to positive, with the most significant gain observed for MBEEG\\_SENet (+1.65 pp; +0.022), followed by EEGNet (+0.76 pp; +0.010) and EEGTCNet (+0.54 pp; +0.008). Inspection of the subject material reveals significant enhancements in challenging recordings (e.g., non-stationary sessions), indicating that RDWT can mitigate localized noise and enhance rhythm-specific information. In conclusion, RDWT is shown to be a low-overhead, architecture-aware preprocessing technique that can yield tangible gains in accuracy and agreement for deep model families and challenging subjects.",
      "code_url": null
    },
    "2510.09095v1": {
      "title": "Neural Codecs as Biosignal Tokenizers",
      "url": "http://arxiv.org/abs/2510.09095v1",
      "authors": "Kleanthis Avramidis, Tiantian Feng, Woojae Jeong, Jihwan Lee, Wenhui Cui, Richard M Leahy, Shrikanth Narayanan",
      "update_time": "2025-10-10",
      "abstract": "Neurophysiological recordings such as electroencephalography (EEG) offer accessible and minimally invasive means of estimating physiological activity for applications in healthcare, diagnostic screening, and even immersive entertainment. However, these recordings yield high-dimensional, noisy time-series data that typically require extensive pre-processing and handcrafted feature extraction to reveal meaningful information. Recently, there has been a surge of interest in applying representation learning techniques from large pre-trained (foundation) models to effectively decode and interpret biosignals. We discuss the challenges posed for incorporating such methods and introduce BioCodec, an alternative representation learning framework inspired by neural codecs to capture low-level signal characteristics in the form of discrete tokens. Pre-trained on thousands of EEG hours, BioCodec shows efficacy across multiple downstream tasks, ranging from clinical diagnostic tasks and sleep physiology to decoding speech and motor imagery, particularly in low-resource settings. Additionally, we provide a qualitative analysis of codebook usage and estimate the spatial coherence of codebook embeddings from EEG connectivity. Notably, we also document the suitability of our method to other biosignal data, i.e., electromyographic (EMG) signals. Overall, the proposed approach provides a versatile solution for biosignal tokenization that performs competitively with state-of-the-art models. The source code and model checkpoints are shared.",
      "code_url": null
    },
    "2510.08984v1": {
      "title": "FedL2T: Personalized Federated Learning with Two-Teacher Distillation for Seizure Prediction",
      "url": "http://arxiv.org/abs/2510.08984v1",
      "authors": "Jionghao Lou, Jian Zhang, Zhongmei Li, Lanlan Chen, Enbo Feng",
      "update_time": "2025-10-10",
      "abstract": "The training of deep learning models in seizure prediction requires large amounts of Electroencephalogram (EEG) data. However, acquiring sufficient labeled EEG data is difficult due to annotation costs and privacy constraints. Federated Learning (FL) enables privacy-preserving collaborative training by sharing model updates instead of raw data. However, due to the inherent inter-patient variability in real-world scenarios, existing FL-based seizure prediction methods struggle to achieve robust performance under heterogeneous client settings. To address this challenge, we propose FedL2T, a personalized federated learning framework that leverages a novel two-teacher knowledge distillation strategy to generate superior personalized models for each client. Specifically, each client simultaneously learns from a globally aggregated model and a dynamically assigned peer model, promoting more direct and enriched knowledge exchange. To ensure reliable knowledge transfer, FedL2T employs an adaptive multi-level distillation strategy that aligns both prediction outputs and intermediate feature representations based on task confidence. In addition, a proximal regularization term is introduced to constrain personalized model updates, thereby enhancing training stability. Extensive experiments on two EEG datasets demonstrate that FedL2T consistently outperforms state-of-the-art FL methods, particularly under low-label conditions. Moreover, FedL2T exhibits rapid and stable convergence toward optimal performance, thereby reducing the number of communication rounds and associated overhead. These results underscore the potential of FedL2T as a reliable and personalized solution for seizure prediction in privacy-sensitive healthcare scenarios.",
      "code_url": null
    },
    "2510.08059v1": {
      "title": "Mitigating Subject Dependency in EEG Decoding with Subject-Specific Low-Rank Adapters",
      "url": "http://arxiv.org/abs/2510.08059v1",
      "authors": "Timon Klein, Piotr Minakowski, Sebastian Sager",
      "update_time": "2025-10-09",
      "abstract": "Subject-specific distribution shifts represent an important obstacle to the development of foundation models for EEG decoding. To address this, we propose Subject-Conditioned Layer,, an adaptive layer designed as a drop-in replacement for standard linear or convolutional layers in any neural network architecture. Our layer captures subject-specific variability by decomposing its weights into a shared, subject-invariant component and a lightweight, low-rank correction unique to each subject. This explicit separation of general knowledge from personalized adaptation allows existing models to become robust to subject shifts. Empirically, models equipped with our layer outperform both a shared-weight-only model (subject-agnostic model) and the average of individually trained subject-specific models. Consequently, the Subject-Conditioned Layer, offers a practical and scalable path towards building effective cross-subject foundation models for EEG.",
      "code_url": null
    },
    "2510.07960v1": {
      "title": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG",
      "url": "http://arxiv.org/abs/2510.07960v1",
      "authors": "Emilio Estevan, Mar\u00eda Sierra-Torralba, Eduardo L\u00f3pez-Larraz, Luis Montesano",
      "update_time": "2025-10-09",
      "abstract": "Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.",
      "code_url": null
    }
  },
  "BCI": {
    "2510.10770v1": {
      "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source Localization and BCI Accuracy",
      "url": "http://arxiv.org/abs/2510.10770v1",
      "authors": "Eva Guttmann-Flury, Yanyan Wei, Shan Zhao, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.",
      "code_url": null
    },
    "2510.10733v1": {
      "title": "Does Re-referencing Matter? Large Laplacian Filter Optimizes Single-Trial P300 BCI Performance",
      "url": "http://arxiv.org/abs/2510.10733v1",
      "authors": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "update_time": "2025-10-12",
      "abstract": "Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation.",
      "code_url": null
    },
    "2510.10604v1": {
      "title": "FusionGen: Feature Fusion-Based Few-Shot EEG Data Generation",
      "url": "http://arxiv.org/abs/2510.10604v1",
      "authors": "Yuheng Chen, Dingkun Liu, Xinyao Yang, Xinping Xu, Baicheng Chen, Dongrui Wu",
      "update_time": "2025-10-12",
      "abstract": "Brain-computer interfaces (BCIs) provide potential for applications ranging from medical rehabilitation to cognitive state assessment by establishing direct communication pathways between the brain and external devices via electroencephalography (EEG). However, EEG-based BCIs are severely constrained by data scarcity and significant inter-subject variability, which hinder the generalization and applicability of EEG decoding models in practical settings. To address these challenges, we propose FusionGen, a novel EEG data generation framework based on disentangled representation learning and feature fusion. By integrating features across trials through a feature matching fusion module and combining them with a lightweight feature extraction and reconstruction pipeline, FusionGen ensures both data diversity and trainability under limited data constraints. Extensive experiments on multiple publicly available EEG datasets demonstrate that FusionGen significantly outperforms existing augmentation techniques, yielding notable improvements in classification accuracy.",
      "code_url": null
    },
    "2510.10169v2": {
      "title": "BrainForm: a Serious Game for BCI Training and Data Collection",
      "url": "http://arxiv.org/abs/2510.10169v2",
      "authors": "Michele Romani, Devis Zanoni, Elisabetta Farella, Luca Turchet",
      "update_time": "2025-10-14",
      "abstract": "$\\textit{BrainForm}$ is a gamified Brain-Computer Interface (BCI) training system designed for scalable data collection using consumer hardware and a minimal setup. We investigated (1) how users develop BCI control skills across repeated sessions and (2) perceptual and performance effects of two visual stimulation textures. Game Experience Questionnaire (GEQ) scores for Flow, Positive Affect, Competence and Challenge were strongly positive, indicating sustained engagement. A within-subject study with multiple runs, two task complexities, and post-session questionnaires revealed no significant performance differences between textures but increased ocular irritation over time. Online metrics$\\unicode{x2013}$Task Accuracy, Task Time, and Information Transfer Rate$\\unicode{x2013}$improved across sessions, confirming learning effects for symbol spelling, even under pressure conditions. Our results highlight the potential of $\\textit{BrainForm}$ as a scalable, user-friendly BCI research tool and offer guidance for sustained engagement and reduced training fatigue.",
      "code_url": null
    },
    "2510.10004v1": {
      "title": "Bidirectional Time-Frequency Pyramid Network for Enhanced Robust EEG Classification",
      "url": "http://arxiv.org/abs/2510.10004v1",
      "authors": "Jiahui Hong, Siqing Li, Muqing Jian, Luming Yang",
      "update_time": "2025-10-11",
      "abstract": "Existing EEG recognition models suffer from poor cross-paradigm generalization due to dataset-specific constraints and individual variability. To overcome these limitations, we propose BITE (Bidirectional Time-Freq Pyramid Network), an end-to-end unified architecture featuring robust multistream synergy, pyramid time-frequency attention (PTFA), and bidirectional adaptive convolutions. The framework uniquely integrates: 1) Aligned time-frequency streams maintaining temporal synchronization with STFT for bidirectional modeling, 2) PTFA-based multi-scale feature enhancement amplifying critical neural patterns, 3) BiTCN with learnable fusion capturing forward/backward neural dynamics. Demonstrating enhanced robustness, BITE achieves state-of-the-art performance across four divergent paradigms (BCICIV-2A/2B, HGD, SD-SSVEP), excelling in both within-subject accuracy and cross-subject generalization. As a unified architecture, it combines robust performance across both MI and SSVEP tasks with exceptional computational efficiency. Our work validates that paradigm-aligned spectral-temporal processing is essential for reliable BCI systems. Just as its name suggests, BITE \"takes a bite out of EEG.\" The source code is available at https://github.com/cindy-hong/BiteEEG.",
      "code_url": null
    },
    "2510.09242v1": {
      "title": "Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models",
      "url": "http://arxiv.org/abs/2510.09242v1",
      "authors": "Marco Siino, Giuseppe Bonomo, Rosario Sorbello, Ilenia Tinnirello",
      "update_time": "2025-10-10",
      "abstract": "The present study investigates the impact of the Rational Discrete Wavelet Transform (RDWT), used as a plug-in preprocessing step for motor imagery electroencephalographic (EEG) decoding prior to applying deep learning classifiers. A systematic paired evaluation (with/without RDWT) is conducted on four state-of-the-art deep learning architectures: EEGNet, ShallowConvNet, MBEEG\\_SENet, and EEGTCNet. This evaluation was carried out across three benchmark datasets: High Gamma, BCI-IV-2a, and BCI-IV-2b. The performance of the RDWT is reported with subject-wise averages using accuracy and Cohen's kappa, complemented by subject-level analyses to identify when RDWT is beneficial. On BCI-IV-2a, RDWT yields clear average gains for EEGTCNet (+4.44 percentage points, pp; kappa +0.059) and MBEEG\\_SENet (+2.23 pp; +0.030), with smaller improvements for EEGNet (+2.08 pp; +0.027) and ShallowConvNet (+0.58 pp; +0.008). On BCI-IV-2b, the enhancements observed are modest yet consistent for EEGNet (+0.21 pp; +0.044) and EEGTCNet (+0.28 pp; +0.077). On HGD, average effects are modest to positive, with the most significant gain observed for MBEEG\\_SENet (+1.65 pp; +0.022), followed by EEGNet (+0.76 pp; +0.010) and EEGTCNet (+0.54 pp; +0.008). Inspection of the subject material reveals significant enhancements in challenging recordings (e.g., non-stationary sessions), indicating that RDWT can mitigate localized noise and enhance rhythm-specific information. In conclusion, RDWT is shown to be a low-overhead, architecture-aware preprocessing technique that can yield tangible gains in accuracy and agreement for deep model families and challenging subjects.",
      "code_url": null
    },
    "2510.08082v1": {
      "title": "Optimizing BCI Rehabilitation Protocols for Stroke: Exploring Task Design and Training Duration",
      "url": "http://arxiv.org/abs/2510.08082v1",
      "authors": "Aniana Cruz, Marko Kuzmanoski, Gabriel Pires",
      "update_time": "2025-10-09",
      "abstract": "Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions.",
      "code_url": null
    },
    "2509.26301v2": {
      "title": "NeuroTTT: Bridging Pretraining-Downstream Task Misalignment in EEG Foundation Models via Test-Time Training",
      "url": "http://arxiv.org/abs/2509.26301v2",
      "authors": "Suli Wang, Yangshen Deng, Zhenghua Bao, Xinyu Zhan, Yiqun Duan",
      "update_time": "2025-10-01",
      "abstract": "Large-scale foundation models for EEG signals offer a promising path to generalizable brain-computer interface (BCI) applications, but they often suffer from misalignment between pretraining objectives and downstream tasks, as well as significant cross-subject distribution shifts. This paper addresses these challenges by introducing a two-stage alignment strategy that bridges the gap between generic pretraining and specific EEG decoding tasks. First, we propose NeuroTTT: a domain-specific self-supervised fine-tuning paradigm that augments the foundation model with task-relevant self-supervised objectives, aligning latent representations to important spectral, spatial, and temporal EEG features without requiring additional labeled data. Second, we incorporate test-time training (TTT) at inference, we perform (i) self-supervised test-time training on individual unlabeled test samples and (ii) prediction entropy minimization (Tent), which updates only normalization statistics to continually calibrate the model to each new input on the fly. Our approach, which, to our knowledge, is the first to unify domain-tuned self-supervision with test-time training in large-scale EEG foundation models, yields substantially improved robustness and accuracy across diverse BCI tasks (imagined speech, stress detection, motor imagery). Using CBraMod and LaBraM as backbones, our method pushes their performance to a markedly higher level. Results on three diverse tasks demonstrate that the proposed alignment strategy achieves state-of-the-art performance, outperforming conventional fine-tuning and adaptation methods. Our code is available at https://github.com/wsl2000/NeuroTTT.",
      "code_url": null
    },
    "2509.25667v1": {
      "title": "EEG-based AI-BCI Wheelchair Advancement: Hybrid Deep Learning with Motor Imagery for Brain Computer Interface",
      "url": "http://arxiv.org/abs/2509.25667v1",
      "authors": "Bipul Thapa, Biplov Paneru, Bishwash Paneru, Khem Narayan Poudyal",
      "update_time": "2025-09-30",
      "abstract": "This paper presents an Artificial Intelligence (AI) integrated novel approach to Brain-Computer Interface (BCI)-based wheelchair development, utilizing a motor imagery right-left-hand movement mechanism for control. The system is designed to simulate wheelchair navigation based on motor imagery right and left-hand movements using electroencephalogram (EEG) data. A pre-filtered dataset, obtained from an open-source EEG repository, was segmented into arrays of 19x200 to capture the onset of hand movements. The data was acquired at a sampling frequency of 200Hz. The system integrates a Tkinter-based interface for simulating wheelchair movements, offering users a functional and intuitive control system. We propose a BiLSTM-BiGRU model that shows a superior test accuracy of 92.26% as compared with various machine learning baseline models, including XGBoost, EEGNet, and a transformer-based model. The Bi-LSTM-BiGRU attention-based model achieved a mean accuracy of 90.13% through cross-validation, showcasing the potential of attention mechanisms in BCI applications.",
      "code_url": null
    },
    "2509.24700v1": {
      "title": "A Robust Multi-Scale Framework with Test-Time Adaptation for sEEG-Based Speech Decoding",
      "url": "http://arxiv.org/abs/2509.24700v1",
      "authors": "Suli Wang, Yang-yang Li, Siqi Cai, Haizhou Li",
      "update_time": "2025-09-29",
      "abstract": "Decoding speech from stereo-electroencephalography (sEEG) signals has emerged as a promising direction for brain-computer interfaces (BCIs). Its clinical applicability, however, is limited by the inherent non-stationarity of neural signals, which causes domain shifts between training and testing, undermining decoding reliability. To address this challenge, a two-stage framework is proposed for enhanced robustness. First, a multi-scale decomposable mixing (MDM) module is introduced to model the hierarchical temporal dynamics of speech production, learning stable multi-timescale representations from sEEG signals. Second, a source-free online test-time adaptation (TTA) method performs entropy minimization to adapt the model to distribution shifts during inference. Evaluations on the public DU-IN spoken word decoding benchmark show that the approach outperforms state-of-the-art models, particularly in challenging cases. This study demonstrates that combining invariant feature learning with online adaptation is a principled strategy for developing reliable BCI systems. Our code is available at https://github.com/lyyi599/MDM-TENT.",
      "code_url": null
    }
  },
  "fMRI": {
    "2510.10791v1": {
      "title": "A compressed code for memory discrimination",
      "url": "http://arxiv.org/abs/2510.10791v1",
      "authors": "Dale Zhou, Sharon Mina Noh, Nora C Harhen, Nidhi V Banavar, C. Brock Kirwan, Michael A Yassa, Aaron M Bornstein",
      "update_time": "2025-10-12",
      "abstract": "The ability to discriminate similar visual stimuli is an important index of memory function. This ability is widely thought to be supported by expanding the dimensionality of relevant neural codes, such that neural representations for similar stimuli are maximally distinct, or ``separated.'' An alternative hypothesis is that discrimination is supported by lossy compression of visual inputs, efficiently coding sensory information by discarding seemingly irrelevant details. A benefit of compression, relative to expansion, is that it allows individuals to retain fewer essential dimensions underlying stimulus variation -- a process linked to higher-order visual processing -- without hindering discrimination. Under this hypothesis, pattern separation is facilitated when more information from similar stimuli can be discarded, rather than preserved. We test the compression versus expansion hypotheses by predicting performance on the canonical mnemonic similarity task. We train neural networks to compress perceptual and semantic factors of stimuli, measuring lossiness using the mathematical framework underlying compression. Consistent with the compression hypothesis, and not the expansion hypothesis, greater lossiness predicts the ease and performance of lure discrimination, especially in deeper convolutional network layers that predict higher-order visual brain activity. We then confirm these predictions across two image sets, four behavioral datasets, and alternative lossiness metrics. Finally, using task fMRI, we identify signatures of lossy compression -- neural dimensionality reduction and information loss -- in higher-order visual regions V4 and IT and hippocampal DG/CA3 and CA1 linked to lure discrimination. These results suggest lossy compression supports mnemonic discrimination by discarding redundant and overlapping information.",
      "code_url": null
    },
    "2510.09415v1": {
      "title": "Estimating Brain Activity with High Spatial and Temporal Resolution using a Naturalistic MEG-fMRI Encoding Model",
      "url": "http://arxiv.org/abs/2510.09415v1",
      "authors": "Beige Jerry Jin, Leila Wehbe",
      "update_time": "2025-10-10",
      "abstract": "Current non-invasive neuroimaging techniques trade off between spatial resolution and temporal resolution. While magnetoencephalography (MEG) can capture rapid neural dynamics and functional magnetic resonance imaging (fMRI) can spatially localize brain activity, a unified picture that preserves both high resolutions remains an unsolved challenge with existing source localization or MEG-fMRI fusion methods, especially for single-trial naturalistic data. We collected whole-head MEG when subjects listened passively to more than seven hours of narrative stories, using the same stimuli in an open fMRI dataset (LeBel et al., 2023). We developed a transformer-based encoding model that combines the MEG and fMRI from these two naturalistic speech comprehension experiments to estimate latent cortical source responses with high spatiotemporal resolution. Our model is trained to predict MEG and fMRI from multiple subjects simultaneously, with a latent layer that represents our estimates of reconstructed cortical sources. Our model predicts MEG better than the common standard of single-modality encoding models, and it also yields source estimates with higher spatial and temporal fidelity than classic minimum-norm solutions in simulation experiments. We validated the estimated latent sources by showing its strong generalizability across unseen subjects and modalities. Estimated activity in our source space predict electrocorticography (ECoG) better than an ECoG-trained encoding model in an entirely new dataset. By integrating the power of large naturalistic experiments, MEG, fMRI, and encoding models, we propose a practical route towards millisecond-and-millimeter brain mapping.",
      "code_url": null
    },
    "2510.07342v1": {
      "title": "Beyond Grid-Locked Voxels: Neural Response Functions for Continuous Brain Encoding",
      "url": "http://arxiv.org/abs/2510.07342v1",
      "authors": "Haomiao Chen, Keith W Jamison, Mert R. Sabuncu, Amy Kuceyeski",
      "update_time": "2025-10-07",
      "abstract": "Neural encoding models aim to predict fMRI-measured brain responses to natural images. fMRI data is acquired as a 3D volume of voxels, where each voxel has a defined spatial location in the brain. However, conventional encoding models often flatten this volume into a 1D vector and treat voxel responses as independent outputs. This removes spatial context, discards anatomical information, and ties each model to a subject-specific voxel grid. We introduce the Neural Response Function (NRF), a framework that models fMRI activity as a continuous function over anatomical space rather than a flat vector of voxels. NRF represents brain activity as a continuous implicit function: given an image and a spatial coordinate (x, y, z) in standardized MNI space, the model predicts the response at that location. This formulation decouples predictions from the training grid, supports querying at arbitrary spatial resolutions, and enables resolution-agnostic analyses. By grounding the model in anatomical space, NRF exploits two key properties of brain responses: (1) local smoothness -- neighboring voxels exhibit similar response patterns; modeling responses continuously captures these correlations and improves data efficiency, and (2) cross-subject alignment -- MNI coordinates unify data across individuals, allowing a model pretrained on one subject to be fine-tuned on new subjects. In experiments, NRF outperformed baseline models in both intrasubject encoding and cross-subject adaptation, achieving high performance while reducing the data size needed by orders of magnitude. To our knowledge, NRF is the first anatomically aware encoding model to move beyond flattened voxels, learning a continuous mapping from images to brain responses in 3D space.",
      "code_url": null
    },
    "2510.05325v1": {
      "title": "Dynamic Functional Connectivity Features for Brain State Classification: Insights from the Human Connectome Project",
      "url": "http://arxiv.org/abs/2510.05325v1",
      "authors": "Valeriya Kirova, Dzerassa Kadieva, Daniil Vlasenko, Isak B. Blank, Fedor Ratnikov",
      "update_time": "2025-10-06",
      "abstract": "We analyze functional magnetic resonance imaging (fMRI) data from the Human Connectome Project (HCP) to match brain activities during a range of cognitive tasks. Our findings demonstrate that even basic linear machine learning models can effectively classify brain states and achieve state-of-the-art accuracy, particularly for tasks related to motor functions and language processing. Feature importance ranking allows to identify distinct sets of brain regions whose activation patterns are uniquely associated with specific cognitive functions. These discriminative features provide strong support for the hypothesis of functional specialization across cortical and subcortical areas of the human brain.   Additionally, we investigate the temporal dynamics of the identified brain regions, demonstrating that the time-dependent structure of fMRI signals are essential for shaping functional connectivity between regions: uncorrelated areas are least important for classification. This temporal perspective provides deeper insights into the formation and modulation of brain neural networks involved in cognitive processing.",
      "code_url": null
    },
    "2510.04670v2": {
      "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
      "url": "http://arxiv.org/abs/2510.04670v2",
      "authors": "Xuanhua Yin, Runkai Zhao, Weidong Cai",
      "update_time": "2025-10-10",
      "abstract": "Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, and MIND, a plug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating. Trained end-to-end for whole-brain prediction, AFIRE decouples the decoder from upstream fusion, while MIND combines token-dependent Top-K sparse routing with a subject prior to personalize expert usage without sacrificing generality. Experiments across multiple multimodal backbones and subjects show consistent improvements over strong baselines, enhanced cross-subject generalization, and interpretable expert patterns that correlate with content type. The framework offers a simple attachment point for new encoders and datasets, enabling robust, plug-and-improve performance for naturalistic neuroimaging studies.",
      "code_url": null
    },
    "2510.05177v1": {
      "title": "Adapting HFMCA to Graph Data: Self-Supervised Learning for Generalizable fMRI Representations",
      "url": "http://arxiv.org/abs/2510.05177v1",
      "authors": "Jakub Frac, Alexander Schmatz, Qiang Li, Guido Van Wingen, Shujian Yu",
      "update_time": "2025-10-05",
      "abstract": "Functional magnetic resonance imaging (fMRI) analysis faces significant challenges due to limited dataset sizes and domain variability between studies. Traditional self-supervised learning methods inspired by computer vision often rely on positive and negative sample pairs, which can be problematic for neuroimaging data where defining appropriate contrasts is non-trivial. We propose adapting a recently developed Hierarchical Functional Maximal Correlation Algorithm (HFMCA) to graph-structured fMRI data, providing a theoretically grounded approach that measures statistical dependence via density ratio decomposition in a reproducing kernel Hilbert space (RKHS),and applies HFMCA-based pretraining to learn robust and generalizable representations. Evaluations across five neuroimaging datasets demonstrate that our adapted method produces competitive embeddings for various classification tasks and enables effective knowledge transfer to unseen datasets. Codebase and supplementary material can be found here: https://github.com/fr30/mri-eigenencoder",
      "code_url": null
    },
    "2510.03156v1": {
      "title": "Neural Correlates of Language Models Are Specific to Human Language",
      "url": "http://arxiv.org/abs/2510.03156v1",
      "authors": "I\u00f1igo Parra",
      "update_time": "2025-10-03",
      "abstract": "Previous work has shown correlations between the hidden states of large language models and fMRI brain responses, on language tasks. These correlations have been taken as evidence of the representational similarity of these models and brain states. This study tests whether these previous results are robust to several possible concerns. Specifically this study shows: (i) that the previous results are still found after dimensionality reduction, and thus are not attributable to the curse of dimensionality; (ii) that previous results are confirmed when using new measures of similarity; (iii) that correlations between brain representations and those from models are specific to models trained on human language; and (iv) that the results are dependent on the presence of positional encoding in the models. These results confirm and strengthen the results of previous research and contribute to the debate on the biological plausibility and interpretability of state-of-the-art large language models.",
      "code_url": null
    },
    "2510.03004v1": {
      "title": "BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia",
      "url": "http://arxiv.org/abs/2510.03004v1",
      "authors": "Tianzheng Hu, Qiang Li, Shu Liu, Vince D. Calhoun, Guido van Wingen, Shujian Yu",
      "update_time": "2025-10-03",
      "abstract": "The development of diagnostic models is gaining traction in the field of psychiatric disorders. Recently, machine learning classifiers based on resting-state functional magnetic resonance imaging (rs-fMRI) have been developed to identify brain biomarkers that differentiate psychiatric disorders from healthy controls. However, conventional machine learning-based diagnostic models often depend on extensive feature engineering, which introduces bias through manual intervention. While deep learning models are expected to operate without manual involvement, their lack of interpretability poses significant challenges in obtaining explainable and reliable brain biomarkers to support diagnostic decisions, ultimately limiting their clinical applicability. In this study, we introduce an end-to-end innovative graph neural network framework named BrainIB++, which applies the information bottleneck (IB) principle to identify the most informative data-driven brain regions as subgraphs during model training for interpretation. We evaluate the performance of our model against nine established brain network classification methods across three multi-cohort schizophrenia datasets. It consistently demonstrates superior diagnostic accuracy and exhibits generalizability to unseen data. Furthermore, the subgraphs identified by our model also correspond with established clinical biomarkers in schizophrenia, particularly emphasizing abnormalities in the visual, sensorimotor, and higher cognition brain functional network. This alignment enhances the model's interpretability and underscores its relevance for real-world diagnostic applications.",
      "code_url": null
    },
    "2510.03351v1": {
      "title": "Interpretable Neuropsychiatric Diagnosis via Concept-Guided Graph Neural Networks",
      "url": "http://arxiv.org/abs/2510.03351v1",
      "authors": "Song Wang, Zhenyu Lei, Zhen Tan, Jundong Li, Javier Rasero, Aiying Zhang, Chirag Agarwal",
      "update_time": "2025-10-02",
      "abstract": "Nearly one in five adolescents currently live with a diagnosed mental or behavioral health condition, such as anxiety, depression, or conduct disorder, underscoring the urgency of developing accurate and interpretable diagnostic tools. Resting-state functional magnetic resonance imaging (rs-fMRI) provides a powerful lens into large-scale functional connectivity, where brain regions are modeled as nodes and inter-regional synchrony as edges, offering clinically relevant biomarkers for psychiatric disorders. While prior works use graph neural network (GNN) approaches for disorder prediction, they remain complex black-boxes, limiting their reliability and clinical translation. In this work, we propose CONCEPTNEURO, a concept-based diagnosis framework that leverages large language models (LLMs) and neurobiological domain knowledge to automatically generate, filter, and encode interpretable functional connectivity concepts. Each concept is represented as a structured subgraph linking specific brain regions, which are then passed through a concept classifier. Our design ensures predictions through clinically meaningful connectivity patterns, enabling both interpretability and strong predictive performance. Extensive experiments across multiple psychiatric disorder datasets demonstrate that CONCEPTNEURO-augmented GNNs consistently outperform their vanilla counterparts, improving accuracy while providing transparent, clinically aligned explanations. Furthermore, concept analyses highlight disorder-specific connectivity patterns that align with expert knowledge and suggest new hypotheses for future investigation, establishing CONCEPTNEURO as an interpretable, domain-informed framework for psychiatric disorder diagnosis.",
      "code_url": null
    },
    "2510.02266v2": {
      "title": "NeuroSwift: A Lightweight Cross-Subject Framework for fMRI Visual Reconstruction of Complex Scenes",
      "url": "http://arxiv.org/abs/2510.02266v2",
      "authors": "Shiyi Zhang, Dong Liang, Yihang Zhou",
      "update_time": "2025-10-12",
      "abstract": "Reconstructing visual information from brain activity via computer vision technology provides an intuitive understanding of visual neural mechanisms. Despite progress in decoding fMRI data with generative models, achieving accurate cross-subject reconstruction of visual stimuli remains challenging and computationally demanding. This difficulty arises from inter-subject variability in neural representations and the brain's abstract encoding of core semantic features in complex visual inputs. To address these challenges, we propose NeuroSwift, which integrates complementary adapters via diffusion: AutoKL for low-level features and CLIP for semantics. NeuroSwift's CLIP Adapter is trained on Stable Diffusion generated images paired with COCO captions to emulate higher visual cortex encoding. For cross-subject generalization, we pretrain on one subject and then fine-tune only 17 percent of parameters (fully connected layers) for new subjects, while freezing other components. This enables state-of-the-art performance with only one hour of training per subject on lightweight GPUs (three RTX 4090), and it outperforms existing methods.",
      "code_url": null
    }
  },
  "MEG": {
    "2510.09415v1": {
      "title": "Estimating Brain Activity with High Spatial and Temporal Resolution using a Naturalistic MEG-fMRI Encoding Model",
      "url": "http://arxiv.org/abs/2510.09415v1",
      "authors": "Beige Jerry Jin, Leila Wehbe",
      "update_time": "2025-10-10",
      "abstract": "Current non-invasive neuroimaging techniques trade off between spatial resolution and temporal resolution. While magnetoencephalography (MEG) can capture rapid neural dynamics and functional magnetic resonance imaging (fMRI) can spatially localize brain activity, a unified picture that preserves both high resolutions remains an unsolved challenge with existing source localization or MEG-fMRI fusion methods, especially for single-trial naturalistic data. We collected whole-head MEG when subjects listened passively to more than seven hours of narrative stories, using the same stimuli in an open fMRI dataset (LeBel et al., 2023). We developed a transformer-based encoding model that combines the MEG and fMRI from these two naturalistic speech comprehension experiments to estimate latent cortical source responses with high spatiotemporal resolution. Our model is trained to predict MEG and fMRI from multiple subjects simultaneously, with a latent layer that represents our estimates of reconstructed cortical sources. Our model predicts MEG better than the common standard of single-modality encoding models, and it also yields source estimates with higher spatial and temporal fidelity than classic minimum-norm solutions in simulation experiments. We validated the estimated latent sources by showing its strong generalizability across unseen subjects and modalities. Estimated activity in our source space predict electrocorticography (ECoG) better than an ECoG-trained encoding model in an entirely new dataset. By integrating the power of large naturalistic experiments, MEG, fMRI, and encoding models, we propose a practical route towards millisecond-and-millimeter brain mapping.",
      "code_url": null
    },
    "2510.08697v1": {
      "title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution",
      "url": "http://arxiv.org/abs/2510.08697v1",
      "authors": "Terry Yue Zhuo, Xiaolong Jin, Hange Liu, Juyong Jiang, Tianyang Liu, Chen Gong, Bhupesh Bishnoi, Vaisakhi Mishra, Marek Suppa, Noah Ziems, Saiteja Utpala, Ming Xu, Guangyu Song, Kaixin Li, Yuhan Cao, Bo Liu, Zheng Liu, Sabina Abdurakhmanova, Wenhao Yu, Mengzhao Jia, Jihan Yao, Kenneth Hamilton, Kumar Shridhar, Minh Chien Vu, Dingmin Wang, Jiawei Liu, Zijian Wang, Qian Liu, Binyuan Hui, Meg Risdal, Ahsen Khaliq, Atin Sood, Zhenchang Xing, Wasi Uddin Ahmad, John Grundy, David Lo, Banghua Zhu, Xiaoning Du, Torsten Scholak, Leandro von Werra",
      "update_time": "2025-10-09",
      "abstract": "Crowdsourced model evaluation platforms, such as Chatbot Arena, enable real-time evaluation from human perspectives to assess the quality of model responses. In the coding domain, manually examining the quality of LLM-generated content is extremely challenging, as it requires understanding long chunks of raw code and deliberately simulating code execution. To this end, we introduce BigCodeArena, an open human evaluation platform for code generation backed by a comprehensive and on-the-fly execution environment. Built on top of Chatbot Arena, BigCodeArena enables the execution of LLM-generated code and allows humans to interact with the execution process and outcomes. We collected over 14,000 raw code-centric conversation sessions across 10 widely used LLMs, spanning 10 languages and 8 types of execution environments. Among these conversations, we identified more than 4,700 multi-turn samples with pairwise human preferences. Further analysis uncovers underexplored preferences of LLMs in fine-grained domains characterized by tasks, languages, and frameworks. To systematically examine code understanding and generation capabilities of frontier LLMs, we curated two benchmarks based on the collected data, namely BigCodeReward and AutoCodeArena. For BigCodeReward, we post-processed the 4,700 conversations and evaluated the consistency between reward models and human preferences. The evaluation shows that most LLMs have superior performance in judging coding preferences when the execution results are available. Inspired by these findings, we propose AutoCodeArena, an automatic Elo rating benchmark designed to assess the coding quality of LLMs without human involvement. We find that proprietary LLMs like GPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation performance among recent emerging models.",
      "code_url": null
    },
    "2510.08674v1": {
      "title": "Expanding the Landscape of Exotic Muon Decays",
      "url": "http://arxiv.org/abs/2510.08674v1",
      "authors": "Admir Greljo, Ajdin Palavri\u0107, Mirsad Tunja, Jure Zupan",
      "update_time": "2025-10-09",
      "abstract": "We chart new-physics models that produce exotic, high-multiplicity muon decays featuring prompt or displaced $e^+e^-$ pairs and/or photons, with or without missing energy, such as $\\mu \\to 5e$, $\\mu \\to 7e$, etc. Starting from an effective-field-theory perspective, we estimate the reach on the ultraviolet scale and identify conditions under which lower-multiplicity modes are suppressed or occur at comparable rates. We then construct explicit realizations in minimal dark-sector models with light, feebly interacting particles, such as flavor-protected scalars, dark photons, inelastic dark matter, and axion-like particles. The predicted novel signatures can be probed at MEG II and Mu3e, as well as during calibration runs of COMET and Mu2e. A future discovery would provide valuable insights into short-distance dynamics and the mechanism of lepton-flavor symmetry breaking.",
      "code_url": null
    },
    "2510.05515v1": {
      "title": "The Gamma-ray Luminosity Function of Flat-Spectrum Radio Quasars",
      "url": "http://arxiv.org/abs/2510.05515v1",
      "authors": "Garima Rajguru, Lea Marcotulli, Marco Ajello, Mattia Di Mauro, Meg Urry",
      "update_time": "2025-10-07",
      "abstract": "We have utilized the largest sample of $\\gamma$-ray selected Fermi flat-spectrum radio quasars (FSRQs) ever used (519 sources) to construct the luminosity function and its evolution through the cosmic history. In addition to spanning large redshift ($0<z\\lesssim 4$) and luminosity ranges ($2.9\\times10^{43}$ erg s$^{-1}$ - $7.3\\times10^{48}$ erg s$^{-1}$), this sample also has a robust calculation of the detection efficiency associated with its observation, making its selection effects and biases well understood. We confirm that the local luminosity function is best explained by a double power law. The evolution of the luminosity function of FSRQs follows a luminosity-dependent density evolution. FSRQs experience positive evolution with their space density growing with increasing redshift up to a maximum redshift, after which the numbers decrease. This peak in redshift occurs at larger redshifts for higher luminosity sources and at lower redshifts for lower luminosity sources. We find an unexpected similarity between the luminosity function of FSRQs and that of BL Lacertae objects at intermediate luminosity. This could be a sign of a strong genetic link between the two blazar sub-classes or that BL Lac samples are contaminated by large amounts of FSRQs with their jets nearly perfectly aligned with our line of sight.",
      "code_url": null
    },
    "2509.14772v1": {
      "title": "UMind: A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding",
      "url": "http://arxiv.org/abs/2509.14772v1",
      "authors": "Chengjian Xu, Yonghao Song, Zelin Liao, Haochuan Zhang, Qiong Wang, Qingqing Zheng",
      "update_time": "2025-09-18",
      "abstract": "Decoding visual information from time-resolved brain recordings, such as EEG and MEG, plays a pivotal role in real-time brain-computer interfaces. However, existing approaches primarily focus on direct brain-image feature alignment and are limited to single-task frameworks or task-specific models. In this paper, we propose a Unified MultItask Network for zero-shot M/EEG visual Decoding (referred to UMind), including visual stimulus retrieval, classification, and reconstruction, where multiple tasks mutually enhance each other. Our method learns robust neural-visual and semantic representations through multimodal alignment with both image and text modalities. The integration of both coarse and fine-grained texts enhances the extraction of these neural representations, enabling more detailed semantic and visual decoding. These representations then serve as dual conditional inputs to a pre-trained diffusion model, guiding visual reconstruction from both visual and semantic perspectives. Extensive evaluations on MEG and EEG datasets demonstrate the effectiveness, robustness, and biological plausibility of our approach in capturing spatiotemporal neural dynamics. Our approach sets a multitask pipeline for brain visual decoding, highlighting the synergy of semantic information in visual feature extraction.",
      "code_url": null
    },
    "2509.16253v1": {
      "title": "Quantum-like representation of neuronal networks' activity: modeling \"mental entanglement\"",
      "url": "http://arxiv.org/abs/2509.16253v1",
      "authors": "Andrei Khrennikov, Makiko Yamada",
      "update_time": "2025-09-17",
      "abstract": "Quantum-like modeling (QLM) - quantum theory applications outside of physics - are intensively developed with applications in biology, cognition, psychology, and decision-making. For cognition, QLM should be distinguished from quantum reductionist models in the spirit of Hameroff and Penrose and well as Umezawa and Vitiello. QLM is not concerned with just quantum physical processes in the brain but also QL information processing by macroscopic neuronal structures. Although QLM of cognition and decision-making has seen some success, it suffers from a knowledge gap that exists between oscillatory neuronal network functioning in the brain and QL behavioral patterns. Recently, steps toward closing this gap have been taken using the generalized probability theory and prequantum classical statistical field theory (PCSFT) - a random field model beyond the complex Hilbert space formalism. PCSFT is used to move from the classical ``oscillatory cognition'' of the neuronal networks to QLM for decision.making. In this study, we addressed the most difficult problem within this construction: QLM for entanglement generation by classical networks, i.e., mental entanglement. We started with the observational approach to entanglement based on operator algebras describing local observables and bringing into being the tensor product structure in the space of QL states. Moreover, we applied the standard states entanglement approach: entanglement generation by spatially separated networks in the brain. Finally, we discussed possible future experiments on mental entanglement detection using the EEG/MEG technique.",
      "code_url": null
    },
    "2509.14118v1": {
      "title": "Multi-Source Neural Activity Indices and Spatial Filters for EEG/MEG Inverse Problem: An Extension to MNE-Python",
      "url": "http://arxiv.org/abs/2509.14118v1",
      "authors": "Julia Jurkowska, Joanna Dreszer, Monika Lewandowska, Krzysztof To\u0142pa, Tomasz Piotrowski",
      "update_time": "2025-09-17",
      "abstract": "Accurate EEG/MEG source localization is essential for understanding brain function, yet remains challenging because the inverse problem is inherently ill-posed. In spatial filtering (beamforming) approaches, single-source LCMV spatial filters, though widely used, suffer from source cancellation when sources are correlated - a common experimental scenario. Multi-source frameworks, such as the multi-source minimum-variance pseudo-unbiased reduced-rank (MV-PURE) method, offer improved reconstruction and robust neural activity indices, yet their adoption has been limited by incomplete theory and lack of accessible implementations. In this paper, we present a rigorous derivation of multi-source neural activity indices and spatial filters, establishing a complete analytical framework with automated parameter selection. The resulting compact algebraic forms enable straightforward implementation. To facilitate adoption, we provide a full implementation extending MNE-Python, along with an accompanying tutorial, and demonstrate its utility on EEG experimental data, highlighting the practical advantages of multi-source spatial filtering for source localization and reconstruction.",
      "code_url": null
    },
    "2509.07021v2": {
      "title": "MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning",
      "url": "http://arxiv.org/abs/2509.07021v2",
      "authors": "Jiarui Chen, Yikeng Chen, Yingshuang Zou, Ye Huang, Peng Wang, Yuan Liu, Yujing Sun, Wenping Wang",
      "update_time": "2025-09-23",
      "abstract": "3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis technique, but its high memory consumption severely limits its applicability on edge devices. A growing number of 3DGS compression methods have been proposed to make 3DGS more efficient, yet most only focus on storage compression and fail to address the critical bottleneck of rendering memory. To address this problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that tackles this challenge by jointly optimizing two key factors: the total primitive number and the parameters per primitive, achieving unprecedented memory compression. Specifically, we replace the memory-intensive spherical harmonics with lightweight, arbitrarily oriented spherical Gaussian lobes as our color representations. More importantly, we propose a unified soft pruning framework that models primitive-number and lobe-number pruning as a single constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a 50% static VRAM reduction and a 40% rendering VRAM reduction compared to existing methods, while maintaining comparable rendering quality. Project page: https://megs-2.github.io/",
      "code_url": null
    },
    "2509.04331v2": {
      "title": "A fast machine learning tool to predict the composition of astronomical ices from infrared absorption spectra",
      "url": "http://arxiv.org/abs/2509.04331v2",
      "authors": "Andr\u00e9s Meg\u00edas, Izaskun Jim\u00e9nez-Serra, Fran\u00e7ois Dulieu, Julie Vitorino, Bel\u00e9n Mat\u00e9, David Ciudad, Will R. M. Rocha, Marcos Mart\u00ednez Jim\u00e9nez, Jacobo Aguirre",
      "update_time": "2025-09-15",
      "abstract": "Current observations taken by James Webb Space Telescope (JWST) allow us to observe the absorption features of icy mantles that cover interstellar dust grains, which are mainly composed of $\\mathrm{H_2O}$, $\\mathrm{CO}$, and $\\mathrm{CO_2}$, along with other minor species. Thanks to its sensitivity and spectral resolution, JWST has the potential to observe ice features towards hundreds of sources at different stages along the process of star formation. However, identifying the spectral features of the different species and quantifying the ice composition is not trivial and requires complex spectroscopic analysis. We present Automatic Ice Composition Estimator (AICE), a new tool based on artificial neural networks. Based on the infrared (IR) ice absorption spectrum between 2.5 and 10 microns, AICE predicts the ice fractional composition in terms of $\\mathrm{H_2O}$, $\\mathrm{CO}$, $\\mathrm{CO_2}$, $\\mathrm{CH_3OH}$, $\\mathrm{NH_3}$, and $\\mathrm{CH_4}$. To train the model, we used hundreds of laboratory experiments of ice mixtures from different databases, which were reprocessed with baseline subtraction and normalisation. Once trained, AICE takes less than one second on a conventional computer to predict the ice composition associated with the observed IR absorption spectrum, with typical errors of $\\sim$3 $\\%$ in the species fraction. We tested its performance on two spectra reported towards the NIR38 and J110621 background stars observed within the JWST Ice Age program, demonstrating a good agreement with previous estimations of the ice composition. The fast and accurate performance of AICE enables the systematic analysis of hundreds of different ice spectra with a modest time investment. In addition, this model can be enhanced and re-trained with more laboratory data, improving the precision of the predictions and expanding the list of predicted species.",
      "code_url": null
    },
    "2509.03107v1": {
      "title": "Towards a 384-channel magnetoencephalography system based on optically pumped magnetometers",
      "url": "http://arxiv.org/abs/2509.03107v1",
      "authors": "Holly Schofield, Ryan M. Hill, Lukas Rier, Ewan Kennett, Gonzalo Reina Rivero, Joseph Gibson, Ashley Tyler, Zoe Tanner, Frank Worcester, Tyler Hayward, James Osborne, Cody Doyle, Vishal Shah, Elena Boto, Niall Holmes, Matthew J. Brookes",
      "update_time": "2025-09-03",
      "abstract": "Magnetoencephalography using optically pumped magnetometers (OPM-MEG) is gaining significant traction as a neuroimaging tool, with the potential for improved performance and practicality compared to conventional instrumentation. However, OPM-MEG has so far lagged conventional-MEG in terms of the number of independent measurements of magnetic field that can be made across the scalp (i.e. the number of channels). This is important since increasing channel count offers improvements in sensitivity, spatial resolution and coverage. Unfortunately, increasing channel count also poses significant technical and practical challenges. Here, we describe a new OPM-MEG array which exploits triaxial sensors and integrated miniaturised electronic control units to measure MEG data from up to 384 channels. We also introduce a high-speed calibration method to ensure the that the fields measured by this array are high fidelity. The system was validated using a phantom, with results showing that dipole localisation accuracy is better than 1 mm, and correlation between the measured magnetic fields and a dipole model is >0.998. We then demonstrate utility in human MEG acquisition: via measurement of visual gamma oscillations we demonstrate the improvements in sensitivity that are afforded by high channel density, and via a moviewatching paradigm we quantify improvements in spatial resolution. In sum, we show the first OPM-MEG system with a channel count larger than that of typical conventional MEG devices. This represents a significant step on the path towards OPMs becoming the sensor of choice for MEG measurement.",
      "code_url": null
    }
  },
  "neuroAI": {
    "2509.23896v2": {
      "title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence",
      "url": "http://arxiv.org/abs/2509.23896v2",
      "authors": "Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang",
      "update_time": "2025-10-09",
      "abstract": "NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",
      "code_url": null
    },
    "2507.06645v1": {
      "title": "Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers",
      "url": "http://arxiv.org/abs/2507.06645v1",
      "authors": "Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding",
      "update_time": "2025-07-09",
      "abstract": "Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as e.g. accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.",
      "code_url": null
    },
    "2507.02103v1": {
      "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
      "url": "http://arxiv.org/abs/2507.02103v1",
      "authors": "Daniel Durstewitz, Bruno Averbeck, Georgia Koppe",
      "update_time": "2025-07-02",
      "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
      "code_url": null
    },
    "2506.04536v2": {
      "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models",
      "url": "http://arxiv.org/abs/2506.04536v2",
      "authors": "Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar",
      "update_time": "2025-06-12",
      "abstract": "Characterizing the diverse computational properties of human neurons via multimodal electrophysiological, transcriptomic, and morphological data provides the foundation for constructing and validating bio-realistic neuron models that can advance our understanding of fundamental mechanisms underlying brain function. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. To capture variability, ensembles of deterministic models are often used, but are difficult to scale as model generation requires repeating computationally expensive optimization for each neuron. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on data generated from biophysically realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE is the first scaled-up deep learning framework validated on real experimental data, enabling efficient generation of synthetic neurons that exhibit trial-to-trial variability and achieve a $4200\\times$ speedup over numerical solvers. To this end, NOBLE captures fundamental neural properties, opening the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.",
      "code_url": null
    },
    "2505.16080v1": {
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "url": "http://arxiv.org/abs/2505.16080v1",
      "authors": "Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang",
      "update_time": "2025-05-21",
      "abstract": "Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.",
      "code_url": null
    },
    "2502.16238v1": {
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "url": "http://arxiv.org/abs/2502.16238v1",
      "authors": "Jenelle Feather, Meenakshi Khosla, N. Apurva Ratan Murty, Aran Nayebi",
      "update_time": "2025-02-22",
      "abstract": "What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \\emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development.",
      "code_url": null
    },
    "2501.02402v1": {
      "title": "Asynchronous Hebbian/anti-Hebbian networks",
      "url": "http://arxiv.org/abs/2501.02402v1",
      "authors": "Henrique Reis Aguiar, Matthias H. Hennig",
      "update_time": "2025-01-04",
      "abstract": "Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.",
      "code_url": null
    },
    "2411.18526v2": {
      "title": "NeuroAI for AI Safety",
      "url": "http://arxiv.org/abs/2411.18526v2",
      "authors": "Patrick Mineault, Niccol\u00f2 Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias, Anthony Zador",
      "update_time": "2025-04-03",
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety.",
      "code_url": null
    },
    "2411.14633v2": {
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "url": "http://arxiv.org/abs/2411.14633v2",
      "authors": "Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla",
      "update_time": "2025-09-14",
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research.",
      "code_url": null
    },
    "2409.05771v1": {
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "url": "http://arxiv.org/abs/2409.05771v1",
      "authors": "Emily Cheng, Richard J. Antonello",
      "update_time": "2024-09-09",
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.",
      "code_url": null
    }
  },
  "medical": {
    "2510.11670v1": {
      "title": "Understanding the interplay of collagen and myocyte adaptation in cardiac volume overload: a multi-constituent growth and remodeling framework",
      "url": "http://arxiv.org/abs/2510.11670v1",
      "authors": "Ludovica Maga, Mathias Peirlinck, Lise No\u00ebl",
      "update_time": "2025-10-13",
      "abstract": "Hearts subjected to volume overload (VO) are prone to detrimental anatomical and functional changes in response to elevated mechanical stretches, ultimately leading to heart failure. Experimental findings increasingly emphasize that organ-scale changes following VO cannot be explained by myocyte growth alone, as traditionally proposed in the literature. Collagen degradation, in particular, has been associated with left ventricular adaptation in both acute and chronic stages of VO. These hypotheses remain to be substantiated by comprehensive mechanistic evidence, and the contribution of each constituent to myocardial growth and remodeling (G&R) processes is yet to be quantified. In this work, we establish a hybrid G&R framework in which we integrate a mixture-based constitutive model with the kinematic growth formulation. This multi-constituent model enables us to mechanistically assess the relative contributions of collagen and myocyte changes to alterations in tissue properties, ventricular dimensions, and growth phenotype. Our numerical results confirm that collagen dynamics control the passive mechanical response of the myocardium, whereas myocytes predominantly impact the extent and the phenotype of eccentric hypertrophy. Importantly, collagen degradation exacerbates myocyte hypertrophy, demonstrating a synergistic interplay that accelerates left ventricular progression toward diastolic dysfunction. This work constitutes an important step towards an integrated characterization of the early compensatory stages of VO-induced cardiac G&R.",
      "code_url": null
    },
    "2510.11578v1": {
      "title": "A comparison of approaches to incorporate patient-selected and patient-ranked outcomes in clinical trials",
      "url": "http://arxiv.org/abs/2510.11578v1",
      "authors": "David S. Robertson, Thomas Jaki",
      "update_time": "2025-10-13",
      "abstract": "A key aspect of patient-focused drug development is identifying and measuring outcomes that are important to patients in clinical trials. Many medical conditions affect multiple symptom domains, and a consensus approach to determine the relative importance of the associated multiple outcomes ignores the heterogeneity in individual patient preferences. Patient-selected outcomes offer one way to incorporate individual patient preferences, as proposed in recent regulatory guidance for the treatment for migraine, where each patient selects their most bothersome migraine-associated symptom in addition to pain. Patient-ranked outcomes have also recently been proposed, which go further and consider the full ranking of the relative importance of all the outcomes. This can be assessed using a composite DOOR (Desirability of Outcome Ranking) endpoint. In this paper, we compare the advantages and disadvantages of using patient-selected versus patient-ranked outcomes in the context of a two-arm randomised controlled trial for multiple sclerosis. We compare the power and type I error rate by simulation, and discuss several other important considerations when using the two approaches.",
      "code_url": null
    },
    "2510.11568v1": {
      "title": "Elastic Rod Origami (RodOri) for Programming Static and Dynamic Mechanical Properties",
      "url": "http://arxiv.org/abs/2510.11568v1",
      "authors": "Sophie Leanza, Jeseung Lee, Ruike Renee Zhao",
      "update_time": "2025-10-13",
      "abstract": "Reconfigurable mechanical systems enable precise programmable control over structural properties, opening new opportunities in architected materials, adaptive devices, and multifunctional structures. Here, we introduce elastic rod origami (RodOri), a platform that exploits remarkably simple elements (pre-stressed, naturally curved rods) into a system with an extraordinary degree of multistability and configurational richness. For example, a single 6-rod RodOri unit can easily access 11 distinct configurations, far exceeding the reconfigurability of conventional origami or general mechanical reconfigurable systems. Individual rods, constrained under clamped boundary conditions, undergo snapping transitions between discrete morphologies whose strain energy and stiffness are precisely prescribed by their natural curvature. Assembling these rods into modular multi-rod architectures yields metamaterials with numerous stable configurations that can be selectively and reversibly programmed. This configurational diversity enables tunable static stiffness, nonlinear force response, and thus enables tunable dynamic behaviors such as vibration filtering, wave-propagation switching, and mode conversion within a single, easily-manufactured platform. By leveraging curvature-induced mechanical instability, RodOri unlocks highly programmable static and dynamic mechanical behavior, offering new design strategies in reconfigurable structures, soft robotics, medical devices, and adaptive materials.",
      "code_url": null
    },
    "2510.11537v1": {
      "title": "An Encoder-Integrated PhoBERT with Graph Attention for Vietnamese Token-Level Classification",
      "url": "http://arxiv.org/abs/2510.11537v1",
      "authors": "Ba-Quang Nguyen",
      "update_time": "2025-10-13",
      "abstract": "We propose a novel neural architecture named TextGraphFuseGAT, which integrates a pretrained transformer encoder (PhoBERT) with Graph Attention Networks for token-level classification tasks. The proposed model constructs a fully connected graph over the token embeddings produced by PhoBERT, enabling the GAT layer to capture rich inter-token dependencies beyond those modeled by sequential context alone. To further enhance contextualization, a Transformer-style self-attention layer is applied on top of the graph-enhanced embeddings. The final token representations are passed through a classification head to perform sequence labeling. We evaluate our approach on three Vietnamese benchmark datasets: PhoNER-COVID19 for named entity recognition in the COVID-19 domain, PhoDisfluency for speech disfluency detection, and VietMed-NER for medical-domain NER. VietMed-NER is the first Vietnamese medical spoken NER dataset, featuring 18 entity types collected from real-world medical speech transcripts and annotated with the BIO tagging scheme. Its specialized vocabulary and domain-specific expressions make it a challenging benchmark for token-level classification models. Experimental results show that our method consistently outperforms strong baselines, including transformer-only and hybrid neural models such as BiLSTM + CNN + CRF, confirming the effectiveness of combining pretrained semantic features with graph-based relational modeling for improved token classification across multiple domains.",
      "code_url": null
    },
    "2510.11514v2": {
      "title": "Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach",
      "url": "http://arxiv.org/abs/2510.11514v2",
      "authors": "Yinchao Yang, Yahao Ding, Zhaohui Yang, Chongwen Huang, Zhaoyang Zhang, Dusit Niyato, Mohammad Shikh-Bahaei",
      "update_time": "2025-10-14",
      "abstract": "Real-time and contactless monitoring of vital signs, such as respiration and heartbeat, alongside reliable communication, is essential for modern healthcare systems, especially in remote and privacy-sensitive environments. Traditional wireless communication and sensing networks fall short in meeting all the stringent demands of eHealth, including accurate sensing, high data efficiency, and privacy preservation. To overcome the challenges, we propose a novel integrated sensing, computing, and semantic communication (ISCSC) framework. In the proposed system, a service robot utilises radar to detect patient positions and monitor their vital signs, while sending updates to the medical devices. Instead of transmitting raw physiological information, the robot computes and communicates semantically extracted health features to medical devices. This semantic processing improves data throughput and preserves the clinical relevance of the messages, while enhancing data privacy by avoiding the transmission of sensitive data. Leveraging the estimated patient locations, the robot employs an interacting multiple model (IMM) filter to actively track patient motion, thereby enabling robust beam steering for continuous and reliable monitoring. We then propose a joint optimisation of the beamforming matrices and the semantic extraction ratio, subject to computing capability and power budget constraints, with the objective of maximising both the semantic secrecy rate and sensing accuracy. Simulation results validate that the ISCSC framework achieves superior sensing accuracy, improved semantic transmission efficiency, and enhanced privacy preservation compared to conventional joint sensing and communication methods.",
      "code_url": null
    },
    "2510.11504v2": {
      "title": "Towards polarization-enhanced PET: Study of random background in polarization-correlated Compton events",
      "url": "http://arxiv.org/abs/2510.11504v2",
      "authors": "Ana Marija Ko\u017euljevi\u0107, Tomislav Bokuli\u0107, Darko Gro\u0161ev, Siddharth Parashari, Luka Paveli\u0107, Marinko Rade, Marijan \u017duvi\u0107, Mihael Makek",
      "update_time": "2025-10-14",
      "abstract": "Positron Emission Tomography (PET) is a medical imaging modality that utilizes positron-emitting isotopes, such as Ga-68 and F-18, for many diagnostic purposes. The positron annihilates with an electron from the surrounding area, creating two photons of 511 keV energy and opposite momenta, entangled in their orthogonal polarizations. When each photon undergoes a Compton scattering process, the difference of their azimuthal scattering angles reflects the initial orthogonality of their polarizations, peaking at $\\pm$90$^{\\circ}$. This type of correlation is not yet utilized in conventional PET scanners, but could potentially offer an energy-independent method for background reduction. Measurements of these kinds of correlations can be achieved using Compton polarimeters, built from a single layer of segmented scintillating crystals such as Gadolinium Aluminium Gallium Garnet doped with Cerium (GAGG:Ce), read out by silicon photomultipliers (SiPMs). In this paper, we study the signal-to-random background ratios in measurements of these correlated annihilation photons from coincidence time spectra across clinically relevant source activities, from $\\sim$200 MBq to $\\sim$378 MBq. These are then compared to the standard single-pixel (photoelectric) measurements. We find that the signal-to-random background ratios (SBRs) obtained from the polarization-correlated events for Compton scattering angles $\\theta_{1,2}\\in[72^{\\circ}, 90^{\\circ}]$ and azimuthal angle difference $\\Delta\\phi=90^{\\circ}\\pm20^{\\circ}$ are consistently higher than those from single-pixel events, with the ratio of their SBR values of 1.23. The SBR of the selected events also increases with the polarimetric modulation factor $\\mu$, gaining $\\sim$50\\% in value during the experiment.",
      "code_url": null
    },
    "2510.11437v1": {
      "title": "GADA: Graph Attention-based Detection Aggregation for Ultrasound Video Classification",
      "url": "http://arxiv.org/abs/2510.11437v1",
      "authors": "Li Chen, Naveen Balaraju, Jochen Kruecker, Balasundar Raju, Alvin Chen",
      "update_time": "2025-10-13",
      "abstract": "Medical ultrasound video analysis is challenging due to variable sequence lengths, subtle spatial cues, and the need for interpretable video-level assessment. We introduce GADA, a Graph Attention-based Detection Aggregation framework that reformulates video classification as a graph reasoning problem over spatially localized regions of interest. Rather than relying on 3D CNNs or full-frame analysis, GADA detects pathology-relevant regions across frames and represents them as nodes in a spatiotemporal graph, with edges encoding spatial and temporal dependencies. A graph attention network aggregates these node-level predictions through edge-aware attention to generate a compact, discriminative video-level output. Evaluated on a large-scale, multi-center clinical lung ultrasound dataset, GADA outperforms conventional baselines on two pathology video classification tasks while providing interpretable region- and frame-level attention.",
      "code_url": null
    },
    "2510.11390v1": {
      "title": "Medical Interpretability and Knowledge Maps of Large Language Models",
      "url": "http://arxiv.org/abs/2510.11390v1",
      "authors": "Razvan Marinescu, Victoria-Elisabeth Gruber, Diego Fajardo",
      "update_time": "2025-10-13",
      "abstract": "We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama3.3-70B, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied.",
      "code_url": null
    },
    "2510.11304v1": {
      "title": "In-situ Radiation Damage Study of Silicon Carbide Detectors Subjected to Clinical Proton Beams",
      "url": "http://arxiv.org/abs/2510.11304v1",
      "authors": "Daniel Radmanovac, Andreas Gsponer, Simon Waid, Sebastian Onder, Matthias Knopf, J\u00fcrgen Burin, Stefan Gundacker, Thomas Bergauer",
      "update_time": "2025-10-13",
      "abstract": "Silicon carbide (SiC) planar PiN diodes from two different manufacturers were irradiated with 252.7 MeV protons from a medical synchrotron. Over the course of two 8h irradiation shifts, the samples were exposed to increasing fluences ranging from 1.4e+11 to 3.5e+13 p+/cm^2. Electrical characterizations, including IV and CV measurements, were performed both before and after irradiation using probe stations, and for selected samples even in-situ between fluence steps directly at the irradiation facility. The results show a gradual compensation of the effective epitaxial doping concentration with each incremental fluence step, observed as a reduction in capacitance before full depletion and confirmed by the extracted effective doping concentration. From these measurements, linear donor removal rates are determined for all sample groups, with values ranging from 4.2/cm to 6.4/cm. These findings provide a quantitative basis for understanding radiation-induced charge carrier removal in 4H-SiC devices and are relevant for predicting the performance and lifetime of future radiation-hard detector technologies, including 4H-SiC LGADs.",
      "code_url": null
    },
    "2510.11301v1": {
      "title": "TDADL-IE: A Deep Learning-Driven Cryptographic Architecture for Medical Image Security",
      "url": "http://arxiv.org/abs/2510.11301v1",
      "authors": "Junhua Zhou, Quanjun Li, Weixuan Li, Guang Yu, Yihua Shao, Yihang Dong, Mengqian Wang, Zimeng Li, Changwei Gong, Xuhang Chen",
      "update_time": "2025-10-13",
      "abstract": "The rise of digital medical imaging, like MRI and CT, demands strong encryption to protect patient data in telemedicine and cloud storage. Chaotic systems are popular for image encryption due to their sensitivity and unique characteristics, but existing methods often lack sufficient security. This paper presents the Three-dimensional Diffusion Algorithm and Deep Learning Image Encryption system (TDADL-IE), built on three key elements. First, we propose an enhanced chaotic generator using an LSTM network with a 1D-Sine Quadratic Chaotic Map (1D-SQCM) for better pseudorandom sequence generation. Next, a new three-dimensional diffusion algorithm (TDA) is applied to encrypt permuted images. TDADL-IE is versatile for images of any size. Experiments confirm its effectiveness against various security threats. The code is available at \\href{https://github.com/QuincyQAQ/TDADL-IE}{https://github.com/QuincyQAQ/TDADL-IE}.",
      "code_url": null
    }
  }
}