{
  "Brain": {
    "2406.16848v1": {
      "title": "Unsupervised Domain Adaptation for Pediatric Brain Tumor Segmentation",
      "url": "http://arxiv.org/abs/2406.16848v1",
      "authors": "Jingru Fu, Simone Bendazzoli, \u00d6rjan Smedby, Rodrigo Moreno",
      "update_time": "2024-06-24",
      "abstract": "Significant advances have been made toward building accurate automatic segmentation models for adult gliomas. However, the performance of these models often degrades when applied to pediatric glioma due to their imaging and clinical differences (domain shift). Obtaining sufficient annotated data for pediatric glioma is typically difficult because of its rare nature. Also, manual annotations are scarce and expensive. In this work, we propose Domain-Adapted nnU-Net (DA-nnUNet) to perform unsupervised domain adaptation from adult glioma (source domain) to pediatric glioma (target domain). Specifically, we add a domain classifier connected with a gradient reversal layer (GRL) to a backbone nnU-Net. Once the classifier reaches a very high accuracy, the GRL is activated with the goal of transferring domain-invariant features from the classifier to the segmentation model while preserving segmentation accuracy on the source domain. The accuracy of the classifier slowly degrades to chance levels. No annotations are used in the target domain. The method is compared to 8 different supervised models using BraTS-Adult glioma (N=1251) and BraTS-PED glioma data (N=99). The proposed method shows notable performance enhancements in the tumor core (TC) region compared to the model that only uses adult data: ~32% better Dice scores and ~20 better 95th percentile Hausdorff distances. Moreover, our unsupervised approach shows no statistically significant difference compared to the practical upper bound model using manual annotations from both datasets in TC region. The code is shared at https://github.com/Fjr9516/DA_nnUNet."
    },
    "2406.16692v1": {
      "title": "Stationary and Sparse Denoising Approach for Corticomuscular Causality Estimation",
      "url": "http://arxiv.org/abs/2406.16692v1",
      "authors": "Farwa Abbas, Verity McClelland, Zoran Cvetkovic, Wei Dai",
      "update_time": "2024-06-24",
      "abstract": "Objective: Cortico-muscular communication patterns are instrumental in understanding movement control. Estimating significant causal relationships between motor cortex electroencephalogram (EEG) and surface electromyogram (sEMG) from concurrently active muscles presents a formidable challenge since the relevant processes underlying muscle control are typically weak in comparison to measurement noise and background activities. Methodology: In this paper, a novel framework is proposed to simultaneously estimate the order of the autoregressive model of cortico-muscular interactions along with the parameters while enforcing stationarity condition in a convex program to ensure global optimality. The proposed method is further extended to a non-convex program to account for the presence of measurement noise in the recorded signals by introducing a wavelet sparsity assumption on the excitation noise in the model. Results: The proposed methodology is validated using both simulated data and neurophysiological signals. In case of simulated data, the performance of the proposed methods has been compared with the benchmark approaches in terms of order identification, computational efficiency, and goodness of fit in relation to various noise levels. In case of physiological signals our proposed methods are compared against the state-of-the-art approaches in terms of the ability to detect Granger causality. Significance: The proposed methods are shown to be effective in handling stationarity and measurement noise assumptions, revealing significant causal interactions from brain to muscles and vice versa."
    },
    "2406.16479v1": {
      "title": "Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing",
      "url": "http://arxiv.org/abs/2406.16479v1",
      "authors": "Erik B. Terres-Escudero, Javier Del Ser, Pablo Garc\u00eda-Bringas",
      "update_time": "2024-06-24",
      "abstract": "Advances in neural computation have predominantly relied on the gradient backpropagation algorithm (BP). However, the recent shift towards non-stationary data modeling has highlighted the limitations of this heuristic, exposing that its adaptation capabilities are far from those seen in biological brains. Unlike BP, where weight updates are computed through a reverse error propagation path, Hebbian learning dynamics provide synaptic updates using only information within the layer itself. This has spurred interest in biologically plausible learning algorithms, hypothesized to overcome BP's shortcomings. In this context, Hinton recently introduced the Forward-Forward Algorithm (FFA), which employs local learning rules for each layer and has empirically proven its efficacy in multiple data modeling tasks. In this work we argue that when employing a squared Euclidean norm as a goodness function driving the local learning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To verify this result, we compare the training behavior of FFA in analog networks with its Hebbian adaptation in spiking neural networks. Our experiments demonstrate that both versions of FFA produce similar accuracy and latent distributions. The findings herein reported provide empirical evidence linking biological learning rules with currently used training algorithms, thus paving the way towards extrapolating the positive outcomes from FFA to Hebbian learning rules. Simultaneously, our results imply that analog networks trained under FFA could be directly applied to neuromorphic computing, leading to reduced energy usage and increased computational speed.",
      "code_url": "https://github.com/erikberter/hebbian_ffa"
    },
    "2406.16453v1": {
      "title": "Learning in Wilson-Cowan model for metapopulation",
      "url": "http://arxiv.org/abs/2406.16453v1",
      "authors": "Raffaele Marino, Lorenzo Buffoni, Lorenzo Chicchi, Francesca Di Patti, Diego Febbe, Lorenzo Giambagli, Duccio Fanelli",
      "update_time": "2024-06-24",
      "abstract": "The Wilson-Cowan model for metapopulation, a Neural Mass Network Model, treats different subcortical regions of the brain as connected nodes, with connections representing various types of structural, functional, or effective neuronal connectivity between these regions. Each region comprises interacting populations of excitatory and inhibitory cells, consistent with the standard Wilson-Cowan model. By incorporating stable attractors into such a metapopulation model's dynamics, we transform it into a learning algorithm capable of achieving high image and text classification accuracy. We test it on MNIST and Fashion MNIST, in combination with convolutional neural networks, on CIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture (BERT), on IMDB, always showing high classification accuracy. These numerical evaluations illustrate that minimal modifications to the Wilson-Cowan model for metapopulation can reveal unique and previously unobserved dynamics.",
      "code_url": "https://github.com/raffaelemarino/learning_in_wilsoncowan"
    },
    "2406.16214v1": {
      "title": "Reducing the Sampling Burden of Fourier Sensing with a Non-rectangular Field-of-View",
      "url": "http://arxiv.org/abs/2406.16214v1",
      "authors": "Nicholas Dwork, Erin K. Englund, Alex J. Barker",
      "update_time": "2024-06-23",
      "abstract": "With Fourier sensing, it is commonly the case that the field-of-view (FOV), the area of space to be imaged, is known prior to reconstruction. To date, reconstruction algorithms have focused on FOVs with simple geometries: a rectangle or a hexagon. This yields sampling patterns that are more burdensome than necessary. Due to the reduced area of imaging possible with an arbitrary (e.g., non-rectangular) FOV, the number of samples required for a high-quality images is reduced. However, when an arbitrary FOV has been considered, the reconstruction algorithm is computationally expensive. In this manuscript, we present a method to reduce the sampling pattern for an arbitrary FOV with an accompanying direct (non-iterative) reconstruction algorithm. We also present a method to decrease the computational cost of the (iterative) model-based reconstruction (MBR) algorithm. We present results using MRI data of an ankle, a pineapple, and a brain."
    },
    "2406.16074v1": {
      "title": "CAVM: Conditional Autoregressive Vision Model for Contrast-Enhanced Brain Tumor MRI Synthesis",
      "url": "http://arxiv.org/abs/2406.16074v1",
      "authors": "Lujun Gui, Chuyang Ye, Tianyi Yan",
      "update_time": "2024-06-23",
      "abstract": "Contrast-enhanced magnetic resonance imaging (MRI) is pivotal in the pipeline of brain tumor segmentation and analysis. Gadolinium-based contrast agents, as the most commonly used contrast agents, are expensive and may have potential side effects, and it is desired to obtain contrast-enhanced brain tumor MRI scans without the actual use of contrast agents. Deep learning methods have been applied to synthesize virtual contrast-enhanced MRI scans from non-contrast images. However, as this synthesis problem is inherently ill-posed, these methods fall short in producing high-quality results. In this work, we propose Conditional Autoregressive Vision Model (CAVM) for improving the synthesis of contrast-enhanced brain tumor MRI. As the enhancement of image intensity grows with a higher dose of contrast agents, we assume that it is less challenging to synthesize a virtual image with a lower dose, where the difference between the contrast-enhanced and non-contrast images is smaller. Thus, CAVM gradually increases the contrast agent dosage and produces higher-dose images based on previous lower-dose ones until the final desired dose is achieved. Inspired by the resemblance between the gradual dose increase and the Chain-of-Thought approach in natural language processing, CAVM uses an autoregressive strategy with a decomposition tokenizer and a decoder. Specifically, the tokenizer is applied to obtain a more compact image representation for computational efficiency, and it decomposes the image into dose-variant and dose-invariant tokens. Then, a masked self-attention mechanism is developed for autoregression that gradually increases the dose of the virtual image based on the dose-variant tokens. Finally, the updated dose-variant tokens corresponding to the desired dose are decoded together with dose-invariant tokens to produce the final contrast-enhanced MRI."
    },
    "2406.16062v1": {
      "title": "Towards Biologically Plausible Computing: A Comprehensive Comparison",
      "url": "http://arxiv.org/abs/2406.16062v1",
      "authors": "Changze Lv, Yufei Gu, Zhengkang Guo, Zhibo Xu, Yixin Wu, Feiran Zhang, Tianyuan Shi, Zhenghua Wang, Ruicheng Yin, Yu Shang, Siqi Zhong, Xiaohua Wang, Muling Wu, Wenhao Liu, Tianlong Li, Jianhao Zhu, Cenyuan Zhang, Zixuan Ling, Xiaoqing Zheng",
      "update_time": "2024-06-23",
      "abstract": "Backpropagation is a cornerstone algorithm in training neural networks for supervised learning, which uses a gradient descent method to update network weights by minimizing the discrepancy between actual and desired outputs. Despite its pivotal role in propelling deep learning advancements, the biological plausibility of backpropagation is questioned due to its requirements for weight symmetry, global error computation, and dual-phase training. To address this long-standing challenge, many studies have endeavored to devise biologically plausible training algorithms. However, a fully biologically plausible algorithm for training multilayer neural networks remains elusive, and interpretations of biological plausibility vary among researchers. In this study, we establish criteria for biological plausibility that a desirable learning algorithm should meet. Using these criteria, we evaluate a range of existing algorithms considered to be biologically plausible, including Hebbian learning, spike-timing-dependent plasticity, feedback alignment, target propagation, predictive coding, forward-forward algorithm, perturbation learning, local losses, and energy-based learning. Additionally, we empirically evaluate these algorithms across diverse network architectures and datasets. We compare the feature representations learned by these algorithms with brain activity recorded by non-invasive devices under identical stimuli, aiming to identify which algorithm can most accurately replicate brain activity patterns. We are hopeful that this study could inspire the development of new biologically plausible algorithms for training multilayer networks, thereby fostering progress in both the fields of neuroscience and machine learning."
    },
    "2406.15665v1": {
      "title": "Brain states analysis of EEG data distinguishes Multiple Sclerosis",
      "url": "http://arxiv.org/abs/2406.15665v1",
      "authors": "Istv\u00e1n M\u00f3rocz, Mojtaba Jouzizadeh, Amir H. Ghaderi, Hamed Cheraghmakani, Seyed M. Baghbanian, Reza Khanbabaie, Andrei Mogoutov",
      "update_time": "2024-06-21",
      "abstract": "Background: The treatment of multiple sclerosis implies, beside protecting the body, the preserving of mental functions, considering how adverse cognitive decay affects quality of life. However a cognitive assessment is nowadays still realized with neuro-psychological tests without monitoring cognition on objective neurobiological grounds whereas the ongoing neural activity is in fact readily observable and readable.   Objective: The proposed method deciphers electrical brain states which as multi-dimensional cognetoms discriminate quantitatively normal from pathological patterns in the EEG signal.   Methods: Baseline recordings from a prior EEG study of 93 subjects, 37 with MS, were analyzed. Spectral bands served to compute cognetoms and categorize subsequent feature combination sets.   Results: Using cognetoms and spectral bands, a cross-sectional comparison separated patients from controls with a precision of 82\\% while using bands alone arrived at 64\\%. A few feature combinations were identified to drive this distinction.   Conclusions: Brain states analysis distinguishes successfully controls from patients with MS. Our results imply that this data-driven cross-sectional comparison of EEG data may complement customary diagnostic methods in neurology and psychiatry. However, thinking ahead in terms of quantitative monitoring of disease time course and treatment efficacy, we hope having established the analytic principles applicable to longitudinal clinical studies."
    },
    "2406.15656v1": {
      "title": "Adaptive Self-Supervised Consistency-Guided Diffusion Model for Accelerated MRI Reconstruction",
      "url": "http://arxiv.org/abs/2406.15656v1",
      "authors": "Mojtaba Safari, Zach Eidex, Shaoyan Pan, Richard L. J. Qiu, Xiaofeng Yang",
      "update_time": "2024-06-21",
      "abstract": "Purpose: To propose a self-supervised deep learning-based compressed sensing MRI (DL-based CS-MRI) method named \"Adaptive Self-Supervised Consistency Guided Diffusion Model (ASSCGD)\" to accelerate data acquisition without requiring fully sampled datasets. Materials and Methods: We used the fastMRI multi-coil brain axial T2-weighted (T2-w) dataset from 1,376 cases and single-coil brain quantitative magnetization prepared 2 rapid acquisition gradient echoes (MP2RAGE) T1 maps from 318 cases to train and test our model. Robustness against domain shift was evaluated using two out-of-distribution (OOD) datasets: multi-coil brain axial postcontrast T1 -weighted (T1c) dataset from 50 cases and axial T1-weighted (T1-w) dataset from 50 patients. Data were retrospectively subsampled at acceleration rates R in {2x, 4x, 8x}. ASSCGD partitions a random sampling pattern into two disjoint sets, ensuring data consistency during training. We compared our method with ReconFormer Transformer and SS-MRI, assessing performance using normalized mean squared error (NMSE), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM). Statistical tests included one-way analysis of variance (ANOVA) and multi-comparison Tukey's Honesty Significant Difference (HSD) tests. Results: ASSCGD preserved fine structures and brain abnormalities visually better than comparative methods at R = 8x for both multi-coil and single-coil datasets. It achieved the lowest NMSE at R in {4x, 8x}, and the highest PSNR and SSIM values at all acceleration rates for the multi-coil dataset. Similar trends were observed for the single-coil dataset, though SSIM values were comparable to ReconFormer at R in {2x, 8x}. These results were further confirmed by the voxel-wise correlation scatter plots. OOD results showed significant (p << 10^-5 ) improvements in undersampled image quality after reconstruction."
    },
    "2406.15537v1": {
      "title": "R&B -- Rhythm and Brain: Cross-subject Decoding of Music from Human Brain Activity",
      "url": "http://arxiv.org/abs/2406.15537v1",
      "authors": "Matteo Ferrante, Matteo Ciferri, Nicola Toschi",
      "update_time": "2024-06-21",
      "abstract": "Music is a universal phenomenon that profoundly influences human experiences across cultures. This study investigates whether music can be decoded from human brain activity measured with functional MRI (fMRI) during its perception. Leveraging recent advancements in extensive datasets and pre-trained computational models, we construct mappings between neural data and latent representations of musical stimuli. Our approach integrates functional and anatomical alignment techniques to facilitate cross-subject decoding, addressing the challenges posed by the low temporal resolution and signal-to-noise ratio (SNR) in fMRI data. Starting from the GTZan fMRI dataset, where five participants listened to 540 musical stimuli from 10 different genres while their brain activity was recorded, we used the CLAP (Contrastive Language-Audio Pretraining) model to extract latent representations of the musical stimuli and developed voxel-wise encoding models to identify brain regions responsive to these stimuli. By applying a threshold to the association between predicted and actual brain activity, we identified specific regions of interest (ROIs) which can be interpreted as key players in music processing. Our decoding pipeline, primarily retrieval-based, employs a linear map to project brain activity to the corresponding CLAP features. This enables us to predict and retrieve the musical stimuli most similar to those that originated the fMRI data. Our results demonstrate state-of-the-art identification accuracy, with our methods significantly outperforming existing approaches. Our findings suggest that neural-based music retrieval systems could enable personalized recommendations and therapeutic applications. Future work could use higher temporal resolution neuroimaging and generative models to improve decoding accuracy and explore the neural underpinnings of music perception and emotion."
    }
  },
  "EEG": {
    "2406.16692v1": {
      "title": "Stationary and Sparse Denoising Approach for Corticomuscular Causality Estimation",
      "url": "http://arxiv.org/abs/2406.16692v1",
      "authors": "Farwa Abbas, Verity McClelland, Zoran Cvetkovic, Wei Dai",
      "update_time": "2024-06-24",
      "abstract": "Objective: Cortico-muscular communication patterns are instrumental in understanding movement control. Estimating significant causal relationships between motor cortex electroencephalogram (EEG) and surface electromyogram (sEMG) from concurrently active muscles presents a formidable challenge since the relevant processes underlying muscle control are typically weak in comparison to measurement noise and background activities. Methodology: In this paper, a novel framework is proposed to simultaneously estimate the order of the autoregressive model of cortico-muscular interactions along with the parameters while enforcing stationarity condition in a convex program to ensure global optimality. The proposed method is further extended to a non-convex program to account for the presence of measurement noise in the recorded signals by introducing a wavelet sparsity assumption on the excitation noise in the model. Results: The proposed methodology is validated using both simulated data and neurophysiological signals. In case of simulated data, the performance of the proposed methods has been compared with the benchmark approaches in terms of order identification, computational efficiency, and goodness of fit in relation to various noise levels. In case of physiological signals our proposed methods are compared against the state-of-the-art approaches in terms of the ability to detect Granger causality. Significance: The proposed methods are shown to be effective in handling stationarity and measurement noise assumptions, revealing significant causal interactions from brain to muscles and vice versa."
    },
    "2406.15665v1": {
      "title": "Brain states analysis of EEG data distinguishes Multiple Sclerosis",
      "url": "http://arxiv.org/abs/2406.15665v1",
      "authors": "Istv\u00e1n M\u00f3rocz, Mojtaba Jouzizadeh, Amir H. Ghaderi, Hamed Cheraghmakani, Seyed M. Baghbanian, Reza Khanbabaie, Andrei Mogoutov",
      "update_time": "2024-06-21",
      "abstract": "Background: The treatment of multiple sclerosis implies, beside protecting the body, the preserving of mental functions, considering how adverse cognitive decay affects quality of life. However a cognitive assessment is nowadays still realized with neuro-psychological tests without monitoring cognition on objective neurobiological grounds whereas the ongoing neural activity is in fact readily observable and readable.   Objective: The proposed method deciphers electrical brain states which as multi-dimensional cognetoms discriminate quantitatively normal from pathological patterns in the EEG signal.   Methods: Baseline recordings from a prior EEG study of 93 subjects, 37 with MS, were analyzed. Spectral bands served to compute cognetoms and categorize subsequent feature combination sets.   Results: Using cognetoms and spectral bands, a cross-sectional comparison separated patients from controls with a precision of 82\\% while using bands alone arrived at 64\\%. A few feature combinations were identified to drive this distinction.   Conclusions: Brain states analysis distinguishes successfully controls from patients with MS. Our results imply that this data-driven cross-sectional comparison of EEG data may complement customary diagnostic methods in neurology and psychiatry. However, thinking ahead in terms of quantitative monitoring of disease time course and treatment efficacy, we hope having established the analytic principles applicable to longitudinal clinical studies."
    },
    "2406.15269v1": {
      "title": "You Only Acquire Sparse-channel (YOAS): A Unified Framework for Dense-channel EEG Generation",
      "url": "http://arxiv.org/abs/2406.15269v1",
      "authors": "Hongyu Chen, Weiming Zeng, Luhui Cai, Yueyang Li, Lei Wang, Jia Lu, Hongjie Yan, Wai Ting Siok, Nizhuan Wang",
      "update_time": "2024-06-21",
      "abstract": "High-precision acquisition of dense-channel electroencephalogram (EEG) signals is often impeded by the costliness and lack of portability of equipment. In contrast, generating dense-channel EEG signals effectively from sparse channels shows promise and economic viability. However, sparse-channel EEG poses challenges such as reduced spatial resolution, information loss, signal mixing, and heightened susceptibility to noise and interference. To address these challenges, we first theoretically formulate the dense-channel EEG generation problem as by optimizing a set of cross-channel EEG signal generation problems. Then, we propose the YOAS framework for generating dense-channel data from sparse-channel EEG signals. The YOAS totally consists of four sequential stages: Data Preparation, Data Preprocessing, Biased-EEG Generation, and Synthetic EEG Generation. Data Preparation and Preprocessing carefully consider the distribution of EEG electrodes and low signal-to-noise ratio problem of EEG signals. Biased-EEG Generation includes sub-modules of BiasEEGGanFormer and BiasEEGDiffFormer, which facilitate long-term feature extraction with attention and generate signals by combining electrode position alignment with diffusion model, respectively. Synthetic EEG Generation synthesizes the final signals, employing a deduction paradigm for multi-channel EEG generation. Extensive experiments confirmed YOAS's feasibility, efficiency, and theoretical validity, even remarkably enhancing data discernibility. This breakthrough in dense-channel EEG signal generation from sparse-channel data opens new avenues for exploration in EEG signal processing and application."
    },
    "2406.15155v1": {
      "title": "Introducing the modularity graph: an application to brain functional networks",
      "url": "http://arxiv.org/abs/2406.15155v1",
      "authors": "Tiziana Cattai, Camilla Caporali, Marie-Constance Corsi, Stefania Colonnese",
      "update_time": "2024-06-21",
      "abstract": "In signal processing, exploring complex systems through network representations has become an area of growing interest. This study introduces the modularity graph, a new graph-based feature, to highlight the relationship across the graph communities. After showing an application to the random graph class known as Stochastic Block Model, we consider the brain functional connectivity network estimated from real EEG data. The modularity graph provides a quantitative framework for examining the interactions between neuron clusters within the brain's network. The modularity graph works alongside multiscale community detection algorithms, thereby enabling the identification of community structures at various scales. After introducing the modularity graph, we apply it to the brain functional connectivity network, estimated from publicly available EEG recordings of motor imagery experiments. Statistical analysis across multiple scales shows that the modularity graph differs for the distinct brain connectivity states associated with various motor imagery tasks. This work emphasizes the application of signal on graph processing techniques to understand brain behavior during specific cognitive tasks, leveraging the novel modularity graph to identify patterns of brain connectivity in different cognitive conditions. This approach sets the stage for further signal on graph analysis to devise brain network modularity, and to gain insights into the motor imagery mechanisms."
    },
    "2406.15142v1": {
      "title": "Community Detection from Multiple Observations: from Product Graph Model to Brain Applications",
      "url": "http://arxiv.org/abs/2406.15142v1",
      "authors": "Tiziana Cattai, Gaetano Scarano, Marie-Constance Corsi, Fabrizio De Vico Fallani, Stefania Colonnese",
      "update_time": "2024-06-21",
      "abstract": "This paper proposes a multilayer graph model for the community detection from multiple observations. This is a very frequent situation, when different estimators are applied to infer graph edges from signals at its nodes, or when different signal measurements are carried out. The multilayer network stacks the graph observations at the different layers, and it links replica nodes at adjacent layers. This configuration matches the Cartesian product between the ground truth graph and a path graph, where the number of nodes corresponds to the number of the observations. Stemming on the algebraic structure of the Laplacian of the Cartesian multilayer network, we infer a subset of the eigenvectors of the true graph and perform community detection. Experimental results on synthetic graphs prove the accuracy of the method, which outperforms state-of-the-art approaches in terms of ability of correctly detecting graph communities. Finally, we show the application of our method to discriminate different brain networks derived from real EEG data collected during motor imagery experiments. We conclude that our approach appears promising in identifying graph communities when multiple observations of the graph are available and it results promising for EEG-based motor imagery applications."
    },
    "2406.14014v1": {
      "title": "Feature Fusion Based on Mutual-Cross-Attention Mechanism for EEG Emotion Recognition",
      "url": "http://arxiv.org/abs/2406.14014v1",
      "authors": "Yimin Zhao, Jin Gu",
      "update_time": "2024-06-20",
      "abstract": "An objective and accurate emotion diagnostic reference is vital to psychologists, especially when dealing with patients who are difficult to communicate with for pathological reasons. Nevertheless, current systems based on Electroencephalography (EEG) data utilized for sentiment discrimination have some problems, including excessive model complexity, mediocre accuracy, and limited interpretability. Consequently, we propose a novel and effective feature fusion mechanism named Mutual-Cross-Attention (MCA). Combining with a specially customized 3D Convolutional Neural Network (3D-CNN), this purely mathematical mechanism adeptly discovers the complementary relationship between time-domain and frequency-domain features in EEG data. Furthermore, the new designed Channel-PSD-DE 3D feature also contributes to the high performance. The proposed method eventually achieves 99.49% (valence) and 99.30% (arousal) accuracy on DEAP dataset.",
      "code_url": "https://github.com/ztony0712/MCA"
    },
    "2406.13570v1": {
      "title": "System Immersion of a Driving Simulator Affects the Oscillatory Brain Activity",
      "url": "http://arxiv.org/abs/2406.13570v1",
      "authors": "Nikol Figalov\u00e1, J\u00fcrgen Pichen, Lewis L. Chuang, Martin Baumann, Olga Pollatos",
      "update_time": "2024-06-19",
      "abstract": "The technological properties of a system delivering simulation experience are a crucial dimension of immersion. To create a sense of presence and reproduce drivers behaviour as realistically as possible, we need reliable driving simulators that allow drivers to become highly immersed. This study investigates the impact of a system immersion of a driving simulator on the drivers' brain activity while operating a conditionally automated vehicle. Nineteen participants drove approximately 40 minutes while their brain activity was recorded using electroencephalography (EEG). We found a significant effect of the system immersion in the occipital and parietal areas, primarily in the high-Beta bandwidth. No effect was found in the Theta, Alpha, and low-Beta bandwidths. These findings suggest that the system immersion might influence the drivers' physiological arousal, consequently influencing their cognitive and emotional processes."
    },
    "2406.11500v2": {
      "title": "ESI-GAL: EEG Source Imaging-based Kinematics Parameter Estimation for Grasp and Lift Task",
      "url": "http://arxiv.org/abs/2406.11500v2",
      "authors": "Anant Jain, Lalan Kumar",
      "update_time": "2024-06-18",
      "abstract": "Objective: Electroencephalogram (EEG) signals-based motor kinematics prediction (MKP) has been an active area of research to develop brain-computer interface (BCI) systems such as exosuits, prostheses, and rehabilitation devices. However, EEG source imaging (ESI) based kinematics prediction is sparsely explored in the literature. Approach: In this study, pre-movement EEG features are utilized to predict three-dimensional (3D) hand kinematics for the grasp-and-lift motor task. A public dataset, WAY-EEG-GAL, is utilized for MKP analysis. In particular, sensor-domain (EEG data) and source-domain (ESI data) based features from the frontoparietal region are explored for MKP. Deep learning-based models are explored to achieve efficient kinematics decoding. Various time-lagged and window sizes are analyzed for hand kinematics prediction. Subsequently, intra-subject and inter-subject MKP analysis is performed to investigate the subject-specific and subject-independent motor-learning capabilities of the neural decoders. The Pearson correlation coefficient (PCC) is used as the performance metric for kinematics trajectory decoding. Main results: The rEEGNet neural decoder achieved the best performance with sensor-domain and source-domain features with the time lag and window size of 100 ms and 450 ms, respectively. The highest mean PCC values of 0.790, 0.795, and 0.637 are achieved using sensor-domain features, while 0.769, 0.777, and 0.647 are achieved using source-domain features in x, y, and z-directions, respectively. Significance: This study explores the feasibility of trajectory prediction using EEG sensor-domain and source-domain EEG features for the grasp-and-lift task. Furthermore, inter-subject trajectory estimation is performed using the proposed deep learning decoder with EEG source domain features."
    },
    "2406.10184v2": {
      "title": "Hyperbolic embedding of brain networks as a tool for epileptic seizures forecasting",
      "url": "http://arxiv.org/abs/2406.10184v2",
      "authors": "Martin Guillemaud, Louis Cousyn, Vincent Navarro, Mario Chavez",
      "update_time": "2024-06-18",
      "abstract": "The evidence indicates that intracranial EEG connectivity, as estimated from daily resting state recordings from epileptic patients, may be capable of identifying preictal states. In this study, we employed hyperbolic embedding of brain networks to capture non-trivial patterns that discriminate between connectivity networks from days with (preictal) and without (interictal) seizure. A statistical model was constructed by combining hyperbolic geometry and machine learning tools, which allowed for the estimation of the probability of an upcoming seizure. The results demonstrated that representing brain networks in a hyperbolic space enabled an accurate discrimination (85%) between interictal (no-seizure) and preictal (seizure within the next 24 hours) states. The proposed method also demonstrated excellent prediction performances, with an overall accuracy of 87% and an F1-score of 89% (mean Brier score and Brier skill score of 0.12 and 0.37, respectively). In conclusion, our findings indicate that representations of brain connectivity in a latent geometry space can reveal a daily and reliable signature of the upcoming seizure(s), thus providing a promising biomarker for seizure forecasting."
    },
    "2406.09608v1": {
      "title": "Human-Machine Interface Evaluation Using EEG in Driving Simulator",
      "url": "http://arxiv.org/abs/2406.09608v1",
      "authors": "Y. C. Liu, N. Figalova, M. Baumann, K Bengler",
      "update_time": "2024-06-13",
      "abstract": "Automated vehicles are pictured as the future of transportation, and facilitating safer driving is only one of the many benefits. However, due to the constantly changing role of the human driver, users are easily confused and have little knowledge about their responsibilities. Being the bridge between automation and human, the human-machine interface (HMI) is of great importance to driving safety. This study was conducted in a static driving simulator. Three HMI designs were developed, among which significant differences in mental workload using NASA-TLX and the subjective transparency test were found. An electroencephalogram was applied throughout the study to determine if differences in the mental workload could also be found using EEG's spectral power analysis. Results suggested that more studies are required to determine the effectiveness of the spectral power of EEG on mental workload, but the three interface designs developed in this study could serve as a solid basis for future research to evaluate the effectiveness of psychophysiological measures. Marie Sklodowska-Curie Actions; Innovative Training Network (ITN); SHAPE-IT; Grant number 860410; Publication date: [27 July 2023]; DOI: [10.1109/IV55152.2023.10186567]"
    }
  },
  "BCI": {
    "2406.14801v1": {
      "title": "Model Predictive Control of the Neural Manifold",
      "url": "http://arxiv.org/abs/2406.14801v1",
      "authors": "Christof Fehrman, C. Daniel Meliza",
      "update_time": "2024-06-21",
      "abstract": "Neural manifolds are an attractive theoretical framework for characterizing the complex behaviors of neural populations. However, many of the tools for identifying these low-dimensional subspaces are correlational and provide limited insight into the underlying dynamics. The ability to precisely control this latent activity would allow researchers to investigate the structure and function of neural manifolds. Employing techniques from the field of optimal control, we simulate controlling the latent dynamics of a neural population using closed-loop, dynamically generated sensory inputs. Using a spiking neural network (SNN) as a model of a neural circuit, we find low-dimensional representations of both the network activity (the neural manifold) and a set of salient visual stimuli. With a data-driven latent dynamics model, we apply model predictive control (MPC) to provide anticipatory, optimal control over the trajectory of the circuit in a latent space. We are able to control the latent dynamics of the SNN to follow several reference trajectories despite observing only a subset of neurons and with a substantial amount of unknown noise injected into the network. These results provide a framework to experimentally test for causal relationships between manifold dynamics and other variables of interest such as organismal behavior and BCI performance."
    },
    "2406.14179v1": {
      "title": "Single Channel-based Motor Imagery Classification using Fisher's Ratio and Pearson Correlation",
      "url": "http://arxiv.org/abs/2406.14179v1",
      "authors": "Sonal Santosh Baberwal, Tomas Ward, Shirley Coyle",
      "update_time": "2024-06-20",
      "abstract": "Motor imagery-based BCI systems have been promising and gaining popularity in rehabilitation and Activities of daily life(ADL). Despite this, the technology is still emerging and has not yet been outside the laboratory constraints. Channel reduction is one contributing avenue to make these systems part of ADL. Although Motor Imagery classification heavily depends on spatial factors, single channel-based classification remains an avenue to be explored thoroughly. Since Fisher's ratio and Pearson Correlation are powerful measures actively used in the domain, we propose an integrated framework (FRPC integrated framework) that integrates Fisher's Ratio to select the best channel and Pearson correlation to select optimal filter banks and extract spectral and temporal features respectively. The framework is tested for a 2-class motor imagery classification on 2 open-source datasets and 1 collected dataset and compared with state-of-art work. Apart from implementing the framework, this study also explores the most optimal channel among all the subjects and later explores classes where the single-channel framework is efficient."
    },
    "2406.11799v1": {
      "title": "Mix-Domain Contrastive Learning for Unpaired H&E-to-IHC Stain Translation",
      "url": "http://arxiv.org/abs/2406.11799v1",
      "authors": "Song Wang, Zhong Zhang, Huan Yan, Ming Xu, Guanghui Wang",
      "update_time": "2024-06-17",
      "abstract": "H&E-to-IHC stain translation techniques offer a promising solution for precise cancer diagnosis, especially in low-resource regions where there is a shortage of health professionals and limited access to expensive equipment. Considering the pixel-level misalignment of H&E-IHC image pairs, current research explores the pathological consistency between patches from the same positions of the image pair. However, most of them overemphasize the correspondence between domains or patches, overlooking the side information provided by the non-corresponding objects. In this paper, we propose a Mix-Domain Contrastive Learning (MDCL) method to leverage the supervision information in unpaired H&E-to-IHC stain translation. Specifically, the proposed MDCL method aggregates the inter-domain and intra-domain pathology information by estimating the correlation between the anchor patch and all the patches from the matching images, encouraging the network to learn additional contrastive knowledge from mixed domains. With the mix-domain pathology information aggregation, MDCL enhances the pathological consistency between the corresponding patches and the component discrepancy of the patches from the different positions of the generated IHC image. Extensive experiments on two H&E-to-IHC stain translation datasets, namely MIST and BCI, demonstrate that the proposed method achieves state-of-the-art performance across multiple metrics."
    },
    "2406.11568v1": {
      "title": "Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models",
      "url": "http://arxiv.org/abs/2406.11568v1",
      "authors": "Sheng Feng, Heyang Liu, Yu Wang, Yanfeng Wang",
      "update_time": "2024-06-17",
      "abstract": "In this paper, we introduce a groundbreaking end-to-end (E2E) framework for decoding invasive brain signals, marking a significant advancement in the field of speech neuroprosthesis. Our methodology leverages the comprehensive reasoning abilities of large language models (LLMs) to facilitate direct decoding. By fully integrating LLMs, we achieve results comparable to the state-of-the-art cascade models. Our findings underscore the immense potential of E2E frameworks in speech neuroprosthesis, particularly as the technology behind brain-computer interfaces (BCIs) and the availability of relevant datasets continue to evolve. This work not only showcases the efficacy of combining LLMs with E2E decoding for enhancing speech neuroprosthesis but also sets a new direction for future research in BCI applications, underscoring the impact of LLMs in decoding complex neural signals for communication restoration. Code will be made available at https://github.com/FsFrancis15/BrainLLM.",
      "code_url": "https://github.com/fsfrancis15/brainllm"
    },
    "2406.11500v2": {
      "title": "ESI-GAL: EEG Source Imaging-based Kinematics Parameter Estimation for Grasp and Lift Task",
      "url": "http://arxiv.org/abs/2406.11500v2",
      "authors": "Anant Jain, Lalan Kumar",
      "update_time": "2024-06-18",
      "abstract": "Objective: Electroencephalogram (EEG) signals-based motor kinematics prediction (MKP) has been an active area of research to develop brain-computer interface (BCI) systems such as exosuits, prostheses, and rehabilitation devices. However, EEG source imaging (ESI) based kinematics prediction is sparsely explored in the literature. Approach: In this study, pre-movement EEG features are utilized to predict three-dimensional (3D) hand kinematics for the grasp-and-lift motor task. A public dataset, WAY-EEG-GAL, is utilized for MKP analysis. In particular, sensor-domain (EEG data) and source-domain (ESI data) based features from the frontoparietal region are explored for MKP. Deep learning-based models are explored to achieve efficient kinematics decoding. Various time-lagged and window sizes are analyzed for hand kinematics prediction. Subsequently, intra-subject and inter-subject MKP analysis is performed to investigate the subject-specific and subject-independent motor-learning capabilities of the neural decoders. The Pearson correlation coefficient (PCC) is used as the performance metric for kinematics trajectory decoding. Main results: The rEEGNet neural decoder achieved the best performance with sensor-domain and source-domain features with the time lag and window size of 100 ms and 450 ms, respectively. The highest mean PCC values of 0.790, 0.795, and 0.637 are achieved using sensor-domain features, while 0.769, 0.777, and 0.647 are achieved using source-domain features in x, y, and z-directions, respectively. Significance: This study explores the feasibility of trajectory prediction using EEG sensor-domain and source-domain EEG features for the grasp-and-lift task. Furthermore, inter-subject trajectory estimation is performed using the proposed deep learning decoder with EEG source domain features."
    },
    "2406.11081v1": {
      "title": "A Bayesian dynamic stopping method for evoked response brain-computer interfacing",
      "url": "http://arxiv.org/abs/2406.11081v1",
      "authors": "Sara Ahmadi, Peter Desain, Jordy Thielen",
      "update_time": "2024-06-16",
      "abstract": "As brain-computer interfacing (BCI) systems transition from assistive technology to more diverse applications, their speed, reliability, and user experience become increasingly important. Dynamic stopping methods enhance BCI system speed by deciding at any moment whether to output a result or wait for more information. Such approach leverages trial variance, allowing good trials to be detected earlier, thereby speeding up the process without significantly compromising accuracy. Existing dynamic stopping algorithms typically optimize measures such as symbols per minute (SPM) and information transfer rate (ITR). However, these metrics may not accurately reflect system performance for specific applications or user types. Moreover, many methods depend on arbitrary thresholds or parameters that require extensive training data. We propose a model-based approach that takes advantage of the analytical knowledge that we have about the underlying classification model. By using a risk minimisation approach, our model allows precise control over the types of errors and the balance between precision and speed. This adaptability makes it ideal for customizing BCI systems to meet the diverse needs of various applications. We validate our proposed method on a publicly available dataset, comparing it with established static and dynamic stopping methods. Our results demonstrate that our approach offers a broad range of accuracy-speed trade-offs and achieves higher precision than baseline stopping methods."
    },
    "2406.07481v1": {
      "title": "The end of multiple choice tests: using AI to enhance assessment",
      "url": "http://arxiv.org/abs/2406.07481v1",
      "authors": "Michael Klymkowsky, Melanie M. Cooper",
      "update_time": "2024-06-11",
      "abstract": "Effective teaching relies on knowing what students know-or think they know. Revealing student thinking is challenging. Often used because of their ease of grading, even the best multiple choice (MC) tests, those using research based distractors (wrong answers) are intrinsically limited in the insights they provide due to two factors. When distractors do not reflect student beliefs they can be ignored, increasing the likelihood that the correct answer will be chosen by chance. Moreover, making the correct choice does not guarantee that the student understands why it is correct. To address these limitations, we recommend asking students to explain why they chose their answer, and why \"wrong\" choices are wrong. Using a discipline-trained artificial intelligence-based bot it is possible to analyze their explanations, identifying the concepts and scientific principles that maybe missing or misapplied. The bot also makes suggestions for how instructors can use these data to better guide student thinking. In a small \"proof of concept\" study, we tested this approach using questions from the Biology Concepts Instrument (BCI). The result was rapid, informative, and provided actionable feedback on student thinking. It appears that the use of AI addresses the weaknesses of conventional MC test. It seems likely that incorporating AI-analyzed formative assessments will lead to improved overall learning outcomes."
    },
    "2406.03115v3": {
      "title": "GET: A Generative EEG Transformer for Continuous Context-Based Neural Signals",
      "url": "http://arxiv.org/abs/2406.03115v3",
      "authors": "Omair Ali, Muhammad Saif-ur-Rehman, Marita Metzler, Tobias Glasmachers, Ioannis Iossifidis, Christian Klaes",
      "update_time": "2024-06-10",
      "abstract": "Generating continuous electroencephalography (EEG) signals through advanced artificial neural networks presents a novel opportunity to enhance brain-computer interface (BCI) technology. This capability has the potential to significantly enhance applications ranging from simulating dynamic brain activity and data augmentation to improving real-time epilepsy detection and BCI inference. By harnessing generative transformer neural networks, specifically designed for EEG signal generation, we can revolutionize the interpretation and interaction with neural data. Generative AI has demonstrated significant success across various domains, from natural language processing (NLP) and computer vision to content creation in visual arts and music. It distinguishes itself by using large-scale datasets to construct context windows during pre-training, a technique that has proven particularly effective in NLP, where models are fine-tuned for specific downstream tasks after extensive foundational training. However, the application of generative AI in the field of BCIs, particularly through the development of continuous, context-rich neural signal generators, has been limited. To address this, we introduce the Generative EEG Transformer (GET), a model leveraging transformer architecture tailored for EEG data. The GET model is pre-trained on diverse EEG datasets, including motor imagery and alpha wave datasets, enabling it to produce high-fidelity neural signals that maintain contextual integrity. Our empirical findings indicate that GET not only faithfully reproduces the frequency spectrum of the training data and input prompts but also robustly generates continuous neural signals. By adopting the successful training strategies of the NLP domain for BCIs, the GET sets a new standard for the development and application of neural signal generation technologies."
    },
    "2406.01512v1": {
      "title": "MAD: Multi-Alignment MEG-to-Text Decoding",
      "url": "http://arxiv.org/abs/2406.01512v1",
      "authors": "Yiqian Yang, Hyejeong Jo, Yiqun Duan, Qiang Zhang, Jinni Zhou, Won Hee Lee, Renjing Xu, Hui Xiong",
      "update_time": "2024-06-03",
      "abstract": "Deciphering language from brain activity is a crucial task in brain-computer interface (BCI) research. Non-invasive cerebral signaling techniques including electroencephalography (EEG) and magnetoencephalography (MEG) are becoming increasingly popular due to their safety and practicality, avoiding invasive electrode implantation. However, current works under-investigated three points: 1) a predominant focus on EEG with limited exploration of MEG, which provides superior signal quality; 2) poor performance on unseen text, indicating the need for models that can better generalize to diverse linguistic contexts; 3) insufficient integration of information from other modalities, which could potentially constrain our capacity to comprehensively understand the intricate dynamics of brain activity.   This study presents a novel approach for translating MEG signals into text using a speech-decoding framework with multiple alignments. Our method is the first to introduce an end-to-end multi-alignment framework for totally unseen text generation directly from MEG signals. We achieve an impressive BLEU-1 score on the $\\textit{GWilliams}$ dataset, significantly outperforming the baseline from 5.49 to 10.44 on the BLEU-1 metric. This improvement demonstrates the advancement of our model towards real-world applications and underscores its potential in advancing BCI research. Code is available at $\\href{https://github.com/NeuSpeech/MAD-MEG2text}{https://github.com/NeuSpeech/MAD-MEG2text}$.",
      "code_url": "https://github.com/neuspeech/mad-meg2text"
    },
    "2406.00470v1": {
      "title": "MI 2 MI: Training Dyad with Collaborative Brain-Computer Interface and Cooperative Motor Imagery Tasks for Better BCI Performance",
      "url": "http://arxiv.org/abs/2406.00470v1",
      "authors": "Shiwei Cheng, Jialing Wang",
      "update_time": "2024-06-01",
      "abstract": "Collaborative brain-computer interface (cBCI) that conduct motor imagery (MI) among multiple users has the potential not only to improve overall BCI performance by integrating information from multiple users, but also to leverage individuals' performance in decision-making or control. However, existed research mostly focused on the brain signals changes through a single user, not noticing the possible interaction between users during the collaboration. In this work, we utilized cBCI and designed a cooperative four-classes MI task to train the dyad. A humanoid robot would stimulate the dyad to conduct both left/right hand and tongue/foot MI. Single user was asked to conduct single MI task before and after the cooperative MI task. The experiment results showed that our training could activate better performance (e.g., high quality of EEG /MI classification accuracy) for the single user than single MI task, and the single user also obtained better single MI performance after cooperative MI training."
    }
  },
  "fMRI": {
    "2406.15537v1": {
      "title": "R&B -- Rhythm and Brain: Cross-subject Decoding of Music from Human Brain Activity",
      "url": "http://arxiv.org/abs/2406.15537v1",
      "authors": "Matteo Ferrante, Matteo Ciferri, Nicola Toschi",
      "update_time": "2024-06-21",
      "abstract": "Music is a universal phenomenon that profoundly influences human experiences across cultures. This study investigates whether music can be decoded from human brain activity measured with functional MRI (fMRI) during its perception. Leveraging recent advancements in extensive datasets and pre-trained computational models, we construct mappings between neural data and latent representations of musical stimuli. Our approach integrates functional and anatomical alignment techniques to facilitate cross-subject decoding, addressing the challenges posed by the low temporal resolution and signal-to-noise ratio (SNR) in fMRI data. Starting from the GTZan fMRI dataset, where five participants listened to 540 musical stimuli from 10 different genres while their brain activity was recorded, we used the CLAP (Contrastive Language-Audio Pretraining) model to extract latent representations of the musical stimuli and developed voxel-wise encoding models to identify brain regions responsive to these stimuli. By applying a threshold to the association between predicted and actual brain activity, we identified specific regions of interest (ROIs) which can be interpreted as key players in music processing. Our decoding pipeline, primarily retrieval-based, employs a linear map to project brain activity to the corresponding CLAP features. This enables us to predict and retrieve the musical stimuli most similar to those that originated the fMRI data. Our results demonstrate state-of-the-art identification accuracy, with our methods significantly outperforming existing approaches. Our findings suggest that neural-based music retrieval systems could enable personalized recommendations and therapeutic applications. Future work could use higher temporal resolution neuroimaging and generative models to improve decoding accuracy and explore the neural underpinnings of music perception and emotion."
    },
    "2406.12179v1": {
      "title": "The Wisdom of a Crowd of Brains: A Universal Brain Encoder",
      "url": "http://arxiv.org/abs/2406.12179v1",
      "authors": "Roman Beliy, Navve Wasserman, Amit Zalcher, Michal Irani",
      "update_time": "2024-06-18",
      "abstract": "Image-to-fMRI encoding is important for both neuroscience research and practical applications. However, such \"Brain-Encoders\" have been typically trained per-subject and per fMRI-dataset, thus restricted to very limited training data. In this paper we propose a Universal Brain-Encoder, which can be trained jointly on data from many different subjects/datasets/machines. What makes this possible is our new voxel-centric Encoder architecture, which learns a unique \"voxel-embedding\" per brain-voxel. Our Encoder trains to predict the response of each brain-voxel on every image, by directly computing the cross-attention between the brain-voxel embedding and multi-level deep image features. This voxel-centric architecture allows the functional role of each brain-voxel to naturally emerge from the voxel-image cross-attention. We show the power of this approach to (i) combine data from multiple different subjects (a \"Crowd of Brains\") to improve each individual brain-encoding, (ii) quick & effective Transfer-Learning across subjects, datasets, and machines (e.g., 3-Tesla, 7-Tesla), with few training examples, and (iii) use the learned voxel-embeddings as a powerful tool to explore brain functionality (e.g., what is encoded where in the brain)."
    },
    "2406.12065v1": {
      "title": "STNAGNN: Spatiotemporal Node Attention Graph Neural Network for Task-based fMRI Analysis",
      "url": "http://arxiv.org/abs/2406.12065v1",
      "authors": "Jiyao Wang, Nicha C. Dvornek, Peiyu Duan, Lawrence H. Staib, Pamela Ventola, James S. Duncan",
      "update_time": "2024-06-17",
      "abstract": "Task-based fMRI uses actions or stimuli to trigger task-specific brain responses and measures them using BOLD contrast. Despite the significant task-induced spatiotemporal brain activation fluctuations, most studies on task-based fMRI ignore the task context information aligned with fMRI and consider task-based fMRI a coherent sequence. In this paper, we show that using the task structures as data-driven guidance is effective for spatiotemporal analysis. We propose STNAGNN, a GNN-based spatiotemporal architecture, and validate its performance in an autism classification task. The trained model is also interpreted for identifying autism-related spatiotemporal brain biomarkers."
    },
    "2406.09387v1": {
      "title": "Oblivious subspace embeddings for compressed Tucker decompositions",
      "url": "http://arxiv.org/abs/2406.09387v1",
      "authors": "Matthew Pietrosanu, Bei Jiang, Linglong Kong",
      "update_time": "2024-06-13",
      "abstract": "Emphasis in the tensor literature on random embeddings (tools for low-distortion dimension reduction) for the canonical polyadic (CP) tensor decomposition has left analogous results for the more expressive Tucker decomposition comparatively lacking. This work establishes general Johnson-Lindenstrauss (JL) type guarantees for the estimation of Tucker decompositions when an oblivious random embedding is applied along each mode. When these embeddings are drawn from a JL-optimal family, the decomposition can be estimated within $\\varepsilon$ relative error under restrictions on the embedding dimension that are in line with recent CP results. We implement a higher-order orthogonal iteration (HOOI) decomposition algorithm with random embeddings to demonstrate the practical benefits of this approach and its potential to improve the accessibility of otherwise prohibitive tensor analyses. On moderately large face image and fMRI neuroimaging datasets, empirical results show that substantial dimension reduction is possible with minimal increase in reconstruction error relative to traditional HOOI ($\\leq$5% larger error, 50%-60% lower computation time for large models with 50% dimension reduction along each mode). Especially for large tensors, our method outperforms traditional higher-order singular value decomposition (HOSVD) and recently proposed TensorSketch methods."
    },
    "2406.08266v2": {
      "title": "Refining Self-Supervised Learnt Speech Representation using Brain Activations",
      "url": "http://arxiv.org/abs/2406.08266v2",
      "authors": "Hengyu Li, Kangdi Mei, Zhaoci Liu, Yang Ai, Liping Chen, Jie Zhang, Zhenhua Ling",
      "update_time": "2024-06-13",
      "abstract": "It was shown in literature that speech representations extracted by self-supervised pre-trained models exhibit similarities with brain activations of human for speech perception and fine-tuning speech representation models on downstream tasks can further improve the similarity. However, it still remains unclear if this similarity can be used to optimize the pre-trained speech models. In this work, we therefore propose to use the brain activations recorded by fMRI to refine the often-used wav2vec2.0 model by aligning model representations toward human neural responses. Experimental results on SUPERB reveal that this operation is beneficial for several downstream tasks, e.g., speaker verification, automatic speech recognition, intent classification.One can then consider the proposed method as a new alternative to improve self-supervised speech models."
    },
    "2406.08140v1": {
      "title": "Functional voxel hierarchy and afferent capacity revealed mental state transition on dynamic correlation resting-state fMRI",
      "url": "http://arxiv.org/abs/2406.08140v1",
      "authors": "Dong Soo Lee, Hyun Joo Kim, Youngmin Huh, Yeon Koo Kang, Wonseok Whi, Hyekyoung Lee, Hyejin Kang",
      "update_time": "2024-06-12",
      "abstract": "Voxel hierarchy on dynamic brain graphs is produced by k core percolation on functional dynamic amplitude correlation of resting-state fMRI. Directed graphs and their afferent/efferent capacities are produced by Markov modeling of the universal cover of undirected graphs simultaneously with the calculation of volume entropy. Positive and unsigned negative brain graphs were analyzed separately on sliding-window representation to underpin the visualization and quantitation of mental dynamic states with their transitions. Voxel hierarchy animation maps of positive graphs revealed abrupt changes in coreness k and kmaxcore, which we called mental state transitions. Afferent voxel capacities of the positive graphs also revealed transient modules composed of dominating voxels/independent components and their exchanges representing mental state transitions. Animation and quantification plots of voxel hierarchy and afferent capacity corroborated each other in underpinning mental state transitions and afferent module exchange on the positive directed functional connectivity graphs. We propose the use of spatiotemporal trajectories of voxels on positive dynamic graphs to construct hierarchical structures by k core percolation and quantified in- and out-flows of information of voxels by volume entropy/directed graphs to subserve diverse resting mental state transitions on resting-state fMRI graphs in normal human individuals."
    },
    "2406.07662v3": {
      "title": "Progress Towards Decoding Visual Imagery via fNIRS",
      "url": "http://arxiv.org/abs/2406.07662v3",
      "authors": "Michel Adamic, Wellington Avelino, Anna Brandenberger, Bryan Chiang, Hunter Davis, Stephen Fay, Andrew Gregory, Aayush Gupta, Raphael Hotter, Grace Jiang, Fiona Leng, Stephen Polcyn, Thomas Ribeiro, Paul Scotti, Michelle Wang, Marley Xiong, Jonathan Xu",
      "update_time": "2024-06-22",
      "abstract": "We demonstrate the possibility of reconstructing images from fNIRS brain activity and start building a prototype to match the required specs. By training an image reconstruction model on downsampled fMRI data, we discovered that cm-scale spatial resolution is sufficient for image generation. We obtained 71% retrieval accuracy with 1-cm resolution, compared to 93% on the full-resolution fMRI, and 20% with 2-cm resolution. With simulations and high-density tomography, we found that time-domain fNIRS can achieve 1-cm resolution, compared to 2-cm resolution for continuous-wave fNIRS. Lastly, we share designs for a prototype time-domain fNIRS device, consisting of a laser driver, a single photon detector, and a time-to-digital converter system."
    },
    "2406.07151v1": {
      "title": "EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels",
      "url": "http://arxiv.org/abs/2406.07151v1",
      "authors": "Shuqi Zhu, Ziyi Ye, Qingyao Ai, Yiqun Liu",
      "update_time": "2024-06-11",
      "abstract": "Identifying and reconstructing what we see from brain activity gives us a special insight into investigating how the biological visual system represents the world. While recent efforts have achieved high-performance image classification and high-quality image reconstruction from brain signals collected by Functional Magnetic Resonance Imaging (fMRI) or magnetoencephalogram (MEG), the expensiveness and bulkiness of these devices make relevant applications difficult to generalize to practical applications. On the other hand, Electroencephalography (EEG), despite its advantages of ease of use, cost-efficiency, high temporal resolution, and non-invasive nature, has not been fully explored in relevant studies due to the lack of comprehensive datasets. To address this gap, we introduce EEG-ImageNet, a novel EEG dataset comprising recordings from 16 subjects exposed to 4000 images selected from the ImageNet dataset. EEG-ImageNet consists of 5 times EEG-image pairs larger than existing similar EEG benchmarks. EEG-ImageNet is collected with image stimuli of multi-granularity labels, i.e., 40 images with coarse-grained labels and 40 with fine-grained labels. Based on it, we establish benchmarks for object classification and image reconstruction. Experiments with several commonly used models show that the best models can achieve object classification with accuracy around 60% and image reconstruction with two-way identification around 64%. These results demonstrate the dataset's potential to advance EEG-based visual brain-computer interfaces, understand the visual perception of biological systems, and provide potential applications in improving machine visual models.",
      "code_url": "https://github.com/promise-z5q2sq/eeg-imagenet-dataset"
    },
    "2406.07584v1": {
      "title": "BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models",
      "url": "http://arxiv.org/abs/2406.07584v1",
      "authors": "Wanaiu Huang",
      "update_time": "2024-06-10",
      "abstract": "Semantic information is vital for human interaction, and decoding it from brain activity enables non-invasive clinical augmentative and alternative communication. While there has been significant progress in reconstructing visual images, few studies have focused on the language aspect. To address this gap, leveraging the powerful capabilities of the decoder-based vision-language pretrained model CoCa, this paper proposes BrainChat, a simple yet effective generative framework aimed at rapidly accomplishing semantic information decoding tasks from brain activity, including fMRI question answering and fMRI captioning. BrainChat employs the self-supervised approach of Masked Brain Modeling to encode sparse fMRI data, obtaining a more compact embedding representation in the latent space. Subsequently, BrainChat bridges the gap between modalities by applying contrastive loss, resulting in aligned representations of fMRI, image, and text embeddings. Furthermore, the fMRI embeddings are mapped to the generative Brain Decoder via cross-attention layers, where they guide the generation of textual content about fMRI in a regressive manner by minimizing caption loss. Empirically, BrainChat exceeds the performance of existing state-of-the-art methods in the fMRI captioning task and, for the first time, implements fMRI question answering. Additionally, BrainChat is highly flexible and can achieve high performance without image data, making it better suited for real-world scenarios with limited data."
    },
    "2406.05859v1": {
      "title": "From First-order to Higher-order Interactions: Enhanced Representation of Homotopic Functional Connectivity through Control of Intervening Variables",
      "url": "http://arxiv.org/abs/2406.05859v1",
      "authors": "Behdad Khodabandehloo, Payam Jannatdoust, Babak Nadjar Araabi",
      "update_time": "2024-06-09",
      "abstract": "The brain's complex functionality emerges from network interactions that go beyond dyadic connections, with higher-order interactions significantly contributing to this complexity. One method of capturing higher-order interactions is through traversing the brain network using random walks. The efficacy of these random walks depends on the defined mutual interactions between two brain entities. More precise capture of higher-order interactions enables a better reflection of the brain's intrinsic neurophysiological characteristics. One well-established neurophysiological concept is Homotopic Functional Connectivity (HoFC), which illustrates the synchronized spontaneous activity between corresponding regions in the brain's left and right hemispheres. We employ node2vec, a random walk node embedding approach, alongside resting-state fMRI from the Human Connectome Project (HCP) to obtain higher-order feature vectors. We assess the efficacy of different functional connectivity parameterizations using HoFC. The results indicates that the quality of capturing higher-order interactions largely depends on the statistical dependency measure between brain regions. Higher-order interactions defined by partial correlation, better reflects HoFC compare to other statistical associations. In this case of first-order interactions, tangent space embedding more effectively demonstrates HoFC. The findings validate HoFC and underscore the importance of functional connectivity construction method in capturing intrinsic characteristics of the human brain."
    }
  },
  "MEG": {
    "2406.07151v1": {
      "title": "EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels",
      "url": "http://arxiv.org/abs/2406.07151v1",
      "authors": "Shuqi Zhu, Ziyi Ye, Qingyao Ai, Yiqun Liu",
      "update_time": "2024-06-11",
      "abstract": "Identifying and reconstructing what we see from brain activity gives us a special insight into investigating how the biological visual system represents the world. While recent efforts have achieved high-performance image classification and high-quality image reconstruction from brain signals collected by Functional Magnetic Resonance Imaging (fMRI) or magnetoencephalogram (MEG), the expensiveness and bulkiness of these devices make relevant applications difficult to generalize to practical applications. On the other hand, Electroencephalography (EEG), despite its advantages of ease of use, cost-efficiency, high temporal resolution, and non-invasive nature, has not been fully explored in relevant studies due to the lack of comprehensive datasets. To address this gap, we introduce EEG-ImageNet, a novel EEG dataset comprising recordings from 16 subjects exposed to 4000 images selected from the ImageNet dataset. EEG-ImageNet consists of 5 times EEG-image pairs larger than existing similar EEG benchmarks. EEG-ImageNet is collected with image stimuli of multi-granularity labels, i.e., 40 images with coarse-grained labels and 40 with fine-grained labels. Based on it, we establish benchmarks for object classification and image reconstruction. Experiments with several commonly used models show that the best models can achieve object classification with accuracy around 60% and image reconstruction with two-way identification around 64%. These results demonstrate the dataset's potential to advance EEG-based visual brain-computer interfaces, understand the visual perception of biological systems, and provide potential applications in improving machine visual models.",
      "code_url": "https://github.com/promise-z5q2sq/eeg-imagenet-dataset"
    },
    "2406.01512v1": {
      "title": "MAD: Multi-Alignment MEG-to-Text Decoding",
      "url": "http://arxiv.org/abs/2406.01512v1",
      "authors": "Yiqian Yang, Hyejeong Jo, Yiqun Duan, Qiang Zhang, Jinni Zhou, Won Hee Lee, Renjing Xu, Hui Xiong",
      "update_time": "2024-06-03",
      "abstract": "Deciphering language from brain activity is a crucial task in brain-computer interface (BCI) research. Non-invasive cerebral signaling techniques including electroencephalography (EEG) and magnetoencephalography (MEG) are becoming increasingly popular due to their safety and practicality, avoiding invasive electrode implantation. However, current works under-investigated three points: 1) a predominant focus on EEG with limited exploration of MEG, which provides superior signal quality; 2) poor performance on unseen text, indicating the need for models that can better generalize to diverse linguistic contexts; 3) insufficient integration of information from other modalities, which could potentially constrain our capacity to comprehensively understand the intricate dynamics of brain activity.   This study presents a novel approach for translating MEG signals into text using a speech-decoding framework with multiple alignments. Our method is the first to introduce an end-to-end multi-alignment framework for totally unseen text generation directly from MEG signals. We achieve an impressive BLEU-1 score on the $\\textit{GWilliams}$ dataset, significantly outperforming the baseline from 5.49 to 10.44 on the BLEU-1 metric. This improvement demonstrates the advancement of our model towards real-world applications and underscores its potential in advancing BCI research. Code is available at $\\href{https://github.com/NeuSpeech/MAD-MEG2text}{https://github.com/NeuSpeech/MAD-MEG2text}$.",
      "code_url": "https://github.com/neuspeech/mad-meg2text"
    },
    "2405.19479v1": {
      "title": "Participation in the age of foundation models",
      "url": "http://arxiv.org/abs/2405.19479v1",
      "authors": "Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy",
      "update_time": "2024-05-29",
      "abstract": "Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of public services. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to marginalized communities. Participatory approaches hold promise to instead lend agency and decision-making power to marginalized stakeholders. But existing approaches in participatory AI/ML are typically deeply grounded in context - how do we apply these approaches to foundation models, which are, by design, disconnected from context? Our paper interrogates this question.   First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the \"foundation\" layer, our framework proposes the \"subfloor'' layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain, and the \"surface'' layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate \"subfloor'' layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer."
    },
    "2405.17698v3": {
      "title": "BaboonLand Dataset: Tracking Primates in the Wild and Automating Behaviour Recognition from Drone Videos",
      "url": "http://arxiv.org/abs/2405.17698v3",
      "authors": "Isla Duporge, Maksim Kholiavchenko, Roi Harel, Scott Wolf, Dan Rubenstein, Meg Crofoot, Tanya Berger-Wolf, Stephen Lee, Julie Barreau, Jenna Kline, Michelle Ramirez, Charles Stewart",
      "update_time": "2024-06-03",
      "abstract": "Using drones to track multiple individuals simultaneously in their natural environment is a powerful approach for better understanding group primate behavior. Previous studies have demonstrated that it is possible to automate the classification of primate behavior from video data, but these studies have been carried out in captivity or from ground-based cameras. To understand group behavior and the self-organization of a collective, the whole troop needs to be seen at a scale where behavior can be seen in relation to the natural environment in which ecological decisions are made. This study presents a novel dataset from drone videos for baboon detection, tracking, and behavior recognition. The baboon detection dataset was created by manually annotating all baboons in drone videos with bounding boxes. A tiling method was subsequently applied to create a pyramid of images at various scales from the original 5.3K resolution images, resulting in approximately 30K images used for baboon detection. The tracking dataset is derived from the detection dataset, where all bounding boxes are assigned the same ID throughout the video. This process resulted in half an hour of very dense tracking data. The behavior recognition dataset was generated by converting tracks into mini-scenes, a video subregion centered on each animal; each mini-scene was manually annotated with 12 distinct behavior types, resulting in over 20 hours of data. Benchmark results show mean average precision (mAP) of 92.62\\% for the YOLOv8-X detection model, multiple object tracking precision (MOTA) of 63.81\\% for the BotSort tracking algorithm, and micro top-1 accuracy of 63.97\\% for the X3D behavior recognition model. Using deep learning to classify wildlife behavior from drone footage facilitates non-invasive insight into the collective behavior of an entire group."
    },
    "2405.13875v1": {
      "title": "On the Inapproximability of Finding Minimum Monitoring Edge-Geodetic Sets",
      "url": "http://arxiv.org/abs/2405.13875v1",
      "authors": "Davide Bil\u00f2, Giordano Colli, Luca Forlizzi, Stefano Leucci",
      "update_time": "2024-05-22",
      "abstract": "Given an undirected connected graph $G = (V(G), E(G))$ on $n$ vertices, the minimum Monitoring Edge-Geodetic Set (MEG-set) problem asks to find a subset $M \\subseteq V(G)$ of minimum cardinality such that, for every edge $e \\in E(G)$, there exist $x,y \\in M$ for which all shortest paths between $x$ and $y$ in $G$ traverse $e$.   We show that, for any constant $c < \\frac{1}{2}$, no polynomial-time $(c \\log n)$-approximation algorithm for the minimum MEG-set problem exists, unless $\\mathsf{P} = \\mathsf{NP}$."
    },
    "2405.01012v1": {
      "title": "Correcting Biased Centered Kernel Alignment Measures in Biological and Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2405.01012v1",
      "authors": "Alex Murphy, Joel Zylberberg, Alona Fyshe",
      "update_time": "2024-05-02",
      "abstract": "Centred Kernel Alignment (CKA) has recently emerged as a popular metric to compare activations from biological and artificial neural networks (ANNs) in order to quantify the alignment between internal representations derived from stimuli sets (e.g. images, text, video) that are presented to both systems. In this paper we highlight issues that the community should take into account if using CKA as an alignment metric with neural data. Neural data are in the low-data high-dimensionality domain, which is one of the cases where (biased) CKA results in high similarity scores even for pairs of random matrices. Using fMRI and MEG data from the THINGS project, we show that if biased CKA is applied to representations of different sizes in the low-data high-dimensionality domain, they are not directly comparable due to biased CKA's sensitivity to differing feature-sample ratios and not stimuli-driven responses. This situation can arise both when comparing a pre-selected area of interest (e.g. ROI) to multiple ANN layers, as well as when determining to which ANN layer multiple regions of interest (ROIs) / sensor groups of different dimensionality are most similar. We show that biased CKA can be artificially driven to its maximum value when using independent random data of different sample-feature ratios. We further show that shuffling sample-feature pairs of real neural data does not drastically alter biased CKA similarity in comparison to unshuffled data, indicating an undesirable lack of sensitivity to stimuli-driven neural responses. Positive alignment of true stimuli-driven responses is only achieved by using debiased CKA. Lastly, we report findings that suggest biased CKA is sensitive to the inherent structure of neural data, only differing from shuffled data when debiased CKA detects stimuli-driven alignment.",
      "code_url": "https://github.com/Alxmrphi/correcting_CKA_alignment"
    },
    "2404.15588v1": {
      "title": "Minimal Evidence Group Identification for Claim Verification",
      "url": "http://arxiv.org/abs/2404.15588v1",
      "authors": "Xiangci Li, Sihao Chen, Rajvi Kapadia, Jessica Ouyang, Fan Zhang",
      "update_time": "2024-04-24",
      "abstract": "Claim verification in real-world settings (e.g. against a large collection of candidate evidences retrieved from the web) typically requires identifying and aggregating a complete set of evidence pieces that collectively provide full support to the claim. The problem becomes particularly challenging when there exists distinct sets of evidence that could be used to verify the claim from different perspectives. In this paper, we formally define and study the problem of identifying such minimal evidence groups (MEGs) for claim verification. We show that MEG identification can be reduced from Set Cover problem, based on entailment inference of whether a given evidence group provides full/partial support to a claim. Our proposed approach achieves 18.4% and 34.8% absolute improvements on the WiCE and SciFact datasets over LLM prompting. Finally, we demonstrate the benefits of MEGs in downstream applications such as claim generation."
    },
    "2404.10869v1": {
      "title": "Alpha rhythm slowing in temporal epilepsy across Scalp EEG and MEG",
      "url": "http://arxiv.org/abs/2404.10869v1",
      "authors": "Vytene Janiukstyte, Csaba Kozma, Thomas W. Owen, Umair J Chaudhury, Beate Diehl, Louis Lemieux, John S Duncan, Fergus Rugg-Gunn, Jane de Tisi, Yujiang Wang, Peter N. Taylor",
      "update_time": "2024-04-16",
      "abstract": "EEG slowing is reported in various neurological disorders including Alzheimer's, Parkinson's and Epilepsy. Here, we investigate alpha rhythm slowing in individuals with refractory temporal lobe epilepsy (TLE), compared to healthy controls, using scalp electroencephalography (EEG) and magnetoencephalography (MEG).   We retrospectively analysed data from 17,(46) healthy controls and 22,(24) individuals with TLE who underwent scalp EEG and (MEG) recordings as part of presurgical evaluation. Resting-state, eyes-closed recordings were source reconstructed using the standardized low-resolution brain electrographic tomography (sLORETA) method. We extracted low (slow) 6-9 Hz and high (fast) 10-11 Hz alpha relative band power and calculated the alpha power ratio by dividing low (slow) alpha by high (fast) alpha. This ratio was computed for all brain regions in all individuals.   Alpha oscillations were slower in individuals with TLE than controls (p<0.05). This effect was present in both the ipsilateral and contralateral hemispheres, and across widespread brain regions.   Alpha slowing in TLE was found in both EEG and MEG recordings. We interpret greater low (slow)-alpha as greater deviation from health."
    },
    "2404.09256v1": {
      "title": "Foundational GPT Model for MEG",
      "url": "http://arxiv.org/abs/2404.09256v1",
      "authors": "Richard Csaky, Mats W. J. van Es, Oiwi Parker Jones, Mark Woolrich",
      "update_time": "2024-04-14",
      "abstract": "Deep learning techniques can be used to first training unsupervised models on large amounts of unlabelled data, before fine-tuning the models on specific tasks. This approach has seen massive success for various kinds of data, e.g. images, language, audio, and holds the promise of improving performance in various downstream tasks (e.g. encoding or decoding brain data). However, there has been limited progress taking this approach for modelling brain signals, such as Magneto-/electroencephalography (M/EEG). Here we propose two classes of deep learning foundational models that can be trained using forecasting of unlabelled MEG. First, we consider a modified Wavenet; and second, we consider a modified Transformer-based (GPT2) model. The modified GPT2 includes a novel application of tokenisation and embedding methods, allowing a model developed initially for the discrete domain of language to be applied to continuous multichannel time series data. We also extend the forecasting framework to include condition labels as inputs, enabling better modelling (encoding) of task data. We compare the performance of these deep learning models with standard linear autoregressive (AR) modelling on MEG data. This shows that GPT2-based models provide better modelling capabilities than Wavenet and linear AR models, by better reproducing the temporal, spatial and spectral characteristics of real data and evoked activity in task data. We show how the GPT2 model scales well to multiple subjects, while adapting its model to each subject through subject embedding. Finally, we show how such a model can be useful in downstream decoding tasks through data simulation. All code is available on GitHub (https://github.com/ricsinaruto/MEG-transfer-decoding).",
      "code_url": "https://github.com/ricsinaruto/meg-transfer-decoding"
    },
    "2404.07839v1": {
      "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models",
      "url": "http://arxiv.org/abs/2404.07839v1",
      "authors": "Aleksandar Botev, Soham De, Samuel L Smith, Anushan Fernando, George-Cristian Muraru, Ruba Haroun, Leonard Berrada, Razvan Pascanu, Pier Giuseppe Sessa, Robert Dadashi, L\u00e9onard Hussenot, Johan Ferret, Sertan Girgin, Olivier Bachem, Alek Andreev, Kathleen Kenealy, Thomas Mesnard, Cassidy Hardin, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\u00e8re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, Armand Joulin, Noah Fiedel, Evan Senter, Yutian Chen, Srivatsan Srinivasan, Guillaume Desjardins, David Budden, Arnaud Doucet, Sharad Vikram, Adam Paszke, Trevor Gale, Sebastian Borgeaud, Charlie Chen, Andy Brock, Antonia Paterson, Jenny Brennan, Meg Risdal, Raj Gundluru, Nesh Devanathan, Paul Mooney, Nilay Chauhan, Phil Culliton, Luiz GUStavo Martins, Elisa Bandy, David Huntsperger, Glenn Cameron, Arthur Zucker, Tris Warkentin, Ludovic Peran, Minh Giang, Zoubin Ghahramani, Cl\u00e9ment Farabet, Koray Kavukcuoglu, Demis Hassabis, Raia Hadsell, Yee Whye Teh, Nando de Frietas",
      "update_time": "2024-04-11",
      "abstract": "We introduce RecurrentGemma, an open language model which uses Google's novel Griffin architecture. Griffin combines linear recurrences with local attention to achieve excellent performance on language. It has a fixed-sized state, which reduces memory use and enables efficient inference on long sequences. We provide a pre-trained model with 2B non-embedding parameters, and an instruction tuned variant. Both models achieve comparable performance to Gemma-2B despite being trained on fewer tokens.",
      "code_url": "https://github.com/google-deepmind/recurrentgemma"
    }
  },
  "neuroAI": {
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    },
    "2112.15459v3": {
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "authors": "Samuele Bolotta, Guillaume Dumas",
      "update_time": "2022-04-11",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied."
    },
    "2011.07464v2": {
      "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
      "url": "http://arxiv.org/abs/2011.07464v2",
      "authors": "Joseph Marino",
      "update_time": "2021-10-23",
      "abstract": "This paper reviews predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (non-linear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field."
    },
    "1909.02603v2": {
      "title": "Additive function approximation in the brain",
      "url": "http://arxiv.org/abs/1909.02603v2",
      "authors": "Kameron Decker Harris",
      "update_time": "2019-09-13",
      "abstract": "Many biological learning systems such as the mushroom body, hippocampus, and cerebellum are built from sparsely connected networks of neurons. For a new understanding of such networks, we study the function spaces induced by sparse random features and characterize what functions may and may not be learned. A network with $d$ inputs per neuron is found to be equivalent to an additive model of order $d$, whereas with a degree distribution the network combines additive terms of different orders. We identify three specific advantages of sparsity: additive function approximation is a powerful inductive bias that limits the curse of dimensionality, sparse networks are stable to outlier noise in the inputs, and sparse random features are scalable. Thus, even simple brain architectures can be powerful function approximators. Finally, we hope that this work helps popularize kernel theories of networks among computational neuroscientists.",
      "code_url": "https://github.com/kharris/sparse-random-features"
    }
  },
  "medical": {
    "2406.16845v1": {
      "title": "RaTEScore: A Metric for Radiology Report Generation",
      "url": "http://arxiv.org/abs/2406.16845v1",
      "authors": "Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie",
      "update_time": "2024-06-24",
      "abstract": "This paper introduces a novel, entity-aware metric, termed as Radiological Report (Text) Evaluation (RaTEScore), to assess the quality of medical reports generated by AI models. RaTEScore emphasizes crucial medical entities such as diagnostic outcomes and anatomical details, and is robust against complex medical synonyms and sensitive to negation expressions. Technically, we developed a comprehensive medical NER dataset, RaTE-NER, and trained an NER model specifically for this purpose. This model enables the decomposition of complex radiological reports into constituent medical entities. The metric itself is derived by comparing the similarity of entity embeddings, obtained from a language model, based on their types and relevance to clinical significance. Our evaluations demonstrate that RaTEScore aligns more closely with human preference than existing metrics, validated both on established public benchmarks and our newly proposed RaTE-Eval benchmark."
    },
    "2406.16809v1": {
      "title": "3D distortion-free, reduced field of view diffusion-prepared GRE at 3T",
      "url": "http://arxiv.org/abs/2406.16809v1",
      "authors": "Sarah McElroy, Raphael Tomi-Tricot, Jon Cleary, Shawna Kinsella, Sami Jeljeli, Vicky Goh, Radhouene Neji",
      "update_time": "2024-06-24",
      "abstract": "Purpose: To develop a 3D distortion-free reduced-FOV diffusion-prepared GRE sequence and demonstrate its in-vivo application for diffusion imaging of the spinal cord in healthy volunteers. Methods: A 3D multi-shot reduced-FOV diffusion-prepared GRE (RFOV-DP-GRE) acquisition is achieved using a slice-selective tip-down pulse in the phase encoding direction in the diffusion preparation, combined with magnitude stabilisers. The efficacy of the developed reduced FOV approach and accuracy of ADC estimates were evaluated in a phantom. In addition, 5 healthy volunteers were enrolled and scanned at 3T using the proposed sequence and a standard spin echo diffusion-weighted single-shot EPI sequence (DW-SS-EPI) for spinal cord imaging. Image quality, perceived SNR and image distortion were assessed by two expert readers and quantitative measurements of apparent SNR were performed. Results: The phantom scan demonstrates the efficacy of the proposed reduced FOV approach. Consistent ADC estimates were measured with RFOV-DP-GRE when compared with DW-SS-EPI. In-vivo, RFOV-DP-GRE demonstrated improved image quality and reduced perceived distortion, while maintaining perceived SNR compared to DW-SS-EPI. Conclusion: 3D Distortion-free diffusion-prepared imaging can be achieved using the proposed sequence"
    },
    "2406.16804v1": {
      "title": "Comment on Chen et al.'s Authentication Protocol for Internet of Health Things",
      "url": "http://arxiv.org/abs/2406.16804v1",
      "authors": "Iman Jafarian, Siavash Khorsandi",
      "update_time": "2024-06-24",
      "abstract": "The Internet of Medical Things has revolutionized the healthcare industry, enabling the seamless integration of connected medical devices and wearable sensors to enhance patient care and optimize healthcare services. However, the rapid adoption of the Internet of Medical Things also introduces significant security challenges that must be effectively addressed to preserve patient privacy, protect sensitive medical data, and ensure the overall reliability and safety of Internet of Medical Things systems. In this context, a key agreement protocol is used to securely establish shared cryptographic keys between interconnected medical devices and the central system, ensuring confidential and authenticated communication. Recently Chen et al. proposed a lightweight authentication and key agreement protocol for the Internet of health things. In this article, we provide a descriptive analysis of their proposed scheme and prove that Chen et al.'s scheme is vulnerable to Known session-specific temporary information attacks and stolen verifier attacks."
    },
    "2406.16734v1": {
      "title": "Scheduling with Obligatory Tests",
      "url": "http://arxiv.org/abs/2406.16734v1",
      "authors": "Konstantinos Dogeas, Thomas Erlebach, Ya-Chun Liang",
      "update_time": "2024-06-24",
      "abstract": "Motivated by settings such as medical treatments or aircraft maintenance, we consider a scheduling problem with jobs that consist of two operations, a test and a processing part. The time required to execute the test is known in advance while the time required to execute the processing part becomes known only upon completion of the test. We use competitive analysis to study algorithms for minimizing the sum of completion times for $n$ given jobs on a single machine. As our main result, we prove using a novel analysis technique that the natural $1$-SORT algorithm has competitive ratio at most 1.861. For the special case of uniform test times, we show that a simple threshold-based algorithm has competitive ratio at most 1.585. We also prove a lower bound that shows that no deterministic algorithm can be better than $\\sqrt{2}$-competitive even in the case of uniform test times."
    },
    "2406.16724v1": {
      "title": "\u03bc-Net: A Deep Learning-Based Architecture for \u03bc-CT Segmentation",
      "url": "http://arxiv.org/abs/2406.16724v1",
      "authors": "Pierangela Bruno, Edoardo De Rose, Carlo Adornetto, Francesco Calimeri, Sandro Donato, Raffaele Giuseppe Agostino, Daniela Amelio, Riccardo Barberi, Maria Carmela Cerra, Maria Caterina Crocco, Mariacristina Filice, Raffaele Filosa, Gianluigi Greco, Sandra Imbrogno, Vincenzo Formoso",
      "update_time": "2024-06-24",
      "abstract": "X-ray computed microtomography ({\\mu}-CT) is a non-destructive technique that can generate high-resolution 3D images of the internal anatomy of medical and biological samples. These images enable clinicians to examine internal anatomy and gain insights into the disease or anatomical morphology. However, extracting relevant information from 3D images requires semantic segmentation of the regions of interest, which is usually done manually and results time-consuming and tedious. In this work, we propose a novel framework that uses a convolutional neural network (CNN) to automatically segment the full morphology of the heart of Carassius auratus. The framework employs an optimized 2D CNN architecture that can infer a 3D segmentation of the sample, avoiding the high computational cost of a 3D CNN architecture. We tackle the challenges of handling large and high-resoluted image data (over a thousand pixels in each dimension) and a small training database (only three samples) by proposing a standard protocol for data normalization and processing. Moreover, we investigate how the noise, contrast, and spatial resolution of the sample and the training of the architecture are affected by the reconstruction technique, which depends on the number of input images. Experiments show that our framework significantly reduces the time required to segment new samples, allowing a faster microtomography analysis of the Carassius auratus heart shape. Furthermore, our framework can work with any bio-image (biological and medical) from {\\mu}-CT with high-resolution and small dataset size"
    },
    "2406.16701v1": {
      "title": "Demystifying the Effect of Receptive Field Size in U-Net Models for Medical Image Segmentation",
      "url": "http://arxiv.org/abs/2406.16701v1",
      "authors": "Vincent Loos, Rohit Pardasani, Navchetan Awasthi",
      "update_time": "2024-06-24",
      "abstract": "Medical image segmentation is a critical task in healthcare applications, and U-Nets have demonstrated promising results. This work delves into the understudied aspect of receptive field (RF) size and its impact on the U-Net and Attention U-Net architectures. This work explores several critical elements including the relationship between RF size, characteristics of the region of interest, and model performance, as well as the balance between RF size and computational costs for U-Net and Attention U-Net methods for different datasets. This work also proposes a mathematical notation for representing the theoretical receptive field (TRF) of a given layer in a network and proposes two new metrics - effective receptive field (ERF) rate and the Object rate to quantify the fraction of significantly contributing pixels within the ERF against the TRF area and assessing the relative size of the segmentation object compared to the TRF size respectively. The results demonstrate that there exists an optimal TRF size that successfully strikes a balance between capturing a wider global context and maintaining computational efficiency, thereby optimizing model performance. Interestingly, a distinct correlation is observed between the data complexity and the required TRF size; segmentation based solely on contrast achieved peak performance even with smaller TRF sizes, whereas more complex segmentation tasks necessitated larger TRFs. Attention U-Net models consistently outperformed their U-Net counterparts, highlighting the value of attention mechanisms regardless of TRF size. These novel insights present an invaluable resource for developing more efficient U-Net-based architectures for medical imaging and pave the way for future exploration. A tool is also developed that calculates the TRF for a U-Net (and Attention U-Net) model, and also suggest an appropriate TRF size for a given model and dataset."
    },
    "2406.16611v1": {
      "title": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings",
      "url": "http://arxiv.org/abs/2406.16611v1",
      "authors": "Andrea Posada, Daniel Rueckert, Felix Meissen, Philip M\u00fcller",
      "update_time": "2024-06-24",
      "abstract": "Since the emergence of the Transformer architecture, language model development has increased, driven by their promising potential. However, releasing these models into production requires properly understanding their behavior, particularly in sensitive domains such as medicine. Despite this need, the medical literature still lacks technical assessments of pre-trained language models, which are especially valuable in resource-constrained settings in terms of computational power or limited budget. To address this gap, we provide a comprehensive survey of language models in the medical domain. In addition, we selected a subset of these models for thorough evaluation, focusing on classification and text generation tasks. Our subset encompasses 53 models, ranging from 110 million to 13 billion parameters, spanning the three families of Transformer-based models and from diverse knowledge domains. This study employs a series of approaches for text classification together with zero-shot prompting instead of model training or fine-tuning, which closely resembles the limited resource setting in which many users of language models find themselves. Encouragingly, our findings reveal remarkable performance across various tasks and datasets, underscoring the latent potential of certain models to contain medical knowledge, even without domain specialization. Consequently, our study advocates for further exploration of model applications in medical contexts, particularly in resource-constrained settings. The code is available on https://github.com/anpoc/Language-models-in-medicine.",
      "code_url": "https://github.com/anpoc/language-models-in-medicine"
    },
    "2406.16455v1": {
      "title": "Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models",
      "url": "http://arxiv.org/abs/2406.16455v1",
      "authors": "Daniel Lopez-Martinez",
      "update_time": "2024-06-24",
      "abstract": "Generative AI (GenAI) models have demonstrated remarkable capabilities in a wide variety of medical tasks. However, as these models are trained using generalist datasets with very limited human oversight, they can learn uses of medical products that have not been adequately evaluated for safety and efficacy, nor approved by regulatory agencies. Given the scale at which GenAI may reach users, unvetted recommendations pose a public health risk. In this work, we propose an approach to identify potentially harmful product recommendations, and demonstrate it using a recent multimodal large language model."
    },
    "2406.16433v1": {
      "title": "Multiscale Mechanical Modeling of Skeletal Muscle: A Systemic Review of the Literature",
      "url": "http://arxiv.org/abs/2406.16433v1",
      "authors": "Aude Loumeaud, Philippe Pouletaut, Sabine Bensamoun, Daniel George, Simon Chatelin",
      "update_time": "2024-06-24",
      "abstract": "Purpose: From the myofibrils to the whole muscle scale, muscle micro-constituents exhibit passive and active mechanical properties, potentially coupled to electrical, chemical, and thermal properties. Experimental characterization of some of these properties is currently not available for all muscle constituents. Multiscale multiphysics models have recently gained interest as a numerical alternative to investigate the healthy and diseased physiological behavior of the skeletal muscle. Methods: This paper refers to the multiscale mechanical models proposed in the literature to investigate the mechanical properties and behavior of skeletal muscles. More specifically, we focus on the scale transition methods, constitutive laws and experimental data implemented in these models. Results: Using scale transition methods such as homogenization, coupled to appropriate constitutive behavior of the constituents, these models explore the mechanisms of ageing, myopathies, sportive injuries, and muscle contraction. Conclusion: Emerging trends include the development of multiphysics simulations and the coupling of modeling with the acquisition of experimental data at different scales, with increasing focus to little known constituents such as the extracellular matrix and the protein titin."
    },
    "2406.16341v1": {
      "title": "EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records",
      "url": "http://arxiv.org/abs/2406.16341v1",
      "authors": "Yeonsu Kwon, Jiho Kim, Gyubok Lee, Seongsu Bae, Daeun Kyung, Wonchul Cha, Tom Pollard, Alistair Johnson, Edward Choi",
      "update_time": "2024-06-24",
      "abstract": "Electronic Health Records (EHRs) are integral for storing comprehensive patient medical records, combining structured data (e.g., medications) with detailed clinical notes (e.g., physician notes). These elements are essential for straightforward data retrieval and provide deep, contextual insights into patient care. However, they often suffer from discrepancies due to unintuitive EHR system designs and human errors, posing serious risks to patient safety. To address this, we developed EHRCon, a new dataset and task specifically designed to ensure data consistency between structured tables and unstructured notes in EHRs. EHRCon was crafted in collaboration with healthcare professionals using the MIMIC-III EHR dataset, and includes manual annotations of 3,943 entities across 105 clinical notes checked against database entries for consistency. EHRCon has two versions, one using the original MIMIC-III schema, and another using the OMOP CDM schema, in order to increase its applicability and generalizability. Furthermore, leveraging the capabilities of large language models, we introduce CheckEHR, a novel framework for verifying the consistency between clinical notes and database tables. CheckEHR utilizes an eight-stage process and shows promising results in both few-shot and zero-shot settings. The code is available at https://github.com/dustn1259/EHRCon.",
      "code_url": "https://github.com/dustn1259/ehrcon"
    }
  }
}