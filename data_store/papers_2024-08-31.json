{
  "Brain": {
    "2408.16719v1": {
      "title": "H-SGANet: Hybrid Sparse Graph Attention Network for Deformable Medical Image Registration",
      "url": "http://arxiv.org/abs/2408.16719v1",
      "authors": "Yufeng Zhou, Wenming Cao",
      "update_time": "2024-08-29",
      "abstract": "The integration of Convolutional Neural Network (ConvNet) and Transformer has emerged as a strong candidate for image registration, leveraging the strengths of both models and a large parameter space. However, this hybrid model, treating brain MRI volumes as grid or sequence structures, faces challenges in accurately representing anatomical connectivity, diverse brain regions, and vital connections contributing to the brain's internal architecture. Concerns also arise regarding the computational expense and GPU memory usage associated with this model. To tackle these issues, a lightweight hybrid sparse graph attention network (H-SGANet) has been developed. This network incorporates a central mechanism, Sparse Graph Attention (SGA), based on a Vision Graph Neural Network (ViG) with predetermined anatomical connections. The SGA module expands the model's receptive field and seamlessly integrates into the network. To further amplify the advantages of the hybrid network, the Separable Self-Attention (SSA) is employed as an enhanced token mixer, integrated with depth-wise convolution to constitute SSAFormer. This strategic integration is designed to more effectively extract long-range dependencies. As a hybrid ConvNet-ViG-Transformer model, H-SGANet offers threefold benefits for volumetric medical image registration. It optimizes fixed and moving images concurrently through a hybrid feature fusion layer and an end-to-end learning framework. Compared to VoxelMorph, a model with a similar parameter count, H-SGANet demonstrates significant performance enhancements of 3.5% and 1.5% in Dice score on the OASIS dataset and LPBA40 dataset, respectively."
    },
    "2408.16564v1": {
      "title": "Human-Inspired Audio-Visual Speech Recognition: Spike Activity, Cueing Interaction and Causal Processing",
      "url": "http://arxiv.org/abs/2408.16564v1",
      "authors": "Qianhui Liu, Jiadong Wang, Yang Wang, Xin Yang, Gang Pan, Haizhou Li",
      "update_time": "2024-08-29",
      "abstract": "Humans naturally perform audiovisual speech recognition (AVSR), enhancing the accuracy and robustness by integrating auditory and visual information. Spiking neural networks (SNNs), which mimic the brain's information-processing mechanisms, are well-suited for emulating the human capability of AVSR. Despite their potential, research on SNNs for AVSR is scarce, with most existing audio-visual multimodal methods focused on object or digit recognition. These models simply integrate features from both modalities, neglecting their unique characteristics and interactions. Additionally, they often rely on future information for current processing, which increases recognition latency and limits real-time applicability. Inspired by human speech perception, this paper proposes a novel human-inspired SNN named HI-AVSNN for AVSR, incorporating three key characteristics: cueing interaction, causal processing and spike activity. For cueing interaction, we propose a visual-cued auditory attention module (VCA2M) that leverages visual cues to guide attention to auditory features. We achieve causal processing by aligning the SNN's temporal dimension with that of visual and auditory features and applying temporal masking to utilize only past and current information. To implement spike activity, in addition to using SNNs, we leverage the event camera to capture lip movement as spikes, mimicking the human retina and providing efficient visual data. We evaluate HI-AVSNN on an audiovisual speech recognition dataset combining the DVS-Lip dataset with its corresponding audio samples. Experimental results demonstrate the superiority of our proposed fusion method, outperforming existing audio-visual SNN fusion methods and achieving a 2.27% improvement in accuracy over the only existing SNN-based AVSR method."
    },
    "2408.16347v1": {
      "title": "Desynchronization Index: a New Approach for Exploring Complex Epileptogenic Networks in Stereoelectroencephalography",
      "url": "http://arxiv.org/abs/2408.16347v1",
      "authors": "Federico Mason, Lorenzo Ferri, Lidia Di Vito, Lara Alvisi, Luca Zanuttini, Matteo Martinoni, Roberto Mai, Francesco Cardinale, Paolo Tinuper, Roberto Michelucci, Elena Pasini, Francesca Bisulli",
      "update_time": "2024-08-29",
      "abstract": "Stereoelectroencephalography (SEEG) is an invasive surgical procedure to record the electrical activities in cortical brain regions, aiming at identifying the Epileptogenic Zone (EZ) in patients with drug-resistant epilepsy. To improve the accuracy of the EZ definition, SEEG analysis can be supported by computational tools, among which the Epileptogenic Index (EI) represents the most common solution. However, the scientific community has still not found an agreement on which quantitative biomarkers can characterize the cortical sites within the EZ. In this work, we design a new algorithm, named Desynchronization Index (DI), to assist neurophysiologists in SEEG interpretation. Our algorithm estimates the effective connectivity between cortical sites and hypothesizes that the EZ is identified by those sites getting abnormally desynchronized from the network during the seizure generation. We test the proposed method over a SEEG dataset of 10 seizures, comparing its accuracy in terms of EZ definition against the EI algorithm and clinical ground truth. Our results indicate that the DI algorithm underscores specific connectivity dynamics that can hardly be identified with a pure visual analysis, increasing sensitivity in detecting epileptogenic cortical sites."
    },
    "2408.16214v1": {
      "title": "Action potential dynamics on heterogenous neural networks: from kinetic to macroscopic equations",
      "url": "http://arxiv.org/abs/2408.16214v1",
      "authors": "Marzia Bisi, Martina Conte, Maria Groppi",
      "update_time": "2024-08-29",
      "abstract": "In the context of multi-agent systems of binary interacting particles, a kinetic model for action potential dynamics on a neural network is proposed, accounting for heterogeneity in the neuron-to-neuron connections, as well as in the brain structure. Two levels of description are coupled: in a single area, pairwise neuron interactions for the exchange of membrane potential are statistically described; among different areas, a graph description of the brain network topology is included. Equilibria of the kinetic and macroscopic settings are determined and numerical simulations of the system dynamics are performed with the aim of studying the influence of the network heterogeneities on the membrane potential propagation and synchronization."
    },
    "2408.16145v1": {
      "title": "DrowzEE-G-Mamba: Leveraging EEG and State Space Models for Driver Drowsiness Detection",
      "url": "http://arxiv.org/abs/2408.16145v1",
      "authors": "Gourav Siddhad, Sayantan Dey, Partha Pratim Roy",
      "update_time": "2024-08-28",
      "abstract": "Driver drowsiness is identified as a critical factor in road accidents, necessitating robust detection systems to enhance road safety. This study proposes a driver drowsiness detection system, DrowzEE-G-Mamba, that combines Electroencephalography (EEG) with State Space Models (SSMs). EEG data, known for its sensitivity to alertness, is used to model driver state transitions between alert and drowsy. Compared to traditional methods, DrowzEE-G-Mamba achieves significantly improved detection rates and reduced false positives. Notably, it achieves a peak accuracy of 83.24% on the SEED-VIG dataset, surpassing existing techniques. The system maintains high accuracy across varying complexities, making it suitable for real-time applications with limited resources. This robustness is attributed to the combination of channel-split, channel-concatenation, and channel-shuffle operations within the architecture, optimizing information flow from EEG data. Additionally, the integration of convolutional layers and SSMs facilitates comprehensive analysis, capturing both local features and long-range dependencies in the EEG signals. These findings suggest the potential of DrowzEE-G-Mamba for enhancing road safety through accurate drowsiness detection. It also paves the way for developing powerful SSM-based AI algorithms in Brain-Computer Interface applications."
    },
    "2408.15958v1": {
      "title": "Efficient Slice Anomaly Detection Network for 3D Brain MRI Volume",
      "url": "http://arxiv.org/abs/2408.15958v1",
      "authors": "Zeduo Zhang, Yalda Mohsenzadeh",
      "update_time": "2024-08-28",
      "abstract": "Current anomaly detection methods excel with benchmark industrial data but struggle with natural images and medical data due to varying definitions of 'normal' and 'abnormal.' This makes accurate identification of deviations in these fields particularly challenging. Especially for 3D brain MRI data, all the state-of-the-art models are reconstruction-based with 3D convolutional neural networks which are memory-intensive, time-consuming and producing noisy outputs that require further post-processing. We propose a framework called Simple Slice-based Network (SimpleSliceNet), which utilizes a model pre-trained on ImageNet and fine-tuned on a separate MRI dataset as a 2D slice feature extractor to reduce computational cost. We aggregate the extracted features to perform anomaly detection tasks on 3D brain MRI volumes. Our model integrates a conditional normalizing flow to calculate log likelihood of features and employs the Semi-Push-Pull Mechanism to enhance anomaly detection accuracy. The results indicate improved performance, showcasing our model's remarkable adaptability and effectiveness when addressing the challenges exists in brain MRI data. In addition, for the large-scale 3D brain volumes, our model SimpleSliceNet outperforms the state-of-the-art 2D and 3D models in terms of accuracy, memory usage and time consumption. Code is available at: https://anonymous.4open.science/r/SimpleSliceNet-8EA3."
    },
    "2408.15800v1": {
      "title": "Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing",
      "url": "http://arxiv.org/abs/2408.15800v1",
      "authors": "Kenneth Stewart, Michael Neumeier, Sumit Bam Shrestha, Garrick Orchard, Emre Neftci",
      "update_time": "2024-08-28",
      "abstract": "Achieving personalized intelligence at the edge with real-time learning capabilities holds enormous promise in enhancing our daily experiences and helping decision making, planning, and sensing. However, efficient and reliable edge learning remains difficult with current technology due to the lack of personalized data, insufficient hardware capabilities, and inherent challenges posed by online learning.   Over time and across multiple developmental stages, the brain has evolved to efficiently incorporate new knowledge by gradually building on previous knowledge. In this work, we emulate the multiple stages of learning with digital neuromorphic technology that simulates the neural and synaptic processes of the brain using two stages of learning. First, a meta-training stage trains the hyperparameters of synaptic plasticity for one-shot learning using a differentiable simulation of the neuromorphic hardware. This meta-training process refines a hardware local three-factor synaptic plasticity rule and its associated hyperparameters to align with the trained task domain. In a subsequent deployment stage, these optimized hyperparameters enable fast, data-efficient, and accurate learning of new classes. We demonstrate our approach using event-driven vision sensor data and the Intel Loihi neuromorphic processor with its plasticity dynamics, achieving real-time one-shot learning of new classes that is vastly improved over transfer learning. Our methodology can be deployed with arbitrary plasticity models and can be applied to situations demanding quick learning and adaptation at the edge, such as navigating unfamiliar environments or learning unexpected categories of data through user engagement.",
      "code_url": "https://github.com/nmi-lab/snn_maml"
    },
    "2408.15769v1": {
      "title": "A Survey on Evaluation of Multimodal Large Language Models",
      "url": "http://arxiv.org/abs/2408.15769v1",
      "authors": "Jiaxing Huang, Jingyi Zhang",
      "update_time": "2024-08-28",
      "abstract": "Multimodal Large Language Models (MLLMs) mimic human perception and reasoning system by integrating powerful Large Language Models (LLMs) with various modality encoders (e.g., vision, audio), positioning LLMs as the \"brain\" and various modality encoders as sensory organs. This framework endows MLLMs with human-like capabilities, and suggests a potential pathway towards achieving artificial general intelligence (AGI). With the emergence of all-round MLLMs like GPT-4V and Gemini, a multitude of evaluation methods have been developed to assess their capabilities across different dimensions. This paper presents a systematic and comprehensive review of MLLM evaluation methods, covering the following key aspects: (1) the background of MLLMs and their evaluation; (2) \"what to evaluate\" that reviews and categorizes existing MLLM evaluation tasks based on the capabilities assessed, including general multimodal recognition, perception, reasoning and trustworthiness, and domain-specific applications such as socioeconomic, natural sciences and engineering, medical usage, AI agent, remote sensing, video and audio processing, 3D point cloud analysis, and others; (3) \"where to evaluate\" that summarizes MLLM evaluation benchmarks into general and specific benchmarks; (4) \"how to evaluate\" that reviews and illustrates MLLM evaluation steps and metrics; Our overarching goal is to provide valuable insights for researchers in the field of MLLM evaluation, thereby facilitating the development of more capable and reliable MLLMs. We emphasize that evaluation should be regarded as a critical discipline, essential for advancing the field of MLLMs."
    },
    "2408.15663v1": {
      "title": "NeuroVE: Brain-inspired Linear-Angular Velocity Estimation with Spiking Neural Networks",
      "url": "http://arxiv.org/abs/2408.15663v1",
      "authors": "Xiao Li, Xieyuanli Chen, Ruibin Guo, Yujie Wu, Zongtan Zhou, Fangwen Yu, Huimin Lu",
      "update_time": "2024-08-28",
      "abstract": "Vision-based ego-velocity estimation is a fundamental problem in robot state estimation. However, the constraints of frame-based cameras, including motion blur and insufficient frame rates in dynamic settings, readily lead to the failure of conventional velocity estimation techniques. Mammals exhibit a remarkable ability to accurately estimate their ego-velocity during aggressive movement. Hence, integrating this capability into robots shows great promise for addressing these challenges. In this paper, we propose a brain-inspired framework for linear-angular velocity estimation, dubbed NeuroVE. The NeuroVE framework employs an event camera to capture the motion information and implements spiking neural networks (SNNs) to simulate the brain's spatial cells' function for velocity estimation. We formulate the velocity estimation as a time-series forecasting problem. To this end, we design an Astrocyte Leaky Integrate-and-Fire (ALIF) neuron model to encode continuous values. Additionally, we have developed an Astrocyte Spiking Long Short-term Memory (ASLSTM) structure, which significantly improves the time-series forecasting capabilities, enabling an accurate estimate of ego-velocity. Results from both simulation and real-world experiments indicate that NeuroVE has achieved an approximate 60% increase in accuracy compared to other SNN-based approaches."
    },
    "2408.15647v1": {
      "title": "Leveraging Persistent Homology for Differential Diagnosis of Mild Cognitive Impairment",
      "url": "http://arxiv.org/abs/2408.15647v1",
      "authors": "Ninad Aithal, Debanjali Bhattacharya, Neelam Sinha, Thomas Gregor Issac",
      "update_time": "2024-08-28",
      "abstract": "Mild cognitive impairment (MCI) is characterized by subtle changes in cognitive functions, often associated with disruptions in brain connectivity. The present study introduces a novel fine-grained analysis to examine topological alterations in neurodegeneration pertaining to six different brain networks of MCI subjects (Early/Late MCI). To achieve this, fMRI time series from two distinct populations are investigated: (i) the publicly accessible ADNI dataset and (ii) our in-house dataset. The study utilizes sliding window embedding to convert each fMRI time series into a sequence of 3-dimensional vectors, facilitating the assessment of changes in regional brain topology. Distinct persistence diagrams are computed for Betti descriptors of dimension-0, 1, and 2. Wasserstein distance metric is used to quantify differences in topological characteristics. We have examined both (i) ROI-specific inter-subject interactions and (ii) subject-specific inter-ROI interactions. Further, a new deep learning model is proposed for classification, achieving a maximum classification accuracy of 95% for the ADNI dataset and 85% for the in-house dataset. This methodology is further adapted for the differential diagnosis of MCI sub-types, resulting in a peak accuracy of 76.5%, 91.1% and 80% in classifying HC Vs. EMCI, HC Vs. LMCI and EMCI Vs. LMCI, respectively. We showed that the proposed approach surpasses current state-of-the-art techniques designed for classifying MCI and its sub-types using fMRI."
    }
  },
  "EEG": {
    "2408.16343v1": {
      "title": "Toward Robust Early Detection of Alzheimer's Disease via an Integrated Multimodal Learning Approach",
      "url": "http://arxiv.org/abs/2408.16343v1",
      "authors": "Yifei Chen, Shenghao Zhu, Zhaojie Fang, Chang Liu, Binfeng Zou, Yuhe Wang, Shuo Chang, Fan Jia, Feiwei Qin, Jin Fan, Yong Peng, Changmiao Wang",
      "update_time": "2024-08-29",
      "abstract": "Alzheimer's Disease (AD) is a complex neurodegenerative disorder marked by memory loss, executive dysfunction, and personality changes. Early diagnosis is challenging due to subtle symptoms and varied presentations, often leading to misdiagnosis with traditional unimodal diagnostic methods due to their limited scope. This study introduces an advanced multimodal classification model that integrates clinical, cognitive, neuroimaging, and EEG data to enhance diagnostic accuracy. The model incorporates a feature tagger with a tabular data coding architecture and utilizes the TimesBlock module to capture intricate temporal patterns in Electroencephalograms (EEG) data. By employing Cross-modal Attention Aggregation module, the model effectively fuses Magnetic Resonance Imaging (MRI) spatial information with EEG temporal data, significantly improving the distinction between AD, Mild Cognitive Impairment, and Normal Cognition. Simultaneously, we have constructed the first AD classification dataset that includes three modalities: EEG, MRI, and tabular data. Our innovative approach aims to facilitate early diagnosis and intervention, potentially slowing the progression of AD. The source code and our private ADMC dataset are available at https://github.com/JustlfC03/MSTNet.",
      "code_url": "https://github.com/justlfc03/mstnet"
    },
    "2408.16315v1": {
      "title": "Passenger hazard perception based on EEG signals for highly automated driving vehicles",
      "url": "http://arxiv.org/abs/2408.16315v1",
      "authors": "Ashton Yu Xuan Tan, Yingkai Yang, Xiaofei Zhang, Bowen Li, Xiaorong Gao, Sifa Zheng, Jianqiang Wang, Xinyu Gu, Jun Li, Yang Zhao, Yuxin Zhang, Tania Stathaki",
      "update_time": "2024-08-29",
      "abstract": "Enhancing the safety of autonomous vehicles is crucial, especially given recent accidents involving automated systems. As passengers in these vehicles, humans' sensory perception and decision-making can be integrated with autonomous systems to improve safety. This study explores neural mechanisms in passenger-vehicle interactions, leading to the development of a Passenger Cognitive Model (PCM) and the Passenger EEG Decoding Strategy (PEDS). Central to PEDS is a novel Convolutional Recurrent Neural Network (CRNN) that captures spatial and temporal EEG data patterns. The CRNN, combined with stacking algorithms, achieves an accuracy of $85.0\\% \\pm 3.18\\%$. Our findings highlight the predictive power of pre-event EEG data, enhancing the detection of hazardous scenarios and offering a network-driven framework for safer autonomous vehicles."
    },
    "2408.16145v1": {
      "title": "DrowzEE-G-Mamba: Leveraging EEG and State Space Models for Driver Drowsiness Detection",
      "url": "http://arxiv.org/abs/2408.16145v1",
      "authors": "Gourav Siddhad, Sayantan Dey, Partha Pratim Roy",
      "update_time": "2024-08-28",
      "abstract": "Driver drowsiness is identified as a critical factor in road accidents, necessitating robust detection systems to enhance road safety. This study proposes a driver drowsiness detection system, DrowzEE-G-Mamba, that combines Electroencephalography (EEG) with State Space Models (SSMs). EEG data, known for its sensitivity to alertness, is used to model driver state transitions between alert and drowsy. Compared to traditional methods, DrowzEE-G-Mamba achieves significantly improved detection rates and reduced false positives. Notably, it achieves a peak accuracy of 83.24% on the SEED-VIG dataset, surpassing existing techniques. The system maintains high accuracy across varying complexities, making it suitable for real-time applications with limited resources. This robustness is attributed to the combination of channel-split, channel-concatenation, and channel-shuffle operations within the architecture, optimizing information flow from EEG data. Additionally, the integration of convolutional layers and SSMs facilitates comprehensive analysis, capturing both local features and long-range dependencies in the EEG signals. These findings suggest the potential of DrowzEE-G-Mamba for enhancing road safety through accurate drowsiness detection. It also paves the way for developing powerful SSM-based AI algorithms in Brain-Computer Interface applications."
    },
    "2408.15906v1": {
      "title": "Exploring the potential of AI in nurturing learner empathy, prosocial values and environmental stewardship",
      "url": "http://arxiv.org/abs/2408.15906v1",
      "authors": "Kenneth Y T Lim, Minh Anh Nguyen Duc, Minh Tuan Nguyen Thien",
      "update_time": "2024-08-28",
      "abstract": "With Artificial Intelligence (AI) becoming a powerful tool for education (Zawacki-Richter et al., 2019), this chapter describes the concept of combining generative and traditional AI, citizen-science physiological, neuroergonomic wearables and environmental sensors into activities for learners to understand their own well-being and emotional states better with a view to developing empathy and environmental stewardship. Alongside bespoke and affordable wearables (DIY EEG headsets and biometric wristbands), interpretable AI and data science are used for learners to explore how the environment affects them physiologically and mentally in authentic environments. For example, relationships between environmental changes (e.g. poorer air quality) and their well-being (e.g. cognitive functioning) can be discovered. This is particularly crucial, as relevant knowledge can influence the way people treat the environment, as suggested by the disciplines of environmental neuroscience and environmental psychology (Doell et al., 2023). Yet, according to Palme and Salvati, there have been relatively few studies on the relationships between microclimates and human health and emotions (Palme and Salvati, 2021). As anthropogenic environmental pollution is becoming a prevalent problem, our research also aims to leverage on generative AI to introduce hypothetical scenarios of the environment as emotionally strong stimuli of relevance to the learners. This would provoke an emotional response for them to learn about their own physiological and neurological responses (using neuro-physiological data). Ultimately, we hope to establish a bidirectional understanding of how the environment affects humans physiologically and mentally; after which, to gain insights as to how AI can be used to effectively foster empathy, pro-environmental attitudes and stewardship."
    },
    "2408.13930v1": {
      "title": "Neural Networks Meet Neural Activity: Utilizing EEG for Mental Workload Estimation",
      "url": "http://arxiv.org/abs/2408.13930v1",
      "authors": "Gourav Siddhad, Partha Pratim Roy, Byung-Gyu Kim",
      "update_time": "2024-08-25",
      "abstract": "Electroencephalography (EEG) offers non-invasive, real-time mental workload assessment, which is crucial in high-stakes domains like aviation and medicine and for advancing brain-computer interface (BCI) technologies. This study introduces a customized ConvNeXt architecture, a powerful convolutional neural network, specifically adapted for EEG analysis. ConvNeXt addresses traditional EEG challenges like high dimensionality, noise, and variability, enhancing the precision of mental workload classification. Using the STEW dataset, the proposed ConvNeXt model is evaluated alongside SVM, EEGNet, and TSception on binary (No vs SIMKAP task) and ternary (SIMKAP multitask) class mental workload tasks. Results demonstrated that ConvNeXt significantly outperformed the other models, achieving accuracies of 95.76% for binary and 95.11% for multi-class classification. This demonstrates ConvNeXt's resilience and efficiency for EEG data analysis, establishing new standards for mental workload evaluation. These findings represent a considerable advancement in EEG-based mental workload estimation, laying the foundation for future improvements in cognitive state measurements. This has broad implications for safety, efficiency, and user experience across various scenarios. Integrating powerful neural networks such as ConvNeXt is a critical step forward in non-invasive cognitive monitoring."
    },
    "2408.13929v1": {
      "title": "Awake at the Wheel: Enhancing Automotive Safety through EEG-Based Fatigue Detection",
      "url": "http://arxiv.org/abs/2408.13929v1",
      "authors": "Gourav Siddhad, Sayantan Dey, Partha Pratim Roy, Masakazu Iwamura",
      "update_time": "2024-08-25",
      "abstract": "Driver fatigue detection is increasingly recognized as critical for enhancing road safety. This study introduces a method for detecting driver fatigue using the SEED-VIG dataset, a well-established benchmark in EEG-based vigilance analysis. By employing advanced pattern recognition technologies, including machine learning and deep neural networks, EEG signals are meticulously analyzed to discern patterns indicative of fatigue. This methodology combines feature extraction with a classification framework to improve the accuracy of fatigue detection. The proposed NLMDA-Net reached an impressive accuracy of 83.71% in detecting fatigue from EEG signals by incorporating two novel attention modules designed specifically for EEG signals, the channel and depth attention modules. NLMDA-Net effectively integrate features from multiple dimensions, resulting in improved classification performance. This success stems from integrating temporal convolutions and attention mechanisms, which effectively interpret EEG data. Designed to capture both temporal and spatial characteristics of EEG signals, deep learning classifiers have proven superior to traditional methods. The results of this study reveal a substantial enhancement in detection rates over existing models, highlighting the efficacy of the proposed approach for practical applications. The implications of this research are profound, extending beyond academic realms to inform the development of more sophisticated driver assistance systems. Incorporating this fatigue detection algorithm into these systems could significantly reduce fatigue-related incidents on the road, thus fostering safer driving conditions. This paper provides an exhaustive analysis of the dataset, methods employed, results obtained, and the potential real-world applications of the findings, aiming to contribute significantly to advancements in automotive safety."
    },
    "2408.13919v2": {
      "title": "Quantum Multimodal Contrastive Learning Framework",
      "url": "http://arxiv.org/abs/2408.13919v2",
      "authors": "Chi-Sheng Chen, Aidan Hung-Wen Tsai, Sheng-Chieh Huang",
      "update_time": "2024-08-27",
      "abstract": "In this paper, we propose a novel framework for multimodal contrastive learning utilizing a quantum encoder to integrate EEG (electroencephalogram) and image data. This groundbreaking attempt explores the integration of quantum encoders within the traditional multimodal learning framework. By leveraging the unique properties of quantum computing, our method enhances the representation learning capabilities, providing a robust framework for analyzing time series and visual information concurrently. We demonstrate that the quantum encoder effectively captures intricate patterns within EEG signals and image features, facilitating improved contrastive learning across modalities. This work opens new avenues for integrating quantum computing with multimodal data analysis, particularly in applications requiring simultaneous interpretation of temporal and visual data."
    },
    "2408.13360v1": {
      "title": "Symbolic dynamics of joint brain states during dyadic coordination",
      "url": "http://arxiv.org/abs/2408.13360v1",
      "authors": "Italo Ivo Lima Dias Pinto, Zhibin Zhou, Javier O. Garcia, Ramesh Srinivasan",
      "update_time": "2024-08-23",
      "abstract": "We propose a novel approach to investigate the brain mechanisms that support coordination of behavior between individuals. Brain states in single individuals defined by the patterns of functional connectivity between brain regions are used to create joint symbolic representations of the evolution of brain states in two or more individuals performing a task together. These symbolic dynamics can be analyzed to reveal aspects of the dynamics of joint brain states that are related to coordination or other interactive behaviors. We apply this approach to simultaneous electroencephalographic (EEG) data from pairs of subjects engaged in two different modes of finger-tapping coordination tasks (synchronization and syncopation) under different interaction conditions (Uncoupled, Leader-Follower, and Mutual) to explore the neural mechanisms of multi-person motor coordination. Our results reveal that the dyads exhibit mostly the same joint symbols in different interaction conditions - the most important differences are reflected in the symbolic dynamics. Recurrence analysis shows that interaction influences the dwell time in specific joint symbols and the structure of joint symbol sequences (motif length). In synchronization, increasing feedback promotes stability with longer dwell times and motif length. In syncopation, Leader-Follower interactions enhance stability (increase dwell time and motif length), but Mutual feedback dramatically reduces stability. Network analysis reveals distinct topological changes with task and feedback. In synchronization, stronger coupling stabilizes a few states restricting the pattern of flow between states, preserving a core-periphery structure of the joint brain states. In syncopation, a more distributed flow amongst a larger set of joint brain states reduces the dominance of core joint brain states."
    },
    "2408.12124v1": {
      "title": "Recording Brain Activity While Listening to Music Using Wearable EEG Devices Combined with Bidirectional Long Short-Term Memory Networks",
      "url": "http://arxiv.org/abs/2408.12124v1",
      "authors": "Jingyi Wang, Zhiqun Wang, Guiran Liu",
      "update_time": "2024-08-22",
      "abstract": "Electroencephalography (EEG) signals are crucial for investigating brain function and cognitive processes. This study aims to address the challenges of efficiently recording and analyzing high-dimensional EEG signals while listening to music to recognize emotional states. We propose a method combining Bidirectional Long Short-Term Memory (Bi-LSTM) networks with attention mechanisms for EEG signal processing. Using wearable EEG devices, we collected brain activity data from participants listening to music. The data was preprocessed, segmented, and Differential Entropy (DE) features were extracted. We then constructed and trained a Bi-LSTM model to enhance key feature extraction and improve emotion recognition accuracy. Experiments were conducted on the SEED and DEAP datasets. The Bi-LSTM-AttGW model achieved 98.28% accuracy on the SEED dataset and 92.46% on the DEAP dataset in multi-class emotion recognition tasks, significantly outperforming traditional models such as SVM and EEG-Net. This study demonstrates the effectiveness of combining Bi-LSTM with attention mechanisms, providing robust technical support for applications in brain-computer interfaces (BCI) and affective computing. Future work will focus on improving device design, incorporating multimodal data, and further enhancing emotion recognition accuracy, aiming to achieve practical applications in real-world scenarios."
    },
    "2408.12121v1": {
      "title": "Emotion-Agent: Unsupervised Deep Reinforcement Learning with Distribution-Prototype Reward for Continuous Emotional EEG Analysis",
      "url": "http://arxiv.org/abs/2408.12121v1",
      "authors": "Zhihao Zhou, Qile Liu, Jiyuan Wang, Zhen Liang",
      "update_time": "2024-08-22",
      "abstract": "Continuous electroencephalography (EEG) signals are widely used in affective brain-computer interface (aBCI) applications. However, not all continuously collected EEG signals are relevant or meaningful to the task at hand (e.g., wondering thoughts). On the other hand, manually labeling the relevant parts is nearly impossible due to varying engagement patterns across different tasks and individuals. Therefore, effectively and efficiently identifying the important parts from continuous EEG recordings is crucial for downstream BCI tasks, as it directly impacts the accuracy and reliability of the results. In this paper, we propose a novel unsupervised deep reinforcement learning framework, called Emotion-Agent, to automatically identify relevant and informative emotional moments from continuous EEG signals. Specifically, Emotion-Agent involves unsupervised deep reinforcement learning combined with a heuristic algorithm. We first use the heuristic algorithm to perform an initial global search and form prototype representations of the EEG signals, which facilitates the efficient exploration of the signal space and identify potential regions of interest. Then, we design distribution-prototype reward functions to estimate the interactions between samples and prototypes, ensuring that the identified parts are both relevant and representative of the underlying emotional states. Emotion-Agent is trained using Proximal Policy Optimization (PPO) to achieve stable and efficient convergence. Our experiments compare the performance with and without Emotion-Agent. The results demonstrate that selecting relevant and informative emotional parts before inputting them into downstream tasks enhances the accuracy and reliability of aBCI applications."
    }
  },
  "BCI": {
    "2408.13996v2": {
      "title": "Research Advances and New Paradigms for Biology-inspired Spiking Neural Networks",
      "url": "http://arxiv.org/abs/2408.13996v2",
      "authors": "Tianyu Zheng, Liyuan Han, Tielin Zhang",
      "update_time": "2024-08-28",
      "abstract": "Spiking neural networks (SNNs) are gaining popularity in the computational simulation and artificial intelligence fields owing to their biological plausibility and computational efficiency. This paper explores the historical development of SNN and concludes that these two fields are intersecting and merging rapidly. Following the successful application of Dynamic Vision Sensors (DVS) and Dynamic Audio Sensors (DAS), SNNs have found some proper paradigms, such as continuous visual signal tracking, automatic speech recognition, and reinforcement learning for continuous control, that have extensively supported their key features, including spike encoding, neuronal heterogeneity, specific functional circuits, and multiscale plasticity. Compared to these real-world paradigms, the brain contains a spiking version of the biology-world paradigm, which exhibits a similar level of complexity and is usually considered a mirror of the real world. Considering the projected rapid development of invasive and parallel Brain-Computer Interface (BCI), as well as the new BCI-based paradigms that include online pattern recognition and stimulus control of biological spike trains, SNNs naturally leverage their advantages in energy efficiency, robustness, and flexibility. The biological brain has inspired the present study of SNNs and effective SNN machine-learning algorithms, which can help enhance neuroscience discoveries in the brain by applying them to the new BCI paradigm. Such two-way interactions with positive feedback can accelerate brain science research and brain-inspired intelligence technology."
    },
    "2408.13930v1": {
      "title": "Neural Networks Meet Neural Activity: Utilizing EEG for Mental Workload Estimation",
      "url": "http://arxiv.org/abs/2408.13930v1",
      "authors": "Gourav Siddhad, Partha Pratim Roy, Byung-Gyu Kim",
      "update_time": "2024-08-25",
      "abstract": "Electroencephalography (EEG) offers non-invasive, real-time mental workload assessment, which is crucial in high-stakes domains like aviation and medicine and for advancing brain-computer interface (BCI) technologies. This study introduces a customized ConvNeXt architecture, a powerful convolutional neural network, specifically adapted for EEG analysis. ConvNeXt addresses traditional EEG challenges like high dimensionality, noise, and variability, enhancing the precision of mental workload classification. Using the STEW dataset, the proposed ConvNeXt model is evaluated alongside SVM, EEGNet, and TSception on binary (No vs SIMKAP task) and ternary (SIMKAP multitask) class mental workload tasks. Results demonstrated that ConvNeXt significantly outperformed the other models, achieving accuracies of 95.76% for binary and 95.11% for multi-class classification. This demonstrates ConvNeXt's resilience and efficiency for EEG data analysis, establishing new standards for mental workload evaluation. These findings represent a considerable advancement in EEG-based mental workload estimation, laying the foundation for future improvements in cognitive state measurements. This has broad implications for safety, efficiency, and user experience across various scenarios. Integrating powerful neural networks such as ConvNeXt is a critical step forward in non-invasive cognitive monitoring."
    },
    "2408.12124v1": {
      "title": "Recording Brain Activity While Listening to Music Using Wearable EEG Devices Combined with Bidirectional Long Short-Term Memory Networks",
      "url": "http://arxiv.org/abs/2408.12124v1",
      "authors": "Jingyi Wang, Zhiqun Wang, Guiran Liu",
      "update_time": "2024-08-22",
      "abstract": "Electroencephalography (EEG) signals are crucial for investigating brain function and cognitive processes. This study aims to address the challenges of efficiently recording and analyzing high-dimensional EEG signals while listening to music to recognize emotional states. We propose a method combining Bidirectional Long Short-Term Memory (Bi-LSTM) networks with attention mechanisms for EEG signal processing. Using wearable EEG devices, we collected brain activity data from participants listening to music. The data was preprocessed, segmented, and Differential Entropy (DE) features were extracted. We then constructed and trained a Bi-LSTM model to enhance key feature extraction and improve emotion recognition accuracy. Experiments were conducted on the SEED and DEAP datasets. The Bi-LSTM-AttGW model achieved 98.28% accuracy on the SEED dataset and 92.46% on the DEAP dataset in multi-class emotion recognition tasks, significantly outperforming traditional models such as SVM and EEG-Net. This study demonstrates the effectiveness of combining Bi-LSTM with attention mechanisms, providing robust technical support for applications in brain-computer interfaces (BCI) and affective computing. Future work will focus on improving device design, incorporating multimodal data, and further enhancing emotion recognition accuracy, aiming to achieve practical applications in real-world scenarios."
    },
    "2408.12121v1": {
      "title": "Emotion-Agent: Unsupervised Deep Reinforcement Learning with Distribution-Prototype Reward for Continuous Emotional EEG Analysis",
      "url": "http://arxiv.org/abs/2408.12121v1",
      "authors": "Zhihao Zhou, Qile Liu, Jiyuan Wang, Zhen Liang",
      "update_time": "2024-08-22",
      "abstract": "Continuous electroencephalography (EEG) signals are widely used in affective brain-computer interface (aBCI) applications. However, not all continuously collected EEG signals are relevant or meaningful to the task at hand (e.g., wondering thoughts). On the other hand, manually labeling the relevant parts is nearly impossible due to varying engagement patterns across different tasks and individuals. Therefore, effectively and efficiently identifying the important parts from continuous EEG recordings is crucial for downstream BCI tasks, as it directly impacts the accuracy and reliability of the results. In this paper, we propose a novel unsupervised deep reinforcement learning framework, called Emotion-Agent, to automatically identify relevant and informative emotional moments from continuous EEG signals. Specifically, Emotion-Agent involves unsupervised deep reinforcement learning combined with a heuristic algorithm. We first use the heuristic algorithm to perform an initial global search and form prototype representations of the EEG signals, which facilitates the efficient exploration of the signal space and identify potential regions of interest. Then, we design distribution-prototype reward functions to estimate the interactions between samples and prototypes, ensuring that the identified parts are both relevant and representative of the underlying emotional states. Emotion-Agent is trained using Proximal Policy Optimization (PPO) to achieve stable and efficient convergence. Our experiments compare the performance with and without Emotion-Agent. The results demonstrate that selecting relevant and informative emotional parts before inputting them into downstream tasks enhances the accuracy and reliability of aBCI applications."
    },
    "2408.07083v1": {
      "title": "Masked EEG Modeling for Driving Intention Prediction",
      "url": "http://arxiv.org/abs/2408.07083v1",
      "authors": "Jinzhao Zhou, Justin Sia, Yiqun Duan, Yu-Cheng Chang, Yu-Kai Wang, Chin-Teng Lin",
      "update_time": "2024-08-08",
      "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular accidents. Although recent efforts have focused on using electroencephalography to detect drowsiness, helping prevent accidents caused by driving in such states, seamless human-machine interaction in driving scenarios requires a more versatile EEG-based system. This system should be capable of understanding a driver's intention while demonstrating resilience to artifacts induced by sudden movements. This paper pioneers a novel research direction in BCI-assisted driving, studying the neural patterns related to driving intentions and presenting a novel method for driving intention prediction. In particular, our preliminary analysis of the EEG signal using independent component analysis suggests a close relation between the intention of driving maneuvers and the neural activities in central-frontal and parietal areas. Power spectral density analysis at a group level also reveals a notable distinction among various driving intentions in the frequency domain. To exploit these brain dynamics, we propose a novel Masked EEG Modeling framework for predicting human driving intentions, including the intention for left turning, right turning, and straight proceeding. Extensive experiments, encompassing comprehensive quantitative and qualitative assessments on public dataset, demonstrate the proposed method is proficient in predicting driving intentions across various vigilance states. Specifically, our model attains an accuracy of 85.19% when predicting driving intentions for drowsy subjects, which shows its promising potential for mitigating traffic accidents related to drowsy driving. Notably, our method maintains over 75% accuracy when more than half of the channels are missing or corrupted, underscoring its adaptability in real-life driving."
    },
    "2408.04679v1": {
      "title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings",
      "url": "http://arxiv.org/abs/2408.04679v1",
      "authors": "Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin",
      "update_time": "2024-08-08",
      "abstract": "Decoding linguistic information from non-invasive brain signals using EEG has gained increasing research attention due to its vast applicational potential. Recently, a number of works have adopted a generative-based framework to decode electroencephalogram (EEG) signals into sentences by utilizing the power generative capacity of pretrained large language models (LLMs). However, this approach has several drawbacks that hinder the further development of linguistic applications for brain-computer interfaces (BCIs). Specifically, the ability of the EEG encoder to learn semantic information from EEG data remains questionable, and the LLM decoder's tendency to generate sentences based on its training memory can be hard to avoid. These issues necessitate a novel approach for converting EEG signals into sentences. In this paper, we propose a novel two-step pipeline that addresses these limitations and enhances the validity of linguistic EEG decoding research. We first confirm that word-level semantic information can be learned from EEG data recorded during natural reading by training a Conformer encoder via a masked contrastive objective for word-level classification. To achieve sentence decoding results, we employ a training-free retrieval method to retrieve sentences based on the predictions from the EEG encoder. Extensive experiments and ablation studies were conducted in this paper for a comprehensive evaluation of the proposed approach. Visualization of the top prediction candidates reveals that our model effectively groups EEG segments into semantic categories with similar meanings, thereby validating its ability to learn patterns from unspoken EEG recordings. Despite the exploratory nature of this work, these results suggest that our method holds promise for providing more reliable solutions for converting EEG signals into text."
    },
    "2408.04123v1": {
      "title": "Knowledge-based Emotion Recognition using Large Language Models",
      "url": "http://arxiv.org/abs/2408.04123v1",
      "authors": "Bin Han, Cleo Yau, Su Lei, Jonathan Gratch",
      "update_time": "2024-08-07",
      "abstract": "Emotion recognition in social situations is a complex task that requires integrating information from both facial expressions and the situational context. While traditional approaches to automatic emotion recognition have focused on decontextualized signals, recent research emphasizes the importance of context in shaping emotion perceptions. This paper contributes to the emerging field of context-based emotion recognition by leveraging psychological theories of human emotion perception to inform the design of automated methods. We propose an approach that combines emotion recognition methods with Bayesian Cue Integration (BCI) to integrate emotion inferences from decontextualized facial expressions and contextual knowledge inferred via Large-language Models. We test this approach in the context of interpreting facial expressions during a social task, the prisoner's dilemma. Our results provide clear support for BCI across a range of automatic emotion recognition methods. The best automated method achieved results comparable to human observers, suggesting the potential for this approach to advance the field of affective computing."
    },
    "2408.03449v1": {
      "title": "EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures",
      "url": "http://arxiv.org/abs/2408.03449v1",
      "authors": "Teng Liang, Andrews Damoah",
      "update_time": "2024-08-06",
      "abstract": "Electroencephalography (EEG) analysis is an important domain in the realm of Brain-Computer Interface (BCI) research. To ensure BCI devices are capable of providing practical applications in the real world, brain signal processing techniques must be fast, accurate, and resource-conscious to deliver low-latency neural analytics. This study presents a model that leverages a pre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression tasks. Our results showcase that this model is capable of performing at a level comparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the EEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our research presents a cost-effective model applicable to resource-constrained devices and contributes to expanding future research on lightweight, mobile-friendly models for EEG regression.",
      "code_url": "https://github.com/t0nyliang/EEGMobile"
    },
    "2408.01242v1": {
      "title": "A modular open-source software platform for BCI research with application in closed-loop deep brain stimulation",
      "url": "http://arxiv.org/abs/2408.01242v1",
      "authors": "Matthias Dold, Joana Pereira, Bastian Sajonz, Volker A. Coenen, Marcus L. F. Janssen, Michael Tangermann",
      "update_time": "2024-08-02",
      "abstract": "This work introduces Dareplane, a modular and broad technology agnostic open source software platform for brain-computer interface research with an application focus on adaptive deep brain stimulation (aDBS). While the search for suitable biomarkers to inform aDBS has provided rich results over the last two decades, development of control strategies is not progressing at the same pace. One difficulty for investigating control approaches resides with the complex setups required for aDBS experiments. The Dareplane platform supports aDBS setups, and more generally brain computer interfaces, by providing a modular, technology-agnostic, and easy-to-implement software platform to make experimental setups more resilient and replicable. The key features of the platform are presented and the composition of modules into a full experimental setup is discussed in the context of a Python-based orchestration module. The performance of a typical experimental setup on Dareplane for aDBS is evaluated in three benchtop experiments, covering (a) an easy-to-replicate setup using an Arduino microcontroller, (b) a setup with hardware of an implantable pulse generator, and (c) a setup using an established and CE certified external neurostimulator. Benchmark results are presented for individual processing steps and full closed-loop processing. The results show that the microcontroller setup in (a) provides timing comparable to the realistic setups in (b) and (c). The Dareplane platform was successfully used in a total of 19 open-loop DBS sessions with externalized DBS and electrocorticography (ECoG) leads. In addition, the full technical feasibility of the platform in the aDBS context is demonstrated in a first closed-loop session with externalized leads on a patient with Parkinson's disease receiving DBS treatment."
    },
    "2407.20622v1": {
      "title": "Decoding Linguistic Representations of Human Brain",
      "url": "http://arxiv.org/abs/2407.20622v1",
      "authors": "Yu Wang, Heyang Liu, Yuhao Wang, Chuan Xuan, Yixuan Hou, Sheng Feng, Hongcheng Liu, Yusheng Liao, Yanfeng Wang",
      "update_time": "2024-07-30",
      "abstract": "Language, as an information medium created by advanced organisms, has always been a concern of neuroscience regarding how it is represented in the brain. Decoding linguistic representations in the evoked brain has shown groundbreaking achievements, thanks to the rapid improvement of neuroimaging, medical technology, life sciences and artificial intelligence. In this work, we present a taxonomy of brain-to-language decoding of both textual and speech formats. This work integrates two types of research: neuroscience focusing on language understanding and deep learning-based brain decoding. Generating discernible language information from brain activity could not only help those with limited articulation, especially amyotrophic lateral sclerosis (ALS) patients but also open up a new way for the next generation's brain-computer interface (BCI). This article will help brain scientists and deep-learning researchers to gain a bird's eye view of fine-grained language perception, and thus facilitate their further investigation and research of neural process and language decoding."
    }
  },
  "fMRI": {
    "2408.15647v1": {
      "title": "Leveraging Persistent Homology for Differential Diagnosis of Mild Cognitive Impairment",
      "url": "http://arxiv.org/abs/2408.15647v1",
      "authors": "Ninad Aithal, Debanjali Bhattacharya, Neelam Sinha, Thomas Gregor Issac",
      "update_time": "2024-08-28",
      "abstract": "Mild cognitive impairment (MCI) is characterized by subtle changes in cognitive functions, often associated with disruptions in brain connectivity. The present study introduces a novel fine-grained analysis to examine topological alterations in neurodegeneration pertaining to six different brain networks of MCI subjects (Early/Late MCI). To achieve this, fMRI time series from two distinct populations are investigated: (i) the publicly accessible ADNI dataset and (ii) our in-house dataset. The study utilizes sliding window embedding to convert each fMRI time series into a sequence of 3-dimensional vectors, facilitating the assessment of changes in regional brain topology. Distinct persistence diagrams are computed for Betti descriptors of dimension-0, 1, and 2. Wasserstein distance metric is used to quantify differences in topological characteristics. We have examined both (i) ROI-specific inter-subject interactions and (ii) subject-specific inter-ROI interactions. Further, a new deep learning model is proposed for classification, achieving a maximum classification accuracy of 95% for the ADNI dataset and 85% for the in-house dataset. This methodology is further adapted for the differential diagnosis of MCI sub-types, resulting in a peak accuracy of 76.5%, 91.1% and 80% in classifying HC Vs. EMCI, HC Vs. LMCI and EMCI Vs. LMCI, respectively. We showed that the proposed approach surpasses current state-of-the-art techniques designed for classifying MCI and its sub-types using fMRI."
    },
    "2408.14950v1": {
      "title": "NeuralOOD: Improving Out-of-Distribution Generalization Performance with Brain-machine Fusion Learning Framework",
      "url": "http://arxiv.org/abs/2408.14950v1",
      "authors": "Shuangchen Zhao, Changde Du, Hui Li, Huiguang He",
      "update_time": "2024-08-27",
      "abstract": "Deep Neural Networks (DNNs) have demonstrated exceptional recognition capabilities in traditional computer vision (CV) tasks. However, existing CV models often suffer a significant decrease in accuracy when confronted with out-of-distribution (OOD) data. In contrast to these DNN models, human can maintain a consistently low error rate when facing OOD scenes, partly attributed to the rich prior cognitive knowledge stored in the human brain. Previous OOD generalization researches only focus on the single modal, overlooking the advantages of multimodal learning method. In this paper, we utilize the multimodal learning method to improve the OOD generalization and propose a novel Brain-machine Fusion Learning (BMFL) framework. We adopt the cross-attention mechanism to fuse the visual knowledge from CV model and prior cognitive knowledge from the human brain. Specially, we employ a pre-trained visual neural encoding model to predict the functional Magnetic Resonance Imaging (fMRI) from visual features which eliminates the need for the fMRI data collection and pre-processing, effectively reduces the workload associated with conventional BMFL methods. Furthermore, we construct a brain transformer to facilitate the extraction of knowledge inside the fMRI data. Moreover, we introduce the Pearson correlation coefficient maximization regularization method into the training process, which improves the fusion capability with better constrains. Our model outperforms the DINOv2 and baseline models on the ImageNet-1k validation dataset as well as six curated OOD datasets, showcasing its superior performance in diverse scenarios."
    },
    "2408.14453v1": {
      "title": "Reconstructing physiological signals from fMRI across the adult lifespan",
      "url": "http://arxiv.org/abs/2408.14453v1",
      "authors": "Shiyu Wang, Ziyuan Xu, Yamin Li, Mara Mather, Roza G. Bayrak, Catie Chang",
      "update_time": "2024-08-26",
      "abstract": "Interactions between the brain and body are of fundamental importance for human behavior and health. Functional magnetic resonance imaging (fMRI) captures whole-brain activity noninvasively, and modeling how fMRI signals interact with physiological dynamics of the body can provide new insight into brain function and offer potential biomarkers of disease. However, physiological recordings are not always possible to acquire since they require extra equipment and setup, and even when they are, the recorded physiological signals may contain substantial artifacts. To overcome this limitation, machine learning models have been proposed to directly extract features of respiratory and cardiac activity from resting-state fMRI signals. To date, such work has been carried out only in healthy young adults and in a pediatric population, leaving open questions about the efficacy of these approaches on older adults. Here, we propose a novel framework that leverages Transformer-based architectures for reconstructing two key physiological signals - low-frequency respiratory volume (RV) and heart rate (HR) fluctuations - from fMRI data, and test these models on a dataset of individuals aged 36-89 years old. Our framework outperforms previously proposed approaches (attaining median correlations between predicted and measured signals of r ~ .698 for RV and r ~ .618 for HR), indicating the potential of leveraging attention mechanisms to model fMRI-physiological signal relationships. We also evaluate several model training and fine-tuning strategies, and find that incorporating young-adult data during training improves the performance when predicting physiological signals in the aging cohort. Overall, our approach successfully infers key physiological variables directly from fMRI data from individuals across a wide range of the adult lifespan."
    },
    "2408.14254v1": {
      "title": "Integrated Brain Connectivity Analysis with fMRI, DTI, and sMRI Powered by Interpretable Graph Neural Networks",
      "url": "http://arxiv.org/abs/2408.14254v1",
      "authors": "Gang Qu, Ziyu Zhou, Vince D. Calhoun, Aiying Zhang, Yu-Ping Wang",
      "update_time": "2024-08-26",
      "abstract": "Multimodal neuroimaging modeling has becomes a widely used approach but confronts considerable challenges due to heterogeneity, which encompasses variability in data types, scales, and formats across modalities. This variability necessitates the deployment of advanced computational methods to integrate and interpret these diverse datasets within a cohesive analytical framework. In our research, we amalgamate functional magnetic resonance imaging, diffusion tensor imaging, and structural MRI into a cohesive framework. This integration capitalizes on the unique strengths of each modality and their inherent interconnections, aiming for a comprehensive understanding of the brain's connectivity and anatomical characteristics. Utilizing the Glasser atlas for parcellation, we integrate imaging derived features from various modalities: functional connectivity from fMRI, structural connectivity from DTI, and anatomical features from sMRI within consistent regions. Our approach incorporates a masking strategy to differentially weight neural connections, thereby facilitating a holistic amalgamation of multimodal imaging data. This technique enhances interpretability at connectivity level, transcending traditional analyses centered on singular regional attributes. The model is applied to the Human Connectome Project's Development study to elucidate the associations between multimodal imaging and cognitive functions throughout youth. The analysis demonstrates improved predictive accuracy and uncovers crucial anatomical features and essential neural connections, deepening our understanding of brain structure and function."
    },
    "2408.13074v1": {
      "title": "Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis",
      "url": "http://arxiv.org/abs/2408.13074v1",
      "authors": "Yuxiang Wei, Anees Abrol, Reihaneh Hassanzadeh, Vince Calhoun",
      "update_time": "2024-08-23",
      "abstract": "Recent advances in deep learning structured state space models, especially the Mamba architecture, have demonstrated remarkable performance improvements while maintaining linear complexity. In this study, we introduce functional spatiotemporal Mamba (FST-Mamba), a Mamba-based model designed for discovering neurological biomarkers using functional magnetic resonance imaging (fMRI). We focus on dynamic functional network connectivity (dFNC) derived from fMRI and propose a hierarchical spatiotemporal Mamba-based network that processes spatial and temporal information separately using Mamba-based encoders. Leveraging the topological uniqueness of the FNC matrix, we introduce a component-wise varied-scale aggregation (CVA) mechanism to aggregate connectivity across individual components within brain networks, enabling the model to capture both inter-component and inter-network information. To better handle the FNC data, we develop a new component-specific scanning order. Additionally, we propose symmetric rotary position encoding (SymRope) to encode the relative positions of each functional connection while considering the symmetric nature of the FNC matrix. Experimental results demonstrate significant improvements in the proposed FST-Mamba model on various brain-based classification and regression tasks. Our work reveals the substantial potential of attention-free sequence modeling in brain discovery."
    },
    "2408.12804v1": {
      "title": "Universal dimensions of visual representation",
      "url": "http://arxiv.org/abs/2408.12804v1",
      "authors": "Zirui Chen, Michael F. Bonner",
      "update_time": "2024-08-23",
      "abstract": "Do neural network models of vision learn brain-aligned representations because they share architectural constraints and task objectives with biological vision or because they learn universal features of natural image processing? We characterized the universality of hundreds of thousands of representational dimensions from visual neural networks with varied construction. We found that networks with varied architectures and task objectives learn to represent natural images using a shared set of latent dimensions, despite appearing highly distinct at a surface level. Next, by comparing these networks with human brain representations measured with fMRI, we found that the most brain-aligned representations in neural networks are those that are universal and independent of a network's specific characteristics. Remarkably, each network can be reduced to fewer than ten of its most universal dimensions with little impact on its representational similarity to the human brain. These results suggest that the underlying similarities between artificial and biological vision are primarily governed by a core set of universal image representations that are convergently learned by diverse systems.",
      "code_url": "https://github.com/zche377/universal_dimensions"
    },
    "2408.10567v1": {
      "title": "Prompt Your Brain: Scaffold Prompt Tuning for Efficient Adaptation of fMRI Pre-trained Model",
      "url": "http://arxiv.org/abs/2408.10567v1",
      "authors": "Zijian Dong, Yilei Wu, Zijiao Chen, Yichi Zhang, Yueming Jin, Juan Helen Zhou",
      "update_time": "2024-08-20",
      "abstract": "We introduce Scaffold Prompt Tuning (ScaPT), a novel prompt-based framework for adapting large-scale functional magnetic resonance imaging (fMRI) pre-trained models to downstream tasks, with high parameter efficiency and improved performance compared to fine-tuning and baselines for prompt tuning. The full fine-tuning updates all pre-trained parameters, which may distort the learned feature space and lead to overfitting with limited training data which is common in fMRI fields. In contrast, we design a hierarchical prompt structure that transfers the knowledge learned from high-resource tasks to low-resource ones. This structure, equipped with a Deeply-conditioned Input-Prompt (DIP) mapping module, allows for efficient adaptation by updating only 2% of the trainable parameters. The framework enhances semantic interpretability through attention mechanisms between inputs and prompts, and it clusters prompts in the latent space in alignment with prior knowledge. Experiments on public resting state fMRI datasets reveal ScaPT outperforms fine-tuning and multitask-based prompt tuning in neurodegenerative diseases diagnosis/prognosis and personality trait prediction, even with fewer than 20 participants. It highlights ScaPT's efficiency in adapting pre-trained fMRI models to low-resource tasks."
    },
    "2408.08023v1": {
      "title": "Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks",
      "url": "http://arxiv.org/abs/2408.08023v1",
      "authors": "Rujia Shen, Boran Wang, Chao Zhao, Yi Guan, Jingchi Jiang",
      "update_time": "2024-08-15",
      "abstract": "Causal discovery from time-series data aims to capture both intra-slice (contemporaneous) and inter-slice (time-lagged) causality between variables within the temporal chain, which is crucial for various scientific disciplines. Compared to causal discovery from non-time-series data, causal discovery from time-series data necessitates more serialized samples with a larger amount of observed time steps. To address the challenges, we propose a novel gradient-based causal discovery approach STIC, which focuses on \\textbf{S}hort-\\textbf{T}erm \\textbf{I}nvariance using \\textbf{C}onvolutional neural networks to uncover the causal relationships from time-series data. Specifically, STIC leverages both the short-term time and mechanism invariance of causality within each window observation, which possesses the property of independence, to enhance sample efficiency. Furthermore, we construct two causal convolution kernels, which correspond to the short-term time and mechanism invariance respectively, to estimate the window causal graph. To demonstrate the necessity of convolutional neural networks for causal discovery from time-series data, we theoretically derive the equivalence between convolution and the underlying generative principle of time-series data under the assumption that the additive noise model is identifiable. Experimental evaluations conducted on both synthetic and FMRI benchmark datasets demonstrate that our STIC outperforms baselines significantly and achieves the state-of-the-art performance, particularly when the datasets contain a limited number of observed time steps. Code is available at \\url{https://github.com/HITshenrj/STIC}.",
      "code_url": "https://github.com/hitshenrj/stic"
    },
    "2408.07977v1": {
      "title": "Cortical network reconfiguration aligns with shifts of basal ganglia and cerebellar influence",
      "url": "http://arxiv.org/abs/2408.07977v1",
      "authors": "Kimberly Nestor, Javier Rasero, Richard Betzel, Peter J. Gianaros, Timothy Verstynen",
      "update_time": "2024-08-15",
      "abstract": "Mammalian functional architecture flexibly adapts, transitioning from integration where information is distributed across the cortex, to segregation where information is focal in densely connected communities of brain regions. This flexibility in cortical brain networks is hypothesized to be driven by control signals originating from subcortical pathways, with the basal ganglia shifting the cortex towards integrated processing states and the cerebellum towards segregated states. In a sample of healthy human participants (N=242), we used fMRI to measure temporal variation in global brain networks while participants performed two tasks with similar cognitive demands (Stroop and Multi-Source Inference Task (MSIT)). Using the modularity index, we determined cortical networks shifted from integration (low modularity) at rest to high modularity during easier i.e. congruent (segregation). Increased task difficulty (incongruent) resulted in lower modularity in comparison to the easier counterpart indicating more integration of the cortical network. Influence of basal ganglia and cerebellum was measured using eigenvector centrality. Results correlated with decreases and increases in cortical modularity respectively, with only the basal ganglia influence preceding cortical integration. Our results support the theory the basal ganglia shifts cortical networks to integrated states due to environmental demand. Cerebellar influence correlates with shifts to segregated cortical states, though may not play a causal role."
    },
    "2408.03596v2": {
      "title": "Hierarchical Quantum Control Gates for Functional MRI Understanding",
      "url": "http://arxiv.org/abs/2408.03596v2",
      "authors": "Xuan-Bac Nguyen, Hoang-Quan Nguyen, Hugh Churchill, Samee U. Khan, Khoa Luu",
      "update_time": "2024-08-13",
      "abstract": "Quantum computing has emerged as a powerful tool for solving complex problems intractable for classical computers, particularly in popular fields such as cryptography, optimization, and neurocomputing. In this paper, we present a new quantum-based approach named the Hierarchical Quantum Control Gates (HQCG) method for efficient understanding of Functional Magnetic Resonance Imaging (fMRI) data. This approach includes two novel modules: the Local Quantum Control Gate (LQCG) and the Global Quantum Control Gate (GQCG), which are designed to extract local and global features of fMRI signals, respectively. Our method operates end-to-end on a quantum machine, leveraging quantum mechanics to learn patterns within extremely high-dimensional fMRI signals, such as 30,000 samples which is a challenge for classical computers. Empirical results demonstrate that our approach significantly outperforms classical methods. Additionally, we found that the proposed quantum model is more stable and less prone to overfitting than the classical methods."
    }
  },
  "MEG": {
    "2408.15419v1": {
      "title": "Bayesian Inference General Procedures for A Single-subject Test Study",
      "url": "http://arxiv.org/abs/2408.15419v1",
      "authors": "Jie Li, Gary Green, Sarah J. A. Carr, Peng Liu, Jian Zhang",
      "update_time": "2024-08-27",
      "abstract": "This paper presents a Bayesian Inference General Procedures for A Single-Subject Test (BIGPAST), designed to mitigate the effects of skewness. BIGPAST operates under the null hypothesis that the single-subject follows the same distribution as the control group.   We assess BIGPAST's performance against other methods through a series of simulation studies. The results demonstrate that BIGPAST is robust against deviations from normality and outperforms the existing approaches in terms of accuracy. This is because BIGPAST can effectively reduce model misspecification errors under the skewed Student's \\( t \\) assumption. We apply BIGPAST to a MEG dataset consisting of an individual with mild traumatic brain injury and an age and gender-matched control group, demonstrating its effectiveness in detecting abnormalities in the single-subject."
    },
    "2408.04815v1": {
      "title": "Towards improving Alzheimer's intervention: a machine learning approach for biomarker detection through combining MEG and MRI pipelines",
      "url": "http://arxiv.org/abs/2408.04815v1",
      "authors": "Alwani Liyana Ahmad, Jose Sanchez-Bornot, Roberto C. Sotero, Damien Coyle, Zamzuri Idris, Ibrahima Faye",
      "update_time": "2024-08-09",
      "abstract": "MEG are non invasive neuroimaging techniques with excellent temporal and spatial resolution, crucial for studying brain function in dementia and Alzheimer Disease. They identify changes in brain activity at various Alzheimer stages, including preclinical and prodromal phases. MEG may detect pathological changes before clinical symptoms, offering potential biomarkers for intervention. This study evaluates classification techniques using MEG features to distinguish between healthy controls and mild cognitive impairment participants from the BioFIND study. We compare MEG based biomarkers with MRI based anatomical features, both independently and combined. We used 3 Tesla MRI and MEG data from 324 BioFIND participants;158 MCI and 166 HC. Analyses were performed using MATLAB with SPM12 and OSL toolboxes. Machine learning analyses, including 100 Monte Carlo replications of 10 fold cross validation, were conducted on sensor and source spaces. Combining MRI with MEG features achieved the best performance; 0.76 accuracy and AUC of 0.82 for GLMNET using LCMV source based MEG. MEG only analyses using LCMV and eLORETA also performed well, suggesting that combining uncorrected MEG with z-score-corrected MRI features is optimal."
    },
    "2408.02760v1": {
      "title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis",
      "url": "http://arxiv.org/abs/2408.02760v1",
      "authors": "Adri\u00e0 Solana, Erik Frans\u00e9n, Gonzalo Uribarri",
      "update_time": "2024-08-05",
      "abstract": "Multivariate Time Series Classification (MTSC) is a ubiquitous problem in science and engineering, particularly in neuroscience, where most data acquisition modalities involve the simultaneous time-dependent recording of brain activity in multiple brain regions. In recent years, Random Convolutional Kernel models such as ROCKET and MiniRocket have emerged as highly effective time series classification algorithms, capable of achieving state-of-the-art accuracy results with low computational load. Despite their success, these types of models face two major challenges when employed in neuroscience: 1) they struggle to deal with high-dimensional data such as EEG and MEG, and 2) they are difficult to interpret. In this work, we present a novel ROCKET-based algorithm, named Detach-Rocket Ensemble, that is specifically designed to address these two problems in MTSC. Our algorithm leverages pruning to provide an integrated estimation of channel importance, and ensembles to achieve better accuracy and provide a label probability. Using a synthetic multivariate time series classification dataset in which we control the amount of information carried by each of the channels, we first show that our algorithm is able to correctly recover the channel importance for classification. Then, using two real-world datasets, a MEG dataset and an EEG dataset, we show that Detach-Rocket Ensemble is able to provide both interpretable channel relevance and competitive classification accuracy, even when applied directly to the raw brain data, without the need for feature engineering."
    },
    "2408.08877v1": {
      "title": "Hotspots and Trends in Magnetoencephalography Research (2013-2022): A Bibliometric Analysis",
      "url": "http://arxiv.org/abs/2408.08877v1",
      "authors": "Shen Liu, Jingwen Zhao",
      "update_time": "2024-08-02",
      "abstract": "This study aimed to utilize bibliometric methods to analyze trends in international Magnetoencephalography (MEG) research from 2013 to 2022. Due to the limited volume of domestic literature on MEG, this analysis focuses solely on the global research landscape, providing insights from the past decade as a representative sample. This study utilized bibliometric methods to explore and analyze the progress, hotspots and developmental trends in international MEG research spanning from 1995 to 2022. The results indicated a dynamic and steady growth trend in the overall number of publications in MEG. Ryusuke Kakigi emerged as the most prolific author, while Neuroimage led as the most prolific journal. Current hotspots in MEG research encompass resting state, networks, functional connectivity, phase dynamics, oscillation, and more. Future trends in MEG research are poised to advance across three key aspects: disease treatment and practical applications, experimental foundations and technical advancements, and fundamental and advanced human cognition. In the future, there should be a focus on enhancing cross-integration and utilization of MEG with other instruments to diversify research methodologies in this field"
    },
    "2408.00118v2": {
      "title": "Gemma 2: Improving Open Language Models at a Practical Size",
      "url": "http://arxiv.org/abs/2408.00118v2",
      "authors": "Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, L\u00e9onard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ram\u00e9, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozi\u0144ska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Pluci\u0144ska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin G\u00f6rner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Perrin, S\u00e9bastien M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev",
      "update_time": "2024-08-02",
      "abstract": "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community."
    },
    "2407.19417v1": {
      "title": "Photon energy reconstruction with the MEG II liquid xenon calorimeter",
      "url": "http://arxiv.org/abs/2407.19417v1",
      "authors": "Kensuke Yamamoto, Sei Ban, Lukas Gerritzen, Toshiyuki Iwamoto, Satoru Kobayashi, Ayaka Matsushita, Toshinori Mori, Rina Onda, Wataru Ootani, Atsushi Oya",
      "update_time": "2024-07-28",
      "abstract": "The MEG II experiment searches for a charged-lepton-flavour-violating $\\mu \\to e \\gamma$ with the target sensitivity of $6 \\times 10^{-14}$. A liquid xenon calorimeter with VUV-sensitive photosensors measures photon position, timing, and energy. This paper concentrates on the precise photon energy reconstruction with the MEG II liquid xenon calorimeter. Since a muon beam rate is $3\\text{-}5 \\times 10^{7}~\\text{s}^{-1}$, multi-photon elimination analysis is performed using waveform analysis techniques such as a template waveform fit. As a result, background events in the energy range of 48-58 MeV were reduced by 34 %. The calibration of an energy scale of the calorimeter with several calibration sources is also discussed to achieve a high resolution of 1.8 %."
    },
    "2407.16784v1": {
      "title": "A Sub-solar Fe/O, logT~7.5 Gas Component Permeating the Milky Way's CGM",
      "url": "http://arxiv.org/abs/2407.16784v1",
      "authors": "Armando Lara-DI, Yair Krongold, Smita Mathur, Sanskriti Das, Anjali Gupta, O. Segura Montero",
      "update_time": "2024-07-23",
      "abstract": "Our study focuses on characterizing the highly ionized gas within the Milky Way's (MW) Circumgalactic Medium (CGM) that gives rise to ionic transitions in the X-ray band 2 - 25 \\AA. Utilizing stacked \\Chandra/\\ACISS\\ \\MEG\\ and \\LETG\\ spectra toward QSO sightlines, we employ the self-consistent hybrid ionization code PHASE to model our data. The stacked spectra are optimally described by three distinct gas phase components: a \\warm\\ (\\logT\\ $\\sim$ 5.5), \\warmhot\\ (\\logT\\ $\\sim 6$), and \\hot\\ (\\logT\\ $\\sim$ 7.5) components. These findings confirm the presence of the \\hot\\ component in the MW's CGM indicating its coexistence with a \\warm\\ and a \\warmhot\\ gas phases. We find this \\hot\\ component to be homogeneous in temperature but inhomogeneous in column density. The gas in the \\hot\\ component requires over-abundances relative to solar to be consistent with the Dispersion Measure (DM) from the Galactic halo reported in the literature. {For the hot phase we estimated a DM = $55.1^{+29.9}_{-23.7}$ pc cm$^{-3}$}. We conclude that this phase is either enriched in Oxygen, Silicon, and Sulfur, or has metallicity {over 6} times solar value, or a combination of both. We do not detect Fe L-shell absorption lines, implying O/Fe $\\geq$ 4. The non-solar abundance ratios found in the super-virial gas component in the Galactic halo suggest that this phase arises from Galactic feedback."
    },
    "2407.13733v1": {
      "title": "Revisiting Neutrino Masses In Clockwork Models",
      "url": "http://arxiv.org/abs/2407.13733v1",
      "authors": "Aadarsh Singh",
      "update_time": "2024-07-18",
      "abstract": "In this paper, we have looked at various variants of the clockwork model and studied their impact on the neutrino masses. Some of the generalizations such as generalized CW and next-to-nearest neighbour interaction CW have already been explored by a few authors. In this study, we studied non-local CW for the fermionic case and found that non-local models relax the $\\left| q \\right| > 1$ constraint to produce localization of the zero mode. We also made a comparison among them and have shown that for some parameter ranges, non-local variants of CW are more efficient than ordinary CW in generating the hierarchy required for the $\\nu$ mass scale. Finally, phenomenological constraints from $BR(\\mu \\rightarrow e \\gamma )$ FCNC process and Higgs decay width have been imposed on the parameter space in non-local and both-sided clockwork models. We have listed benchmark points which are surviving current experimental bounds from MEG and are within the reach of the upcoming MEG-II experiment."
    },
    "2407.07245v2": {
      "title": "Accelerating Mobile Edge Generation (MEG) by Constrained Learning",
      "url": "http://arxiv.org/abs/2407.07245v2",
      "authors": "Xiaoxia Xu, Yuanwei Liu, Xidong Mu, Hong Xing, Arumugam Nallanathan",
      "update_time": "2024-08-06",
      "abstract": "A novel accelerated mobile edge generation (MEG) framework is proposed for generating high-resolution images on mobile devices. Exploiting a large-scale latent diffusion model (LDM) distributed across edge server (ES) and user equipment (UE), cost-efficient artificial intelligence generated content (AIGC) is achieved by transmitting low-dimensional features between ES and UE. To reduce overheads of both distributed computations and transmissions, a dynamic diffusion and feature merging scheme is conceived. By jointly optimizing the denoising steps and feature merging ratio, the image generation quality is maximized subject to latency and energy consumption constraints. To address this problem and tailor LDM sub-models, a low-complexity MEG acceleration protocol is developed. Particularly, a backbone meta-architecture is trained via offline distillation. Then, dynamic diffusion and feature merging are determined in online channel environment, which can be viewed as a constrained Markov Decision Process (MDP). A constrained variational policy optimization (CVPO) based MEG algorithm is further proposed for constraint-guaranteed learning, namely MEG-CVPO. Numerical results verify that: 1) The proposed framework can generate 1024$\\times$1024 high-quality images over noisy channels while reducing over $40\\%$ latency compared to conventional generation schemes. 2) The developed MEG-CVPO effectively mitigates constraint violations, thus flexibly controlling the trade-off between image distortion and generation costs."
    },
    "2407.05060v2": {
      "title": "Volume-optimal persistence homological scaffolds of hemodynamic networks covary with MEG theta-alpha aperiodic dynamics",
      "url": "http://arxiv.org/abs/2407.05060v2",
      "authors": "Nghi Nguyen, Tao Hou, Enrico Amico, Jingyi Zheng, Huajun Huang, Alan D. Kaplan, Giovanni Petri, Joaqu\u00edn Go\u00f1i, Ralph Kaufmann, Yize Zhao, Duy Duong-Tran, Li Shen",
      "update_time": "2024-07-23",
      "abstract": "Higher-order properties of functional magnetic resonance imaging (fMRI) induced connectivity have been shown to unravel many exclusive topological and dynamical insights beyond pairwise interactions. Nonetheless, whether these fMRI-induced higher-order properties play a role in disentangling other neuroimaging modalities' insights remains largely unexplored and poorly understood. In this work, by analyzing fMRI data from the Human Connectome Project Young Adult dataset using persistent homology, we discovered that the volume-optimal persistence homological scaffolds of fMRI-based functional connectomes exhibited conservative topological reconfigurations from the resting state to attentional task-positive state. Specifically, while reflecting the extent to which each cortical region contributed to functional cycles following different cognitive demands, these reconfigurations were constrained such that the spatial distribution of cavities in the connectome is relatively conserved. Most importantly, such level of contributions covaried with powers of aperiodic activities mostly within the theta-alpha (4-12 Hz) band measured by magnetoencephalography (MEG). This comprehensive result suggests that fMRI-induced hemodynamics and MEG theta-alpha aperiodic activities are governed by the same functional constraints specific to each cortical morpho-structure. Methodologically, our work paves the way toward an innovative computing paradigm in multimodal neuroimaging topological learning.",
      "code_url": "https://github.com/ngcaonghi/scaffold_noise"
    }
  },
  "neuroAI": {
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    },
    "2112.15459v3": {
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "authors": "Samuele Bolotta, Guillaume Dumas",
      "update_time": "2022-04-11",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied."
    },
    "2011.07464v2": {
      "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
      "url": "http://arxiv.org/abs/2011.07464v2",
      "authors": "Joseph Marino",
      "update_time": "2021-10-23",
      "abstract": "This paper reviews predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (non-linear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field."
    },
    "1909.02603v2": {
      "title": "Additive function approximation in the brain",
      "url": "http://arxiv.org/abs/1909.02603v2",
      "authors": "Kameron Decker Harris",
      "update_time": "2019-09-13",
      "abstract": "Many biological learning systems such as the mushroom body, hippocampus, and cerebellum are built from sparsely connected networks of neurons. For a new understanding of such networks, we study the function spaces induced by sparse random features and characterize what functions may and may not be learned. A network with $d$ inputs per neuron is found to be equivalent to an additive model of order $d$, whereas with a degree distribution the network combines additive terms of different orders. We identify three specific advantages of sparsity: additive function approximation is a powerful inductive bias that limits the curse of dimensionality, sparse networks are stable to outlier noise in the inputs, and sparse random features are scalable. Thus, even simple brain architectures can be powerful function approximators. Finally, we hope that this work helps popularize kernel theories of networks among computational neuroscientists.",
      "code_url": "https://github.com/kharris/sparse-random-features"
    }
  },
  "medical": {
    "2408.16769v1": {
      "title": "PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning",
      "url": "http://arxiv.org/abs/2408.16769v1",
      "authors": "Noor Hussein, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",
      "update_time": "2024-08-29",
      "abstract": "Medical vision-language models (Med-VLMs) trained on large datasets of medical image-text pairs and later fine-tuned for specific tasks have emerged as a mainstream paradigm in medical image analysis. However, recent studies have highlighted the susceptibility of these Med-VLMs to adversarial attacks, raising concerns about their safety and robustness. Randomized smoothing is a well-known technique for turning any classifier into a model that is certifiably robust to adversarial perturbations. However, this approach requires retraining the Med-VLM-based classifier so that it classifies well under Gaussian noise, which is often infeasible in practice. In this paper, we propose a novel framework called PromptSmooth to achieve efficient certified robustness of Med-VLMs by leveraging the concept of prompt learning. Given any pre-trained Med-VLM, PromptSmooth adapts it to handle Gaussian noise by learning textual prompts in a zero-shot or few-shot manner, achieving a delicate balance between accuracy and robustness, while minimizing the computational overhead. Moreover, PromptSmooth requires only a single model to handle multiple noise levels, which substantially reduces the computational cost compared to traditional methods that rely on training a separate model for each noise level. Comprehensive experiments based on three Med-VLMs and across six downstream datasets of various imaging modalities demonstrate the efficacy of PromptSmooth. Our code and models are available at https://github.com/nhussein/promptsmooth.",
      "code_url": "https://github.com/nhussein/promptsmooth"
    },
    "2408.16719v1": {
      "title": "H-SGANet: Hybrid Sparse Graph Attention Network for Deformable Medical Image Registration",
      "url": "http://arxiv.org/abs/2408.16719v1",
      "authors": "Yufeng Zhou, Wenming Cao",
      "update_time": "2024-08-29",
      "abstract": "The integration of Convolutional Neural Network (ConvNet) and Transformer has emerged as a strong candidate for image registration, leveraging the strengths of both models and a large parameter space. However, this hybrid model, treating brain MRI volumes as grid or sequence structures, faces challenges in accurately representing anatomical connectivity, diverse brain regions, and vital connections contributing to the brain's internal architecture. Concerns also arise regarding the computational expense and GPU memory usage associated with this model. To tackle these issues, a lightweight hybrid sparse graph attention network (H-SGANet) has been developed. This network incorporates a central mechanism, Sparse Graph Attention (SGA), based on a Vision Graph Neural Network (ViG) with predetermined anatomical connections. The SGA module expands the model's receptive field and seamlessly integrates into the network. To further amplify the advantages of the hybrid network, the Separable Self-Attention (SSA) is employed as an enhanced token mixer, integrated with depth-wise convolution to constitute SSAFormer. This strategic integration is designed to more effectively extract long-range dependencies. As a hybrid ConvNet-ViG-Transformer model, H-SGANet offers threefold benefits for volumetric medical image registration. It optimizes fixed and moving images concurrently through a hybrid feature fusion layer and an end-to-end learning framework. Compared to VoxelMorph, a model with a similar parameter count, H-SGANet demonstrates significant performance enhancements of 3.5% and 1.5% in Dice score on the OASIS dataset and LPBA40 dataset, respectively."
    },
    "2408.16659v1": {
      "title": "Motion-Driven Neural Optimizer for Prophylactic Braces Made by Distributed Microstructures",
      "url": "http://arxiv.org/abs/2408.16659v1",
      "authors": "Xingjian Han, Yu Jiang, Weiming Wang, Guoxin Fang, Simeon Gill, Zhiqiang Zhang, Shengfa Wang, Jun Saito, Deepak Kumar, Zhongxuan Luo, Emily Whiting, Charlie C. L. Wang",
      "update_time": "2024-08-29",
      "abstract": "Joint injuries, and their long-term consequences, present a substantial global health burden. Wearable prophylactic braces are an attractive potential solution to reduce the incidence of joint injuries by limiting joint movements that are related to injury risk. Given human motion and ground reaction forces, we present a computational framework that enables the design of personalized braces by optimizing the distribution of microstructures and elasticity. As varied brace designs yield different reaction forces that influence kinematics and kinetics analysis outcomes, the optimization process is formulated as a differentiable end-to-end pipeline in which the design domain of microstructure distribution is parameterized onto a neural network. The optimized distribution of microstructures is obtained via a self-learning process to determine the network coefficients according to a carefully designed set of losses and the integrated biomechanical and physical analyses. Since knees and ankles are the most commonly injured joints, we demonstrate the effectiveness of our pipeline by designing, fabricating, and testing prophylactic braces for the knee and ankle to prevent potentially harmful joint movements."
    },
    "2408.16622v1": {
      "title": "Sparse Signal Reconstruction for Overdispersed Low-photon Count Biomedical Imaging Using $\\ell_p$ Total Variation",
      "url": "http://arxiv.org/abs/2408.16622v1",
      "authors": "Yu Lu, Roummel F. Marcia",
      "update_time": "2024-08-29",
      "abstract": "The negative binomial model, which generalizes the Poisson distribution model, can be found in applications involving low-photon signal recovery, including medical imaging. Recent studies have explored several regularization terms for the negative binomial model, such as the $\\ell_p$ quasi-norm with $0 < p < 1$, $\\ell_1$ norm, and the total variation (TV) quasi-seminorm for promoting sparsity in signal recovery. These penalty terms have been shown to improve image reconstruction outcomes. In this paper, we investigate the $\\ell_p$ quasi-seminorm, both isotropic and anisotropic $\\ell_p$ TV quasi-seminorms, within the framework of the negative binomial statistical model. This problem can be formulated as an optimization problem, which we solve using a gradient-based approach. We present comparisons between the negative binomial and Poisson statistical models using the $\\ell_p$ TV quasi-seminorm as well as common penalty terms. Our experimental results highlight the efficacy of the proposed method."
    },
    "2408.16496v1": {
      "title": "An automated and time efficient framework for simulation of coronary blood flow under steady and pulsatile conditions",
      "url": "http://arxiv.org/abs/2408.16496v1",
      "authors": "Guido Nannini, Simone Saitta, Luca Mariani, Riccardo Maragna, Andrea Baggiano, Saima Mushtaq, Gianluca Pontone, Alberto Redaelli",
      "update_time": "2024-08-29",
      "abstract": "Fractional flow reserve (FFR) is the gold standard for diagnosing coronary artery disease (CAD). FFRCT uses computational fluid dynamics (CFD) to evaluate FFR non-invasively by simulating coronary flow in geometries reconstructed from computed tomography (CT). However, it faces challenges related to the cost of computing and uncertainties in defining patient-specific boundary conditions (BCs). We investigated using time-averaged steady BCs instead of pulsatile ones to reduce computational time and deployed a self-adjusting method for tuning BCs to patient clinical data. 133 coronary arteries were reconstructed from CT images of CAD patients. For each vessel, invasive FFR was measured. Steady BCs for CFD were defined in two steps: i) rest BCs were extrapolated from clinical and image-derived data; ii) hyperemic BCs were computed from resting conditions. Flow rate was iteratively adjusted during the simulation until patient aortic pressure was matched. Pulsatile BCs were defined using the convergence values of steady BCs. Lesion-specific hemodynamic indexes were computed and compared between groups of patients indicated for surgery and those not. The whole pipeline was implemented as a straightforward, fully automated process. Steady and pulsatile FFRCT showed a strong correlation (r=0.988) and correlated with invasive FFR (r=0.797). The per-point difference between the pressure and FFRCT field predicted by the two methods was below 0.01 and 0.02, respectively. Both approaches exhibited good diagnostic performance: accuracy was 0.860 and 0.864, with AUCs of 0.923 and 0.912, for steady and pulsatile cases, respectively. Computational time for steady BCs CFD was approximately 30-fold lower than for the pulsatile case. This work demonstrates the feasibility of using steady BCs CFD for computing FFRCT in coronary arteries and its performance in a fully automated pipeline."
    },
    "2408.16485v1": {
      "title": "A multiple imputation approach to distinguish curative from life-prolonging effects in the presence of missing covariates",
      "url": "http://arxiv.org/abs/2408.16485v1",
      "authors": "Marta Cipriani, Marta Fiocco, Marco Alf\u00f2, Maria Quelhas, Eni Musta",
      "update_time": "2024-08-29",
      "abstract": "Medical advancements have increased cancer survival rates and the possibility of finding a cure. Hence, it is crucial to evaluate the impact of treatments in terms of both curing the disease and prolonging survival. We may use a Cox proportional hazards (PH) cure model to achieve this. However, a significant challenge in applying such a model is the potential presence of partially observed covariates in the data. We aim to refine the methods for imputing partially observed covariates based on multiple imputation and fully conditional specification (FCS) approaches. To be more specific, we consider a more general case, where different covariate vectors are used to model the cure probability and the survival of patients who are not cured. We also propose an approximation of the exact conditional distribution using a regression approach, which helps draw imputed values at a lower computational cost. To assess its effectiveness, we compare the proposed approach with a complete case analysis and an analysis without any missing covariates. We discuss the application of these techniques to a real-world dataset from the BO06 clinical trial on osteosarcoma."
    },
    "2408.16440v1": {
      "title": "Instruction-tuned Large Language Models for Machine Translation in the Medical Domain",
      "url": "http://arxiv.org/abs/2408.16440v1",
      "authors": "Miguel Rios",
      "update_time": "2024-08-29",
      "abstract": "Large Language Models (LLMs) have shown promising results on machine translation for high resource language pairs and domains. However, in specialised domains (e.g. medical) LLMs have shown lower performance compared to standard neural machine translation models. The consistency in the machine translation of terminology is crucial for users, researchers, and translators in specialised domains. In this study, we compare the performance between baseline LLMs and instruction-tuned LLMs in the medical domain. In addition, we introduce terminology from specialised medical dictionaries into the instruction formatted datasets for fine-tuning LLMs. The instruction-tuned LLMs significantly outperform the baseline models with automatic metrics."
    },
    "2408.16422v1": {
      "title": "CollectionLocator Level 1: Metadata-Based Search for Collections in Federated Biobanks",
      "url": "http://arxiv.org/abs/2408.16422v1",
      "authors": "Volodymyr A. Shekhovtsov, Bence Slajcho, Aron Sacherer, Johann Eder",
      "update_time": "2024-08-29",
      "abstract": "Biobanks are indispensable resources for medical research collecting biological material and associated data and making them available for research projects and medical studies. For that, the biobank data has to meet certain criteria which can be formulated as adherence to the FAIR (findable, accessible, interoperable and reusable) principles.   We developed a tool, CollectionLocator, which aims at increasing the FAIR compliance of biobank data by supporting researchers in identifying which biobank and which collection are likely to contain cases (material and data) satisfying the requirements of a defined research project when the detailed sample data is not available due to privacy restrictions. The CollectionLocator is based on an ontology-based metadata model to address the enormous heterogeneities and ensure the privacy of the donors of the biological samples and the data. Furthermore, the CollectionLocator represents the data and metadata quality of the collections such that the quality requirements of the requester can be matched with the quality of the available data. The concept of CollectionLocator is evaluated with a proof-of-concept implementation."
    },
    "2408.16413v1": {
      "title": "Chemometrics-aided Surface-enhanced Raman spectrometric detection and quantification of GH and TE hormones in blood",
      "url": "http://arxiv.org/abs/2408.16413v1",
      "authors": "Annah M. Ondieki, Zephania Birech, Kenneth A. Kaduki, Peter W. Mwangi, Moses Juma, Boniface M. Chege",
      "update_time": "2024-08-29",
      "abstract": "This work explores the use of Surface-Enhanced Raman Spectroscopy (SERS) combined with artificial neural network (ANN) models to detect and quantify growth hormone (GH) and testosterone (TE) in the blood of Sprague Dawley (SD) rats. SERS spectra were recorded from blood samples of SD rats injected with GH, TE, both hormones, and non-injected controls using 785 nm laser excitation. The samples were mixed with silver nanoparticles (AgNPs) synthesized in distilled water, applied onto a microscope slide, and air-dried. The resulting SERS spectra displayed similar profiles with intensity variations depending on the hormone, revealing specific bands at 658, 798, 878, 914, 932, 1064, 1190, 1354, 1410, and 1658 cm-1. PCA analysis indicated time-dependent intensity changes in bands centered around 1378 (all groups), 658 and 1614 cm-1 (GH-injected rats), and others for different hormone combinations. These variations reflect subtle biochemical changes induced by hormone injections. The ANN models, trained with six PCA scores of blood spiked with various hormone concentrations, showed high accuracy, with coefficients of determination greater than 87.71% and low root mean square error (RMSE) values below 0.6436. The hormone levels in injected rats increased initially and later declined, a trend confirmed by ELISA kits. Although ELISA and SERS produced similar results, SERS offered advantages such as rapid analysis (about two minutes), simple sample preparation, small sample volumes, and non-specificity to hormones. This suggests that SERS, combined with ANN models, could be used to detect exogenous sports dopants. These findings expand the potential applications of SERS in sports science, clinical diagnostics, and biomedical research."
    },
    "2408.16355v1": {
      "title": "NeRF-CA: Dynamic Reconstruction of X-ray Coronary Angiography with Extremely Sparse-views",
      "url": "http://arxiv.org/abs/2408.16355v1",
      "authors": "Kirsten W. H. Maas, Danny Ruijters, Anna Vilanova, Nicola Pezzotti",
      "update_time": "2024-08-29",
      "abstract": "Dynamic three-dimensional (4D) reconstruction from two-dimensional X-ray coronary angiography (CA) remains a significant clinical problem. Challenges include sparse-view settings, intra-scan motion, and complex vessel morphology such as structure sparsity and background occlusion. Existing CA reconstruction methods often require extensive user interaction or large training datasets. On the other hand, Neural Radiance Field (NeRF), a promising deep learning technique, has successfully reconstructed high-fidelity static scenes for natural and medical scenes. Recent work, however, identified that sparse-views, background occlusion, and dynamics still pose a challenge when applying NeRF in the X-ray angiography context. Meanwhile, many successful works for natural scenes propose regularization for sparse-view reconstruction or scene decomposition to handle dynamics. However, these techniques do not directly translate to the CA context, where both challenges and background occlusion are significant. This paper introduces NeRF-CA, the first step toward a 4D CA reconstruction method that achieves reconstructions from sparse coronary angiograms with cardiac motion. We leverage the motion of the coronary artery to decouple the scene into a dynamic coronary artery component and static background. We combine this scene decomposition with tailored regularization techniques. These techniques enforce the separation of the coronary artery from the background by enforcing dynamic structure sparsity and scene smoothness. By uniquely combining these approaches, we achieve 4D reconstructions from as few as four angiogram sequences. This setting aligns with clinical workflows while outperforming state-of-the-art X-ray sparse-view NeRF reconstruction techniques. We validate our approach quantitatively and qualitatively using 4D phantom datasets and ablation studies.",
      "code_url": "https://github.com/kirstenmaas/nerf-ca"
    }
  }
}