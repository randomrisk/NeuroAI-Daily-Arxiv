{
  "Brain": {
    "2407.17450v1": {
      "title": "Longitudinal Principal Manifold Estimation",
      "url": "http://arxiv.org/abs/2407.17450v1",
      "authors": "Robert Zielinski, Kun Meng, Ani Eloyan",
      "update_time": "2024-07-24",
      "abstract": "Longitudinal magnetic resonance imaging data is used to model trajectories of change in brain regions of interest to identify areas susceptible to atrophy in those with neurodegenerative conditions like Alzheimer's disease. Most methods for extracting brain regions are applied to scans from study participants independently, resulting in wide variability in shape and volume estimates of these regions over time in longitudinal studies. To address this problem, we propose a longitudinal principal manifold estimation method, which seeks to recover smooth, longitudinally meaningful manifold estimates of shapes over time. The proposed approach uses a smoothing spline to smooth over the coefficients of principal manifold embedding functions estimated at each time point. This mitigates the effects of random disturbances to the manifold between time points. Additionally, we propose a novel data augmentation approach to enable principal manifold estimation on self-intersecting manifolds. Simulation studies demonstrate performance improvements over naive applications of principal manifold estimation and principal curve/surface methods. The proposed method improves the estimation of surfaces of hippocampuses and thalamuses using data from participants of the Alzheimer's Disease Neuroimaging Initiative. An analysis of magnetic resonance imaging data from 236 individuals shows the advantages of our proposed methods that leverage regional longitudinal trends for segmentation."
    },
    "2407.17356v1": {
      "title": "Gradient-based inference of abstract task representations for generalization in neural networks",
      "url": "http://arxiv.org/abs/2407.17356v1",
      "authors": "Ali Hummos, Felipe del R\u00edo, Brabeeba Mien Wang, Julio Hurtado, Cristian B. Calderon, Guangyu Robert Yang",
      "update_time": "2024-07-24",
      "abstract": "Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals. The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction). Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity. We investigate if such benefits might extend to neural networks trained with task abstractions. For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition). To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework. We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI). Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations. Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting. Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples."
    },
    "2407.17324v2": {
      "title": "Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population",
      "url": "http://arxiv.org/abs/2407.17324v2",
      "authors": "Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis",
      "update_time": "2024-07-25",
      "abstract": "Dementia, a debilitating neurological condition affecting millions worldwide, presents significant diagnostic challenges. In this work, we introduce a novel methodology for the classification of demented and non-demented elderly patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach features a unique technique for selectively processing MRI slices, focusing on the most relevant brain regions and excluding less informative sections. This methodology is complemented by a confidence-based classification committee composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and Dem3D EfficientNet. These models work synergistically to enhance decision-making accuracy, leveraging their collective strengths. Tested on the Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore, validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset confirmed the robustness and generalizability of our approach. The use of explainable AI (XAI) techniques and comprehensive ablation studies further substantiate the effectiveness of our techniques, providing insights into the decision-making process and the importance of our methodology. This research offers a significant advancement in dementia diagnosis, providing a highly accurate and efficient tool for clinical applications."
    },
    "2407.17220v1": {
      "title": "Scale-free behavior of weight distributions of connectomes",
      "url": "http://arxiv.org/abs/2407.17220v1",
      "authors": "Michelle Cirunay, G\u00e9za \u00d3dor, Istv\u00e1n Papp",
      "update_time": "2024-07-24",
      "abstract": "To determine the precise link between form and function, brain studies primarily concentrate on the anatomical wiring of the brain and its topological properties. In this work, we investigate the weighted degree and connection length distributions of the KKI-113 and KKI-18 human connectomes, the fruit fly, and of the mouse retina. We found that the node strength (weighted degree) distribution behavior differs depending on the considered scale. On the global scale, the distributions are found to follow a power-law behavior, with a roughly universal exponent close to 3. However, this behavior breaks at the local scale as the node strength distributions of the KKI-18 follow a stretched exponential, and the fly and mouse retina follow the log-normal distribution, respectively which are indicative of underlying random multiplicative processes and underpins non-locality of learning in a brain close to the critical state. However, for the case of the KKI-113 and the H01 human (1mm$^3$) datasets, the local weighted degree distributions follow an exponentially truncated power-law, which may hint at the fact that the critical learning mechanism may have manifested at the node level too."
    },
    "2407.17082v1": {
      "title": "A Coupled Diffusion Approximation for Spatiotemporal Hemodynamic Response and Deoxygenated Blood Volume Fraction in Microcirculation",
      "url": "http://arxiv.org/abs/2407.17082v1",
      "authors": "Maryam Samavaki, Santtu S\u00f6derholm, Arash Zarrin Nia, Sampsa Pursiainen",
      "update_time": "2024-07-24",
      "abstract": "Background and Objective: This article concerns a diffusion-based mathematical model for analyzing blood flow and oxygen transport within the capillaries, emphasizing its significance in understanding the physiological and biochemical dynamics of the cerebrovascular system and brain tissue. The focus of this study is, in particular, on neurovascular coupling and the spatiotemporal aspects of blood flow and oxygen transport in microcirculation. Methods: By adopting a coupled modelling approach that integrates the hemodynamic response function (HRF) with Fick's law and the Navier-Stokes equations (NSEs), we provide a computational framework for the diffusion-driven transport of deoxygenated and total blood volume fractions (DBV and TBV), essential for understanding blood oxygenation level-dependent functional magnetic resonance imaging (fMRI) and near-infrared spectroscopy (NIRS) applications. Results: The applicability of the model is further demonstrated through numerical experiments utilizing a 7 Tesla magnetic resonance imaging (MRI) dataset for head segmentation, which facilitates the differentiation of arterial blood vessels and various brain tissue compartments. By simulating hemodynamical responses and analyzing their impact on volumetric DBV and TBV, this study offers valuable insights into spatiotemporal modelling of brain tissue and blood flow. Conclusions: By integrating spatiotemporal modelling within a realistic head model derived from high-resolution 7 Tesla-MRI, we analyze the complex interplay between blood flow, oxygen transport, and brain tissue dynamics. This inclusion of a realistic head model not only enriches the accuracy of our simulations but is also beneficial for understanding the physiological and hemodynamic responses within the human brain."
    },
    "2407.16684v1": {
      "title": "AutoRG-Brain: Grounded Report Generation for Brain MRI",
      "url": "http://arxiv.org/abs/2407.16684v1",
      "authors": "Jiayu Lei, Xiaoman Zhang, Chaoyi Wu, Lisong Dai, Ya Zhang, Yanyong Zhang, Yanfeng Wang, Weidi Xie, Yuehua Li",
      "update_time": "2024-07-23",
      "abstract": "Radiologists are tasked with interpreting a large number of images in a daily base, with the responsibility of generating corresponding reports. This demanding workload elevates the risk of human error, potentially leading to treatment delays, increased healthcare costs, revenue loss, and operational inefficiencies. To address these challenges, we initiate a series of work on grounded Automatic Report Generation (AutoRG), starting from the brain MRI interpretation system, which supports the delineation of brain structures, the localization of anomalies, and the generation of well-organized findings. We make contributions from the following aspects, first, on dataset construction, we release a comprehensive dataset encompassing segmentation masks of anomaly regions and manually authored reports, termed as RadGenome-Brain MRI. This data resource is intended to catalyze ongoing research and development in the field of AI-assisted report generation systems. Second, on system design, we propose AutoRG-Brain, the first brain MRI report generation system with pixel-level grounded visual clues. Third, for evaluation, we conduct quantitative assessments and human evaluations of brain structure segmentation, anomaly localization, and report generation tasks to provide evidence of its reliability and accuracy. This system has been integrated into real clinical scenarios, where radiologists were instructed to write reports based on our generated findings and anomaly segmentation masks. The results demonstrate that our system enhances the report-writing skills of junior doctors, aligning their performance more closely with senior doctors, thereby boosting overall productivity."
    },
    "2407.16616v1": {
      "title": "Implementing engrams from a machine learning perspective: the relevance of a latent space",
      "url": "http://arxiv.org/abs/2407.16616v1",
      "authors": "J Marco de Lucas",
      "update_time": "2024-07-23",
      "abstract": "In our previous work, we proposed that engrams in the brain could be biologically implemented as autoencoders over recurrent neural networks. These autoencoders would comprise basic excitatory/inhibitory motifs, with credit assignment deriving from a simple homeostatic criterion. This brief note examines the relevance of the latent space in these autoencoders. We consider the relationship between the dimensionality of these autoencoders and the complexity of the information being encoded. We discuss how observed differences between species in their connectome could be linked to their cognitive capacities. Finally, we link this analysis with a basic but often overlooked fact: human cognition is likely limited by our own brain structure. However, this limitation does not apply to machine learning systems, and we should be aware of the need to learn how to exploit this augmented vision of the nature."
    },
    "2407.16613v1": {
      "title": "No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots",
      "url": "http://arxiv.org/abs/2407.16613v1",
      "authors": "Alican Mertan, Nick Cheney",
      "update_time": "2024-07-23",
      "abstract": "It is prevalent in contemporary AI and robotics to separately postulate a brain modeled by neural networks and employ it to learn intelligent and adaptive behavior. While this method has worked very well for many types of tasks, it isn't the only type of intelligence that exists in nature. In this work, we study the ways in which intelligent behavior can be created without a separate and explicit brain for robot control, but rather solely as a result of the computation occurring within the physical body of a robot. Specifically, we show that adaptive and complex behavior can be created in voxel-based virtual soft robots by using simple reactive materials that actively change the shape of the robot, and thus its behavior, under different environmental cues. We demonstrate a proof of concept for the idea of closed-loop morphological computation, and show that in our implementation, it enables behavior mimicking logic gates, enabling us to demonstrate how such behaviors may be combined to build up more complex collective behaviors.",
      "code_url": "https://github.com/mertan-a/no-brainer"
    },
    "2407.16589v1": {
      "title": "Hyperbolic embedding of brain networks detects regions disrupted by neurodegeneration",
      "url": "http://arxiv.org/abs/2407.16589v1",
      "authors": "Alice Longhena, Martin Guillemaud, Fabrizio De Vico Fallani, Raffaella Lara Migliaccio, Mario Chavez",
      "update_time": "2024-07-23",
      "abstract": "Graph theoretical methods have proven valuable for investigating alterations in both anatomical and functional brain connectivity networks during Alzheimer's disease (AD). Recent studies suggest that representing brain networks in a suitable geometric space can better capture their connectivity structure. This study introduces a novel approach to characterize brain connectivity changes using low-dimensional, informative representations of networks in a latent geometric space. Specifically, the networks are embedded in the Poincar\\'e disk model of hyperbolic geometry. Here, we define a local measure of distortion of the geometric neighborhood of a node following a perturbation. The method is applied to a brain networks dataset of patients with AD and healthy participants, derived from DWI and fMRI scans. We show that, compared with standard graph measures, our method identifies more accurately the brain regions most affected by neurodegeneration. Notably, the abnormality detection in memory-related and frontal areas are robust across multiple brain parcellation scales. Finally, our findings suggest that the geometric perturbation score could serve as a potential biomarker for characterizing disease progression."
    },
    "2407.16571v1": {
      "title": "Correlating Stroke Risk with Non-Invasive Tracing of Brain Blood Dynamic via a Portable Speckle Contrast Optical Spectroscopy Laser Device",
      "url": "http://arxiv.org/abs/2407.16571v1",
      "authors": "Yu Xi Huang, Simon Mahler, Aidin Abedi, Julian Michael Tyszka, Yu Tung Lo, Patrick D. Lyden, Jonathan Russin, Charles Liu, Changhuei Yang",
      "update_time": "2024-07-23",
      "abstract": "Stroke poses a significant global health threat, with millions affected annually, leading to substantial morbidity and mortality. Current stroke risk assessment for the general population relies on markers such as demographics, blood tests, and comorbidities. A minimally invasive, clinically scalable, and cost-effective way to directly measure cerebral blood flow presents an opportunity. This opportunity has potential to positively impact effective stroke risk assessment prevention and intervention. Physiological changes in the cerebral vascular system, particularly in response to carbon dioxide level changes and oxygen deprivation, such as during breath-holding, can offer insights into stroke risk assessment. However, existing methods for measuring cerebral perfusion reserve, such as blood flow and blood volume changes, are limited by either invasiveness or impracticality. Here, we propose a transcranial approach using speckle contrast optical spectroscopy (SCOS) to non-invasively monitor regional changes in brain blood flow and volume during breath-holding. Our study, conducted on 50 individuals classified into two groups (low-risk and higher-risk for stroke), shows significant differences in blood dynamic changes during breath-holding between the two groups, providing physiological insights for stroke risk assessment using a non-invasive quantification paradigm. Given its cost-effectiveness, scalability, portability, and simplicity, this laser-centric tool has significant potential in enhancing the pre-screening of stroke and mitigating strokes in the general population through early diagnosis and intervention."
    }
  },
  "EEG": {
    "2407.16249v1": {
      "title": "How Does a Single EEG Channel Tell Us About Brain States in Brain-Computer Interfaces ?",
      "url": "http://arxiv.org/abs/2407.16249v1",
      "authors": "Zaineb Ajra, Binbin Xu, G\u00e9rard Dray, Jacky Montmain, St\u00e9phane Perrey",
      "update_time": "2024-07-23",
      "abstract": "Over recent decades, neuroimaging tools, particularly electroencephalography (EEG), have revolutionized our understanding of the brain and its functions. EEG is extensively used in traditional brain-computer interface (BCI) systems due to its low cost, non-invasiveness, and high temporal resolution. This makes it invaluable for identifying different brain states relevant to both medical and non-medical applications. Although this practice is widely recognized, current methods are mainly confined to lab or clinical environments because they rely on data from multiple EEG electrodes covering the entire head. Nonetheless, a significant advancement for these applications would be their adaptation for \"real-world\" use, using portable devices with a single-channel. In this study, we tackle this challenge through two distinct strategies: the first approach involves training models with data from multiple channels and then testing new trials on data from a single channel individually. The second method focuses on training with data from a single channel and then testing the performances of the models on data from all the other channels individually. To efficiently classify cognitive tasks from EEG data, we propose Convolutional Neural Networks (CNNs) with only a few parameters and fast learnable spectral-temporal features. We demonstrated the feasibility of these approaches on EEG data recorded during mental arithmetic and motor imagery tasks from three datasets. We achieved the highest accuracies of 100%, 91.55% and 73.45% in binary and 3-class classification on specific channels across three datasets. This study can contribute to the development of single-channel BCI and provides a robust EEG biomarker for brain states classification."
    },
    "2407.15167v1": {
      "title": "The VEP Booster: A Closed-Loop AI System for Visual EEG Biomarker Auto-generation",
      "url": "http://arxiv.org/abs/2407.15167v1",
      "authors": "Junwen Luo, Chengyong Jiang, Qingyuan Chen, Dongqi Han, Yansen Wang, Biao Yan, Dongsheng Li, Jiayi Zhang",
      "update_time": "2024-07-21",
      "abstract": "Effective visual brain-machine interfaces (BMI) is based on reliable and stable EEG biomarkers. However, traditional adaptive filter-based approaches may suffer from individual variations in EEG signals, while deep neural network-based approaches may be hindered by the non-stationarity of EEG signals caused by biomarker attenuation and background oscillations. To address these challenges, we propose the Visual Evoked Potential Booster (VEP Booster), a novel closed-loop AI framework that generates reliable and stable EEG biomarkers under visual stimulation protocols. Our system leverages an image generator to refine stimulus images based on real-time feedback from human EEG signals, generating visual stimuli tailored to the preferences of primary visual cortex (V1) neurons and enabling effective targeting of neurons most responsive to stimuli. We validated our approach by implementing a system and employing steady-state visual evoked potential (SSVEP) visual protocols in five human subjects. Our results show significant enhancements in the reliability and utility of EEG biomarkers for all individuals, with the largest improvement in SSVEP response being 105%, the smallest being 28%, and the average increase being 76.5%. These promising results have implications for both clinical and technological applications"
    },
    "2407.14876v1": {
      "title": "Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction",
      "url": "http://arxiv.org/abs/2407.14876v1",
      "authors": "Petros Koutsouvelis, Bartlomiej Chybowski, Alfredo Gonzalez-Sulser, Shima Abdullateef, Javier Escudero",
      "update_time": "2024-07-20",
      "abstract": "Accurate prediction of epileptic seizures could prove critical for improving patient safety and quality of life in drug-resistant epilepsy. Although deep learning-based approaches have shown promising seizure prediction performance using scalp electroencephalogram (EEG) signals, substantial limitations still impede their clinical adoption. Furthermore, identifying the optimal preictal period (OPP) for labeling EEG segments remains a challenge. Here, we not only develop a competitive deep learning model for seizure prediction but, more importantly, leverage it to demonstrate a methodology to comprehensively evaluate the predictive performance in the seizure prediction task. For this, we introduce a CNN-Transformer deep learning model to detect preictal spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model on 19 pediatric patients of the open-access CHB-MIT dataset in a subject-specific manner. Using the OPP of each patient, preictal and interictal segments were correctly identified with an average sensitivity of 99.31%, specificity of 95.34%, AUC of 99.35%, and F1- score of 97.46%, while prediction time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric allowed outlining the impact of different preictal period definitions on prediction time, accuracy, output stability, and transition time between interictal and preictal states in a comprehensive and quantitative way and highlighted the importance of considering both inter- and intra-patient variability in seizure prediction."
    },
    "2407.14850v1": {
      "title": "A Tale of Single-channel Electroencephalogram: Devices, Datasets, Signal Processing, Applications, and Future Directions",
      "url": "http://arxiv.org/abs/2407.14850v1",
      "authors": "Yueyang Li, Weiming Zeng, Wenhao Dong, Di Han, Lei Chen, Hongyu Chen, Hongjie Yan, Wai Ting Siok, Nizhuan Wang",
      "update_time": "2024-07-20",
      "abstract": "Single-channel electroencephalogram (EEG) is a cost-effective, comfortable, and non-invasive method for monitoring brain activity, widely adopted by researchers, consumers, and clinicians. The increasing number and proportion of articles on single-channel EEG underscore its growing potential. This paper provides a comprehensive review of single-channel EEG, focusing on development trends, devices, datasets, signal processing methods, recent applications, and future directions. Definitions of bipolar and unipolar configurations in single-channel EEG are clarified to guide future advancements. Applications mainly span sleep staging, emotion recognition, educational research, and clinical diagnosis. Ongoing advancements of single-channel EEG in AI-based EEG generation techniques suggest potential parity or superiority over multichannel EEG performance."
    },
    "2407.14020v1": {
      "title": "NeuroBind: Towards Unified Multimodal Representations for Neural Signals",
      "url": "http://arxiv.org/abs/2407.14020v1",
      "authors": "Fengyu Yang, Chao Feng, Daniel Wang, Tianye Wang, Ziyao Zeng, Zhiyang Xu, Hyoungseob Park, Pengliang Ji, Hanbin Zhao, Yuanning Li, Alex Wong",
      "update_time": "2024-07-19",
      "abstract": "Understanding neural activity and information representation is crucial for advancing knowledge of brain function and cognition. Neural activity, measured through techniques like electrophysiology and neuroimaging, reflects various aspects of information processing. Recent advances in deep neural networks offer new approaches to analyzing these signals using pre-trained models. However, challenges arise due to discrepancies between different neural signal modalities and the limited scale of high-quality neural data. To address these challenges, we present NeuroBind, a general representation that unifies multiple brain signal types, including EEG, fMRI, calcium imaging, and spiking data. To achieve this, we align neural signals in these image-paired neural datasets to pre-trained vision-language embeddings. Neurobind is the first model that studies different neural modalities interconnectedly and is able to leverage high-resource modality models for various neuroscience tasks. We also showed that by combining information from different neural signal modalities, NeuroBind enhances downstream performance, demonstrating the effectiveness of the complementary strengths of different neural modalities. As a result, we can leverage multiple types of neural signals mapped to the same space to improve downstream tasks, and demonstrate the complementary strengths of different neural modalities. This approach holds significant potential for advancing neuroscience research, improving AI systems, and developing neuroprosthetics and brain-computer interfaces."
    },
    "2407.13514v1": {
      "title": "Topological Analysis of Seizure-Induced Changes in Brain Hierarchy Through Effective Connectivity",
      "url": "http://arxiv.org/abs/2407.13514v1",
      "authors": "Anass B. El-Yaagoubi, Moo K. Chung, Hernando Ombao",
      "update_time": "2024-07-18",
      "abstract": "Traditional Topological Data Analysis (TDA) methods, such as Persistent Homology (PH), rely on distance measures (e.g., cross-correlation, partial correlation, coherence, and partial coherence) that are symmetric by definition. While useful for studying topological patterns in functional brain connectivity, the main limitation of these methods is their inability to capture the directional dynamics - which is crucial for understanding effective brain connectivity. We propose the Causality-Based Topological Ranking (CBTR) method, which integrates Causal Inference (CI) to assess effective brain connectivity with Hodge Decomposition (HD) to rank brain regions based on their mutual influence. Our simulations confirm that the CBTR method accurately and consistently identifies hierarchical structures in multivariate time series data. Moreover, this method effectively identifies brain regions showing the most significant interaction changes with other regions during seizures using electroencephalogram (EEG) data. These results provide novel insights into the brain's hierarchical organization and illuminate the impact of seizures on its dynamics."
    },
    "2407.11617v1": {
      "title": "Feature interpretability in BCIs: exploring the role of network lateralization",
      "url": "http://arxiv.org/abs/2407.11617v1",
      "authors": "Juliana Gonzalez-Astudillo, Fabrizio De Vico Fallani",
      "update_time": "2024-07-16",
      "abstract": "Brain-computer interfaces (BCIs) enable users to interact with the external world using brain activity. Despite their potential in neuroscience and industry, BCI performance remains inconsistent in noninvasive applications, often prioritizing algorithms that achieve high classification accuracies while masking the neural mechanisms driving that performance. In this study, we investigated the interpretability of features derived from brain network lateralization, benchmarking against widely used techniques like power spectrum density (PSD), common spatial pattern (CSP), and Riemannian geometry. We focused on the spatial distribution of the functional connectivity within and between hemispheres during motor imagery tasks, introducing network-based metrics such as integration and segregation. Evaluating these metrics across multiple EEG-based BCI datasets, our findings reveal that network lateralization offers neurophysiological plausible insights, characterized by stronger lateralization in sensorimotor and frontal areas contralateral to imagined movements. While these lateralization features did not outperform CSP and Riemannian geometry in terms of classification accuracy, they demonstrated competitive performance against PSD alone and provided biologically relevant interpretation. This study underscores the potential of brain network lateralization as a new feature to be integrated in motor imagery-based BCIs for enhancing the interpretability of noninvasive applications.",
      "code_url": "https://github.com/julianagonzalezastudillo/netfeat"
    },
    "2407.10414v1": {
      "title": "Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment",
      "url": "http://arxiv.org/abs/2407.10414v1",
      "authors": "Zitong Lu, Yile Wang",
      "update_time": "2024-07-15",
      "abstract": "Deep convolutional neural networks (DCNNs) have demonstrated excellent performance in object recognition and have been found to share some similarities with brain visual processing. However, the substantial gap between DCNNs and human visual perception still exists. Functional magnetic resonance imaging (fMRI) as a widely used technique in cognitive neuroscience can record neural activation in the human visual cortex during the process of visual perception. Can we teach DCNNs human fMRI signals to achieve a more brain-like model? To answer this question, this study proposed ReAlnet-fMRI, a model based on the SOTA vision model CORnet but optimized using human fMRI data through a multi-layer encoding-based alignment framework. This framework has been shown to effectively enable the model to learn human brain representations. The fMRI-optimized ReAlnet-fMRI exhibited higher similarity to the human brain than both CORnet and the control model in within-and across-subject as well as within- and across-modality model-brain (fMRI and EEG) alignment evaluations. Additionally, we conducted an in-depth analyses to investigate how the internal representations of ReAlnet-fMRI differ from CORnet in encoding various object dimensions. These findings provide the possibility of enhancing the brain-likeness of visual models by integrating human neural data, helping to bridge the gap between computer vision and visual neuroscience."
    },
    "2407.09950v1": {
      "title": "PSO Fuzzy XGBoost Classifier Boosted with Neural Gas Features on EEG Signals in Emotion Recognition",
      "url": "http://arxiv.org/abs/2407.09950v1",
      "authors": "Seyed Muhammad Hossein Mousavi",
      "update_time": "2024-07-13",
      "abstract": "Emotion recognition is the technology-driven process of identifying and categorizing human emotions from various data sources, such as facial expressions, voice patterns, body motion, and physiological signals, such as EEG. These physiological indicators, though rich in data, present challenges due to their complexity and variability, necessitating sophisticated feature selection and extraction methods. NGN, an unsupervised learning algorithm, effectively adapts to input spaces without predefined grid structures, improving feature extraction from physiological data. Furthermore, the incorporation of fuzzy logic enables the handling of fuzzy data by introducing reasoning that mimics human decision-making. The combination of PSO with XGBoost aids in optimizing model performance through efficient hyperparameter tuning and decision process optimization. This study explores the integration of Neural-Gas Network (NGN), XGBoost, Particle Swarm Optimization (PSO), and fuzzy logic to enhance emotion recognition using physiological signals. Our research addresses three critical questions concerning the improvement of XGBoost with PSO and fuzzy logic, NGN's effectiveness in feature selection, and the performance comparison of the PSO-fuzzy XGBoost classifier with standard benchmarks. Acquired results indicate that our methodologies enhance the accuracy of emotion recognition systems and outperform other feature selection techniques using the majority of classifiers, offering significant implications for both theoretical advancement and practical application in emotion recognition technology."
    },
    "2407.09922v1": {
      "title": "Transcranial low-level laser stimulation in near infrared-II region for brain safety and protection",
      "url": "http://arxiv.org/abs/2407.09922v1",
      "authors": "Zhilin Li, Yongheng Zhao, Yiqing Hu, Yang Li, Keyao Zhang, Zhibing Gao, Lirou Tan, Hanli Liu, Xiaoli Li, Aihua Cao, Zaixu Cui, Chenguang Zhao",
      "update_time": "2024-07-13",
      "abstract": "Background: The use of near-infrared lasers for transcranial photobiomodulation (tPBM) offers a non-invasive method for influencing brain activity and is beneficial for various neurological conditions. Objective: To investigate the safety and neuroprotective properties of tPBM using near-infrared (NIR)-II laser stimulation. Methods: We conducted thirteen experiments involving multidimensional and quantitative methods and measured serum neurobiomarkers, performed electroencephalogram (EEG) and magnetic resonance imaging (MRI) scans, assessed executive functions, and collected a subjective questionnaire. Results: Significant reductions (n=15) in neuron specific enolase (NSE) levels were observed after treatment, indicating neuroprotective effects. No structural or functional brain abnormalities were observed, confirming the safety of tPBM. Additionally, cognitive and executive functions were not impaired, with participants' feedback indicating minimal discomfort. Conclusions: Our data indicate that NIR-II tPBM is safe with specific parameters, highlighting its potential for brain protection."
    }
  },
  "BCI": {
    "2407.16249v1": {
      "title": "How Does a Single EEG Channel Tell Us About Brain States in Brain-Computer Interfaces ?",
      "url": "http://arxiv.org/abs/2407.16249v1",
      "authors": "Zaineb Ajra, Binbin Xu, G\u00e9rard Dray, Jacky Montmain, St\u00e9phane Perrey",
      "update_time": "2024-07-23",
      "abstract": "Over recent decades, neuroimaging tools, particularly electroencephalography (EEG), have revolutionized our understanding of the brain and its functions. EEG is extensively used in traditional brain-computer interface (BCI) systems due to its low cost, non-invasiveness, and high temporal resolution. This makes it invaluable for identifying different brain states relevant to both medical and non-medical applications. Although this practice is widely recognized, current methods are mainly confined to lab or clinical environments because they rely on data from multiple EEG electrodes covering the entire head. Nonetheless, a significant advancement for these applications would be their adaptation for \"real-world\" use, using portable devices with a single-channel. In this study, we tackle this challenge through two distinct strategies: the first approach involves training models with data from multiple channels and then testing new trials on data from a single channel individually. The second method focuses on training with data from a single channel and then testing the performances of the models on data from all the other channels individually. To efficiently classify cognitive tasks from EEG data, we propose Convolutional Neural Networks (CNNs) with only a few parameters and fast learnable spectral-temporal features. We demonstrated the feasibility of these approaches on EEG data recorded during mental arithmetic and motor imagery tasks from three datasets. We achieved the highest accuracies of 100%, 91.55% and 73.45% in binary and 3-class classification on specific channels across three datasets. This study can contribute to the development of single-channel BCI and provides a robust EEG biomarker for brain states classification."
    },
    "2407.14936v1": {
      "title": "EidetiCom: A Cross-modal Brain-Computer Semantic Communication Paradigm for Decoding Visual Perception",
      "url": "http://arxiv.org/abs/2407.14936v1",
      "authors": "Linfeng Zheng, Peilin Chen, Shiqi Wang",
      "update_time": "2024-07-20",
      "abstract": "Brain-computer interface (BCI) facilitates direct communication between the human brain and external systems by utilizing brain signals, eliminating the need for conventional communication methods such as speaking, writing, or typing. Nevertheless, the continuous generation of brain signals in BCI frameworks poses challenges for efficient storage and real-time transmission. While considering the human brain as a semantic source, the meaningful information associated with cognitive activities often gets obscured by substantial noise present in acquired brain signals, resulting in abundant redundancy. In this paper, we propose a cross-modal brain-computer semantic communication paradigm, named EidetiCom, for decoding visual perception under limited-bandwidth constraint. The framework consists of three hierarchical layers, each responsible for compressing the semantic information of brain signals into representative features. These low-dimensional compact features are transmitted and converted into semantically meaningful representations at the receiver side, serving three distinct tasks for decoding visual perception: brain signal-based visual classification, brain-to-caption translation, and brain-to-image generation, in a scalable manner. Through extensive qualitative and quantitative experiments, we demonstrate that the proposed paradigm facilitates the semantic communication under low bit rate conditions ranging from 0.017 to 0.192 bits-per-sample, achieving high-quality semantic reconstruction and highlighting its potential for efficient storage and real-time communication of brain recordings in BCI applications, such as eidetic memory storage and assistive communication for patients."
    },
    "2407.12582v1": {
      "title": "Embracing Events and Frames with Hierarchical Feature Refinement Network for Object Detection",
      "url": "http://arxiv.org/abs/2407.12582v1",
      "authors": "Hu Cao, Zehua Zhang, Yan Xia, Xinyi Li, Jiahao Xia, Guang Chen, Alois Knoll",
      "update_time": "2024-07-17",
      "abstract": "In frame-based vision, object detection faces substantial performance degradation under challenging conditions due to the limited sensing capability of conventional cameras. Event cameras output sparse and asynchronous events, providing a potential solution to solve these problems. However, effectively fusing two heterogeneous modalities remains an open issue. In this work, we propose a novel hierarchical feature refinement network for event-frame fusion. The core concept is the design of the coarse-to-fine fusion module, denoted as the cross-modality adaptive feature refinement (CAFR) module. In the initial phase, the bidirectional cross-modality interaction (BCI) part facilitates information bridging from two distinct sources. Subsequently, the features are further refined by aligning the channel-level mean and variance in the two-fold adaptive feature refinement (TAFR) part. We conducted extensive experiments on two benchmarks: the low-resolution PKU-DDD17-Car dataset and the high-resolution DSEC dataset. Experimental results show that our method surpasses the state-of-the-art by an impressive margin of $\\textbf{8.0}\\%$ on the DSEC dataset. Besides, our method exhibits significantly better robustness (\\textbf{69.5}\\% versus \\textbf{38.7}\\%) when introducing 15 different corruption types to the frame images. The code can be found at the link (https://github.com/HuCaoFighting/FRN)."
    },
    "2407.11617v1": {
      "title": "Feature interpretability in BCIs: exploring the role of network lateralization",
      "url": "http://arxiv.org/abs/2407.11617v1",
      "authors": "Juliana Gonzalez-Astudillo, Fabrizio De Vico Fallani",
      "update_time": "2024-07-16",
      "abstract": "Brain-computer interfaces (BCIs) enable users to interact with the external world using brain activity. Despite their potential in neuroscience and industry, BCI performance remains inconsistent in noninvasive applications, often prioritizing algorithms that achieve high classification accuracies while masking the neural mechanisms driving that performance. In this study, we investigated the interpretability of features derived from brain network lateralization, benchmarking against widely used techniques like power spectrum density (PSD), common spatial pattern (CSP), and Riemannian geometry. We focused on the spatial distribution of the functional connectivity within and between hemispheres during motor imagery tasks, introducing network-based metrics such as integration and segregation. Evaluating these metrics across multiple EEG-based BCI datasets, our findings reveal that network lateralization offers neurophysiological plausible insights, characterized by stronger lateralization in sensorimotor and frontal areas contralateral to imagined movements. While these lateralization features did not outperform CSP and Riemannian geometry in terms of classification accuracy, they demonstrated competitive performance against PSD alone and provided biologically relevant interpretation. This study underscores the potential of brain network lateralization as a new feature to be integrated in motor imagery-based BCIs for enhancing the interpretability of noninvasive applications.",
      "code_url": "https://github.com/julianagonzalezastudillo/netfeat"
    },
    "2407.07595v1": {
      "title": "Scaling Law in Neural Data: Non-Invasive Speech Decoding with 175 Hours of EEG Data",
      "url": "http://arxiv.org/abs/2407.07595v1",
      "authors": "Motoshige Sato, Kenichi Tomeoka, Ilya Horiguchi, Kai Arulkumaran, Ryota Kanai, Shuntaro Sasai",
      "update_time": "2024-07-10",
      "abstract": "Brain-computer interfaces (BCIs) hold great potential for aiding individuals with speech impairments. Utilizing electroencephalography (EEG) to decode speech is particularly promising due to its non-invasive nature. However, recordings are typically short, and the high variability in EEG data has led researchers to focus on classification tasks with a few dozen classes. To assess its practical applicability for speech neuroprostheses, we investigate the relationship between the size of EEG data and decoding accuracy in the open vocabulary setting. We collected extensive EEG data from a single participant (175 hours) and conducted zero-shot speech segment classification using self-supervised representation learning. The model trained on the entire dataset achieved a top-1 accuracy of 48\\% and a top-10 accuracy of 76\\%, while mitigating the effects of myopotential artifacts. Conversely, when the data was limited to the typical amount used in practice ($\\sim$10 hours), the top-1 accuracy dropped to 2.5\\%, revealing a significant scaling effect. Additionally, as the amount of training data increased, the EEG latent representation progressively exhibited clearer temporal structures of spoken phrases. This indicates that the decoder can recognize speech segments in a data-driven manner without explicit measurements of word recognition. This research marks a significant step towards the practical realization of EEG-based speech BCIs."
    },
    "2407.05550v1": {
      "title": "MEEG and AT-DGNN: Advancing EEG Emotion Recognition with Music and Graph Learning",
      "url": "http://arxiv.org/abs/2407.05550v1",
      "authors": "Minghao Xiao, Zhengxi Zhu, Wenyu Wang, Meixia Qu",
      "update_time": "2024-07-08",
      "abstract": "Recent advances in neuroscience have elucidated the crucial role of coordinated brain region activities during cognitive tasks. To explore the complexity, we introduce the MEEG dataset, a comprehensive multi-modal music-induced electroencephalogram (EEG) dataset and the Attention-based Temporal Learner with Dynamic Graph Neural Network (AT-DGNN), a novel framework for EEG-based emotion recognition. The MEEG dataset captures a wide range of emotional responses to music, enabling an in-depth analysis of brainwave patterns in musical contexts. The AT-DGNN combines an attention-based temporal learner with a dynamic graph neural network (DGNN) to accurately model the local and global graph dynamics of EEG data across varying brain network topology. Our evaluations show that AT-DGNN achieves superior performance, with an accuracy (ACC) of 83.06\\% in arousal and 85.31\\% in valence, outperforming state-of-the-art (SOTA) methods on the MEEG dataset. Comparative analyses with traditional datasets like DEAP highlight the effectiveness of our approach and underscore the potential of music as a powerful medium for emotion induction. This study not only advances our understanding of the brain emotional processing, but also enhances the accuracy of emotion recognition technologies in brain-computer interfaces (BCI), leveraging both graph-based learning and the emotional impact of music. The source code and dataset are available at \\textit{https://github.com/xmh1011/AT-DGNN}."
    },
    "2407.04610v1": {
      "title": "Gamification of Motor Imagery Brain-Computer Interface Training Protocols: a systematic review",
      "url": "http://arxiv.org/abs/2407.04610v1",
      "authors": "Fred Atilla, Marie Postma, Maryam Alimardani",
      "update_time": "2024-07-05",
      "abstract": "Current Motor Imagery Brain-Computer Interfaces (MI-BCI) require a lengthy and monotonous training procedure to train both the system and the user. Considering many users struggle with effective control of MI-BCI systems, a more user-centered approach to training might help motivate users and facilitate learning, alleviating inefficiency of the BCI system. With the increase of BCI-controlled games, researchers have suggested using game principles for BCI training, as games are naturally centered on the player. This review identifies and evaluates the application of game design elements to MI-BCI training, a process known as gamification. Through a systematic literature search, we examined how MI-BCI training protocols have been gamified and how specific game elements impacted the training outcomes. We identified 86 studies that employed gamified MI-BCI protocols in the past decade. The prevalence and reported effects of individual game elements on user experience and performance were extracted and synthesized. Results reveal that MI-BCI training protocols are most often gamified by having users move an avatar in a virtual environment that provides visual feedback. Furthermore, in these virtual environments, users were provided with goals that guided their actions. Using gamification, the reviewed protocols allowed users to reach effective MI-BCI control, with studies reporting positive effects of four individual elements on user performance and experience, namely: feedback, avatars, assistance, and social interaction. Based on these elements, this review makes current and future recommendations for effective gamification, such as the use of virtual reality and adaptation of game difficulty to user skill level."
    },
    "2407.03177v1": {
      "title": "EDPNet: An Efficient Dual Prototype Network for Motor Imagery EEG Decoding",
      "url": "http://arxiv.org/abs/2407.03177v1",
      "authors": "Can Han, Chen Liu, Crystal Cai, Jun Wang, Dahong Qian",
      "update_time": "2024-07-03",
      "abstract": "Motor imagery electroencephalograph (MI-EEG) decoding plays a crucial role in developing motor imagery brain-computer interfaces (MI-BCIs). However, decoding intentions from MI remains challenging due to the inherent complexity of EEG signals relative to the small-sample size. In this paper, we propose an Efficient Dual Prototype Network (EDPNet) to enable accurate and fast MI decoding. EDPNet employs a lightweight adaptive spatial-spectral fusion module, which promotes more efficient information fusion between multiple EEG electrodes. Subsequently, a parameter-free multi-scale variance pooling module extracts more comprehensive temporal features. Furthermore, we introduce dual prototypical learning to optimize the feature space distribution and training process, thereby improving the model's generalization ability on small-sample MI datasets. Our experimental results show that the EDPNet outperforms state-of-the-art models with superior classification accuracy and kappa values (84.11% and 0.7881 for dataset BCI competition IV 2a, 86.65% and 0.7330 for dataset BCI competition IV 2b). Additionally, we use the BCI competition III IVa dataset with fewer training data to further validate the generalization ability of the proposed EDPNet. We also achieve superior performance with 82.03% classification accuracy. Benefiting from the lightweight parameters and superior decoding accuracy, our EDPNet shows great potential for MI-BCI applications. The code is publicly available at https://github.com/hancan16/EDPNet.",
      "code_url": "https://github.com/hancan16/edpnet"
    },
    "2407.04736v1": {
      "title": "SCDM: Unified Representation Learning for EEG-to-fNIRS Cross-Modal Generation in MI-BCIs",
      "url": "http://arxiv.org/abs/2407.04736v1",
      "authors": "Yisheng Li, Shuqiang Wang",
      "update_time": "2024-07-01",
      "abstract": "Hybrid motor imagery brain-computer interfaces (MI-BCIs), which integrate both electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) signals, outperform those based solely on EEG. However, simultaneously recording EEG and fNIRS signals is highly challenging due to the difficulty of colocating both types of sensors on the same scalp surface. This physical constraint complicates the acquisition of high-quality hybrid signals, thereby limiting the widespread application of hybrid MI-BCIs. To facilitate the acquisition of hybrid EEG-fNIRS signals, this study proposes the spatio-temporal controlled diffusion model (SCDM) as a framework for cross-modal generation from EEG to fNIRS. The model utilizes two core modules, the spatial cross-modal generation (SCG) module and the multi-scale temporal representation (MTR) module, which adaptively learn the respective latent temporal and spatial representations of both signals in a unified representation space. The SCG module further maps EEG representations to fNIRS representations by leveraging their spatial relationships. Experimental results show high similarity between synthetic and real fNIRS signals. The joint classification performance of EEG and synthetic fNIRS signals is comparable to or even better than that of EEG with real fNIRS signals. Furthermore, the synthetic signals exhibit similar spatio-temporal features to real signals while preserving spatial relationships with EEG signals. Experimental results suggest that the SCDM may represent a promising paradigm for the acquisition of hybrid EEG-fNIRS signals in MI-BCI systems."
    },
    "2406.18425v1": {
      "title": "L-Sort: An Efficient Hardware for Real-time Multi-channel Spike Sorting with Localization",
      "url": "http://arxiv.org/abs/2406.18425v1",
      "authors": "Yuntao Han, Shiwei Wang, Alister Hamilton",
      "update_time": "2024-06-26",
      "abstract": "Spike sorting is essential for extracting neuronal information from neural signals and understanding brain function. With the advent of high-density microelectrode arrays (HDMEAs), the challenges and opportunities in multi-channel spike sorting have intensified. Real-time spike sorting is particularly crucial for closed-loop brain computer interface (BCI) applications, demanding efficient hardware implementations. This paper introduces L-Sort, an hardware design for real-time multi-channel spike sorting. Leveraging spike localization techniques, L-Sort achieves efficient spike detection and clustering without the need to store raw signals during detection. By incorporating median thresholding and geometric features, L-Sort demonstrates promising results in terms of accuracy and hardware efficiency. We assessed the detection and clustering accuracy of our design with publicly available datasets recorded using high-density neural probes (Neuropixel). We implemented our design on an FPGA and compared the results with state of the art. Results show that our designs consume less hardware resource comparing with other FPGA-based spike sorting hardware."
    }
  },
  "fMRI": {
    "2407.17082v1": {
      "title": "A Coupled Diffusion Approximation for Spatiotemporal Hemodynamic Response and Deoxygenated Blood Volume Fraction in Microcirculation",
      "url": "http://arxiv.org/abs/2407.17082v1",
      "authors": "Maryam Samavaki, Santtu S\u00f6derholm, Arash Zarrin Nia, Sampsa Pursiainen",
      "update_time": "2024-07-24",
      "abstract": "Background and Objective: This article concerns a diffusion-based mathematical model for analyzing blood flow and oxygen transport within the capillaries, emphasizing its significance in understanding the physiological and biochemical dynamics of the cerebrovascular system and brain tissue. The focus of this study is, in particular, on neurovascular coupling and the spatiotemporal aspects of blood flow and oxygen transport in microcirculation. Methods: By adopting a coupled modelling approach that integrates the hemodynamic response function (HRF) with Fick's law and the Navier-Stokes equations (NSEs), we provide a computational framework for the diffusion-driven transport of deoxygenated and total blood volume fractions (DBV and TBV), essential for understanding blood oxygenation level-dependent functional magnetic resonance imaging (fMRI) and near-infrared spectroscopy (NIRS) applications. Results: The applicability of the model is further demonstrated through numerical experiments utilizing a 7 Tesla magnetic resonance imaging (MRI) dataset for head segmentation, which facilitates the differentiation of arterial blood vessels and various brain tissue compartments. By simulating hemodynamical responses and analyzing their impact on volumetric DBV and TBV, this study offers valuable insights into spatiotemporal modelling of brain tissue and blood flow. Conclusions: By integrating spatiotemporal modelling within a realistic head model derived from high-resolution 7 Tesla-MRI, we analyze the complex interplay between blood flow, oxygen transport, and brain tissue dynamics. This inclusion of a realistic head model not only enriches the accuracy of our simulations but is also beneficial for understanding the physiological and hemodynamic responses within the human brain."
    },
    "2407.16589v1": {
      "title": "Hyperbolic embedding of brain networks detects regions disrupted by neurodegeneration",
      "url": "http://arxiv.org/abs/2407.16589v1",
      "authors": "Alice Longhena, Martin Guillemaud, Fabrizio De Vico Fallani, Raffaella Lara Migliaccio, Mario Chavez",
      "update_time": "2024-07-23",
      "abstract": "Graph theoretical methods have proven valuable for investigating alterations in both anatomical and functional brain connectivity networks during Alzheimer's disease (AD). Recent studies suggest that representing brain networks in a suitable geometric space can better capture their connectivity structure. This study introduces a novel approach to characterize brain connectivity changes using low-dimensional, informative representations of networks in a latent geometric space. Specifically, the networks are embedded in the Poincar\\'e disk model of hyperbolic geometry. Here, we define a local measure of distortion of the geometric neighborhood of a node following a perturbation. The method is applied to a brain networks dataset of patients with AD and healthy participants, derived from DWI and fMRI scans. We show that, compared with standard graph measures, our method identifies more accurately the brain regions most affected by neurodegeneration. Notably, the abnormality detection in memory-related and frontal areas are robust across multiple brain parcellation scales. Finally, our findings suggest that the geometric perturbation score could serve as a potential biomarker for characterizing disease progression."
    },
    "2407.14020v1": {
      "title": "NeuroBind: Towards Unified Multimodal Representations for Neural Signals",
      "url": "http://arxiv.org/abs/2407.14020v1",
      "authors": "Fengyu Yang, Chao Feng, Daniel Wang, Tianye Wang, Ziyao Zeng, Zhiyang Xu, Hyoungseob Park, Pengliang Ji, Hanbin Zhao, Yuanning Li, Alex Wong",
      "update_time": "2024-07-19",
      "abstract": "Understanding neural activity and information representation is crucial for advancing knowledge of brain function and cognition. Neural activity, measured through techniques like electrophysiology and neuroimaging, reflects various aspects of information processing. Recent advances in deep neural networks offer new approaches to analyzing these signals using pre-trained models. However, challenges arise due to discrepancies between different neural signal modalities and the limited scale of high-quality neural data. To address these challenges, we present NeuroBind, a general representation that unifies multiple brain signal types, including EEG, fMRI, calcium imaging, and spiking data. To achieve this, we align neural signals in these image-paired neural datasets to pre-trained vision-language embeddings. Neurobind is the first model that studies different neural modalities interconnectedly and is able to leverage high-resource modality models for various neuroscience tasks. We also showed that by combining information from different neural signal modalities, NeuroBind enhances downstream performance, demonstrating the effectiveness of the complementary strengths of different neural modalities. As a result, we can leverage multiple types of neural signals mapped to the same space to improve downstream tasks, and demonstrate the complementary strengths of different neural modalities. This approach holds significant potential for advancing neuroscience research, improving AI systems, and developing neuroprosthetics and brain-computer interfaces."
    },
    "2407.14003v1": {
      "title": "Time Series Generative Learning with Application to Brain Imaging Analysis",
      "url": "http://arxiv.org/abs/2407.14003v1",
      "authors": "Zhenghao Li, Sanyou Wu, Long Feng",
      "update_time": "2024-07-19",
      "abstract": "This paper focuses on the analysis of sequential image data, particularly brain imaging data such as MRI, fMRI, CT, with the motivation of understanding the brain aging process and neurodegenerative diseases. To achieve this goal, we investigate image generation in a time series context. Specifically, we formulate a min-max problem derived from the $f$-divergence between neighboring pairs to learn a time series generator in a nonparametric manner. The generator enables us to generate future images by transforming prior lag-k observations and a random vector from a reference distribution. With a deep neural network learned generator, we prove that the joint distribution of the generated sequence converges to the latent truth under a Markov and a conditional invariance condition. Furthermore, we extend our generation mechanism to a panel data scenario to accommodate multiple samples. The effectiveness of our mechanism is evaluated by generating real brain MRI sequences from the Alzheimer's Disease Neuroimaging Initiative. These generated image sequences can be used as data augmentation to enhance the performance of further downstream tasks, such as Alzheimer's disease detection."
    },
    "2407.13196v1": {
      "title": "Statistical thermodynamics of the human brain activity, the Hagedorn temperature and the Zipf law",
      "url": "http://arxiv.org/abs/2407.13196v1",
      "authors": "Dante R. Chialvo, Romuald A. Janik",
      "update_time": "2024-07-18",
      "abstract": "It is well established that the brain spontaneously traverses through a very large number of states. Nevertheless, despite its relevance to understanding brain function, a formal description of this phenomenon is still lacking. To this end, we introduce a machine learning based method allowing for the determination of the probabilities of all possible states at a given coarse-graining, from which all the thermodynamics can be derived. This is a challenge not unique to the brain, since similar problems are at the heart of the statistical mechanics of complex systems. This paper uncovers a linear scaling of the entropies and energies of the brain states, a behaviour first conjectured by Hagedorn to be typical at the limiting temperature in which ordinary matter disintegrates into quark matter. Equivalently, this establishes the existence of a Zipf law scaling underlying the appearance of a wide range of brain states. Based on our estimation of the density of states for large scale functional magnetic resonance imaging (fMRI) human brain recordings, we observe that the brain operates asymptotically at the Hagedorn temperature. The presented approach is not only relevant to brain function but should be applicable for a wide variety of complex systems.",
      "code_url": "https://github.com/rmldj/brain_hagedorn_paper"
    },
    "2407.10414v1": {
      "title": "Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment",
      "url": "http://arxiv.org/abs/2407.10414v1",
      "authors": "Zitong Lu, Yile Wang",
      "update_time": "2024-07-15",
      "abstract": "Deep convolutional neural networks (DCNNs) have demonstrated excellent performance in object recognition and have been found to share some similarities with brain visual processing. However, the substantial gap between DCNNs and human visual perception still exists. Functional magnetic resonance imaging (fMRI) as a widely used technique in cognitive neuroscience can record neural activation in the human visual cortex during the process of visual perception. Can we teach DCNNs human fMRI signals to achieve a more brain-like model? To answer this question, this study proposed ReAlnet-fMRI, a model based on the SOTA vision model CORnet but optimized using human fMRI data through a multi-layer encoding-based alignment framework. This framework has been shown to effectively enable the model to learn human brain representations. The fMRI-optimized ReAlnet-fMRI exhibited higher similarity to the human brain than both CORnet and the control model in within-and across-subject as well as within- and across-modality model-brain (fMRI and EEG) alignment evaluations. Additionally, we conducted an in-depth analyses to investigate how the internal representations of ReAlnet-fMRI differ from CORnet in encoding various object dimensions. These findings provide the possibility of enhancing the brain-likeness of visual models by integrating human neural data, helping to bridge the gap between computer vision and visual neuroscience."
    },
    "2407.10376v1": {
      "title": "Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder",
      "url": "http://arxiv.org/abs/2407.10376v1",
      "authors": "Yuejiao Wang, Xianmin Gong, Lingwei Meng, Xixin Wu, Helen Meng",
      "update_time": "2024-07-15",
      "abstract": "Functional magnetic resonance imaging (fMRI) is essential for developing encoding models that identify functional changes in language-related brain areas of individuals with Neurocognitive Disorders (NCD). While large language model (LLM)-based fMRI encoding has shown promise, existing studies predominantly focus on healthy, young adults, overlooking older NCD populations and cognitive level correlations. This paper explores language-related functional changes in older NCD adults using LLM-based fMRI encoding and brain scores, addressing current limitations. We analyze the correlation between brain scores and cognitive scores at both whole-brain and language-related ROI levels. Our findings reveal that higher cognitive abilities correspond to better brain scores, with correlations peaking in the middle temporal gyrus. This study highlights the potential of fMRI encoding models and brain scores for detecting early functional changes in NCD patients."
    },
    "2407.08174v1": {
      "title": "An Adaptively Weighted Averaging Method for Regional Time Series Extraction of fMRI-based Brain Decoding",
      "url": "http://arxiv.org/abs/2407.08174v1",
      "authors": "Jianfei Zhu, Baichun Wei, Jiaru Tian, Feng Jiang, Chunzhi Yi",
      "update_time": "2024-07-11",
      "abstract": "Brain decoding that classifies cognitive states using the functional fluctuations of the brain can provide insightful information for understanding the brain mechanisms of cognitive functions. Among the common procedures of decoding the brain cognitive states with functional magnetic resonance imaging (fMRI), extracting the time series of each brain region after brain parcellation traditionally averages across the voxels within a brain region. This neglects the spatial information among the voxels and the requirement of extracting information for the downstream tasks. In this study, we propose to use a fully connected neural network that is jointly trained with the brain decoder to perform an adaptively weighted average across the voxels within each brain region. We perform extensive evaluations by cognitive state decoding, manifold learning, and interpretability analysis on the Human Connectome Project (HCP) dataset. The performance comparison of the cognitive state decoding presents an accuracy increase of up to 5\\% and stable accuracy improvement under different time window sizes, resampling sizes, and training data sizes. The results of manifold learning show that our method presents a considerable separability among cognitive states and basically excludes subject-specific information. The interpretability analysis shows that our method can identify reasonable brain regions corresponding to each cognitive state. Our study would aid the improvement of the basic pipeline of fMRI processing."
    },
    "2407.07076v1": {
      "title": "MADE-for-ASD: A Multi-Atlas Deep Ensemble Network for Diagnosing Autism Spectrum Disorder",
      "url": "http://arxiv.org/abs/2407.07076v1",
      "authors": "Md Rakibul Hasan, Xuehan Liu, Tom Gedeon, Md Zakir Hossain",
      "update_time": "2024-07-09",
      "abstract": "In response to the global need for efficient early diagnosis of Autism Spectrum Disorder (ASD), this paper bridges the gap between traditional, time-consuming diagnostic methods and potential automated solutions. We propose a multi-atlas deep ensemble network, MADE-for-ASD, that integrates multiple atlases of the brain's functional magnetic resonance imaging (fMRI) data through a weighted deep ensemble network. Our approach integrates demographic information into the prediction workflow, which enhances ASD diagnosis performance and offers a more holistic perspective on patient profiling. We experiment with the well-known publicly available ABIDE (Autism Brain Imaging Data Exchange) I dataset, consisting of resting state fMRI data from 17 different laboratories around the globe. Our proposed system achieves 75.20% accuracy on the entire dataset and 96.40% on a specific subset $-$ both surpassing reported ASD diagnosis accuracy in ABIDE I fMRI studies. Specifically, our model improves by 4.4 percentage points over prior works on the same amount of data. The model exhibits a sensitivity of 82.90% and a specificity of 69.70% on the entire dataset, and 91.00% and 99.50%, respectively, on the specific subset. We leverage the F-score to pinpoint the top 10 ROI in ASD diagnosis, such as \\emph{precuneus} and anterior \\emph{cingulate/ventromedial}. The proposed system can potentially pave the way for more cost-effective, efficient and scalable strategies in ASD diagnosis. Codes and evaluations are publicly available at TBA."
    },
    "2407.06928v1": {
      "title": "Shifts in Brain Dynamics and Drivers of Consciousness State Transitions",
      "url": "http://arxiv.org/abs/2407.06928v1",
      "authors": "Joseph Bodenheimer, Paul Bogdan, S\u00e9rgio Pequito, Arian Ashourvan",
      "update_time": "2024-07-09",
      "abstract": "Understanding the neural mechanisms underlying the transitions between different states of consciousness is a fundamental challenge in neuroscience. Thus, we investigate the underlying drivers of changes during the resting-state dynamics of the human brain, as captured by functional magnetic resonance imaging (fMRI) across varying levels of consciousness (awake, light sedation, deep sedation, and recovery). We deploy a model-based approach relying on linear time-invariant (LTI) dynamical systems under unknown inputs (UI). Our findings reveal distinct changes in the spectral profile of brain dynamics - particularly regarding the stability and frequency of the system's oscillatory modes during transitions between consciousness states. These models further enable us to identify external drivers influencing large-scale brain activity during naturalistic auditory stimulation. Our findings suggest that these identified inputs delineate how stimulus-induced co-activity propagation differs across consciousness states. Notably, our approach showcases the effectiveness of LTI models under UI in capturing large-scale brain dynamic changes and drivers in complex paradigms, such as naturalistic stimulation, which are not conducive to conventional general linear model analysis. Importantly, our findings shed light on how brain-wide dynamics and drivers evolve as the brain transitions towards conscious states, holding promise for developing more accurate biomarkers of consciousness recovery in disorders of consciousness.",
      "code_url": "https://github.com/aashourv/LTI_Group"
    }
  },
  "MEG": {
    "2407.16784v1": {
      "title": "A Sub-solar Fe/O, logT~7.5 Gas Component Permeating the Milky Way's CGM",
      "url": "http://arxiv.org/abs/2407.16784v1",
      "authors": "Armando Lara-DI, Yair Krongold, Smita Mathur, Sanskriti Das, Anjali Gupta, O. Segura Montero",
      "update_time": "2024-07-23",
      "abstract": "Our study focuses on characterizing the highly ionized gas within the Milky Way's (MW) Circumgalactic Medium (CGM) that gives rise to ionic transitions in the X-ray band 2 - 25 \\AA. Utilizing stacked \\Chandra/\\ACISS\\ \\MEG\\ and \\LETG\\ spectra toward QSO sightlines, we employ the self-consistent hybrid ionization code PHASE to model our data. The stacked spectra are optimally described by three distinct gas phase components: a \\warm\\ (\\logT\\ $\\sim$ 5.5), \\warmhot\\ (\\logT\\ $\\sim 6$), and \\hot\\ (\\logT\\ $\\sim$ 7.5) components. These findings confirm the presence of the \\hot\\ component in the MW's CGM indicating its coexistence with a \\warm\\ and a \\warmhot\\ gas phases. We find this \\hot\\ component to be homogeneous in temperature but inhomogeneous in column density. The gas in the \\hot\\ component requires over-abundances relative to solar to be consistent with the Dispersion Measure (DM) from the Galactic halo reported in the literature. {For the hot phase we estimated a DM = $55.1^{+29.9}_{-23.7}$ pc cm$^{-3}$}. We conclude that this phase is either enriched in Oxygen, Silicon, and Sulfur, or has metallicity {over 6} times solar value, or a combination of both. We do not detect Fe L-shell absorption lines, implying O/Fe $\\geq$ 4. The non-solar abundance ratios found in the super-virial gas component in the Galactic halo suggest that this phase arises from Galactic feedback."
    },
    "2407.13733v1": {
      "title": "Revisiting Neutrino Masses In Clockwork Models",
      "url": "http://arxiv.org/abs/2407.13733v1",
      "authors": "Aadarsh Singh",
      "update_time": "2024-07-18",
      "abstract": "In this paper, we have looked at various variants of the clockwork model and studied their impact on the neutrino masses. Some of the generalizations such as generalized CW and next-to-nearest neighbour interaction CW have already been explored by a few authors. In this study, we studied non-local CW for the fermionic case and found that non-local models relax the $\\left| q \\right| > 1$ constraint to produce localization of the zero mode. We also made a comparison among them and have shown that for some parameter ranges, non-local variants of CW are more efficient than ordinary CW in generating the hierarchy required for the $\\nu$ mass scale. Finally, phenomenological constraints from $BR(\\mu \\rightarrow e \\gamma )$ FCNC process and Higgs decay width have been imposed on the parameter space in non-local and both-sided clockwork models. We have listed benchmark points which are surviving current experimental bounds from MEG and are within the reach of the upcoming MEG-II experiment."
    },
    "2407.07245v1": {
      "title": "Accelerating Mobile Edge Generation (MEG) by Constrained Learning",
      "url": "http://arxiv.org/abs/2407.07245v1",
      "authors": "Xiaoxia Xu, Yuanwei Liu, Xidong Mu, Hong Xing, Arumugam Nallanathan",
      "update_time": "2024-07-09",
      "abstract": "A novel accelerated mobile edge generation (MEG) framework is proposed for generating high-resolution images on mobile devices. Exploiting a large-scale latent diffusion model (LDM) distributed across edge server (ES) and user equipment (UE), cost-efficient artificial intelligence generated content (AIGC) is achieved by transmitting low-dimensional features between ES and UE. To reduce overheads of both distributed computations and transmissions, a dynamic diffusion and feature merging scheme is conceived. By jointly optimizing the denoising steps and feature merging ratio, the image generation quality is maximized subject to latency and energy consumption constraints. To address this problem and tailor LDM sub-models, a low-complexity MEG acceleration protocol is developed. Particularly, a backbone meta-architecture is trained via offline distillation. Then, dynamic diffusion and feature merging are determined in online channel environment, which can be viewed as a constrained Markov Decision Process (MDP). A constrained variational policy optimization (CVPO) based MEG algorithm is further proposed for constraint-guaranteed learning, namely MEG-CVPO. Numerical results verify that: 1) The proposed framework can generate 1024$\\times$1024 high-quality images over noisy channels while reducing over $40\\%$ latency compared to conventional generation schemes. 2) The developed MEG-CVPO effectively mitigates constraint violations, thus flexibly controlling the trade-off between image distortion and generation costs."
    },
    "2407.05060v2": {
      "title": "Volume-optimal persistence homological scaffolds of hemodynamic networks covary with MEG theta-alpha aperiodic dynamics",
      "url": "http://arxiv.org/abs/2407.05060v2",
      "authors": "Nghi Nguyen, Tao Hou, Enrico Amico, Jingyi Zheng, Huajun Huang, Alan D. Kaplan, Giovanni Petri, Joaqu\u00edn Go\u00f1i, Ralph Kaufmann, Yize Zhao, Duy Duong-Tran, Li Shen",
      "update_time": "2024-07-23",
      "abstract": "Higher-order properties of functional magnetic resonance imaging (fMRI) induced connectivity have been shown to unravel many exclusive topological and dynamical insights beyond pairwise interactions. Nonetheless, whether these fMRI-induced higher-order properties play a role in disentangling other neuroimaging modalities' insights remains largely unexplored and poorly understood. In this work, by analyzing fMRI data from the Human Connectome Project Young Adult dataset using persistent homology, we discovered that the volume-optimal persistence homological scaffolds of fMRI-based functional connectomes exhibited conservative topological reconfigurations from the resting state to attentional task-positive state. Specifically, while reflecting the extent to which each cortical region contributed to functional cycles following different cognitive demands, these reconfigurations were constrained such that the spatial distribution of cavities in the connectome is relatively conserved. Most importantly, such level of contributions covaried with powers of aperiodic activities mostly within the theta-alpha (4-12 Hz) band measured by magnetoencephalography (MEG). This comprehensive result suggests that fMRI-induced hemodynamics and MEG theta-alpha aperiodic activities are governed by the same functional constraints specific to each cortical morpho-structure. Methodologically, our work paves the way toward an innovative computing paradigm in multimodal neuroimaging topological learning.",
      "code_url": "https://github.com/ngcaonghi/scaffold_noise"
    },
    "2407.02804v1": {
      "title": "Mobile Edge Generation-Enabled Digital Twin: Architecture Design and Research Opportunities",
      "url": "http://arxiv.org/abs/2407.02804v1",
      "authors": "Xiaoxia Xu, Ruikang Zhong, Xidong Mu, Yuanwei Liu, Kaibin Huang",
      "update_time": "2024-07-03",
      "abstract": "A novel paradigm of mobile edge generation (MEG)-enabled digital twin (DT) is proposed, which enables distributed on-device generation at mobile edge networks for real-time DT applications. First, an MEG-DT architecture is put forward to decentralize generative artificial intelligence (GAI) models onto edge servers (ESs) and user equipments (UEs), which has the advantages of low latency, privacy preservation, and individual-level customization. Then, various single-user and multi-user generation mechanisms are conceived for MEG-DT, which strike trade-offs between generation latency, hardware costs, and device coordination. Furthermore, to perform efficient distributed generation, two operating protocols are explored for transmitting interpretable and latent features between ESs and UEs, namely sketch-based generation and seed-based generation, respectively. Based on the proposed protocols, the convergence between MEG and DT are highlighted. Considering the seed-based image generation scenario, numerical case studies are provided to reveal the superiority of MEG-DT over centralized generation. Finally, promising applications and research opportunities are identified."
    },
    "2406.07151v1": {
      "title": "EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels",
      "url": "http://arxiv.org/abs/2406.07151v1",
      "authors": "Shuqi Zhu, Ziyi Ye, Qingyao Ai, Yiqun Liu",
      "update_time": "2024-06-11",
      "abstract": "Identifying and reconstructing what we see from brain activity gives us a special insight into investigating how the biological visual system represents the world. While recent efforts have achieved high-performance image classification and high-quality image reconstruction from brain signals collected by Functional Magnetic Resonance Imaging (fMRI) or magnetoencephalogram (MEG), the expensiveness and bulkiness of these devices make relevant applications difficult to generalize to practical applications. On the other hand, Electroencephalography (EEG), despite its advantages of ease of use, cost-efficiency, high temporal resolution, and non-invasive nature, has not been fully explored in relevant studies due to the lack of comprehensive datasets. To address this gap, we introduce EEG-ImageNet, a novel EEG dataset comprising recordings from 16 subjects exposed to 4000 images selected from the ImageNet dataset. EEG-ImageNet consists of 5 times EEG-image pairs larger than existing similar EEG benchmarks. EEG-ImageNet is collected with image stimuli of multi-granularity labels, i.e., 40 images with coarse-grained labels and 40 with fine-grained labels. Based on it, we establish benchmarks for object classification and image reconstruction. Experiments with several commonly used models show that the best models can achieve object classification with accuracy around 60% and image reconstruction with two-way identification around 64%. These results demonstrate the dataset's potential to advance EEG-based visual brain-computer interfaces, understand the visual perception of biological systems, and provide potential applications in improving machine visual models.",
      "code_url": "https://github.com/promise-z5q2sq/eeg-imagenet-dataset"
    },
    "2406.01512v1": {
      "title": "MAD: Multi-Alignment MEG-to-Text Decoding",
      "url": "http://arxiv.org/abs/2406.01512v1",
      "authors": "Yiqian Yang, Hyejeong Jo, Yiqun Duan, Qiang Zhang, Jinni Zhou, Won Hee Lee, Renjing Xu, Hui Xiong",
      "update_time": "2024-06-03",
      "abstract": "Deciphering language from brain activity is a crucial task in brain-computer interface (BCI) research. Non-invasive cerebral signaling techniques including electroencephalography (EEG) and magnetoencephalography (MEG) are becoming increasingly popular due to their safety and practicality, avoiding invasive electrode implantation. However, current works under-investigated three points: 1) a predominant focus on EEG with limited exploration of MEG, which provides superior signal quality; 2) poor performance on unseen text, indicating the need for models that can better generalize to diverse linguistic contexts; 3) insufficient integration of information from other modalities, which could potentially constrain our capacity to comprehensively understand the intricate dynamics of brain activity.   This study presents a novel approach for translating MEG signals into text using a speech-decoding framework with multiple alignments. Our method is the first to introduce an end-to-end multi-alignment framework for totally unseen text generation directly from MEG signals. We achieve an impressive BLEU-1 score on the $\\textit{GWilliams}$ dataset, significantly outperforming the baseline from 5.49 to 10.44 on the BLEU-1 metric. This improvement demonstrates the advancement of our model towards real-world applications and underscores its potential in advancing BCI research. Code is available at $\\href{https://github.com/NeuSpeech/MAD-MEG2text}{https://github.com/NeuSpeech/MAD-MEG2text}$.",
      "code_url": "https://github.com/neuspeech/mad-meg2text"
    },
    "2406.16902v1": {
      "title": "Learning Exemplar Representations in Single-Trial EEG Category Decoding",
      "url": "http://arxiv.org/abs/2406.16902v1",
      "authors": "Jack Kilgallen, Barak Pearlmutter, Jeffery Mark Siskind",
      "update_time": "2024-05-31",
      "abstract": "Within neuroimgaing studies it is a common practice to perform repetitions of trials in an experiment when working with a noisy class of data acquisition system, such as electroencephalography (EEG) or magnetoencephalography (MEG). While this approach can be useful in some experimental designs, it presents significant limitations for certain types of analyses, such as identifying the category of an object observed by a subject. In this study we demonstrate that when trials relating to a single object are allowed to appear in both the training and testing sets, almost any classification algorithm is capable of learning the representation of an object given only category labels. This ability to learn object representations is of particular significance as it suggests that the results of several published studies which predict the category of observed objects from EEG signals may be affected by a subtle form of leakage which has inflated their reported accuracies. We demonstrate the ability of both simple classification algorithms, and sophisticated deep learning models, to learn object representations given only category labels. We do this using two datasets; the Kaneshiro et al. (2015) dataset and the Gifford et al. (2022) dataset. Our results raise doubts about the true generalizability of several published models and suggests that the reported performance of these models may be significantly inflated."
    },
    "2405.19479v1": {
      "title": "Participation in the age of foundation models",
      "url": "http://arxiv.org/abs/2405.19479v1",
      "authors": "Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy",
      "update_time": "2024-05-29",
      "abstract": "Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of public services. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to marginalized communities. Participatory approaches hold promise to instead lend agency and decision-making power to marginalized stakeholders. But existing approaches in participatory AI/ML are typically deeply grounded in context - how do we apply these approaches to foundation models, which are, by design, disconnected from context? Our paper interrogates this question.   First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the \"foundation\" layer, our framework proposes the \"subfloor'' layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain, and the \"surface'' layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate \"subfloor'' layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer."
    },
    "2405.17698v3": {
      "title": "BaboonLand Dataset: Tracking Primates in the Wild and Automating Behaviour Recognition from Drone Videos",
      "url": "http://arxiv.org/abs/2405.17698v3",
      "authors": "Isla Duporge, Maksim Kholiavchenko, Roi Harel, Scott Wolf, Dan Rubenstein, Meg Crofoot, Tanya Berger-Wolf, Stephen Lee, Julie Barreau, Jenna Kline, Michelle Ramirez, Charles Stewart",
      "update_time": "2024-06-03",
      "abstract": "Using drones to track multiple individuals simultaneously in their natural environment is a powerful approach for better understanding group primate behavior. Previous studies have demonstrated that it is possible to automate the classification of primate behavior from video data, but these studies have been carried out in captivity or from ground-based cameras. To understand group behavior and the self-organization of a collective, the whole troop needs to be seen at a scale where behavior can be seen in relation to the natural environment in which ecological decisions are made. This study presents a novel dataset from drone videos for baboon detection, tracking, and behavior recognition. The baboon detection dataset was created by manually annotating all baboons in drone videos with bounding boxes. A tiling method was subsequently applied to create a pyramid of images at various scales from the original 5.3K resolution images, resulting in approximately 30K images used for baboon detection. The tracking dataset is derived from the detection dataset, where all bounding boxes are assigned the same ID throughout the video. This process resulted in half an hour of very dense tracking data. The behavior recognition dataset was generated by converting tracks into mini-scenes, a video subregion centered on each animal; each mini-scene was manually annotated with 12 distinct behavior types, resulting in over 20 hours of data. Benchmark results show mean average precision (mAP) of 92.62\\% for the YOLOv8-X detection model, multiple object tracking precision (MOTA) of 63.81\\% for the BotSort tracking algorithm, and micro top-1 accuracy of 63.97\\% for the X3D behavior recognition model. Using deep learning to classify wildlife behavior from drone footage facilitates non-invasive insight into the collective behavior of an entire group."
    }
  },
  "neuroAI": {
    "2407.04117v2": {
      "title": "Predictive Coding Networks and Inference Learning: Tutorial and Survey",
      "url": "http://arxiv.org/abs/2407.04117v2",
      "authors": "Bj\u00f6rn van Zwol, Ro Jefferson, Egon L. van den Broek",
      "update_time": "2024-07-22",
      "abstract": "Recent years have witnessed a growing call for renewed emphasis on neuroscience-inspired approaches in artificial intelligence research, under the banner of NeuroAI. A prime example of this is predictive coding networks (PCNs), based on the neuroscientific framework of predictive coding. This framework views the brain as a hierarchical Bayesian inference model that minimizes prediction errors through feedback connections. Unlike traditional neural networks trained with backpropagation (BP), PCNs utilize inference learning (IL), a more biologically plausible algorithm that explains patterns of neural activity that BP cannot. Historically, IL has been more computationally intensive, but recent advancements have demonstrated that it can achieve higher efficiency than BP with sufficient parallelization. Furthermore, PCNs can be mathematically considered a superset of traditional feedforward neural networks (FNNs), significantly extending the range of trainable architectures. As inherently probabilistic (graphical) latent variable models, PCNs provide a versatile framework for both supervised learning and unsupervised (generative) modeling that goes beyond traditional artificial neural networks. This work provides a comprehensive review and detailed formal specification of PCNs, particularly situating them within the context of modern ML methods. Additionally, we introduce a Python library (PRECO) for practical implementation. This positions PC as a promising framework for future ML innovations."
    },
    "2306.10168v3": {
      "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
      "url": "http://arxiv.org/abs/2306.10168v3",
      "authors": "Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete",
      "update_time": "2023-10-29",
      "abstract": "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
      "code_url": "https://github.com/mitchellostrow/dsa"
    },
    "2305.11275v2": {
      "title": "Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture",
      "url": "http://arxiv.org/abs/2305.11275v2",
      "authors": "Galen Pogoncheff, Jacob Granley, Michael Beyeler",
      "update_time": "2023-05-25",
      "abstract": "Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield state-of-the-art explanation of V1 neural activity and tuning properties. Our results highlight an important advancement in the field of NeuroAI, as we systematically establish a set of architectural components that contribute to unprecedented explanation of V1. The neuroscience insights that could be gleaned from increasingly accurate in-silico models of the brain have the potential to greatly advance the fields of both neuroscience and artificial intelligence."
    },
    "2301.09245v2": {
      "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks",
      "url": "http://arxiv.org/abs/2301.09245v2",
      "authors": "Feng-Lei Fan, Yingxin Li, Hanchuan Peng, Tieyong Zeng, Fei Wang",
      "update_time": "2023-03-11",
      "abstract": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI."
    },
    "2212.04401v1": {
      "title": "A Rubric for Human-like Agents and NeuroAI",
      "url": "http://arxiv.org/abs/2212.04401v1",
      "authors": "Ida Momennejad",
      "update_time": "2022-12-08",
      "abstract": "Researchers across cognitive, neuro-, and computer sciences increasingly reference human-like artificial intelligence and neuroAI. However, the scope and use of the terms are often inconsistent. Contributed research ranges widely from mimicking behaviour, to testing machine learning methods as neurally plausible hypotheses at the cellular or functional levels, or solving engineering problems. However, it cannot be assumed nor expected that progress on one of these three goals will automatically translate to progress in others. Here a simple rubric is proposed to clarify the scope of individual contributions, grounded in their commitments to human-like behaviour, neural plausibility, or benchmark/engineering goals. This is clarified using examples of weak and strong neuroAI and human-like agents, and discussing the generative, corroborate, and corrective ways in which the three dimensions interact with one another. The author maintains that future progress in artificial intelligence will need strong interactions across the disciplines, with iterative feedback loops and meticulous validity tests, leading to both known and yet-unknown advances that may span decades to come."
    },
    "2210.08340v3": {
      "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
      "url": "http://arxiv.org/abs/2210.08340v3",
      "authors": "Anthony Zador, Sean Escola, Blake Richards, Bence \u00d6lveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S. Tolias, Doris Tsao",
      "update_time": "2023-02-22",
      "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
    },
    "2112.15459v3": {
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "authors": "Samuele Bolotta, Guillaume Dumas",
      "update_time": "2022-04-11",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied."
    },
    "2011.07464v2": {
      "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
      "url": "http://arxiv.org/abs/2011.07464v2",
      "authors": "Joseph Marino",
      "update_time": "2021-10-23",
      "abstract": "This paper reviews predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (non-linear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field."
    },
    "1909.02603v2": {
      "title": "Additive function approximation in the brain",
      "url": "http://arxiv.org/abs/1909.02603v2",
      "authors": "Kameron Decker Harris",
      "update_time": "2019-09-13",
      "abstract": "Many biological learning systems such as the mushroom body, hippocampus, and cerebellum are built from sparsely connected networks of neurons. For a new understanding of such networks, we study the function spaces induced by sparse random features and characterize what functions may and may not be learned. A network with $d$ inputs per neuron is found to be equivalent to an additive model of order $d$, whereas with a degree distribution the network combines additive terms of different orders. We identify three specific advantages of sparsity: additive function approximation is a powerful inductive bias that limits the curse of dimensionality, sparse networks are stable to outlier noise in the inputs, and sparse random features are scalable. Thus, even simple brain architectures can be powerful function approximators. Finally, we hope that this work helps popularize kernel theories of networks among computational neuroscientists.",
      "code_url": "https://github.com/kharris/sparse-random-features"
    }
  },
  "medical": {
    "2407.17259v1": {
      "title": "Spatial Conceptual Modeling: Anchoring Knowledge in the Real World",
      "url": "http://arxiv.org/abs/2407.17259v1",
      "authors": "Hans-Georg Fill",
      "update_time": "2024-07-24",
      "abstract": "This paper introduces the concept of spatial conceptual modeling, which allows anchoring mental world knowledge in the physical world using augmented reality technologies. For a first formal characterization, we describe a mapping from the spatial information concepts location, field, object, network, and event, as used in spatial computing, to conceptual modeling concepts using the FDMM formalism. This allows to identify necessary adaptations at the metamodeling level to make the approach applicable to arbitrary types of spatial conceptual modeling languages. Finally, possible application areas of spatial conceptual modeling in the medical domain, manufacturing and engineering, physical IT architectures and smart homes, supply chain management and logistics, civil engineering, and smart cities and cultural heritage are discussed."
    },
    "2407.17225v1": {
      "title": "Asymmetry Analysis of Bilateral Shapes",
      "url": "http://arxiv.org/abs/2407.17225v1",
      "authors": "Kanti V. Mardia, Xiangyu Wu, John T. Kent, Colin R. Goodall, Balvinder S. Khambay",
      "update_time": "2024-07-24",
      "abstract": "Many biological objects possess bilateral symmetry about a midline or midplane, up to a ``noise'' term. This paper uses landmark-based methods to measure departures from bilateral symmetry, especially for the two-group problem where one group is more asymmetric than the other. In this paper, we formulate our work in the framework of size-and-shape analysis including registration via rigid body motion. Our starting point is a vector of elementary asymmetry features defined at the individual landmark coordinates for each object. We introduce two approaches for testing. In the first, the elementary features are combined into a scalar composite asymmetry measure for each object. Then standard univariate tests can be used to compare the two groups. In the second approach, a univariate test statistic is constructed for each elementary feature. The maximum of these statistics lead to an overall test statistic to compare the two groups and we then provide a technique to extract the important features from the landmark data. Our methodology is illustrated on a pre-registered smile dataset collected to assess the success of cleft lip surgery on human subjects. The asymmetry in a group of cleft lip subjects is compared to a group of normal subjects, and statistically significant differences have been found by univariate tests in the first approach. Further, our feature extraction method leads to an anatomically plausible set of landmarks for medical applications."
    },
    "2407.17219v1": {
      "title": "Graph Neural Networks: A suitable Alternative to MLPs in Latent 3D Medical Image Classification?",
      "url": "http://arxiv.org/abs/2407.17219v1",
      "authors": "Johannes Kiechle, Daniel M. Lang, Stefan M. Fischer, Lina Felsner, Jan C. Peeken, Julia A. Schnabel",
      "update_time": "2024-07-24",
      "abstract": "Recent studies have underscored the capabilities of natural imaging foundation models to serve as powerful feature extractors, even in a zero-shot setting for medical imaging data. Most commonly, a shallow multi-layer perceptron (MLP) is appended to the feature extractor to facilitate end-to-end learning and downstream prediction tasks such as classification, thus representing the de facto standard. However, as graph neural networks (GNNs) have become a practicable choice for various tasks in medical research in the recent past, we direct attention to the question of how effective GNNs are compared to MLP prediction heads for the task of 3D medical image classification, proposing them as a potential alternative. In our experiments, we devise a subject-level graph for each volumetric dataset instance. Therein latent representations of all slices in the volume, encoded through a DINOv2 pretrained vision transformer (ViT), constitute the nodes and their respective node features. We use public datasets to compare the classification heads numerically and evaluate various graph construction and graph convolution methods in our experiments. Our findings show enhancements of the GNN in classification performance and substantial improvements in runtime compared to an MLP prediction head. Additional robustness evaluations further validate the promising performance of the GNN, promoting them as a suitable alternative to traditional MLP classification heads. Our code is publicly available at: https://github.com/compai-lab/2024-miccai-grail-kiechle",
      "code_url": "https://github.com/compai-lab/2024-miccai-grail-kiechle"
    },
    "2407.17182v1": {
      "title": "Solving the Electrical Impedance Tomography Problem with a DeepONet Type Neural Network: Theory and Application",
      "url": "http://arxiv.org/abs/2407.17182v1",
      "authors": "Anuj Abhishek, Thilo Strauss",
      "update_time": "2024-07-24",
      "abstract": "In this work, we consider the non-invasive medical imaging modality of Electrical Impedance Tomography, where the problem is to recover the conductivity in a medium from a set of data that arises out of a current-to-voltage map (Neumann-to-Dirichlet operator) defined on the boundary of the medium. We formulate this inverse problem as an operator-learning problem where the goal is to learn the implicitly defined operator-to-function map between the space of Neumann-to-Dirichlet operators to the space of admissible conductivities. Subsequently, we use an operator-learning architecture, popularly called DeepONets, to learn this operator-to-function map. Thus far, most of the operator learning architectures have been implemented to learn operators between function spaces. In this work, we generalize the earlier works and use a DeepONet to actually {learn an operator-to-function} map. We provide a Universal Approximation Theorem type result which guarantees that this implicitly defined operator-to-function map between the space of Neumann-to-Dirichlet operator to the space of conductivity function can be approximated to an arbitrary degree using such a DeepONet. Furthermore, we provide a computational implementation of our proposed approach and compare it against a standard baseline. We show that the proposed approach achieves good reconstructions and outperforms the baseline method in our experiments."
    },
    "2407.17181v1": {
      "title": "Trans2Unet: Neural fusion for Nuclei Semantic Segmentation",
      "url": "http://arxiv.org/abs/2407.17181v1",
      "authors": "Dinh-Phu Tran, Quoc-Anh Nguyen, Van-Truong Pham, Thi-Thao Tran",
      "update_time": "2024-07-24",
      "abstract": "Nuclei segmentation, despite its fundamental role in histopathological image analysis, is still a challenge work. The main challenge of this task is the existence of overlapping areas, which makes separating independent nuclei more complicated. In this paper, we propose a new two-branch architecture by combining the Unet and TransUnet networks for nuclei segmentation task. In the proposed architecture, namely Trans2Unet, the input image is first sent into the Unet branch whose the last convolution layer is removed. This branch makes the network combine features from different spatial regions of the input image and localizes more precisely the regions of interest. The input image is also fed into the second branch. In the second branch, which is called TransUnet branch, the input image will be divided into patches of images. With Vision transformer (ViT) in architecture, TransUnet can serve as a powerful encoder for medical image segmentation tasks and enhance image details by recovering localized spatial information. To boost up Trans2Unet efficiency and performance, we proposed to infuse TransUnet with a computational-efficient variation called \"Waterfall\" Atrous Spatial Pooling with Skip Connection (WASP-KC) module, which is inspired by the \"Waterfall\" Atrous Spatial Pooling (WASP) module. Experiment results on the 2018 Data Science Bowl benchmark show the effectiveness and performance of the proposed architecture while compared with previous segmentation models."
    },
    "2407.17164v1": {
      "title": "Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence",
      "url": "http://arxiv.org/abs/2407.17164v1",
      "authors": "Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu",
      "update_time": "2024-07-24",
      "abstract": "Integrating deep neural networks with the Hawkes process has significantly improved predictive capabilities in finance, health informatics, and information technology. Nevertheless, these models often face challenges in real-world settings, particularly due to substantial label noise. This issue is of significant concern in the medical field, where label noise can arise from delayed updates in electronic medical records or misdiagnoses, leading to increased prediction risks. Our research indicates that deep Hawkes process models exhibit reduced robustness when dealing with label noise, particularly when it affects both event types and timing. To address these challenges, we first investigate the influence of label noise in approximated intensity functions and present a novel framework, the Robust Deep Hawkes Process (RDHP), to overcome the impact of label noise on the intensity function of Hawkes models, considering both the events and their occurrences. We tested RDHP using multiple open-source benchmarks with synthetic noise and conducted a case study on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting with inherent label noise. The results demonstrate that RDHP can effectively perform classification and regression tasks, even in the presence of noise related to events and their timing. To the best of our knowledge, this is the first study to successfully address both event and time label noise in deep Hawkes process models, offering a promising solution for medical applications, specifically in diagnosing OSAHS."
    },
    "2407.17146v2": {
      "title": "Quantifying variabilities in cardiac digital twin models of the electrocardiogram",
      "url": "http://arxiv.org/abs/2407.17146v2",
      "authors": "Elena Zappon, Matthias A. F. Gsell, Karli Gillette, Gernot Plank",
      "update_time": "2024-07-25",
      "abstract": "Cardiac digital twins (CDTs) of human cardiac electrophysiology (EP) are digital replicas of patient hearts that match like-for-like clinical observations. The electrocardiogram (ECG), as the most prevalent non-invasive observation of cardiac electrophysiology, is considered an ideal target for CDT calibration. Recent advanced CDT calibration methods have demonstrated their ability to minimize discrepancies between simulated and measured ECG signals, effectively replicating all key morphological features relevant to diagnostics. However, due to the inherent nature of clinical data acquisition and CDT model generation pipelines, discrepancies inevitably arise between the real physical electrophysiology in a patient and the simulated virtual electrophysiology in a CDT. In this study, we aim to qualitatively and quantitatively analyze the impact of these uncertainties on ECG morphology and diagnostic markers. We analyze residual beat-to-beat variability in ECG recordings obtained from healthy subjects and patients. Using a biophysically detailed and anatomically accurate computational model of whole-heart electrophysiology combined with a detailed torso model calibrated to closely replicate measured ECG signals, we vary anatomical factors (heart location, orientation, size), heterogeneity in electrical conductivities in the heart and torso, and electrode placements across ECG leads to assess their qualitative impact on ECG morphology. Our study demonstrates that diagnostically relevant ECG features and overall morphology appear relatively robust against the investigated uncertainties. This resilience is consistent with the narrow distribution of ECG due to residual beat-to-beat variability observed in both healthy subjects and patients."
    },
    "2407.17126v1": {
      "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
      "url": "http://arxiv.org/abs/2407.17126v1",
      "authors": "Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding",
      "update_time": "2024-07-24",
      "abstract": "Extracting social determinants of health (SDoH) from unstructured medical notes depends heavily on labor-intensive annotations, which are typically task-specific, hampering reusability and limiting sharing. In this study we introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM) method leveraging contrastive examples and concise instructions to extract SDoH without relying on extensive medical annotations or costly human intervention. It achieved tenfold and twentyfold reductions in time and cost respectively, and superior consistency with human annotators measured by Cohen's kappa of up to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the strengths of both, ensuring high accuracy and computational efficiency while consistently maintaining 0.90+ AUROC scores. Testing across three distinct datasets has confirmed its robustness and accuracy. This study highlights the potential of leveraging LLMs to revolutionize medical note classification, demonstrating their capability to achieve highly accurate classifications with significantly reduced time and cost."
    },
    "2407.16999v1": {
      "title": "SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing",
      "url": "http://arxiv.org/abs/2407.16999v1",
      "authors": "Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang",
      "update_time": "2024-07-24",
      "abstract": "Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",
      "code_url": "https://github.com/yinchangchang/sepsislab"
    },
    "2407.16953v1": {
      "title": "Open Challenges on Fairness of Artificial Intelligence in Medical Imaging Applications",
      "url": "http://arxiv.org/abs/2407.16953v1",
      "authors": "Enzo Ferrante, Rodrigo Echeveste",
      "update_time": "2024-07-24",
      "abstract": "Recently, the research community of computerized medical imaging has started to discuss and address potential fairness issues that may emerge when developing and deploying AI systems for medical image analysis. This chapter covers some of the pressing challenges encountered when doing research in this area, and it is intended to raise questions and provide food for thought for those aiming to enter this research field. The chapter first discusses various sources of bias, including data collection, model training, and clinical deployment, and their impact on the fairness of machine learning algorithms in medical image computing. We then turn to discussing open challenges that we believe require attention from researchers and practitioners, as well as potential pitfalls of naive application of common methods in the field. We cover a variety of topics including the impact of biased metrics when auditing for fairness, the leveling down effect, task difficulty variations among subgroups, discovering biases in unseen populations, and explaining biases beyond standard demographic attributes."
    }
  }
}